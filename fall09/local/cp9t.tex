\input{latex-macros/handout-preamble.tex}
\inhandout{
\inclassproblems{9, Tue.}
\usesimpleproblems
}

%F03 ps6
\begin{problem}
\bparts

\ppart Give an elementary proof (without appealing to Stirling's formula)
that $\log (n!) = \Theta(n\log n)$.

\solution{
An elementary proof goes as follows:

First,
\begin{align*}
\log (n!) &= \sum_{i=1}^n \log i\\
&< \sum_{i=1}^n \log n\\
&=n\log n. 
\end{align*}

On the other hand, 
\begin{align*}
\log (n!) &= \sum_{i=1}^n \log i\\
 & > \sum_{i=\ceil{(n+1)/2}}^n \log i\\
    & > \sum_{i=\ceil{(n+1)/2}}^n \log (n/2)\\
    & > \frac{n}{2} \cdot \log (n/2)\\
    & = \frac{n ((\log n) -1)}{2}\\
    & = \frac{n \log n}{2} - \frac{n}{2}\\
    & > \frac{n \log n}{2} -\frac{n \log n}{6} & \text{for $n>8$.}\\
    & = \frac{1}{3} \cdot n \log n.
\end{align*}

Therefore, $(1/3)n \log n < \log(n!) <n\log n$ for $n>8$, proving that
$\log(n!)=\Theta(n\log n)$.}

\ppart Use Stirling's formula to prove that in fact
\[
\log (n!) \sim n \log n
\]
\hint $f \sim g$ for $f,g \geq 1$ implies $\log f \sim \log g$.

\solution{
  Taking logs of both sides of Stirling's formula and using the hint, we
  have
\begin{align*}
\log (n!)
& \sim n \log\paren{\frac{n}{e}} + \log \sqrt{2 \pi n}\\
& = n \log n - n \log e + \log \sqrt{2 \pi n}\\
& \sim n \log n.
\end{align*}

The final step follows from the fact that
\begin{align*}
\lim_{n \to \infty} \frac{n \log n - n \log e + \log \sqrt{2 \pi n}}{n \log n} & =
\lim_{n \to \infty} \paren{\frac{n \log n}{n \log n} - \frac{n \log e}{n \log n}
+ \frac{\log \sqrt{2 \pi n}}{n \log n}}\\
& = 1 - \lim_{n \to \infty} \frac{\log e}{\log n} + \lim_{n \to \infty}
\frac{\log \sqrt{2 \pi n}}{n \log n}\\
& = 1 - 0 - 0 = 1.
\end{align*}
}

\eparts
\end{problem}


%F02 Q2

\begin{problem}
Recall that for functions $f,g$ on the natural numbers,
$\naturals$, $f = O(g)$ iff
\begin{equation}\label{Oh}
\exists c \in \naturals\, \exists n_0 \in \naturals\,
\forall n \geq n_0\quad c \cdot g(n) \geq \abs{f(n)}.
\end{equation}

For each pair of functions below, determine whether $f = O(g)$ and whether
$g = O(f)$.  In cases where one function is O() of the other, indicate the
\emph{smallest natural number}, $c$, and for that smallest $c$, the
\emph{smallest corresponding natural number $n_0$} ensuring that
condition~\eqref{Oh} applies.

\begin{problemparts}

\problempart $f(n) = n^2, g(n) = 3n$.

$f = O(g)$ \hspace{.5in}YES \hspace{.5in}NO \hspace{.5in} 
If YES, $c =$ \brule{.5in}, $n_0$ = \brule{.5in}

\solution{NO.}

$g = O(f)$ \hspace{.5in}YES \hspace{.5in}NO \hspace{.5in} 
If YES, $c =$ \brule{.5in}, $n_0$ = \brule{.5in}

\solution{YES, with $c = 1$, $n_0 = 3$, which works
because $3^2 = 9$, $3 \cdot 3 = 9$.}

\problempart $f(n) = (3n - 7) / (n + 4), g(n) = 4$

$f = O(g)$ \hspace{.5in}YES \hspace{.5in}NO \hspace{.5in} 
If YES, $c =$ \brule{.5in}, $n_0$ = \brule{.5in}

\solution{YES, with $c = 1, n_0 = 0$  (because $\abs{f(n)}< 3$).}

$g = O(f)$ \hspace{.5in}YES \hspace{.5in}NO \hspace{.5in} 
If YES, $c =$ \brule{.5in}, $n_0$ = \brule{.5in}

\solution{YES, with $c =2, n_0 = 15.$

Since $\lim_{n \to \infty} f(n) = 3$, the smallest possible $c$ is 2.
For $c = 2$, the smallest possible $n_0 = 15$ which follows from the
requirement that $2f(n_0) \ge 4$.}

\iffalse

\problempart  (NOT USED) $f(n) = 2^{(n + 2 \sin(n))}, g(n) = 2^n$

$f = O(g)$ \hspace{.5in}YES \hspace{.5in}NO \hspace{.5in} 
If yes, $c =$ \brule{.5in} $n_0$ = \brule{.5in}

$g = O(f)$ \hspace{.5in}YES \hspace{.5in}NO \hspace{.5in} 
If yes, $c =$ \brule{.5in} $n_0$ = \brule{.5in}


\solution{
$f = O(g)$    YES

$c = 4, n_0 = 0$    (because $2 \sin (n)$ contributes at worst $-2$ to the power)

$g = O(f)$    YES

$c = 4, n_0 = 0$    (because the $2 \sin (n)$ contributes at worst $+2$ to the power)
}

\fi

\problempart $f(n) = 1 + (n \sin(n\pi/2))^2, g(n) = 3n$

$f = O(g)$ \hspace{.5in}YES \hspace{.5in}NO \hspace{.5in} 
If yes, $c =$ \brule{.5in} $n_0$ = \brule{.5in}

\solution{NO, because $f(2n)=1$, which rules out $g =
O(f)$ since $g=\Theta(n)$.}

$g = O(f)$ \hspace{.5in}YES \hspace{.5in}NO \hspace{.5in} 
If yes, $c =$ \brule{.5in} $n_0$ = \brule{.5in}

\solution{NO, because $f(2n+1) = n^2+1 \neq O(n)$ which rules out
$f = O(g)$.}

\end{problemparts}

\end{problem}

\inhandout{\instatements{\newpage}}

\begin{problem} 
\begin{falseclm*}
\begin{equation}\label{2n1}
2^n = O(1).
\end{equation}
\end{falseclm*}

Explain why the claim is false.  Then identify and explain the mistake in
the following bogus proof.

\begin{bogusproof} The proof by induction on $n$ where the induction 
hypothesis, $P(n)$, is the assertion~\eqref{2n1}.

{\bf base case:}  $P(0)$ holds trivially.

{\bf inductive step:} We may assume $P(n)$, so there is a constant $c >0$
such that $2^n \leq c \cdot 1$.  Therefore,
\[
2^{n+1} = 2 \cdot 2^n \leq (2c) \cdot 1,
\]
which implies that $2^{n+1} = O(1)$.  That is, $P(n+1)$ holds, which
completes the proof of the inductive step.

We conclude by induction that $2^n = O(1)$ for all $n$.  That is, the
exponential function is bounded by a constant.

\end{bogusproof}

\solution{A function is $O(1)$ iff it is bounded by a constant, and since
the function $2^n$ grows unboundedly with $n$, it is not $O(1)$.

The mistake in the bogus proof is in its misinterpretation of the
expression $2^n$ in assertion~\eqref{2n1}.  The intended interpration
of~\eqref{2n1} is
\begin{equation}\label{f=exp}
\text{Let $f$ be the function defined by the rule $f(n) \eqdef 2^n$.  Then
$f = O(1)$.}
\end{equation}
But the bogus proof treats~\eqref{2n1} as an assertion, $P(n)$, about $n$.
Namely, it misinterprets~\eqref{2n1} as meaning:
\begin{quote}
  Let $f_n$ be the constant function equal to $2^n$.  That is, $f_n(k)
  \eqdef 2^n$ for all $k \in \naturals$.  Then
\begin{equation}\label{fn=c}
f_n = O(1).
\end{equation}
\end{quote}
Now~\eqref{fn=c} is true since every constant function is $O(1)$, and the
bogus proof is an unnecessarily complicated, but \emph{correct}, proof that
that for each $n$, the constant function $f_n$ is $O(1)$.  But in the
last line, the bogus proof switches from the misinterpretation~\eqref{fn=c}
and claims to have proved~\eqref{f=exp}.

So you could say that the exact place where the proof goes wrong is in its
first line, where it defines $P(n)$ based on
misinterpretation~\eqref{fn=c}.  Alternatively, you could say that the
proof was a correct proof (of the misinterpretation), and its first mistake
was in its last line, when it switches from the misinterpretation to the
proper interpretation~\eqref{f=exp}.}

\end{problem}


\inhandout{\instatements{\newpage}
\section*{Asymptotic Notations}

\begin{center}Stirling's Formula\end{center}
\[
n! \sim \left(\frac{n}{e}\right)^n \sqrt{2 \pi n},
\]


\iffalse

More precisely,
\begin{fact*}[Stirling's Approximation]
\[
\sqrt{2 \pi n} \paren{\frac{n}{e}}^n e^{1/(12n+1)} \leq n! \leq
\sqrt{2 \pi n} \paren{\frac{n}{e}}^n e^{1/12n}.
\]
\end{fact*}
\fi

Let $f,g$ be functions from $\reals$ to $\reals$.

\begin{itemize}

\item $f$ is \emph{asymptotically
equal} to $g$, in symbols,
\[
f(x) \sim g(x)
\]
iff
\[
\lim_{x \rightarrow \infty} f(x)/g(x) = 1.
\]

\item $f$ is \emph{asymptotically smaller} than $g$, in symbols,
\[
f(x) = o(g(x)),
\]
iff
\[
\lim_{x \rightarrow \infty} f(x)/g(x) = 0.
\]

\item for $g$ nonnegative,
\[
f = O(g)
\]
iff\footnote{
\[
\limsup_{x \rightarrow \infty} h(x) \eqdef \lim_{x \rightarrow \infty}
\text{lub}_{y \geq x} h(y).
\]}
\[
\limsup_{x \rightarrow \infty} \abs{f(x)}/g(x) < \infty.
\]

An alternative, equivalent, definition is
\[
f = O(g)
\]
iff there exists a constant $c \geq 0$ and an $x_0$ such that for all $x \geq
x_0$, $\abs{f(x)} \leq c g(x)$.

\item Finally,
\[
f = \Theta(g) \quad\text{iff}\quad f=O(g) \land g=O(f).
\]

\end{itemize}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problems end here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{latex-macros/handout-postamble.tex}
