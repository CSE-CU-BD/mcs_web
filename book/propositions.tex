%\hyperdef{propform}{english}
\chapter{Propositional Formulas}\label{propform_chap}

It is amazing that people manage to cope with all the ambiguities in the
English language.  Here are some sentences that illustrate the issue:
%
\begin{itemize}
\item ``You may have cake, or you may have ice cream.''
\item ``If pigs can fly, then you can understand the Chebyshev bound.''
\item ``If you can solve any problem we come up with, then you get an
  \emph{A} for the course.''
\item ``Every American has a dream.''
\end{itemize}
%
What \emph{precisely} do these sentences mean?  Can you have both cake and
ice cream or must you choose just one dessert?  Pigs can't fly, so does
the second sentence say anything about your understanding the Chebyshev
bound?  If you can solve some problems we come up with, can you get an
\emph{A} for the course?  And if you can't solve a single one of the
problems, does it mean you can't get an \emph{A}?  Finally, does the last
sentence imply that all Americans have the same dream---say of owning a
house---or might different Americans may \arm{flesh out dreams} have
different dreams---say, Eric dreams of designing a ``killer'' software
application, Tom of being a tennis champion, Albert of being able to sing?

Some uncertainty is tolerable in normal conversation.  But when we need to
formulate ideas precisely---as in mathematics and programming---the
ambiguities inherent in everyday language can be a real problem.  We can't
hope to make an exact argument if we're not sure exactly what the
statements mean.  So before we start into mathematics, we need to
investigate the problem of how to talk about mathematics.

To get around the ambiguity of English, mathematicians have devised a
special language for talking about logical relationships.  This language
mostly uses ordinary English words and phrases such as ``or'',
``implies'', and ``for all''.  But mathematicians give these words precise
and unambiguous definitions.  \iffalse A pitfall to watch out for is
confusing ordinary language with mathematical language that sounds
ordinary but isn't.\fi

Surprisingly, in the midst of learning the language of logic, we'll come
across the most important open problem in computer science---a problem
whose solution could change the world.


\section{Propositions from Propositions}

In English, we can modify, combine, and relate propositions with words
such as ``not'', ``and'', ``or'', ``implies'', and ``if-then''.
For example, we can combine three propositions into one like this:
%
\begin{center}
\textbf{If} all humans are mortal \textbf{and} all Greeks are human,
\textbf{then} all Greeks are mortal.
\end{center}

For the next while, we won't be much concerned with the internals of
propositions---whether they involve mathematics or Greek mortality---but
rather with how propositions are combined and related.  So we'll
frequently use variables such as $P$ and $Q$ in place of specific
propositions such as ``All humans are mortal'' and ``$2 + 3 = 5$''.  The
understanding is that these \term{propositional variables}, like
propositions, can take on only the values \true~(true) and \false~(false).
Propositional variables are also called \term{Boolean variables} after
their inventor, the nineteenth century mathematician George---you guessed
it---Boole.

\subsection{\QNOT, \QAND, and \QOR}
Mathematicians use the words $\QNOT$, $\QAND$, and $\QOR$
for operations that change or combine propositions.  The precise
mathematical meaning of these special words can be specified by
\term{truth tables}.  For example, if $P$ is a proposition,
then so is ``$\QNOT(P)$,'' and the truth value of the proposition
``$\QNOT(P)$'' is determined by the truth value of $P$ according to the
following truth table:
%
\[
\begin{array}{c|c}
P & \QNOT(P) \\ \hline
\true & \false \\
\false & \true \\
\end{array}
\]
%
The first row of the table indicates that when proposition $P$ is true,
the proposition ``$\QNOT(P)$'' is false.  The second line indicates that
when $P$ is false, ``$\QNOT(P)$'' is true.  This is probably what you
would expect.

In general, a truth table indicates the true/false value of a proposition
for each possible set of truth values for the variables.  For example, the
truth table for the proposition ``$P \QAND Q$'' has four lines, since
there are four settings of truth values for the two variables:
%
\[
\begin{array}{cc|c}
P & Q & P \QAND Q \\ \hline
\true & \true & \true \\
\true & \false & \false \\
\false & \true & \false \\
\false & \false & \false
\end{array}
\]
%
According to this table, the proposition ``$P \QAND Q$'' is true only when
$P$ and $Q$ are both true.  This is probably the way you ordinarily think
about the word ``and.''

There is a subtlety in the truth table for ``$P \QOR Q$'':
%
\[
\begin{array}{cc|c}
P & Q & P \QOR Q \\ \hline
\true & \true & \true \\
\true & \false & \true \\
\false & \true & \true \\
\false & \false & \false
\end{array}
\]
%
The third row of this table says that ``$P \QOR Q$'' is true even if
\textit{both} $P$ and $Q$ are true.  This isn't always the intended
meaning of ``or'' in everyday speech, but this is the standard definition
in mathematical writing.  So if a mathematician says, ``You may have cake,
or you may have ice cream,'' he means that you \textit{could} have both.

If you want to exclude the possibility of both having and eating, you
should combine them with the \term{exclusive-or} operation, $\QXOR$:
%
\[\begin{array}{cc|c}
P & Q & P \QXOR Q \\ \hline
\true & \true & \false \\
\true & \false & \true \\
\false & \true & \true \\
\false & \false & \false
\end{array}
\]

\subsection{\QIMPLIES}

The combining operation with the least intuitive technical meaning is
``implies.''  Here is its truth table, with the lines labeled so we can
refer to them later.
%
\[
\begin{array}{cc|cr}
    P  &   Q    & \parbox[b]{13ex}{$P \QIMP Q$} \\ \hline
\true  & \true  & \true & \text{(tt)}\\
\true  & \false & \false  & \text{(tf)}\\
\false & \true  & \true  & \text{(ft)}\\
\false & \false & \true  & \text{(ff)}
\end{array}
\]
Let's experiment with this definition.  For example, is the following
proposition true or false?
%
\begin{center}
``If Goldbach's Conjecture is true, then $x^2 \geq 0$ for every real
number $x$.''
\end{center}
%
Now, we already mentioned that no one knows whether Goldbach's Conjecture,
Proposition~\ref{Goldbach}, is true or false.  But that doesn't prevent
you from answering the question!  This proposition has the form $P
\QIMP Q$ where the \term{hypothesis}, $P$, is ``Goldbach's Conjecture
is true'' and the \term{conclusion}, $Q$, is ``$x^2 \geq 0$ for every real
number $x$''.  Since the conclusion is definitely true, we're on either
line~(tt) or line~(ft) of the truth table.  Either way, the proposition as
a whole is \textit{true}!

One of our original examples demonstrates an even stranger side of
implications.
\begin{center}
``If pigs fly, then you can understand the Chebyshev bound.''
\end{center}
Don't take this as an insult; we just need to figure out whether this
proposition is true or false.  Curiously, the answer has \textit{nothing}
to do with whether or not you can understand the Chebyshev bound.  Pigs do
not fly, so we're on either line (ft) or line (ff) of the truth table.  In
both cases, the proposition is \textit{true}!

In contrast, here's an example of a false implication:
%
\begin{center}
``If the moon shines white, then the moon is made of white cheddar.''
\end{center}
%
Yes, the moon shines white.  But, no, the moon is not made of white
cheddar cheese.  So we're on line (tf) of the truth table, and the
proposition is false.

The truth table for implications can be summarized in words as
follows:
%
\textbox{
An implication is true exactly when the if-part is false or the
then-part is true.
}
%
This sentence is worth remembering; a large fraction of all
mathematical statements are of the if-then form!

\subsection{If and Only If}

Mathematicians commonly join propositions in one additional way that
doesn't arise in ordinary speech.  The proposition ``$P$ if and only
if $Q$'' asserts that $P$ and $Q$ have the same truth value, that is,
either both are true or both are false.
%
\[
\begin{array}{cc|c}
P & Q & P \QIFF Q \\ \hline
\true & \true & \true \\
\true & \false & \false \\
\false & \true & \false \\
\false & \false & \true
\end{array}
\]
For example, the following if-and-only-if statement is true for every real
number $x$:
%
\[
x^2 - 4 \geq 0 \QIFF |x| \geq 2.
\]
%
For some values of $x$, \textit{both} inequalities are true.  For
other values of $x$, \textit{neither} inequality is true .  In every
case, however, the \QIFF\ proposition as a whole is true.

\begin{problems}
\practiceproblems
\pinput{TP_Basic_Propositions}

\classproblems
\pinput{CP_differentiable_implies_continuous}

\homeworkproblems
\pinput{PS_printout_binary_strings}
\end{problems}


\section{Propositional Logic in Computer Programs}\label{propositions_in_programs_sec}

Propositions and logical connectives arise all the time in computer
programs.  For example, consider the following snippet, which could be
either C, C++, or Java:
%
\begin{tabbing}
\hspace{1in} \= \quad\quad \= \quad\quad \= \quad\quad \= \kill
\> \texttt{if ( x > 0 || (x <= 0 \&\& y > 100) )} \\
\> \> \vdots\\
\> \textit{(further instructions)}
\end{tabbing}
%
Java uses The symbol \texttt{||} for ``\QOR,'' and the
symbol \texttt{\&\&} for ``\QAND.''  The \textit{further instructions}
are carried out only if the proposition following the word \texttt{if}
is true.  On closer inspection, this big expression is built from two
simpler propositions.  Let $A$ be the proposition that \texttt{x > 0},
and let $B$ be the proposition that \texttt{y > 100}.  Then we can
rewrite the condition as
\begin{equation}\label{ANAB}
A \QOR (\QNOT(A) \QAND B).
\end{equation}

\subsection{Truth Table Calculation}
A truth table calculation reveals that the more complicated
expression~\ref{ANAB} always has the same truth value as
\begin{equation}\label{AOB}
A \QOR B.
\end{equation}
Namely, we begin with a table with just the truth values of $A$ and $B$:
\[
\begin{array}{cc|ccccc|c}
A      & B      & A  & \QOR  & (\QNOT(A)& \QAND & B) & A \QOR  B \\ \hline
\true  & \true \\
\true  & \false\\
\false & \true \\
\false & \false                       
\end{array}
\]
These values are enough to fill in two more columns:
\[
\begin{array}{cc|ccccc|c}
A      & B      & A & \QOR  & (\QNOT(A) & \QAND & B) & A \QOR  B \\ \hline
\true  & \true  &   &       & \ \false   &       &    & \lgtrue \\
\true  & \false &   &       & \ \false   &       &    & \lgtrue \\
\false & \true  &   &       & \ \true    &       &    & \lgtrue \\
\false & \false &   &       & \ \true    &       &    & \lgfalse\\
\end{array}
\]
Now we have the values needed to fill in the \QAND\ column:
\[
\begin{array}{cc|ccccc|c}
A      & B      & A & \QOR  & (\QNOT(A) & \QAND   & B) & A \QOR  B \\ \hline
\true  & \true  &   &       & \ \false   &  \false &    & \lgtrue \\
\true  & \false &   &       & \ \false   &  \false &    & \lgtrue \\
\false & \true  &   &       & \ \true    &  \true  &    & \lgtrue \\
\false & \false &   &       & \ \true    &  \false &    & \lgfalse\\
\end{array}
\]
and this provides the values needed to fill in the remaining column for the first \QOR:
\[
\begin{array}{cc|ccccc|c}
A      & B      & A & \QOR     &(\QNOT(A) & \QAND   & B) & A \QOR  B \\ \hline
\true  & \true  &   & \lgtrue  & \false &    \false &    & \lgtrue \\
\true  & \false &   & \lgtrue  & \false &    \false &    & \lgtrue \\
\false & \true  &   & \lgtrue  & \true  &    \true  &    & \lgtrue \\
\false & \false &   & \lgfalse & \true  &    \false &    & \lgfalse\\
\end{array}
\]
Expression whose truth values always match are called \term{equivalent}.
Since the (highlighted) columns of truth values of the two expressions are
the same, they are equivalent.  So we can simplify the code snippet
without changing the program's behavior by replacing the complicated
expression with an equivalent simpler one:
%
\begin{tabbing}
\hspace{1in} \= \quad\quad \= \quad\quad \= \quad\quad \= \kill
\> \texttt{if ( x > 0 || y > 100 )} \\
\> \> \vdots\\
\> \emph{(further instructions)}
\end{tabbing}

The equivalence of~\eqref{ANAB} and~\eqref{AOB} can also be confirmed
reasoning by cases:
\begin{itemize}
\item[$A$ is \true.]  An expression of the form $(\true \QOR
  \text{anything})$ is equivalent to \true.  Since $A$ is \true\
  both~\eqref{ANAB} and~\eqref{AOB} in this case are of this form, so they
  have the same truth value, namely, \true.

\item[$A$ is \false.]  Then an expression of the form $(A \QOR
  \textit{anything})$ will have same truth value as \emph{anything}.
   So~\eqref{AOB} has the same truth value as $B$.

   Now any expression of the form $(\true \QAND \textit{anything})$ is
   equivalent to \emph{anything}, as is any expression of the form $\false
   \QOR \emph{anything}$. 
   So in this case $A \QOR (\QNOT(A) \QAND B)$ is equivalent to
   $(\QNOT(A) \QAND B)$, which in turn is equivalent to $B$.

   Therefore both~\eqref{ANAB} and~\eqref{AOB} will have the same truth
   value in this case, namely, the value of $B$.
\end{itemize}

Simplifying logical expressions has real practical importance in
computer science.  Expression simplification in programs like the one
above can make a program easier to read and understand, and can also
make it faster since fewer operations are needed.  In hardware,
simplifying expressions can decrease the number of logic gates on a
chip.  That's because digital circuits can be described by logical
formulas (see Problems~\ref{CP_binary_adder_logic}
and~\ref{PS_faster_adder_logic}), and minimizing the logical formulas
corresponds to reducing the number of gates in the circuit.  The
payoff of gate minimization is potentially enormous: a chip with fewer
gates is smaller, consumes less power, has a lower defect rate, and is
cheaper to manufacture.

\subsection{Cryptic Notation}
Java uses symbols like ``$\&\&$'' and ``$||$'' in place of \QAND\ and
\QOR.  Circuit designers use ``$\cdot$'' and ``$+$,'' and actually refer
to \QAND\ as a product and \QOR\ as a sum.  Mathematicians use still
other symbols given in the table below.
%
\begin{center}
\begin{tabular}{ll}
\textbf{English} & \textbf{Symbolic Notation} \\[1ex]
$\QNOT(P)$ & $\neg P$ \quad (alternatively, $\bar{P}$) \\
$P \QAND Q$ & $P \land Q$ \\
$P \QOR Q$ & $P \lor Q$ \\
$P \QIMP Q$ & $P \implies Q$ \\
if $P$ then $Q$ & $P \implies Q$ \\
$P \QIFF Q$ & $P \iff Q$\\
$P \QXOR Q$ & $P \oplus Q$
\end{tabular}
\end{center}
%
For example, using this notation, ``If $P \QAND \QNOT(Q)$, then $R$''
would be written:
%
\[
    (P \land \bar{Q}) \implies R.
\]

The mathematical notation is concise but cryptic.  Words such as
``$\QAND$'' and ``$\QOR$'' are easier to remember and won't get
confused with operations on numbers.  We will mostly stick to the
words except when formulas would otherwise run off the page.

\begin{problems}
\classproblems
\pinput{CP_binary_adder_logic}

\homeworkproblems
\pinput{PS_faster_adder_logic}
\end{problems}

\section{Equivalence and Validity}\label{equiv_valid_sec}
%\label{sec:logical_equivalence}

\subsection{Implications and Contrapositives}\label{implication_sec}
Do these two sentences say the same thing?
%
\begin{center}
If I am hungry, then I am grumpy. \\
If I am not grumpy, then I am not hungry.
\end{center}
%
We can settle the issue by recasting both sentences in terms of
propositional logic.  Let $P$ be the proposition ``I am hungry'', and $Q$
be ``I am grumpy''.  The first sentence says ``$P \QIMPLIES Q$'' and the
second says ``$\QNOT(Q) \QIMP \QNOT(P)$''.  Once more, we can compare
these two statements in a truth table:
%
\[
\begin{array}{c|c|c|lcl}
   P   &   Q    & (P  \QIMP  Q) & (\QNOT(Q) & \QIMP & \QNOT(P)) \\ \hline
\true  & \true  &     \lgtrue   &  \false   & \lgtrue  &  \false\\
\true  & \false &     \lgfalse  &  \true    & \lgfalse &  \false\\
\false & \true  &     \lgtrue   &  \false   & \lgtrue  &  \true \\
\false & \false &     \lgtrue   &  \true    & \lgtrue  &  \true \\
\end{array}
\]
%
Sure enough, the highlighted columns showing the truth values of these two
statements are the same.  A statement of the form ``($\QNOT Q) \QIMPLIES
(\QNOT P)$'' is called the \term{contrapositive} of the implication ``$P
\QIMPLIES Q$.''  The truth table shows that an implication and its
contrapositive are equivalent---they are just different ways of saying
the same thing.

In contrast, the \term{converse} of ``$P \QIMPLIES Q$'' is the statement
``$Q \QIMPLIES P$.''  In terms of our example, the converse is:
%
\begin{center}
If I am grumpy, then I am hungry.
\end{center}
%
This sounds like a rather different contention, and a truth table
confirms this suspicion:
%
\[
\begin{array}{c|c|c|c}
P & Q &
    P \QIMPLIES Q &
    Q \QIMPLIES P \\ \hline
\true & \true & \lgtrue & \lgtrue \\
\true & \false & \lgfalse & \lgtrue \\
\false & \true & \lgtrue & \lgfalse \\
\false & \false & \lgtrue & \lgtrue
\end{array}
\]
%
Now the highlighted columns differ in the second and third row, confirming
that an implication is generally \textit{not} equivalent to its converse.

One final relationship: an implication and its converse together are
equivalent to an iff statement, specifically, to these two statements
together.  For example,
%
\begin{center}
If I am grumpy then I am hungry, and if I am hungry then I am grumpy.
\end{center}
%
are equivalent to the single statement:
%
\begin{center}
I am grumpy iff I am hungry.
\end{center}
%
Once again, we can verify this with a truth table.  

\iffalse
We begin with a table with just the truth values of $P$ and $Q$:
%
\[
\begin{array}{c|c|ccc|c}
P & Q & (P \QIMP Q) &\QAND & (Q  \QIMP  P) & P \QIFF Q \\
\hline
\true  &  \true  &&&&\\
\true  &  \false &&&&\\
\false &  \true  &&&&\\
\false &  \false &&&&
\end{array}
\]
These truth values are enough to fill in three more columns:
\[
\begin{array}{c|c|ccc|c}
P & Q & (P \QIMP Q) &\QAND & (Q  \QIMP  P) & P \QIFF Q \\
\hline
\true  &  \true  &\true  &&\true & \lgtrue \\
\true  &  \false &\false &&\true & \lgfalse\\
\false &  \true  &\true  &&\false& \lgfalse\\
\false &  \false &\true  &&\true & \lgtrue 
\end{array}
\]
Finally, now using the first two of the filled in columns, we can fill in
the fourth column:
\fi

\[
\begin{array}{c|c|ccc|c}
P & Q & (P \QIMP Q) &\QAND & (Q  \QIMP  P) & P \QIFF Q \\
\hline
\true  &  \true  &\true  &\lgtrue &\true & \lgtrue \\
\true  &  \false &\false &\lgfalse&\true & \lgfalse\\
\false &  \true  &\true  &\lgfalse&\false& \lgfalse\\
\false &  \false &\true  &\lgtrue &\true & \lgtrue
\end{array}
\]
The fourth column giving the truth values of 
\[
(P \QIMP Q) \QAND (Q \QIMP P)
\]
is the same as the sixth column giving the truth values of $P \QIFF
Q$, which confirms that the \QAND\ of the implications is equivalent
to the \QIFF\ statement.

\subsection{Validity and Satisfiability}
A \term{valid} formula is one which is always true.  The simplest example is
\[
P \QOR \QNOT(P).
\]

You can think about valid formulas as capturing fundamental logical
truths.  For example, a property of implication that we take for
granted is the if one statement implies a second one, and the second
one imlplies a third, then the first implies the third.  The following
valid formula comfirms the truth of this property of implication.
\[
[(P \QIMP Q) \QAND (Q \QIMP R)] \QIMP (P \QIMP R).
\]

Equivalence of formulas is really a special case of validity.  Namely,
statements $F$ and $G$ and equivalent iff the statement $F \QIFF G$ is
valid.  For example, the equivalence of the expressions~\ref{AOB}
and~\ref{ANAB} means that
\[
(A \QOR B) \QIFF (A \QOR (\QNOT(A) \QAND B))
\]
is valid.  Of course validity can also be viewed as as aspect of
equivalence.  Namely, a formula is valid iff it is equivalent
to \true.

A \term{satisfiable} formula is one which can sometimes be true.  One
way satisfiability comes up is when there are a collection of system
specifications.  The job of the system designer is to come up with a
system that follows all the specs.  This means that the \QAND\ of all
the specs had better be satisfiable or the system will be impossible
(see Problem~\ref{CP_file_system_functioning_normally}).

There is also a close relationship between validity and
satisfiability, namely, a statement $P$ is valid iff its negation
$\QNOT(P)$ is \emph{not} satisfiable.

\begin{problems}

\classproblems
\pinput{CP_validity}
\pinput{CP_file_system_functioning_normally}
\end{problems}


\section{The Algebra of Propositions}

\subsection{Propositions in Normal Form}
You can read off a simple expression for any propositional formula
right from its truth table.  Let's use
\begin{equation}\label{ANBRC}
A \QAND (B \QOR C)
\end{equation}
as an example.  Here is its truth table.
\[\begin{array}{c|c|c|cc}
A      & B      & C       & A \QAND (B \QOR C)\\
\true  & \true  & \true   &     \true\\
\true  & \true  & \false  &     \true\\
\true  & \false & \true   &     \true\\
\true  & \false & \false  &     \false\\
\false & \true  & \true   &     \false\\
\false & \true  & \false  &     \false\\
\false & \false & \true   &     \false\\
\false & \false & \false  &     \false
\end{array}\]
So~\eqref{ANBRC} is true in the first row when $A$, $B$, and $C$ are all
true, that is, where $A \QAND B \QAND C$ is true.  It's also true in
the second row where $A \QAND B \QAND \bar{C}$ is true, and in the
third row when $A \QAND \bar{B} \QAND C$ is true, and that's all.
So~\eqref{ANBRC} is true exactly when
\begin{equation}\label{ABCDNF}
(A \QAND B \QAND C) \QOR (A \QAND B \QAND \bar{C}) \QOR
  (A \QAND \bar{B} \QAND C)
\end{equation}
is true.  So~\eqref{ANBRC} and~\eqref{ABCDNF} are equivalent.

Notice that the expression~\eqref{ABCDNF} is simply an \QOR\ of \QAND-terms, where each
\QAND-term is an \QAND\ in turn of each of the variables or their negations.
An expression of this form is called a \term{disjunctive normal form}.

\subsection{Proving Equivalences}
A check of equivalence or validity by truth table runs out of steam
apretty quickly: a proposition with $n$ variables has a truth table
with $2^n$ lines, so the effort required to check a proposition
grows \idx{exponentially} with the number of variables.  For a
proposition with just 30 variables, that's already over a billion
lines to check!

An alternative approach that sometimes helps is to use algebra to
prove equivalence.  We list below a bunch of equivalence axioms with
the symbol ``$\equivalence$'' between equivalent formulas.  These
axioms are important because they are all that's needed to prove every
possible equivalence.  We'll start with some equivalences for \QAND's
that look like the familiar ones for multiplication of numbers:
\begin{align}
A \QAND B           &\eqv B \QAND A
         & \text{commutativity of \QAND}\\
(A \QAND B)\QAND C  & \eqv A \QAND (B \QAND C)
         & \text{associativity of \QAND}\\
\true \QAND A           &\eqv A
         & \text{identity for \QAND}\\
\false \QAND A           &\eqv \false
         & \text{zero for \QAND}
\end{align}
An axiom that doesn't correspond to a number property is
\begin{align}
A \QAND A           &\eqv A
         & \text{idempotence for \QAND}\\
\end{align}
There are a corresponding set of equivalences for $\QOR$ which we
won't bother to list.

There is also a familiar rule connecting \QAND\ and \QOR:
\begin{align}
A \QAND (B \QOR C) & \eqv (A \QAND B) \QOR (A \QAND C)
       & \text{distributivity of \QAND\ over \QOR}
\end{align}




\begin{editingnotes}
DNF from True entries in truth table; CNF from false entries.   DNF from
algebra: distributivity, De Morgan, sort alphabetically.
\end{editingnotes}


\section{The SAT Problem}\label{SAT_sec}

A proposition is \textbf{satisfiable} if some setting of the variables
makes the proposition true.  For example, $P \QAND \bar{Q}$ is
satisfiable because the expression is true if $P$ is true or $Q$ is
false.  On the other hand, $P \QAND \bar{P}$ is not satisfiable because
the expression as a whole is false for both settings of $P$.  But
determining whether or not a more complicated proposition is satisfiable
is not so easy.  How about this one?
%
\[
(P \QOR Q \QOR R) \QAND (\bar P \QOR \bar Q)
                  \QAND (\bar P \QOR \bar R)
                  \QAND (\bar R \QOR \bar Q)
\]

The general problem of deciding whether a proposition is satisfiable
is called \term{SAT}.  One approach to SAT is to construct a truth
table and check whether or not a $\true$ ever appears.  

\iffalse
%inserted above

But this approach runs out of steam pretty quickly: a proposition with
$n$ variables has a truth table with $2^n$ lines, so the effort
required to decide about a proposition grows \idx{exponentially} with
the number of variables.  For a proposition with just 30 variables,
that's already over a billion lines to check!\fi


Is there a more \index{efficient solution} efficient solution
to SAT?  In particular, is there some, presumably very ingenious,
procedure that determines in a number of steps that grows
\emph{polynomially}---like $n^2$ or $n^{14}$---instead of
exponentially, whether any given proposition is satisfiable or not?
No one knows.  And an awful lot hangs on the answer.  An efficient
solution to SAT would immediately imply efficient solutions to many,
many other important problems involving packing, scheduling, routing,
and circuit verification, among other things.  This would be
wonderful, but there would also be worldwide chaos.  Decrypting coded
messages would also become an easy task (for most codes).  Online
financial transactions would be insecure and secret communications
could be read by everyone.

Recently there has been exciting progress on \term{sat-solvers} for
practical applications like digital circuit verification.  These
programs find satisfying assignments with amazing efficiency even for
formulas with millions of variables.  Unfortunately, it's hard to
predict which kind of formulas are amenable to sat-solver methods, and
for formulas that are \emph{un}satisfiable, sat-solvers generally take
exponential time to verify that no assignment works.

So no one has a good idea how to solve SAT in polynomial time, or how
to prove that it can't be done---researchers are completely stuck.
The problem of determining whether or not SAT has a polynomial time
solution is known as the ``\textbf{P} vs.\ \textbf{NP}'' problem.  It
is the outstanding unanswered question in theoretical computer
science.  It is also one of the
seven \href{http://www.claymath.org/millennium/}{Millenium Problems}:
the Clay Institute will award you \$1,000,000 if you solve
the \textbf{P} vs.\ \textbf{NP} problem.

\arm{ SAT vs VALID}
There is a close relation between satisfiability and validity, namely a
formula is satisfiable iff its negation is \emph{not} valid (see
Problem~\ref{CP_valid_vs_satisfiable}).  It follows that there is polynomial time
procedure for SAT iff there is there is polynomial time
procedure for validity.

Now we can see why simplification of formulas in programs or for
circuits which came up in Section~\ref{propositions_in_programs_sec}
would be hard---validity testing is a special case of simplification:
a formula is valid iff it simplies to \true.


\endinput
