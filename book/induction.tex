\chapter{Induction and the Well Ordering Principle}\label{induction_chap}

Now that you understand the basics of how to prove that a proposition
is true, it is time to equip you with the most powerful methods we
have for establishing truth: the Well Ordering Principle, the
Induction Rule, and strong induction.  These methods are especially
useful when you need to prove that a predicate is true for all natural
numbers.

Although the three methods look and feel different, it turns out that
they are equivalent in the sense that whatever you can prove using one
of the methods, you can also prove using either of the others.  The
choice of which method to use depends on whichever seems to be easiest
or most natural for the problem at hand.

\section{The Well Ordering Principle}\label{well_ordering_sec}
%\label{well_ordering_chap}

\textbox{
\centerline{Every \emph{nonempty} set of \emph{nonnegative integers} has a
\emph{smallest} element.}
}

This statement is known as The \term{Well Ordering Principle}.  Do you
believe it?  Seems sort of obvious, right?  But notice how tight it is: it
requires a \emph{nonempty} set---it's false for the empty set which has
\emph{no} smallest element because it has no elements at all!  And it
requires a set of \emph{nonnegative} integers---it's false for the set of
\emph{negative} integers and also false for some sets of nonnegative
\emph{rationals}---for example, the set of positive rationals.  So, the
Well Ordering Principle captures something special about the nonnegative
integers.

\hyperdef{well}{ordering}{\subsection{Well Ordering Proofs}}

While the Well Ordering Principle may seem obvious, \iffalse it looks
nothing like the induction axiom, and\fi it's hard to see offhand why it
is useful.  But in fact, it provides one of the most important proof rules
in discrete mathematics.  \iffalse We'll explain this after we introduce a
template for well ordering principle proofs resembling the template in
Section~\ref{templ-induct-proofs} for a proof by strong induction.\fi

In fact, looking back, we took the Well Ordering Principle for granted in
proving that $\sqrt{2}$ is irrational.  That proof assumed that for any
positive integers $m$ and $n$, the fraction $m/n$ can be written in
\term{lowest terms}, that is, in the form $m'/n'$ where $m'$ and $n'$
are positive integers with no common factors.  How do we know this is
always possible?

Suppose to the contrary\footnote{This means that you are about to see
an informal proof by contradiction.} that there were
$m,n \in \integers^+$ such that the fraction $m/n$ cannot be written
in lowest terms.  Now let $C$ be the set of positive integers that are
numerators of such fractions.  Then $m \in C$, so $C$ is nonempty.
Therefore, by Well Ordering, there must be a smallest integer,
$m_0 \in C$.  So by definition of $C$, there is an integer $n_0 > 0$
such that
\[
\text{the fraction } \frac{m_0}{n_0} \text{ cannot be written in lowest
terms.}
\]
This means that $m_0$ and $n_0$ must have a common factor, $p>1$.  But
\[
\frac{m_0/p}{n_0/p} = \frac{m_0}{n_0},
\]
so any way of expressing the left hand fraction in lowest terms would also
work for $m_0/n_0$, which implies
\[
\text{the fraction } \frac{m_0/p}{n_0/p} \text{ cannot be in written in
lowest terms either.}
\]
So by definition of $C$, the numerator, $m_0/p$, is in $C$.  But $m_0/p <
m_0$, which contradicts the fact that $m_0$ is the smallest element of $C$.

Since the assumption that $C$ is nonempty leads to a contradiction, it
follows that $C$ must be empty.  That is, that there are no numerators of
fractions that can't be written in lowest terms, and hence there are no
such fractions at all.

We've been using the Well Ordering Principle on the sly from early on!

\subsection{Template for Well Ordering Proofs}

More generally, to prove that ``$P(n)$ is true for all
$n\in \naturals$'' using the Well Ordering Principle, you can take the
following steps:
\begin{itemize}

\item Define the set, $C$, of \emph{counterexamples} to $P$ being
  true.  Namely, define\footnote{The notation
    $\set{\,n \suchthat \text{$P(n)$ is false}\,}$
    means ``the set of all elements $n$, for which $P(n)$ is false.}
\[
C \eqdef \set{n\in\naturals \suchthat P(n) \text{ is false}}.
\]

\item Use a proof by contradiction and assume that $C$ is nonempty.

\item By the Well Ordering Principle, there will be a smallest
      element, $n$, in $C$.

\item Reach a contradiction (somehow)---often by showing how to use $n$
to find another member of $C$ that is smaller than $n$.  (This is the
open-ended part of the proof task.)

\item Conclude that $C$ must be empty, that is, no counterexamples exist.
QED

\end{itemize}


\subsection{Examples}

Let's use this this template to prove %Theorem~\ref{th:sum-to-n}. 

\begin{theorem*}  %\label{sum-to-n}
\begin{equation}\label{sum1n}
1 + 2 + 3 + \cdots + n = n(n+1)/2
\end{equation}
for all nonnegative integers, $n$.
\end{theorem*}

First, we better address of a couple of ambiguous special
cases before they trip us up:
%
\begin{itemize}
%
\item If $n = 1$, then there is only one term in the summation, and so $1
  + 2 + 3 + \cdots + n$ is just the term 1.  Don't be misled by the
  appearance of 2 and 3 and the suggestion that $1$ and $n$ are distinct
  terms!
%
\item If $n \leq 0$, then there are no terms at all in the summation.  By
convention, the sum in this case is 0.
%
\end{itemize}
%
So while the dots notation is convenient, you have to watch out for these
special cases where the notation is misleading!  (In fact, whenever you
see the dots, you should be on the lookout to be sure you understand the
pattern, watching out for the beginning and the end.)

We could have eliminated the need for guessing by rewriting the left side
of~\eqref{sum1n} with \term{summation notation}:
\[
\sum_{i=1}^n i
\qquad \text{or} \qquad
\sum_{1 \leq i \leq n} i.
\]
Both of these expressions denote the sum of all values taken by the
expression to the right of the sigma as the variable, $i$, ranges from 1
to $n$.  Both expressions make it clear what~\eqref{sum1n} means when
$n=1$.  The second expression makes it clear that when $n=0$, there are no
terms in the sum, though you still have to know the convention that a sum
of no numbers equals 0 (the \emph{product} of no numbers is 1, by the
way).

OK, back to the proof:

\begin{proof}
By contradiction and use of the Well Ordering Principle.  Assume that
the theorem is \emph{false}.  Then, some nonnegative integers serve as
\emph{counterexamples} to it. Let's collect them in a set:
\[
C \eqdef \set{n\in\naturals \suchthat 
        1 + 2 + 3 + \cdots + n \neq \frac{n(n+1)}{2}}.
\]
By our assumption that the theorem admits counterexamples, $C$ is a
nonempty set of nonnegative integers.  So, by the Well Ordering Principle,
$C$ has a minimum element, call it~$c$.  That is, $c$ is the
\emph{\idx{smallest counterexample}} to the theorem.

Since $c$ is the smallest counterexample, we know that~\eqref{sum1n} is
false for $n=c$ but true for all nonnegative integers $n<c$.
But~\eqref{sum1n} is true for $n=0$, so $c > 0$.  This means $c-1$ is a
nonnegative integer, and since it is less than $c$, equation~\eqref{sum1n}
is true for $c-1$.  That is,
\[
        1 + 2 + 3 + \cdots + (c-1) = \frac{(c-1)c}{2}.
\]
But then, adding $c$ to both sides we get
\[
1 + 2 + 3 + \cdots + (c-1) + c 
        = \frac{(c-1)c}{2} + c
        = \frac{c^2 - c + 2c}{2} 
        = \frac{c(c+1)}{2},
\]
which means that~\eqref{sum1n} does hold for $c$, after all!  This is a
contradiction, and we are done.
\end{proof}

Here is another result that can be proved using Well Ordering.  It
will be useful in Chapter~\ref{number_theory_chap} when we study
number theory and cryptography.

\begin{theorem}\label{factor_into_primes}
Every natural number can be factored as a product of primes.
\end{theorem}
\begin{proof}
By contradiction and Well Ordering.  Assume that the theorem is false
and let $C$ be the set of all integers greater than one that cannot be
factored as a product of primes.  We assume that $C$ is not empty and derive a
contradiction.

If $C$ is not empty, there is a least element, $n \in C$, by Well
Ordering.  The $n$ can't be prime, because a prime by itself is considered
a (length one) product of primes and no such products are in $C$.

So $n$ must be a product of two integers $a$ and $b$ where $1<a,b<n$.
Since $a$ and $b$ are smaller than the smallest element in $C$, we know
that $a,b \notin C$.  In other words, $a$ can be written as a product of
primes $p_1p_2\cdots p_k$ and $b$ as a product of primes $q_1\cdots q_l$.
Therefore, $n=p_1\cdots p_k q_1 \cdots q_l$ can be written as a product of
primes, contradicting the claim that $n \in C$.  Our assumption that
$C$ is not empty must therefore be false.
\end{proof}

\begin{problems}
\practiceproblems
\pinput[title = {Postage by Well Ordering}]{TP_10_and_15_cent_stamps_by_WOP}

\classproblems
\pinput{CP_6_and_15_cent_stamps_by_WOP}
\pinput{PS_Lehmans_equation}
\pinput{CP_sum_of_squares}

\homeworkproblems
\pinput{PS_3_and_5_postage_by_WOP}
\end{problems}

\section{Ordinary Induction}

\idx{Induction} is by far the most powerful and commonly-used proof technique in
discrete mathematics and computer science.  In fact, the use of induction
is a defining characteristic of \emph{discrete}---as opposed to
\emph{continuous}---mathematics.
%
To understand how it works, suppose there is a professor who brings
to class a bottomless bag of assorted miniature candy bars.  She offers to
share the candy in the following way.  First, she lines the students up in
order.  Next she states two rules:

\begin{enumerate}
\item The student at the beginning of the line gets a candy bar.
\item If a student gets a candy bar, then the following student in line
  also gets a candy bar.
\end{enumerate}
%
Let's number the students by their order in line, starting the count with
0, as usual in Computer Science.  Now we can understand the second rule as
a short description of a whole sequence of statements:
%
\begin{itemize}
\item If student 0 gets a candy bar, then student 1 also gets one.
\item If student 1 gets a candy bar, then student 2 also gets one.
\item If student 2 gets a candy bar, then student 3 also gets one.

\hspace{1.2in} \vdots
\end{itemize}
%
Of course this sequence has a more concise mathematical description:
\begin{quote}
  If student $n$ gets a candy bar, then student $n+1$ gets a
  candy bar, for all nonnegative integers $n$.
\end{quote}
So suppose you are student 17.  By these rules, are you entitled to a
miniature candy bar?  Well, student 0 gets a candy bar by the first rule.
Therefore, by the second rule, student 1 also gets one, which means
student 2 gets one, which means student 3 gets one as well, and so on.  By
17 applications of the professor's second rule, you get your candy bar!
Of course the rules actually guarantee a candy bar to \emph{every}
student, no matter how far back in line they may be.


%% Ordinary Induction %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{A Rule for Ordinary Induction}

The reasoning that led us to conclude that every student gets a candy bar is 
essentially all there is to induction.
\textbox{ 
\noindent \textbf{The Principle of Induction.}

\noindent Let $P(n)$ be a predicate.  If
%
\noindent \begin{itemize}
\item $P(0)$ is true, and
\item $P(n) \QIMPLIES P(n+1)$ for all nonnegative integers, $n$,
\end{itemize}
%
\noindent then
\noindent \begin{itemize}
\item $P(m)$ is true for all nonnegative integers, $m$.
\end{itemize}
}
\iffalse
So our claim that all the Professor's students get a candy bar was simply
an application of the Induction Rule with $P(n)$ defined to be the
predicate, ``student $n$ gets a candy bar.''
\fi

Since we're going to consider several useful variants of induction in
later sections, we'll refer to the induction method described above as
\term{ordinary induction} when we need to distinguish it.  Formulated as 
a proof rule, this would be
\begin{rul*} \textbf{Induction Rule}
\Rule{P(0), \quad \forall n \in \naturals\, P(n) \QIMPLIES P(n+1)}
{\forall m \in \naturals.\, P(m)}
\end{rul*}

This general induction rule works for the same intuitive reason that all
the students get candy bars, and we hope the explanation using candy bars
makes it clear why the soundness of the ordinary induction can be taken
for granted.  In fact, the rule is so obvious that it's hard to see what
more basic principle could be used to justify it.\footnote{But see
section~\ref{versusWO}.}  What's not so obvious is how much mileage 
we get by using it.

\subsection{A Familiar Example}

Ordinary induction often works directly in proving that some statement
about nonnegative integers holds for all of them.  For example, here is
the formula for the sum of the nonnegative integers that we already proved
(equation~\eqref{sum1n}) using the \idx{Well Ordering Principle}:

\begin{theorem}\label{sum-to-n-again-theorem}
For all $n \in \naturals$,
\begin{equation}\label{sum-to-n-again}
1 + 2 + 3 + \cdots + n = \frac{n(n+1)}{2}
\end{equation}
\end{theorem}

This time, let's use the Induction Principle to prove
Theorem~\ref{sum-to-n-again-theorem}.

Suppose that we define predicate $P(n)$ to be the
equation~\eqref{sum-to-n-again}.  Recast in terms of this predicate, the
theorem claims that $P(n)$ is true for all $n \in \naturals$.  This is
great, because the induction principle lets us reach precisely that
conclusion, provided we establish two simpler facts:
%
\begin{itemize}
\item $P(0)$ is true.
\item For all $n \in \naturals$, $P(n) \QIMPLIES P(n+1)$.
\end{itemize}

So now our job is reduced to proving these two statements.  The first
is true because $P(0)$ asserts that a sum of zero terms is equal to
$0(0+1)/2 = 0$, which is true by definition.
%
The second statement is more complicated.  But remember the basic plan for
proving the validity of any implication from
subsection~\ref{sec:prove_implies}: \emph{assume} the statement on 
the left and then \emph{prove} the statement on the right.  In this
case, we assume $P(n)$ in order to prove $P(n+1)$, which is the equation
\begin{equation}\label{sum-to-n-again-Pn1}
1 + 2 + 3 + \cdots + n + (n+1) = \frac{(n+1)(n+2)}{2}.
\end{equation}
These two equations are quite similar; in fact, adding $(n+1)$ to both
sides of equation~\eqref{sum-to-n-again} and simplifying the right side 
gives the equation~\eqref{sum-to-n-again-Pn1}:
\begin{align*}
1 + 2 + 3 + \cdots + n + (n+1)
    & = \frac{n(n+1)}{2} + (n+1) \\
    & = \frac{(n+2)(n+1)}{2}
\end{align*}
Thus, if $P(n)$ is true, then so is $P(n+1)$.  This argument is valid for
every nonnegative integer $n$, so this establishes the second fact
required by the induction principle.  Therefore, the induction principle
says that the predicate $P(m)$ is true for all nonnegative integers, $m$,
so the theorem is proved.

\begin{editingnotes}
In effect, we've just proved
that $P(0)$ implies $P(1)$, $P(1)$ implies $P(2)$, $P(2)$ implies
$P(3)$, etc., all in one fell swoop.
\end{editingnotes}

\subsection{A Template for Induction Proofs}
\label{templ-induct-proofs}

The proof of Theorem~\ref{sum-to-n-again-theorem} was relatively simple,
but even the most complicated induction proof follows exactly the same
template.  There are five components:

\begin{enumerate}

\item \textbf{State that the proof uses induction.}  This immediately
conveys the overall structure of the proof, which helps the reader
understand your argument.

\item \textbf{Define an appropriate predicate $P(n)$.}  The eventual
  conclusion of the induction argument will be that $P(n)$ is true for all
  nonnegative $n$.  Thus, you should define the predicate $P(n)$ so that
  your theorem is equivalent to (or follows from) this conclusion.  Often
  the predicate can be lifted straight from the proposition that you
  are trying to prove, as in the example
  above.  The predicate $P(n)$ is called the \term{induction hypothesis}.
  Sometimes the induction hypothesis will involve several variables, in
  which case you should indicate which variable serves as $n$.

\item \textbf{Prove that $P(0)$ is true.}  This is usually easy, as in the
  example above.  This part of the proof is called the \term{base case}
  or \term{basis step}.\iffalse
  (Sometimes the base case will be $n=1$ or even
  some larger number, in which case the starting value of $n$ also should
  be stated.)\fi


\item \textbf{Prove that $P(n)$ implies $P(n+1)$ for every nonnegative
    integer $n$.}  This is called the \term{inductive step}.  The basic
  plan is always the same: assume that $P(n)$ is true and then use this
  assumption to prove that $P(n+1)$ is true.  These two statements should
  be fairly similar, but bridging the gap may require some ingenuity.
  Whatever argument you give must be valid for every nonnegative integer
  $n$, since the goal is to prove the implications $P(0) \rightarrow
  P(1)$, $P(1) \rightarrow P(2)$, $P(2) \rightarrow P(3)$, etc. all at
  once.

\item \textbf{Invoke induction.}  Given these facts, the induction
  principle allows you to conclude that $P(n)$ is true for all nonnegative
  $n$.  This is the logical capstone to the whole argument, but it is so
  standard that it's usual not to mention it explicitly,

\end{enumerate}
%
Always be sure to 
explicitly label the \emph{base case} and the \emph{inductive step}.
It will make your proofs clearer, and it will decrease the chance that
you forget a key step (such as checking the base case).

\subsection{A Clean Writeup}

The proof of Theorem~\ref{sum-to-n-again-theorem} given above is perfectly
valid; however, it contains a lot of extraneous explanation that you won't
usually see in induction proofs.  The writeup below is closer to what you
might see in print and should be prepared to produce yourself.

\begin{proof}[Proof of Theorem~\ref{sum-to-n-again-theorem}]
We use induction.  The induction hypothesis, $P(n)$, will be
equation~\eqref{sum-to-n-again}.

\textbf{Base case:} $P(0)$ is true, because both sides of
equation~\eqref{sum-to-n-again} equal zero when $n=0$.

\textbf{Inductive step:} Assume that $P(n)$ is true, where
$n$ is any nonnegative integer.  Then
\begin{align*}
1 + 2 + 3 + \cdots + n + (n+1)
    & = \frac{n(n+1)}{2} + (n+1) & \text{(by induction hypothesis)}\\
    & = \frac{(n+1)(n+2)}{2}  & \text{(by simple algebra)}
\end{align*}
which proves $P(n+1)$.

So it follows by induction that $P(n)$ is true for all nonnegative $n$.
\end{proof}

Induction was helpful for \emph{proving the correctness} of this
summation formula, but not helpful for \emph{discovering} it in the
first place.   Tricks and methods for finding such formulas will be
covered in Part~III of the text.

\begin{editingnotes}
\subsubsection{Powers of Odd Numbers}

\begin{fact*}
The $n$th power of an odd number is odd, for all nonnegative integers, $n$.
\end{fact*}
The proof of Theorem~\ref{thm:sqrt2irr_by_contra} that $\sqrt[n]{2}$
is irrational used this ``obvious'' fact.  Instead of taking it for
granted, we can prove this fact by induction.  The proof will require
a simple Lemma.
\begin{lemma*}
The product of two odd numbers is odd.
\end{lemma*}
To prove the Lemma, note that the odd numbers are, by definition, the
numbers of the form $2k+1$ where $k$ is an integer.  But
\[
(2k+1)(2k'+1) = 2(2kk' + k + k')+1,
\]
so the product of two odd numbers also has the form of an odd number,
which proves the Lemma.

Now we will prove the Fact using the induction hypothesis
\[
P(n) \eqdef \text{if $a$ is an odd integer, then so is $a^{n}$}.
\]

The base case $P(0)$ holds because $a^{0} =1$, and 1 is odd.

For the inductive step, suppose $n\geq 0$, $a$ is an odd number and $P(n)$
holds.  So $a^n$ is an odd number.  Therefore, $a^{n+1} = a^{n}a$ is a
product of odd numbers, and by the Lemma $a^{n+1}$ is also odd.  This
proves $P(n+1)$, and we conclude by induction that $P(n)$ holds for
nonnegative integers $n$.
\end{editingnotes}


\subsection{A More Challenging Example}

\begin{figure}
\begin{center}
\begin{picture}(100,100)(-20,-20)
\put(40,-10){\makebox(0,0){$2^n$}}
\put(-10,40){\makebox(0,0){$2^n$}}
\put(0,0){\line(1,0){80}}
\put(0,10){\line(1,0){80}}
\put(0,20){\line(1,0){80}}
\put(0,30){\line(1,0){80}}
\put(0,40){\line(1,0){80}}
\put(0,50){\line(1,0){80}}
\put(0,60){\line(1,0){80}}
\put(0,70){\line(1,0){80}}
\put(0,80){\line(1,0){80}}
\put(0,0){\line(0,1){80}}
\put(10,0){\line(0,1){80}}
\put(20,0){\line(0,1){80}}
\put(30,0){\line(0,1){80}}
\put(40,0){\line(0,1){80}}
\put(50,0){\line(0,1){80}}
\put(60,0){\line(0,1){80}}
\put(70,0){\line(0,1){80}}
\put(80,0){\line(0,1){80}}
\end{picture}
\end{center}
\caption{A $2^n \times 2^n$ courtyard for $n = 3$.}
\label{fig:2nx2n-tile}
\end{figure}


During the development of MIT's famous Stata Center, as costs rose
further and further beyond budget, there were some radical fundraising
ideas.  One rumored plan was to install a big courtyard with
dimensions $2^n \times 2^n$ (as shown in Figure~\ref{fig:2nx2n-tile}
for the case where $n = 3$) and to have one of the central
squares\footnote{In the special case $n = 0$, the whole courtyard
  consists of a single central square; otherwise, there are four
  central squares.} be occupied by a statue of a wealthy potential
donor (who we will refer to as ``Bill'', for the purposes of
preserving anonymity). A complication was that the building's
unconventional architect, Frank Gehry, was alleged to require that
only special L-shaped tiles (show in Figure~\ref{fig:Ltile}) be used
for the courtyard.  It was quickly determined that a courtyard meeting
these constraints exists, at least for $n = 2$.  (See
Figure~\ref{fig:2Ltile}.)  But what about for larger values of~$n$?
Is there a way to tile a $2^n \times 2^n$ courtyard with L-shaped
tiles and a statue in the center?  Let's try to prove that this is so.

\begin{figure}
\begin{center}
\thicklines
\begin{picture}(50,50)
\put(0,0){\line(1,0){50}}
\put(50,0){\line(0,1){50}}
\put(50,50){\line(-1,0){25}}
\put(25,50){\line(0,-1){25}}
\put(25,25){\line(-1,0){25}}
\put(0,25){\line(0,-1){25}}
\thinlines
\put(25,25){\line(1,0){25}}
\put(25,25){\line(0,-1){25}}
\end{picture}
\end{center}
\caption{The special L-shaped tile.}
\label{fig:Ltile}
\end{figure}

\begin{figure}
\begin{center}
\begin{picture}(100,100)
\thicklines
\put(0,0){\line(1,0){100}}
\put(25,25){\line(1,0){50}}
\put(25,75){\line(1,0){50}}
\put(0,100){\line(1,0){100}}
\put(0,50){\line(1,0){25}}
\put(75,50){\line(1,0){25}}
\put(0,0){\line(0,1){100}}
\put(25,25){\line(0,1){50}}
\put(75,25){\line(0,1){50}}
\put(100,0){\line(0,1){100}}
\put(50,50){\line(0,1){25}}
\put(50,50){\line(1,0){25}}
\put(50,0,){\line(0,1){25}}
\put(50,75){\line(0,1){25}}
\put(62.5,62.5){\makebox(0,0){\textbf{B}}}
\end{picture}
\end{center}
\caption{A tiling using L-shaped tiles for $n = 2$ with Bill in a
  center square.}
\label{fig:2Ltile}
\end{figure}

\begin{theorem}\label{bill}
For all $n \geq 0$ there exists a tiling of a $2^n \times 2^n$
courtyard with Bill in a central square.
\end{theorem}

\begin{proof}
{\em (doomed attempt)} The proof is by induction.  Let $P(n)$ be the
proposition that there exists a tiling of a $2^n \times 2^n$ courtyard
with Bill in the center.

\textbf{Base case:} $P(0)$ is true because Bill fills the whole courtyard.

\textbf{Inductive step:} Assume that there is a tiling of a
$2^n \times 2^n$ courtyard with Bill in the center for some $n \geq
0$.  We must prove that there is a way to tile a $2^{n+1} \times
2^{n+1}$ courtyard with Bill in the center \dots.
\end{proof}

Now we're in trouble!  The ability to tile a smaller courtyard with Bill
in the center isn't much help in tiling a larger courtyard with Bill in
the center.  We haven't figured out how to bridge the gap between $P(n)$
and $P(n+1)$.

So if we're going to prove Theorem~\ref{bill} by induction, we're going to
need some \emph{other} induction hypothesis than simply the statement
about $n$ that we're trying to prove.

%Hide after lecture:

%We'll describe some hypotheses that do work in class this week.

%end hide

%\iffalse  %Unhide after lecture:

When this happens, your first fallback should be to look for a
\emph{stronger} induction hypothesis; that is, one which implies
your previous hypothesis.  For example, we could make $P(n)$ the
proposition that for \emph{every} location of Bill in a $2^n \times
2^n$ courtyard, there exists a tiling of the remainder.

This advice may sound bizarre: ``If you can't prove something, try to
prove something grander!''  But for induction arguments, this makes sense.
In the inductive step, where you have to prove $P(n) \QIMPLIES P(n+1)$,
you're in better shape because you can {\em assume} $P(n)$, which is now a
more powerful statement.  Let's see how this plays out in the case of
courtyard tiling.

\begin{proof}[Proof (successful attempt)]
The proof is by induction.  Let $P(n)$ be
the proposition that for every location of Bill in a $2^n \times 2^n$
courtyard, there exists a tiling of the remainder.

\textbf{Base case:} $P(0)$ is true because Bill fills the
whole courtyard.

\textbf{Inductive step:} Assume that $P(n)$ is true for some
$n \geq 0$; that is, for every location of Bill in a $2^n \times 2^n$
courtyard, there exists a tiling of the remainder.  Divide the
$2^{n+1} \times 2^{n+1}$ courtyard into four quadrants, each $2^n
\times 2^n$.  One quadrant contains Bill (\textbf{B} in the diagram
below).  Place a temporary Bill (\textbf{X} in the diagram) in each of
the three central squares lying outside this quadrant as shown in
Figure~\ref{fig:bill-strong-induction}.

\begin{figure}
\begin{center}
\begin{picture}(148,148)(-20,-20)
\thinlines
\put(0,0){\line(1,0){128}}
\put(0,0){\line(0,1){128}}
\put(128,128){\line(-1,0){128}}
\put(128,128){\line(0,-1){128}}
\put(64,0){\line(0,1){128}}
\put(0,64){\line(1,0){128}}
\put(56,72){\makebox(0,0){\textbf{X}}}
\put(56,56){\makebox(0,0){\textbf{X}}}
\put(72,56){\makebox(0,0){\textbf{X}}}
\put(48,80){\line(1,0){16}}
\put(48,48){\line(1,0){32}}
\put(80,48){\line(0,1){16}}
\put(48,48){\line(0,1){32}}
\put(96,96){\framebox(16,16){\textbf{B}}}
\put(32,-10){\makebox(0,0){$2^n$}}
\put(96,-10){\makebox(0,0){$2^n$}}
\put(-10,32){\makebox(0,0){$2^n$}}
a\put(-10,96){\makebox(0,0){$2^n$}}
\end{picture}
\end{center}
\caption{Using a stronger inductive hypothesis to prove
  Theorem~\ref{bill}.}
\label{fig:bill-strong-induction}
\end{figure}

Now we can tile each of the four quadrants by the induction
assumption.  Replacing the three temporary Bills with a single
L-shaped tile completes the job.  This proves that $P(n)$ implies
$P(n+1)$ for all $n \geq 0$.  Thus $P(m)$ is true for all $n \in
\naturals$, and the theorem follows as a special case, where we put
Bill in a central square.
\end{proof}

This proof has two nice properties.  First, not only does the argument
guarantee that a tiling exists, but also it gives an algorithm for
finding such a tiling.  Second, we have a stronger result: if Bill
wanted a statue on the edge of the courtyard, away from the pigeons,
we could accommodate him!

Strengthening the induction hypothesis is often a good move when an
induction proof won't go through.  But keep in mind that the stronger
assertion must actually be \emph{true}; otherwise, there isn't much hope
of constructing a valid proof!  Sometimes finding just the right induction
hypothesis requires trial, error, and insight.  For example,
mathematicians spent almost twenty years trying to prove or disprove the
conjecture that ``Every planar graph is
5-choosable''\footnote{5-choosability is a slight generalization of
  5-colorability.  Although every planar graph is 4-colorable and
  therefore 5-colorable, not every planar graph is 4-choosable.  If this
  all sounds like nonsense, don't panic.  We'll discuss graphs, planarity,
  and coloring in Part~II of the text.}.  Then, in 1994, Carsten Thomassen
gave an induction proof simple enough to explain on a napkin.  The key
turned out to be finding an extremely clever induction hypothesis; with
that in hand, completing the argument was easy!

%\fi  %end UnHide after lecture

\subsection{A Faulty Induction Proof}

If we have done a good job in writing this text, right about now you
should be thinking, ``Hey, this induction stuff isn't so hard after
all---just show $P(0)$ is true and that $P(n)$ implies $P(n+1)$ for
any number~$n$.''  And, you would be right, although sometimes when
you start doing induction proofs on your own, you can run into
trouble.  For example, we will now attempt to ruin your day by using
induction to ``prove'' that all horses are the same color.  And just
when you thought it was safe to skip class and work on your robot
program instead.  Bummer!

\begin{falsethm*}
All horses are the same color.
\end{falsethm*}

Notice that no $n$ is mentioned in this assertion, so we're going to have
to reformulate it in a way that makes an $n$ explicit.  In particular,
we'll (falsely) prove that

\begin{falsethm}\label{horses}
In every set of $n \geq 1$ horses, all the horses are the same color.
\end{falsethm}

This a statement about all integers $n \geq 1$ rather $\geq 0$, so it's
natural to use a slight variation on induction: prove $P(1)$ in the base
case and then prove that $P(n)$ implies $P(n+1)$ for all $n \geq 1$ in the
inductive step.  This is a perfectly valid variant of induction and is
{\em not} the problem with the proof below.

\begin{falseproof}

The proof is by induction on $n$.  The induction hypothesis, $P(n)$, will be
\begin{equation}\label{horsehyp}
\text{In every set of $n$ horses, all are the same color.}
\end{equation}

\textbf{Base case:} ($n=1$).  $P(1)$ is true, because in a set of horses
of size 1, there's only one horse, and this horse is definitely the same
color as itself.

\textbf{Inductive step:} Assume that $P(n)$ is true for some $n \geq 1$.
That is, assume that in every set of $n$ horses, all are the same color.
Now consider a set of $n+1$ horses:
%
\[
h_1,\ h_2,\ \dots,\ h_n,\ h_{n+1}
\]
%
By our assumption, the first $n$ horses are the same color:
%
\[
\underbrace{h_1,\ h_2,\ \dots,\ h_n,}_{\text{same color}}\ h_{n+1}
\]
%
Also by our assumption, the last $n$ horses are the same color:
%
\[
h_1,\ \underbrace{h_2,\ \dots,\ h_n,\ h_{n+1}}_{\text{same color}}
\]
%
So $h_1$ is the same color as the remaining horses besides $h_{n+1}$
---that is, $h_2$, \ldots, $h_n$) ---and likewise $h_{n+1}$ is the same color
as the remaining horses besides $h_1$ ---$h_2$, \ldots, $h_n$.
Since $h_1$ and $h_{n+1}$ are the same color as $h_2$, \ldots, $h_n$,
horses $h_1$, $h_2$, \dots, $h_{n+1}$ must all be the same color, and so
$P(n+1)$ is true.  Thus, $P(n)$ implies $P(n+1)$.

By the principle of induction, $P(n)$ is true for all $n \geq 1$.
\end{falseproof}
We've proved something false!  Is math broken?  Should we all become
poets?  No, this proof has a mistake.

The first error in this argument is in the sentence that begins ``So
$h_1$ is the same color as the remaining horses besides $h_{n+1}$
---$h_2$, \dots, $h_n$)\dots''

The ``$\dots$'' notation in the expression ``$h_1$, $h_2$, \dots,
$h_n$, $h_{n+1}$'' creates the impression that there are some
remaining horses (namely $h_2$, \dots, $h_n$) besides $h_1$ and
$h_{n+1}$.  However, this is not true when $n = 1$.  In that case,
$h_1$, $h_2$, \dots, $h_n$, $h_{n+1}$ = $h_1$, $h_2$ and there are no
remaining horses besides $h_1$ and $h_{n+1}$.  So $h_1$ and $h_2$ need
not be the same color!

This mistake knocks a critical link out of our induction argument.  We
proved $P(1)$ and we \emph{correctly} proved $P(2) \implies P(3)$, $P(3)
\implies P(4)$, etc.  But we failed to prove $P(1) \implies P(2)$, and so
everything falls apart: we can not conclude that $P(2)$, $P(3)$, etc., are
true.  And, of course, these propositions are all false; there are
sets of $n$ non-uniformly-colored horses for all $n \ge 2$.

Students sometimes claim that the mistake in the proof is because
$P(n)$ is false for $n \geq 2$, and the proof assumes something false,
namely, $P(n)$, in order to prove $P(n+1)$.  You should think about
how to explain to such a student why this claim would get no credit on
a Math for Computer Science exam.

\subsection{Induction versus Well Ordering}\label{versusWO}

The \idx{Induction Rule} looks nothing like the \idx{Well Ordering
  Principle}, but these two proof methods are closely related.  In fact,
as the examples above suggest, we can take any Well Ordering proof and
reformat it into an Induction proof.  Conversely, it's equally easy to
take any Induction proof and reformat it into a Well Ordering proof.

\begin{editingnotes}
Here's how to reformat an induction proof and into a Well
Ordering proof : suppose that we have a proof by induction with
hypothesis $P(n)$.  Then we start a Well Ordering proof by assuming the
set of counterexamples to $P$ is nonempty.  Then by Well Ordering there is
a smallest counterexample, $s$, that is, a smallest $s$ such that $P(s)$
is false.

Now we use the proof of $P(0)$ that was part of the Induction proof to
conclude that $s$ must be greater than 0.  Also since $s$ is the smallest
counterexample, we can conclude that $P(s-1)$ must be true.  At this point
we reuse the proof of the inductive step in the Induction proof, which
shows that since $P(s-1)$ true, then $P(s)$ is also true.  This
contradicts the assumption that $P(s)$ is false, so we have the
contradiction needed to complete the Well Ordering Proof that $P(n)$ holds
for all $n \in \naturals$.
\end{editingnotes}

So what's the difference?  Well, sometimes induction proofs are clearer
because they resemble recursive procedures that reduce handling an input
of size $n+1$ to handling one of size $n$.  On the other hand, Well
Ordering proofs sometimes seem more natural, and also come out slightly
shorter.  The choice of method is really a matter of style and is up
to you.


%% Strong Induction %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Strong Induction}\label{sec:strong-induction}

Strong induction is a variation of ordinary induction that is useful
when the predicate $P(n+1)$ naturally depends on $P(a)$ for values of
$a < n$.  As with ordinary induction, strong induction is useful to
prove that a predicate $P(n)$ is true for all $n \in \naturals$.

\subsection{A Rule for Strong Induction}

\textbox{
\textbf{Principle of Strong Induction. }  Let $P(n)$ be a predicate.  If
\begin{itemize}
\item $P(0)$ is true, and
\item for all $n \in \naturals$, $P(0)$, $P(1)$, \dots, $P(n)$
\emph{together} imply $P(n+1)$,
\end{itemize}
then $P(n)$ is true for all $n \in \naturals$.
}

The only change from the ordinary induction principle is that strong
induction allows you to assume more stuff in the inductive step of your
proof!  In an ordinary induction argument, you assume that $P(n)$ is true
and try to prove that $P(n+1)$ is also true.  In a strong induction
argument, you may assume that $P(0)$, $P(1)$, \dots, and $P(n)$ are
\emph{all} true when you go to prove $P(n+1)$.  These extra assumptions
can only make your job easier.  Hence the name: \emph{strong}
induction.

Formulated as a proof rule, strong induction is
\begin{rul*} \textbf{Strong Induction Rule}
\Rule{P(0), \quad \forall n \in \naturals. \;
    \bigl(P(0) \land P(1) \land \dots \land P(m) \bigr) \QIMPLIES P(n+1)]}
{\forall m \in \naturals.\, P(m)}
\end{rul*}

The template for strong induction proofs is identical to the template
given in Section~\ref{templ-induct-proofs} except for two things:
\begin{itemize}

\item
you should state that your proof is by strong induction, and

\item
you can assume that $P(0)$, $P(1)$, \dots, $P(n)$ are all true instead
of only $P(n)$ during the inductive step.

\end{itemize}

\subsection{Some Examples}

\subsubsection{Products of Primes}

As a first example, we'll use strong induction to re-prove
Theorem~\ref{factor_into_primes} which we previously proved using \idx{Well
Ordering}.

\begin{lemma}\label{prim}
Every integer greater than 1 is a product of primes.
\end{lemma}

\begin{proof}

We will prove Lemma~\ref{prim} by strong induction, letting the induction
hypothesis, $P(n)$, be
\[
n \text{ is a product of primes}.
\]
So Lemma~\ref{prim} will follow if we prove that $P(n)$ holds for all $n
\geq 2$.

\textbf{Base Case:} ($n=2$) $P(2)$ is true because $2$ is prime, and so it is
a length one product of primes by convention.

\textbf{Inductive step:} Suppose that $n \geq 2$ and that $i$ is a product
of primes for every integer $i$ where $2 \leq i < n+1$.  We must show that
$P(n+1)$ holds, namely, that $n+1$ is also a product of primes.  We argue
by cases:

If $n+1$ is itself prime, then it is a length one product of primes by
convention, and so $P(n+1)$ holds in this case.

Otherwise, $n + 1$ is not prime, which by definition means $n+1 = km$ for
some integers $k,m$ such that $2 \leq k,m < n+1$.  Now by the strong induction
hypothesis, we know that $k$ is a product of primes.  Likewise,
$m$ is a product of primes.  It follows immediately that $km = n$ is
also a product of primes.  Therefore, $P(n+1)$ holds in this case as well.

So $P(n+1)$ holds in any case, which completes the proof by strong
induction that $P(n)$ holds for all~$n \ge 2$.

\end{proof}

\begin{editingnotes}
Here's a fallacious argument: every number can be factored uniquely
into primes.  Apply the same proof as before, adding ``uniquely'' to
the inductive hypothesis.  The problem is that even if $n=ab$ and
$a,b$ have unique factorizations, it is still possible that $n=cd$ for
different $c$ and $d$, producing a different factorization of $n$.

The argument is false, but the claim is true and is known as the
fundamental theorem of arithmetic.

\end{editingnotes}

\subsubsection{Making Change}

The country Inductia, whose unit of currency is the Strong, has coins
worth 3\sg\ (3 Strongs) and 5\sg.  Although the Inductians have some
trouble making small change like 4\sg\ or 7\sg, it turns out that they
can collect coins to make change for any number that is at least 8
Strongs.

Strong induction makes this easy to prove for $n+1 \ge 11$, because then
$(n+1)-3 \ge 8$, so by strong induction the Inductians can make change for
exactly $(n+1)-3$ Strongs, and then they can add a 3\sg\ coin to get
$(n+1)\sg$.  So the only thing to do is check that they can make change
for all the amounts from 8 to 10\sg, which is not too hard to do.

Here's a detailed writeup using the official format:

\begin{proof}

  We prove by strong induction that the Inductians can make change for any
  amount of at least 8\sg.  The induction hypothesis, $P(n)$ will be:
\begin{quote}
There is a collection of coins whose value is $n+8$ Strongs.
\end{quote}

\iffalse
\begin{editingnotes}
Notice that $P(n)$ is an implication.  When the hypothesis of an
implication is false, we know the whole implication is true.  In this
situation, the implication is said to be \emph{vacuously} true.  So $P(n)$
will be vacuously true whenever $n < 8$.
\iffalse
\footnote{Another approach that
avoids these vacuous cases is to define
\[
Q(n) \eqdef \text{there is a collection of coins whose value is $n+8\sg$},
\]
and prove that $Q(n)$ holds for all $n \geq 0$.
\iffalse
The solution to
\href{http://courses.csail.mit.edu/6.042/spring06/solutions/cp3fsol.pdf}
{Class Problem 1 from Spring '06, Friday, Feb. 24} uses this approach.\fi
}\fi

We now proceed with the induction proof:
\end{editingnotes}\fi

\textbf{Base case:} $P(0)$ is true because a 3\sg\ coin together with
a 5\sg coin makes 8\sg.

\textbf{Inductive step:}  We assume $P(m)$ holds for all $m \leq n$, and
prove that $P(n+1)$ holds.  We argue by cases:

\textbf{Case} ($n+1$ = 1): We have to make $(n+1) +8 =9$\sg.  We can do this using three 3\sg\ coins.

\textbf{Case} ($n+1$ = 2): We have to make $(n+1) +8 =10$\sg.  Use two
5\sg\ coins.

\textbf{Case} ($n+1 \geq 3$): Then $0 \leq n - 2 \leq n$, so by the
strong induction hypothesis, the Inductians can make change for $n-2$
Strong.  Now by adding a 3\sg\ coin, they can make change for
$(n+1)\sg$.

So in any case, $P(n+1)$ is true, and we conclude by strong induction
that for all $n \ge 0$, the Inductians can make change for $n+8$
Strong.  That is, they can make change for any number of eight or more
Strong.

\end{proof}

\subsubsection{The Stacking Game}

Here is another exciting game that's surely about to sweep the
nation!

\hyperdef{stack}{game}{You} begin with a stack of $n$ boxes.  Then you
make a sequence of moves.  In each move, you divide one stack of boxes
into two nonempty stacks.  The game ends when you have $n$ stacks, each
containing a single box.  You earn points for each move; in particular, if
you divide one stack of height $a + b$ into two stacks with heights $a$
and $b$, then you score $ab$ points for that move.  Your overall score is
the sum of the points that you earn for each move.  What strategy should
you use to maximize your total score?

As an example, suppose that we begin with a stack of $n = 10$ boxes.
Then the game might proceed as shown in figure~\ref{fig:stacking-10}.
Can you find a better strategy?
\begin{figure}%
\[
\begin{array}{cccccccccccl}
\multicolumn{10}{c}{\textbf{Stack Heights}} & \quad & \textbf{Score} \\
\underline{10}&&&&&&&&& && \\
5&\underline{5}&&&&&&&& && 25 \text{ points} \\
\underline{5}&3&2&&&&&&& && 6 \\
\underline{4}&3&2&1&&&&&& && 4 \\
2&\underline{3}&2&1&2&&&&& && 4 \\
\underline{2}&2&2&1&2&1&&&& && 2 \\
1&\underline{2}&2&1&2&1&1&&& && 1 \\
1&1&\underline{2}&1&2&1&1&1&& && 1 \\
1&1&1&1&\underline{2}&1&1&1&1& && 1 \\
1&1&1&1&1&1&1&1&1&1 && 1 \\ \hline
\multicolumn{10}{r}{\textbf{Total Score}} & = & 45 \text{ points}
\end{array}
\]
\caption{An example of the stacking game with $n = 10$ boxes.  On each
line, the underlined stack is divided in the next step.}
\label{fig:stacking-10}
\end{figure}

Let's use strong induction to analyze the unstacking game.  We'll prove
that your score is determined entirely by the number of boxes---your
strategy is irrelevant!

\begin{theorem}\label{stacking}
Every way of unstacking $n$ blocks gives a score of $n(n-1)/2$ points.
\end{theorem}

There are a couple technical points to notice in the proof:

\begin{itemize}

\item The template for a strong induction proof mirrors the template
for ordinary induction.

\item As with ordinary induction, we have some freedom to adjust indices.
In this case, we prove $P(1)$ in the base case and prove that $P(1),
\dots, P(n)$ imply $P(n+1)$ for all $n \geq 1$ in the inductive step.

\end{itemize}

\begin{proof}
The proof is by strong induction.  Let $P(n)$ be the proposition that
every way of unstacking $n$ blocks gives a score of $n(n-1)/2$.

\textbf{Base case:} If $n = 1$, then there is only one
block.  No moves are possible, and so the total score for the game is
$1(1 - 1)/2 = 0$.  Therefore, $P(1)$ is true.

\textbf{Inductive step:} Now we must show that $P(1)$, \dots, $P(n)$ imply
$P(n+1)$ for all $n \geq 1$.  So assume that $P(1)$, \dots, $P(n)$ are all
true and that we have a stack of $n+1$ blocks.  The first move must split
this stack into substacks with positive sizes $a$ and $b$ where $a+b =
n+1$ and $0<a,b\leq n$.  Now the total score for the game is the sum of
points for this first move plus points obtained by unstacking the two
resulting substacks:
%
\begin{align*}
\text{total score}
    & = \text{(score for 1st move)} \\
    & \quad + \text{(score for unstacking $a$ blocks)} \\
    & \quad + \text{(score for unstacking $b$ blocks)} \\
    & = ab + \frac{a(a-1)}{2} + \frac{b(b-1)}{2} & \text{by $P(a)$ and $P(b)$}\\
    & = \frac{(a+b)^2-(a+b)}{2} = \frac{(a+b)((a+b)-1)}{2}\\
    & = \frac{(n+1)n}{2}
\end{align*}
%
This shows that $P(1)$, $P(2)$, \dots, $P(n)$ imply $P(n+1)$.

Therefore, the claim is true by strong induction.
\end{proof}
%\fi  %end unHide

\subsection{Strong Induction versus Induction} 

Is strong induction really ``stronger'' than ordinary induction?  It
certainly looks that way.  After all, you can assume a lot more when
proving the induction step.  But actually, anything that can be proved
with strong induction can also be proved with ordinary induction---you
just need to use a ``stronger'' induction hypothesis.

Which method should you use?  Whichever you find easier.  But
whichever method you choose, be sure to state the method up front so
that the reader can understand and more easily verify your proof.

\section{Invariants}

One of the most important uses of induction in computer science
involves proving that a program or process preserves one or more
desirable properties as it proceeds.  A property that is preserved
through a series of operations or steps is known as an
\term{invariant}.  Examples of desirable invariants include properties
such as a variable never exceeding a certain value or becoming
negative, the altitude of a plane never dropping below 1,000 feet
without the wingflaps and landing gear being deployed, and the
temperature of a nuclear reactor never exceeding the threshold for a
meltdown.

We typically use induction to prove that a proposition is an
invariant.  In particular, we show that the proposition is true at the
beginning (this is the base case) and that if it is true after $t$
steps have been taken, it will also be true after step~$t + 1$ (this
is the inductive step).  We can then use the induction principle to
conclude that the proposition is indeed an invariant, namely, that it will
always hold.

\subsection{A Simple Example: The Diagonally-Moving Robot}

Invariants are useful in systems that have a \emph{start state} or
configuration and a well-defined series of \emph{steps} during which
the system can change state.\footnote{Such systems are known as state
  machines and we will study them in greater detail in
  Chapter{chap:state-machines}.}  For example, suppose that you have a
robot that can walk across diagonals on an infinite 2-dimensional
grid.  The robot starts at position~$(0, 0)$ and at each step it moves
up or down by 1~unit vertically and left or right by 1~unit
horizontally.  To be clear, the robot must move by exactly 1~unit in
each dimension during each step, since it can only traverse diagonals.

In this example, the \emph{state} of the robot at any time can be
specified by a coordinate pair~$(x, y)$ that denotes the robot's
position.  The \emph{start state} is~$(0, 0)$ since it is given that
the robot starts at that position.  After the first step, the robot
could be in states $(1, 1)$, $(1, -1)$, $(-1, 1)$, or $(-1, -1)$.
After two steps, there are 9 possible states for the robot,
including~$(0, 0)$.

Can the robot ever reach position~$(1, 0)$?

After playing around with the robot for a bit, it will become apparent
that the robot will never be able to reach position~$(1, 0)$.  This is
because the robot can only reach positions~$(x, y)$ for which $x + y$
is even.  This crucial observation quickly leads to the formulation of
a predicate
\begin{equation*}
    P(t) :: \text{if the robot is in state $(x, y)$ after $t$ steps,
      then $x + y$ is even}
\end{equation*}
which we can prove to be an invariant by induction.

\begin{theorem}\label{th:diag-robot}
The sum of robot's coordinates is always even.
\end{theorem}

\begin{proof}
We will prove that $P$ is an invariant by induction.

$P(0)$ is true since the robot starts at~$(0, 0)$ and $0 + 0$ is even.

Assume that $P(t)$ is true for the inductive step.  Let $(x, y)$ be
the position of the robot after $t$ steps.  Since $P(t)$ is assumed to
be true, we know that $x + y$ is even.  There are four cases to
consider for step~$t + 1$, depending on which direction the robot
moves.
\begin{description}

\item[Case 1]
The robot moves to $(x + 1, y + 1)$.  Then the sum of the coordinates
is $x + y + 2$, which is even, and so $P(t+1)$ is true.

\item[Case 2]
The robot moves to $(x + 1, y - 1)$.  The the sum of the coordinates
is $x + y$, which is even, and so $P(t + 1)$ is true.

\item[Case 3]
The robot moves to $(x - 1, y + 1)$.  The the sum of the coordinates
is $x + y$, as with Case~2, and so $P(t + 1)$ is true.

\item[Case 4]
The robot moves to $(x - 1, y - 1)$.  The the sum of the coordinates
is $x + y - 2$, which is even, and so $P(t + 1)$ is true.

\end{description}
In every case, $P(t + 1)$ is true and so we have proved $P(t)
\QIMPLIES P(t + 1)$ and so, by induction, we know that $P(t)$ is true
for all~$t \ge 0$.
\end{proof}

\begin{corollary}\label{cor:diag-robot}
The robot can never reach position~$(1, 0)$.
\end{corollary}

\begin{proof}
By theorem~\ref{th:diag-robot}, we know the robot can only reach
positions with coordinates that sum to an even number, and thus it
cannot reach position~$(1, 0)$.
\end{proof}

Since this was the first time we proved that a predicate was an
invariant, we were careful to go through all four cases in gory
detail.  As you become more experienced with such proofs, you will
likely become more brief as well.  Indeed, if we were going through
the proof again at a later point in the text, we might simply note
that the sum of the coordinates after step~$t + 1$ can be only $x +
y$, $x + y + 2$ or $x + y - 2$ and therefore that it is even.

\subsection{The Invariant Method}

In summary, if you would like to prove that some property
\textsc{nice} holds for every step of a process, then it is often
helpful to use the following method:
\begin{itemize}

\item
Define $P(t)$ to be the predicate that \textsc{nice} holds immediately
after step~$t$.

\item
Show that $P(0)$ is true, namely that \textsc{nice} holds for the
start state.

\item
Show that
\begin{equation*}
    \forall t \in \naturals. \; P(t) \QIMPLIES P(t + 1),
\end{equation*}
namely, that for any $t \ge 0$), if \textsc{nice} holds immediately
after step~$t$, it must also hold after the following step.

\end{itemize}

\subsection{A More Challenging Example: The
  15-Puzzle}\label{sec:15puzzle}

In the late 19th century, Noyes Chapman, a postmaster in Canastota,
New York, invented the 15-puzzle\footnote{Actually, there is a dispute
about who really invented the 15-puzzle.  Sam Lloyd, a well-known
puzzle designer, claimed to be the inventor, but this claim has since
been discounted.}, which consisted of a $4\times 4$ grid containing 15
numbered blocks in which the 14-block and the 15-block were out of
order.  The objective was to move the blocks one at a time into an
adjacent hole in the grid so as to eventually get all 15 blocks into
their natural order.  A picture of the 15-puzzle is shown in
Figure~\ref{fig:15puzzle} along with the configuration after the
12-block is moved into the hole below.  The desired final
configuration is shown in Figure~\ref{fig:15puzzlesolved}.

\begin{figure}
\centering

\subfloat[]{
\begin{tabular}{|c|c|c|c|}
\hline
1 & 2 & 3 & 4 \\\hline
5 & 6 & 7 & 8 \\\hline
9 & 10 & 11 & 12 \\\hline
13 & 15 & 14 &  \\\hline
\end{tabular}
}

\subfloat[]{%
\begin{tabular}{|c|c|c|c|}
\hline
1 & 2 & 3 & 4 \\\hline
5 & 6 & 7 & 8 \\\hline
9 & 10 & 11 &  \\\hline
13 & 14 & 15 & 12  \\\hline
\end{tabular}
}

\caption{The 15-puzzle in its starting configuration~(a) and after the
12-block is moved into the hole below~(b). \textcolor{red}{I'll fix
  the formatting later---dmj.}}
\label{fig:15puzzle}
\end{figure}

\begin{figure}

\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
1 & 2 & 3 & 4 \\\hline
5 & 6 & 7 & 8 \\\hline
9 & 10 & 11 & 12 \\\hline
13 & 14 & 15 &  \\\hline
\end{tabular}
\end{center}

\caption{The desired final configuration for the 15-puzzle.  Can it be
  achieved by only moving one block at a time into an adjacent hole?
  \textcolor{red}{I'll fix the formatting later---dmj.}}
\label{fig:15puzzlesolved}
\end{figure}

The 15-puzzle became very popular in North America and Europe and is
still sold in game and puzzle shops today.  Prizes were offered for
its solution, but it is doubtful that they were ever awarded, since it
is impossible to get from the configuration in
Figure~\ref{fig:15puzzle} to the configuration in
Figure~\ref{fig:15puzzlesolved} by only moving one block at a time
into an adjacent hole.  The proof of this fact is a little tricky so
we have left it for you to figure out on your own.  Instead, we will
prove that the analogous task for the much easier 8-puzzle cannot be
performed.  Both proofs, of course, make use of the Invariant Method.

\subsection{The 8-Puzzle}

In the 8-Puzzle, there are 8 lettered tiles (A--H) and a blank square
arranged in a $3 \by 3$ grid.  Any lettered tile adjacent to the blank
square can be slid into the blank.  For example, a sequence of two
moves is illustrated in Figure~\ref{fig:8puzzleA}.

\begin{figure}

\begin{equation*}
\begin{array}{|c|c|c|}
\hline
A & B & C \\ \hline
D & E & F \\ \hline
H & G &   \\ \hline
\multicolumn{3}{c}{(a)}
\end{array}
%
\to
%
\begin{array}{|c|c|c|}
\hline
A & B & C \\ \hline
D & E & F \\ \hline
H &   & \mathbf{G}  \\ \hline
\multicolumn{3}{c}{(b)}
\end{array}
%
\to
%
\begin{array}{|c|c|c|}
\hline
A & B & C \\ \hline
D &   & F \\ \hline
H & \mathbf{E} & G  \\ \hline
\multicolumn{3}{c}{(c)}
\end{array}
\end{equation*}

\caption{The 8-Puzzle in its initial configuration~(a) and after
  one~(b) and two~(c) possible moves.
\textcolor{red}{I'll fix the formatting later---dmj.}}
\label{fig:8puzzleA}
\end{figure}

In the initial configuration shown in Figure~\ref{fig:8puzzleA}(a),
the G and H tiles are out of order.  We can find a way of swapping G
and~H so that they are in the right order, but then other letters may
be out of order.  Can you find a sequence of moves that puts these two
letters in correct order, but returns every other tile to its original
position?  Some experimentation suggests that the answer is probably
``no,'' and we will prove that is so by finding an \idx{invariant},
namely, a property of the puzzle that is always maintained, no matter
how you move the tiles around.  If we can then show that putting all
the tiles in the correct order would violate the invariant, then we
can conclude that the puzzle cannot be solved.

\begin{theorem}\label{thm:8puzzle}
No sequence of legal moves transforms the configuration in
Figure~\ref{fig:8puzzleA}(a) into the configuration in
Figure~\ref{fig:8puzzlesolved}.
\end{theorem}

\begin{figure}[h]
\begin{equation*}
\begin{array}{|c|c|c|}
\hline
A & B & C \\ \hline
D & E & F \\ \hline
\mathbf{G} & \mathbf{H} &   \\ \hline
\end{array}
\end{equation*}

\caption{The desired final configuration of the 8-puzzle.}
\label{fig:8puzzlesolved}
\end{figure}

We'll build up a sequence of observations, stated as lemmas.  Once we
achieve a critical mass, we'll assemble these observations into a
complete proof of Theorem~\ref{thm:8puzzle}.

Define a \emph{row move} as a move in which a tile slides horizontally
and a \emph{column move} as one in which the tile slides vertically.
Assume that tiles are read top-to-bottom and left-to-right like
English text, that is, the \emph{natural order}, defined as follows:
\begin{equation*}
\begin{array}{|c|c|c|}
\hline
1 & 2 & 3 \\ \hline
4 & 5 & 6 \\ \hline
7 & 8 & 9 \\ \hline
\end{array}
\end{equation*}
So when we say that two tiles are ``out of order'', we mean that the
larger letter precedes the smaller letter in this natural order.

Our difficulty is that one pair of tiles (the G and~H) is out of order
initially.  An immediate observation is that row moves alone are of
little value in addressing this problem:
\begin{lemma}\label{lem:8puzzleA}
A row move does not change the order of the tiles.
\end{lemma}

\begin{proof}
A row move moves a tile from cell~$i$ to cell~$i + 1$ or vice versa.
This tile does not change its order with respect to any other tile.
Since no other tile moves, there is no change in the order of any of
the other pairs of tiles.
\end{proof}

Let's turn to column moves.  This is the more interesting case, since
here the order can change.  For example, the column move in
Figure~\ref{fig:8columnmove} changes the relative order of the pairs
$(G, H)$ and $(G, E)$.

\begin{figure}
\begin{equation*}
\begin{array}{|c|c|c|}
\hline
A & B & C \\ \hline
D & F &  \\ \hline
H & E & \mathbf{G} \\ \hline
\end{array}
\longrightarrow
\begin{array}{|c|c|c|}
\hline
A & B & C \\ \hline
D & F & \mathbf{G} \\ \hline
H & E &  \\ \hline
\end{array}
\end{equation*}
\caption{An example of a column move in which the $G$-tile is moved
  into the adjacent hole above  In this case, $G$ changes order with
  $E$ and~$H$.}
\label{fig:8columnmove}
\end{figure}

\begin{lemma}\label{lem:8puzzleB}
A column move  changes the relative order of exactly two pairs of
tiles.
\end{lemma}

\begin{proof}
Sliding a tile down moves it after the next two tiles in the order.
Sliding a tile up moves it before the previous two tiles in the
order.  Either way, the relative order changes between the moved tile
and each of the two it crosses.  The relative order between any other
pair of tiles does not change.
\end{proof}

These observations suggest that there are limitations on how tiles can
be swapped.  Some such limitation may lead to the invariant we need.
In order to reason about swaps more precisely, let's define a term
referring to a pair of items that are out of order:
\begin{definition}\label{def:8inversion}
A pair of letters $L_1$ and $L_2$ is an \term{inversion} if $L_1$
precedes $L_2$ in the alphabet, but $L_1$ appears after~$L_2$ in the
puzzle order.
\end{definition}

For example, in the puzzle below, there are three inversions: $(D,
F)$, $(E, F)$, $(G, E)$.
\begin{equation*}
\begin{array}{|c|c|c|}
\hline
A & B & C \\ \hline
F & D & G \\ \hline
E & H &   \\ \hline
\end{array}
\end{equation*}

There is exactly one inversion $(G, H)$ in the start state:
\begin{equation*}
\begin{array}{|c|c|c|}
\hline
A & B & C \\ \hline
D & E & F \\ \hline
\mathbf{H} & \mathbf{G} &   \\ \hline
\end{array}
\end{equation*}

There are no inversions in the end state:
\begin{equation*}
\begin{array}{|c|c|c|}
\hline
A & B & C \\ \hline
D & E & F \\ \hline
\mathbf{G} & \mathbf{H} &   \\ \hline
\end{array}
\end{equation*}

Let's work out the effects of row and column moves in terms of
inversions.

\begin{lemma}\label{lem:8puzzleC}
During a move, the number of inversions can only increase by~2,
decrease by~2, or remain the same.
\end{lemma}

\begin{proof}
By Lemma~\ref{lem:8puzzleB}, a row move does not change the order of
the tiles; thus, in particular, a row move does not change the order
of inversions.

By Lemma~\ref{lem:8puzzleC}, a column move changes the relative order
of exactly 2 pairs of tiles.  There are three cases: If both pairs
were originally in order, then the number of inversions after the move
goes up by~2.  If both pairs were originally inverted, then the number
of inversions after the move goes down by~2.  If one pair was
originally inverted, and the other was originally in order, then the
number of inversions stays the same (since changing the former pair
makes the number of inversions smaller by~1, and changing the latter
pair makes the number of inversions larger by~1).
\end{proof}

We are almost there.  If the number of inversions only changes by~2,
then what about the parity?  (The ``parity'' of a number refers to
whether the number is even or odd.  For example, 7 and~5 have odd
parity, and 18 and~0 have even parity.)

Since adding or subtracting~2 from a number does not change its
parity, we have the following corollary:
\begin{corollary}\label{cor:8puzzleparity}
Neither a row nor a column move ever changes the parity of the number
of inversions.
\end{corollary}

Now we can bundle up all these observations and state an
\emph{invariant}, that is, a property of the puzzle that never
changes, no matter how you slide the tiles around.

\begin{lemma}\label{lem:8puzzleD}
In every configuration reachable from the configuration shown in
Figure~\ref{fig:8puzzleA}(a), the \emph{parity of the number of inversions
  is odd}.
\end{lemma}

\begin{proof}
We use induction.  Let $P(n)$ be the proposition that after $n$ moves
from the above configuration, the parity of the number of inversions
is odd.

\emph{Base case}: After zero moves, exactly one pair of tiles is
inverted ($H$ and~$G$), which is an odd number.  Therefore $P(0)$ is
true.

\emph{Inductive step}:
Now we must prove that $P(n)$ implies $P(n+1)$ for all $n \ge 0$.  So
assume that $P(n)$ is true; that is, after $n$ moves the parity of the
number of inversions is odd.  Consider any sequence of $n+1$ moves
$m_1$, \dots, $m_{n+1}$.  By the induction hypothesis $P(n)$, we know
that the parity after moves $m_1$, \dots, $m_{n}$ is odd.  By
Corollary~\ref{cor:8puzzleparity}, we know that the parity does not
change during~$m_{n+1}$.  Therefore, the parity of the number of
inversions after movies $m_1$, \dots, $m_{n+1}$ is odd, so we have $P(n
+ 1)$ is true.

By the principle of induction, $P(n)$ is true for all $n \ge 0$.
\end{proof}

The theorem we originally set out to prove is restated below  With our
invariant in hand, the proof is simple.
\begin{theorem*}
No sequence of legal moves transforms the board below on the left into
the board below on the right.
\begin{equation*}
\begin{array}{|c|c|c|}
\hline
A & B & C \\ \hline
D & E & F \\ \hline
\mathbf{H} & \mathbf{G} &   \\ \hline
\end{array}
\qquad\qquad
\begin{array}{|c|c|c|}
\hline
A & B & C \\ \hline
D & E & F \\ \hline
\mathbf{G} & \mathbf{H} &   \\ \hline
\end{array}
\end{equation*}
\end{theorem*}

\begin{proof}
In the target configuration on the right, the total number of
inversions is zero, which is even.  Therefore, by
Lemma~\ref{lem:8puzzleD}, the target configuration is unreachable.
\end{proof}

\section{Problems}

\begin{problems}
\practiceproblems
%% Strong Induction Problems %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pinput{CP_3_and_5_cent_stamps_by_induction}

\classproblems

%% Ordinary Induction Problems %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pinput{CP_cubic_series}
\pinput{CP_geometric_series_induction}
\pinput{CP_sum_of_inverse_squares_induction}
\pinput{CP_courtyard_tiling_corner}
\pinput{CP_flawed_induction_proof}
\pinput{CP_false_arithmetic_series_proof}
\pinput{CP_box_unstacking} %not strong induction, but depends on stacking game

\homeworkproblems
\pinput{PS_sums_and_products_of_integers}
\pinput{PS_ripple_carry_adder_correctness}
\pinput{PS_periphery_length_game}

%% Strong Induction Problems %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pinput{CP_3_and_7_cent_stamps_by_induction}
\pinput{PS_team_division}
\pinput{PS_prime_divides_integer_product}

\begin{editingnotes}
\begin{problem}
Use strong induction to prove the Well Ordering Principle. \hint Prove
that if a set of nonnegative integers contains an integer, $n$, then it
has a smallest element.
\end{problem}
\end{editingnotes}

\end{problems}

\endinput
