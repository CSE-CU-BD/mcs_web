\chapter{Simple Graphs}\label{simple_graphs_chap}

\term{Simple graphs} model relationships that are
\emph{\idx{symmetric}}, meaning that the relationship is mutual.
Examples of such mutual relationships are being married, speaking the
same language, not speaking the same language, occurring during
overlapping time intervals, or being connected by a conducting wire.
They come up in all sorts of applications, including scheduling,
constraint satisfaction, computer graphics, and communications, but
we'll start with an application designed to get your attention: we are
going to make a professional inquiry into sexual behavior.  Specifically,
we'll look at some data about who, on average, has more
opposite-gender partners, men or women.

\iffalse
An example is shown in
Figure~\ref{fig:graph-example}.  The dots are called \emph{nodes} (or
\emph{vertices}) and the lines are called \emph{edges}.
\fi

Sexual demographics have been the subject of many studies.  In one of
the largest, researchers from the University of Chicago
interviewed a random sample of 2500 people over several years to try
to get an answer to this question.  Their study, published in 1994 and
entitled \emph{The Social Organization of Sexuality}, found that men
have on average 74\% more opposite-gender partners than women.

Other studies have found that the disparity is even larger.  In
particular, ABC News claimed that the average man has 20 partners over his
lifetime, and the average woman has 6, for a percentage disparity of
233\%.  The ABC News study, aired on Primetime Live in 2004, purported to
be one of the most scientific ever done, with only a 2.5\% margin of
error.  It was called ``American Sex Survey: A peek between the sheets"
---raising some questions about the seriousness of their reporting.
\begin{editingnotes}
The promotion for the study is even better:
\begin{quote} 
A ground breaking ABC News ``Primetime Live'' survey finds a range of
eye-popping sexual activities, fantasies and attitudes in this country,
confirming some conventional wisdom, exploding some myths -- and venturing
where few scientific surveys have gone before.
\end{quote}
Probably that last part about going where few scientific surveys have gone
before is pretty accurate!
\end{editingnotes}

Yet again in August, 2007, the New York Times
\href{The-Myth-the-Math-the-Sex.pdf}{reported}
\iffalse
\href{http://www.nytimes.com/2007/08/12/weekinreview/12kolata.html?_r=1&n=Top/Reference/Times\%20Topics/People/K/Kolata,\%20Gina&oref=slogin}{reported}
\fi
on a study by the National Center for Health Statistics of the U.S. government
showing that men had seven partners while women had four.  So, whose numbers do
you think are more accurate: the University of Chicago, ABC News, or the National
Center?  

Don't answer.  This is a setup question like ``When did you stop beating
your wife?''  Using a little graph theory, we'll explain why none of these findings
can be anywhere near the truth.

\section{Vertex Adjacency and Degrees}\label{degreessec}

Simple graphs are defined as digraphs in which edges are
\term{undirected}---they just connect two vertices without pointing
in either direction between the vertices.  So instead of a directed
edge $\diredge{v}{w}$ which starts at vertex $v$ and ends at vertex
$w$, a simple graph only has an undirected edge, $\edge{v}{w}$, that
\idx{connects} $v$ and $w$.

\begin{definition}\label{simplegraphdef}
  A \term{simple graph}, $G$, consists of a nonempty
  set,~$\vertices{G}$, called the \term{vertices} of~$G$, and a set
  $\edges{G}$ called the \term{edges} of $G$.  An element of
  $\vertices{G}$ is called a \term{vertex}.  A vertex is also called a
  \term{node}; the words ``vertex'' and ``node'' are used
  interchangeably.  An element of $\edges{G}$ is an \term{undirected
    edge} or simply an ``edge.''  An undirected edge has two vertices
  $u\neq v$ called its \term{endpoints}.  Such an edge can be
  represented by the two element set $\set{u,v}$.  The notation
  $\edge{u}{v}$ denotes this edge.
\end{definition}
Both $\edge{u}{v}$ and $\edge{v}{u}$ define the same undirected edge,
whose endpoints are $u$ and $v$.

\begin{figure}[h]

\graphic{graph-example}

\caption{An example of a graph with 9 nodes and 8 edges.}

\label{fig:graph-example}

\end{figure}

For example, let $H$ be the graph pictured in
Figure~\ref{fig:graph-example}.  The vertices of $H$ correspond to the
nine dots in Figure~\ref{fig:graph-example}, that is,
\[
\vertices{H} =  \set{a, b, c, d, e, f, g, h, i}\, .
\]
The edges correspond to the eight lines, that is,
\[
\edges{H} =  \set{\, \edge{a}{b}, \edge{a}{c}, \edge{b}{d}, \edge{c}{d},
              \edge{c}{e}, \edge{e}{f}, \edge{e}{g}, \edge{h}{i} \,}.
\]
Mathematically, that's all there is to the graph $H$.

\begin{definition}
Two vertices in a simple graph are said to be \term{adjacent} iff they
are the endpoints of the same edge, and an edge is said to be
\term{incident} to each of its endpoints.  The number of edges
incident to a vertex~$v$ is called the \term{degree} of the vertex and
is denoted by $\degr{v}$.  Equivalently, the degree of a vertex is the
number of vertices adjacent to it.
\end{definition}

For example, for the graph $H$ of Figure~\ref{fig:graph-example},
vertex~$a$ is adjacent to vertex~$b$, and $b$ is adjacent to~$d$.  The
edge $\edge{a}{c}$ is incident to its endpoints $a$ and~$c$.
Vertex~$h$ has degree~1, $d$ has degree~2, and $\degr{e} = 3$.  It is
possible for a vertex to have degree~0, in which case it is not
adjacent to any other vertices.  A simple graph, $G$, does not need to
have any edges at all. $\card{\edges{G}}$ could be zero, implying that
the degree of every vertex would also be zero.  But a simple graph
must have at least one vertex---$\card{\vertices{G}}$ is
required to be at least one.

An edge whose endpoints are the same is called a \term{self-loop}.
Self-loops aren't allowed in simple graphs.\footnote{You might try to
  represent a self-loop going between a vertex $v$ and itself as
  $\set{v, v}$, but this equals $\set{v}$. It wouldn't be an edge,
  which is defined to be a set of \emph{two} vertices.}  In a more
general class of graphs called \term{multigraphs} there can be more
than one edge with the same two endpoints, but this doesn't happen in
simple graphs since every edge is uniquely determined by its two
endpoints.

Sometimes graphs with no vertices, with self-loops, or with more than one
edge between the same two vertices are convenient to have, but we don't
need them, and sticking with simple graphs is simpler.

\emph{For the rest of this chapter we'll use ``graphs'' as an abbreviation
  for ``simple graphs.''}

A synonym for ``vertices'' is ``\term{nodes},'' and we'll use these
words interchangeably.  Simple graphs are sometimes
called \emph{networks}, edges are sometimes called \emph{arcs}.  We
mention this as a ``heads up'' in case you look at other graph theory
literature; we won't use these words.

\section{Sexual Demographics in America}\label{sexam}
%A 1994 University of Chicago study entitled \emph{The Social
%Organization of Sexuality} found that on average men have 74\% more
%opposite-gender partners than women.

Let's model the question of heterosexual partners in graph theoretic
terms.  To do this, we'll let $G$ be the graph whose vertices, $V$,
are all the people in America.  Then we split $V$ into two separate
subsets: $M$, which contains all the males, and $F$, which contains
all the females.\footnote{For simplicity, we'll ignore the possibility
  of someone being \emph{both} a man and a woman, or neither.}  We'll
put an edge between a male and a female iff they have been sexual
partners.  This graph is pictured in Figure~\ref{fig:partners} with
males on the left and females on the right.

\begin{figure}
\graphic{sex-edges}
\caption{The sex partners graph.}
\label{fig:partners}
\end{figure}

Actually, this is a pretty hard graph to figure out, let alone draw.
The graph is \emph{enormous}: the US population is about 300 million,
so $\card{V} \approx 300M$.  Of these, approximately 50.8\% are female
and 49.2\% are male, so $\card{M} \approx 147.6M$, and
$\card{F} \approx 152.4M$.  And we don't even have trustworthy
estimates of how many edges there are, let alone exactly which couples
are adjacent.  But it turns out that we don't need to know any of this
---we just need to figure out the relationship between the average
number of partners per male and partners per female.  To do this, we
note that every edge has exactly one endpoint at an $M$ vertex (remember,
we're only considering male-female relationships); so the sum of the
degrees of the $M$ vertices equals the number of edges.  For the same
reason, the sum of the degrees of the $F$ vertices equals the number
of edges.  So these sums are equal:
%
\[
\sum_{x \in M} \degr{x} = \sum_{y \in F} \degr{y}.
\]
%
Now suppose we divide both sides of this equation by the product of the sizes of the
two sets, $\card{M} \cdot \card{F}$:
%
\[
\left(\frac{\sum_{x \in M} \degr{x}}{\card{M}}\right) \cdot \frac{1}{\card{F}} =
\left(\frac{\sum_{y \in F} \degr{y}}{\card{F}}\right) \cdot \frac{1}{\card{M}}
\]
%
The terms above in parentheses are the \emph{\idx{average degree} of an $M$ vertex} and
  the \emph{average degree of a $F$} vertex.  So we know:
\begin{equation}\label{avgsexMF}
\text{Avg. deg in $M$} = \frac{\card{F}}{\card{M}} \cdot \text{Avg. deg in $F$}
\end{equation}

In other words, we've proved that the average number of female
partners of males in the population compared to the average number of
males per female is \emph{determined solely by the relative number of
  males and females in the population}.

Now the Census Bureau reports that there are slightly more females
than males in America; in particular $\card{F} / \card{M}$ is about
1.035.  So we know that on average, males have 3.5\% more
opposite-gender partners than females, and this tells us nothing about
any sex's promiscuity or selectivity.  Rather, it just has to do with
the relative number of males and females.  Collectively, males and
females have the same number of opposite gender partners, since it
takes one of each set for every partnership, but there are fewer
males, so they have a higher ratio.  This means that the University of
Chicago, ABC, and the Federal government studies are way off.  After a
huge effort, they gave a totally wrong answer.

There's no definite explanation for why such surveys are consistently
wrong.  One hypothesis is that males exaggerate their number of
partners---or maybe females downplay theirs---but these explanations
are speculative.  Interestingly, the principal author of the National
Center for Health Statistics study reported that she knew the results
had to be wrong, but that was the data collected, and her job was to
report it.

The same underlying issue has led to serious misinterpretations of
other survey data.  For example, a couple of years ago, the Boston
Globe ran a story on a survey of the study habits of students on
Boston area campuses.  Their survey showed that on average, minority
students tended to study with non-minority students more than the
other way around.  They went on at great length to explain why this
``remarkable phenomenon'' might be true.  But it's not remarkable at
all.  Using our graph theory formulation, we can see that all it says
is that there are fewer minority students than non-minority students,
which is, of course, what ``minority'' means.

\subsection{Handshaking Lemma}
The previous argument hinged on the connection between a sum of
degrees and the number of edges.  There is a simple connection between
these in any graph:

\begin{lemma}\label{sumedges}
The sum of the degrees of the vertices in a graph equals twice the number of edges.
\end{lemma}

\begin{proof}
Every edge contributes two to the sum of the degrees, one for each of its endpoints.
\end{proof}

Lemma~\ref{sumedges} is sometimes called the \term{Handshake Lemma}:
if we total up the number of people each person at a party shakes
hands with, the total will be twice the number of handshakes that
occurred.


\begin{problems}
\classproblems
\pinput{CP_Handshaking_Lemma}

\examproblems
\pinput{CP_bipartite_sex}
\end{problems}

\section{Some Common Graphs}\label{sec:common_graphs}

Some graphs come up so frequently that they have names.  A
\term{complete graph} $K_n$ has $n$ vertices and an edge between
every two vertices, for a total of $n(n-1)/2$ edges.  For example,
$K_5$ is shown in Figure~\ref{fig:K_5}.

\begin{figure}

\graphic{complete-graph}

\caption{$K_5$: the complete graph on 5 nodes.}
\label{fig:K_5}
\end{figure}

The \term{empty graph} has no edges at all.  For example, the empty
graph with 5 nodes is shown in Figure~\ref{fig:graph_empty_5}.

\begin{figure}

\graphic{empty-graph}

\caption{An empty graph with 5 nodes.}
\label{fig:graph_empty_5}
\end{figure}

An $n$-node graph containing $n - 1$ edges in sequence is known as
a \emph{line graph}~$L_n$.  More formally, $L_n$ has
\begin{equation*}
    \vertices{L_n} = \set{ v_1, v_2, \dots, v_n }
\end{equation*}
and
\begin{equation*}
    \edges{L_n} = \set{\, \edge{v_1}{v_2}, \edge{v_2}{v_3}, \dots,
    \edge{v_{n-1}}{v_n} \, }
\end{equation*}
For example, $L_5$ is pictured in Figure~\ref{fig:graph_L_5}.

\begin{figure}

\graphic{path-graph}

\caption{$L_5$: a 5-node line graph.}

\label{fig:graph_L_5}

\end{figure}

There is also a one-way infinite line graph $L_{\infty}$ which can be
defined by letting the nonnegative integers $\naturals$ be the vertices
with edges $\edge{k}{(k+1)}$ for all $k \in \naturals$.
\begin{editingnotes}
$L_{\infty}$ is pictured in Figure~INSERT%\ref{fig:graph_L_infty}.
\end{editingnotes}

If we add the edge $\edge{v_n}{v_1}$ to the line graph~$L_n$, we get a
graph called a \term{length-$n$ cycle}\index{cycle!of length $n$} \idx{$C_n$}.
Figure~\ref{fig:graph_C_5} shows a picture of length-5 cycle.

\begin{figure}

\graphic{cycle}

\caption{$C_5$: a 5-node cycle graph.}
\label{fig:graph_C_5}
\end{figure}

\section{Isomorphism}
Two graphs that look the same might actually be different in a formal
sense.  For example, the two graphs in Figure~\ref{fig:isomorphic-C4cross}
are both 4-vertex, 5-edge graphs and you get graph (b) by a
$90^{\text{o}}$ clockwise rotation of graph (a).
\begin{figure}

\subfloat[]{%
    \graphic{isomorphism_a}
}
\qquad
\subfloat[]{%
    \graphic{isomorphism_b}
}

\caption{Two Isomorphic graphs.}
\label{fig:isomorphic-C4cross}
\end{figure}

Strictly speaking, these graphs are different mathematical objects,
but this difference doesn't reflect the fact that the two graphs can
be described by the same picture---except for the labels on the
vertices.  This idea of having the same picture ``up to relabeling''
can be captured neatly by adapting
Definition~\ref{relation-isomorphism} of isomorphism of digraphs to
handle simple graphs.  An isomorphism between two graphs is an
edge-preserving bijection between their sets of vertices:

\begin{definition}\label{simple-isomorphism}
An isomorphism between graphs $G$ and $H$ is a bijection
$f:\vertices{G} \to \vertices{H}$ such that
\[
\edge{u}{v} \in \edges{G} \qiff \edge{f(u)}{f(v)} \in \edges{H}
\]
for all $u, v \in \vertices{G}$.  Two graphs are isomorphic when there
is an isomorphism between them.
\end{definition}

Here is an isomorphism, $f$, between the two graphs in
Figure~\ref{fig:isomorphic-C4cross}:
\[
\begin{array}{lll}
f(a) \eqdef 2 & \hspace{0.3in} & f(b) \eqdef 3 \\
f(c) \eqdef 4 & & f(d) \eqdef 1.
\end{array}
\]
You can check that there is an edge between two vertices in the graph on the left if
and only if there is an edge between the two corresponding vertices in the graph on the
right.

Two isomorphic graphs may be drawn very differently.  For example,
Figure~\ref{fig:isomorphic-C5s} shows two different ways of drawing
$C_5$.
\begin{figure}

\graphic{isomorphism-c5}

\caption{Isomorphic~$C_5$ graphs.}
\label{fig:isomorphic-C5s}
\end{figure}

Notice that if $f$ is an isomorphism between $G$ and $H$, then
$f^{-1}$ is an isomorphism between $H$ and $G$.  Isomorphism is also
transitive because the composition of isomorphisms is an isomorphism.
In fact, isomorphism is an equivalence relation.

Isomorphism preserves the connection properties of a graph,
abstracting out what the vertices are called, what they are made out
of, or where they appear in a drawing of the graph.  More precisely, a
property of a graph is said to be \term{preserved under isomorphism}
if whenever $G$ has that property, every graph isomorphic to $G$ also
has that property.  For example, since an isomorphism is a bijection
between sets of vertices, isomorphic graphs must have the same number
of vertices.  What's more, if $f$ is a graph isomorphism that maps a
vertex, $v$, of one graph to the vertex, $f(v)$, of an isomorphic
graph, then by definition of isomorphism, every vertex adjacent to $v$
in the first graph will be mapped by $f$ to a vertex adjacent to
$f(v)$ in the isomorphic graph.  Thus, $v$ and $f(v)$ will have the
same degree.  If one graph has a vertex of degree 4 and another
does not, then they can't be isomorphic.  In fact, they can't be
isomorphic if the number of degree 4 vertices in each of the graphs is
not the same.

Looking for preserved properties can make it easy to determine that two
graphs are not isomorphic, or to guide the search for an
isomorphism when there is one.  It's generally easy in practice to decide
whether two graphs are isomorphic.  However, no one has yet found a
procedure for determining whether two graphs are isomorphic that is
\emph{guaranteed} to run in \idx{polynomial time} on all pairs of
graphs.\footnote{A procedure runs in \emph{polynomial
    time} when it needs an amount of time of at most $p(n)$, where $n$ is
  the total number of vertices and $p()$ is a fixed polynomial.}

Having such a procedure would be useful.  For example, it would make it
easy to search for a particular molecule in a database given the molecular
bonds.  On the other hand, knowing there is no such efficient procedure
would also be valuable: secure protocols for encryption and remote
authentication can be built on the hypothesis that graph isomorphism is
computationally exhausting.

\iffalse

An isomorphism between the two graphs shown in
Figure~\ref{fig:isomorphism} is easy to read off:
\[
\begin{array}{lll}
a \text{ corresponds to } 1 & \hspace{0.5in} & b \text{ corresponds to } 2 \\
d \text{ corresponds to } 4 & & c \text{ corresponds to } 3.
\end{array}
\]

To see why this works, look at any edge in the first graph, say
$\edge{b}{c}$, and make sure that the vertices corresponding to $b$ and
$c$ are the endpoints of an edge in the second graph.  Namely, verify that
$\edge{2}{3}$ is an edge of the second graph; and it is.  Conversely, look
at any edge in the second graph, say $\edge{3}{4}$, and verify that the
corresponding vertices are the endpoints of an edge of the first
graph. Namely, verify that $\edge{c}{d}$ is an edge of the first graph;
and it is.  It's a good practice exercise to verify that every edge in
either of these graphs exactly corresponds in this way to an edge in the
other graph.
\fi

The definitions of bijection and isomorphism apply to infinite graphs
as well as finite graphs, as do most of the results in the rest of
this chapter.  But graph theory focuses mostly on finite graphs, and
we will too.  \emph{In the rest of this chapter we'll assume graphs
  are finite.}

We've actually been taking isomorphism for granted ever since we wrote
``$K_n$ has $n$ vertices\dots'' at the beginning of
section~\ref{sec:common_graphs}.  

\iffalse
A pickier sentence is ``Any graph isomorphic to some graph
that is a $K_n$ has $n$ vertices\dots.''  But since having $n$
vertices is a property preserved by isomorphism, the picky version is
unnecessary if not silly.
\fi

\emph{Graph theory is all about properties preserved by isomorphism.}

%% Simple Graphs Problems %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problems}
\classproblems
\pinput{CP_isomorphic_graphs}
% S09.cp6m.1
% S09.cp6m.3
% S09.cp6m.4

\homeworkproblems
\pinput{PS_choose_isomorphic_graphs}
\pinput{PS_neighbors_under_isomorphisms}
\pinput{PS_bogus_graph_two_ends}

\examproblems
\pinput{MQ_list_isomorphisms}
\end{problems}

%\section{Matching Problems}\label{sexam}

\section{Bipartite Graphs \& Matchings}\label{bipartitesec}

%\subsubsection*{Bipartite Graphs}\label{bipartitesubsec}

There were two kinds of vertices in the ``Sex in America'' graph,
males and females, and edges only went between the two kinds.  Graphs
like this come up so frequently that they have earned a special
name: \emph{bipartite graphs}.

\begin{definition}
  A \term{bipartite graph} \index{graph!bipartite} is a graph whose vertices can be
  \idx{partition}ed\footnote{Partitioning a set means cutting it up into
    \emph{nonempty} pieces.  In this case, it means that $\leftbi{G}$ and
    $\rightbi{G}$ are nonempty, $\leftbi{G} \union \rightbi{G} =
    \vertices{G}$, and $\leftbi{G} \intersect \rightbi{G} =
    \emptyset$.} into two sets, $\leftbi{G}$ and
    $\rightbi{G}$, such that every edge has one endpoint in
    $\leftbi{G}$ and the other endpoint in $\rightbi{G}$.
\end{definition}

\begin{editingnotes}
  \arm{so 1-vertex graphs are not bipartite, but all other empty graphs are.}
\end{editingnotes}

So every bipartite graph looks something like the graph in
Figure~\ref{fig:partners}.

\subsection{The Bipartite Matching Problem}

The bipartite matching problem is related to the sex-in-America
problem that we just studied; only now, the goal is to get everyone
happily married.  As you might imagine, this is not possible for a
variety of reasons, not the least of which is the fact that there are
more women in America than men.  So, it is simply not possible to
marry every woman to a man so that every man is married at most once.

But what about getting a mate for every man so that every woman is married
at most once?  Is it possible to do this so that each man is paired with a
woman that he likes?  The answer, of course, depends on the bipartite graph
that represents who likes who, but the good news is that it is possible to
find natural properties of the who-likes-who graph that completely
determine the answer to this question.

In general, suppose that we have a set of men and an equal-sized or
larger set of women, and there is a graph with an edge between a man
and a woman if the man likes the woman.  In this scenario,
the ``likes'' relationship need not be symmetric, since for the time
being, we will only worry about finding a mate for each man that he
likes.\footnote{By the way, we do not mean to imply that marriage
  should or should not be of a heterosexual nature.  Nor do we mean to
  imply that men should get their choice instead of women.  It's just
  that with bipartite graphs, the edges only connected male nodes to
  female nodes and there are fewer men in America.  So please don't
  take offense.}  (Later, we will consider the ``likes'' relationship
from the female perspective as well.)  For example, we might obtain
the graph in Figure~\ref{fig:5J}.

\begin{figure}

\gnote{Tom: We couldn't figure out what was intended here: these edges
  are inconsistent with the text.}

\graphic{hall-graph}

\caption{A graph where an edge between a man and woman denotes that
  the man likes the woman.}

\label{fig:5J}

\end{figure}

A \term{matching} is defined to be an assignment of a woman to each
man so that different men are assigned to different women, and a man
is always assigned a woman that he likes.  For example, one possible
matching for the men is shown in Figure~\ref{fig:5K}.

\begin{figure}

\gnote{Tom: We couldn't figure out what was intended here: these edges
  are inconsistent with the text.  David: Check line widths.}

\graphic{hall-graph-matched}

\caption{One possible matching for the men is shown with bold edges.
  For example, John is matched with Mergatroid.}

\label{fig:5K}

\end{figure}

\subsubsection{The Matching Condition}

A famous result known as \idx{Hall's Matching Theorem} gives necessary
and sufficient conditions for the existence of a matching in a
bipartite graph.  It turns out to be a remarkably useful mathematical
tool.

We'll state and prove Hall's Theorem using man-likes-woman
terminology.  Define \emph{the set of women liked by a given set of
  men} to consist of all women liked by at least one of those men.
For example, the set of women liked by Tom and John in
Figure~\ref{fig:5J} consists of Martha, Sara, and Mergatroid.  For us
to have any chance at all of matching up the men, the following
\term{matching condition} must hold:

\medskip

\noindent\text{\emph{The Matching Condition}: every subset of men
  likes at least as large a set of women.}

\medskip

For example, we cannot find a matching if some set of 4~men like only
3~women.  Hall's Theorem says that this necessary condition is
actually sufficient; if the matching condition holds, then a matching
exists.

\begin{theorem}\label{thm:matching}
  A matching for a set~$M$ of men with a set~$W$ of women can be found if
  and only if the matching condition holds.
\end{theorem}

\begin{proof}
  First, let's suppose that a matching exists and show that the matching
  condition holds.  For any subset of men, each man likes at least the
  woman he is matched with and a woman is matched with at most one man.
  Therefore, every subset of men likes at least as large a set of women.
  Thus, the matching condition holds.

Next, let's suppose that the matching condition holds and show that a
matching exists.  We use strong induction on $\card{M}$, the number of
men, on the predicate:
\begin{align*}
    P(m) & \eqdef \text{ if the matching condition holds for a set,~$M$,}\\
         &\qquad  \text{of~$m$ men, then there is a matching for~$M$.}
\end{align*}

\inductioncase{Base case} ($\card{M}=1$): If $\card{M} = 1$, then the
matching condition implies that the lone man likes at least one woman,
and so a matching exists.

\inductioncase{Inductive Step}: \iffalse
We need to show that $\forall k \le m.\, P(k) \QIMPLIES
P(m + 1)$.\fi  Suppose that $\card{M} = m + 1 \ge 2$.  To find a
matching for $M$, there are two cases.
\begin{description}

\item[Case 1:] Every nonempty subset of at most $m$ men likes a
  \emph{strictly larger} set of women.  In this case, we have some
  latitude: we pair an arbitrary man with a woman he likes and send
  them both away.  This leaves $m$ men and one fewer women, and the
  matching condition will still hold.  So the induction hypothesis
  $P(m)$ implies we can match the remaining $m$ men.

\item[Case 2:] Some nonempty subset, $X$, of at most $m$ men likes an
  \emph{equal-size} set, $Y$, of women.  The matching condition must
  hold within $X$, so the strong induction hypothesis implies we can
  match the men in $X$ with the women in $Y$.  This leaves the problem
  of matching the set $M-X$ of men to the set $W-Y$ of women.

  But the problem of matching $M-X$ against $W-Y$ also satisfies the
  Matching condition, because any subset of men in $M-X$ who liked
  fewer women in $W-Y$ would imply there was a set of men who liked
  fewer women in the whole set $W$.  Namely, if a subset
  $M_0 \subseteq M-X$ liked only a strictly smaller subset of women
  $W_0 \subseteq W-Y$, then the set $M_0 \union X$ of men would like
  only women in the strictly smaller set $W_0 \union Y$.  So again the
  strong induction hypothesis implies we can match the men in $M-X$
  with the women in $W-Y$, which completes a matching for $M$.
  
\iffalse
We can also match the rest of the men by induction if we show that
  the matching condition holds for the remaining men and women.  To
  check the matching condition for the remaining people, consider an
  arbitrary subset of the remaining men $X' \subseteq (M - X)$, and
  let $Y'$ be the set of remaining women that they like.  We must show
  that $\card{X'} \leq \card{Y'}$.  Originally, the combined set of
  men $X \cup X'$ liked the set of women $Y \cup Y'$.  So, by the
  matching condition, we know:
%
  \begin{equation*}
  \card{X \cup X'}  \leq  \card{Y \cup Y'}
  \end{equation*}
%
  We sent away $\card{X}$ men from the set on the left (leaving $X'$)
  and sent away an equal number of women from the set on the right
  (leaving $Y'$).  Therefore, it must be that $\card{X'} \leq
  \card{Y'}$ as claimed.
\fi

\end{description}

So in both cases, there is a matching for the men, which completes the
proof of the Inductive step.  The theorem follows by induction.
\end{proof}

The proof of Theorem~\ref{thm:matching} gives an algorithm for finding
a matching in a bipartite graph, albeit not a very efficient one.
However, efficient algorithms for finding a matching in a bipartite
graph do exist.  Thus, if a problem can be reduced to finding a
matching, the problem is essentially solved from a computational
perspective.

\subsubsection{A Formal Statement}

Let's restate Theorem~\ref{thm:matching} in abstract terms so that
you'll not always be condemned to saying, ``Now this group of men
likes at least as many women\dots''

\begin{definition}\label{def:5K}
\index{graph!matching} A \term{matching} in a graph $G$ is a set $M$
of edges of $G$ such that no vertex is an endpoint of more than one
edge in $M$.  A matching is said to \term{cover} \index{edge cover}
\index{set!covering} a set, $S$, of vertices iff each vertex in $S$ is
an endpoint of an edge of the matching.  A matching is said to be
\emph{perfect} \index{perfect graph}\index{graph!perfect} if it covers
$\vertices{G}$.  In any graph, $G$, the set $E(S)$ of \term{neighbors} of
some set $S$ of vertices is the image of $S$ under the edge-relation,
\iffalse set of all vertices adjacent to some vertex in $S$.  \fi that
is,
\[
E(S) \eqdef \set{\,r \suchthat \edge{s}{r} \in \edges{G} \text{ for
    some } s \in S\,}.
\]
$S$ is called a \term{bottleneck} if
\[
\card{S} > \card{E(S)}.
\]
\end{definition}

\begin{theorem}[\idx{Hall's Theorem}]\label{thm:halls}
  Let $G$ be a \idx{bipartite graph}.  There is a matching in $G$ that
  covers $\leftbi{G}$ iff no subset of $\leftbi{G}$ is a bottleneck.
\end{theorem}

\subsubsection{An Easy Matching Condition}

The bipartite matching condition requires that \emph{every} subset of
men has a certain property.  In general, verifying that every subset
has some property, even if it's easy to check any particular subset
for the property, quickly becomes overwhelming because the number of
subsets of even relatively small sets is enormous---over a billion
subsets for a set of size 30.  However, there is a simple property of
vertex degrees in a bipartite graph that guarantees the existence of a
matching.  Call a bipartite graph \term*{degree-constrained}
if vertex degrees on the left are at least as large as those on the
right.  More precisely,

\begin{definition}\label{degree-constrained_def}
  A bipartite graph $G$ is \index{bipartite
    graph!degree-constrained}\term{degree-constrained} when $\degr{l} \geq
  \degr{r}$ for every $l \in \leftbi{G}$ and $r \in \rightbi{G}$.
\end{definition}

For example, the graph in Figure~\ref{fig:5J} is degree-constrained
since every node on the left is adjacent to at least two nodes on the
right while every node on the right is adjacent to at most two nodes
on the left.

\begin{theorem}\label{lem:no_bottleneck_degree_constrained}
  If $G$ is a degree-constrained bipartite graph, then there is a matching
  that covers~$\leftbi{G}$.
\end{theorem}

\begin{proof}

\iffalse
  The proof is by contradiction.  Suppose that $G$ is degree-constrained
  but that there is no matching that covers~$\leftbi{G}$.  By
  Theorem~\ref{thm:halls}, this means that there must be a bottleneck $S
  \subseteq \leftbi{G}$.
\fi

  We will show that $G$ satisfies Hall's condition, namely, if $S$ is
  an arbitrary subset of $\leftbi{G}$, then
\begin{equation}\label{not_bottleneck_ineq}
\card{E(S)} \ge \card{S}.  
\end{equation}
  Since $G$ is degree-constrained, there is a $d>0$ such that
  $\degr{l} \ge d \ge \degr{r}$ for every $l \in L$ and $r \in R$.
  Since every edge with an endpoint in~$S$ has its other endpoint in
  $E(S)$ by definition, and every node in $E(S)$ is incident to at
  most $d$ edges, we know that
\[
d\card{E(S)} \geq \#\text{edges with an endpoint in $S$}.
\]
Also, since every node in~$S$ is the endpoint of at least $d$ edges,
\[
\#\text{edges incident to a vertex in $S$} \geq d\card{S}.
\]
It follows that $d\card{E(S)} \ge d\card{S}$.  Cancelling $d$
completes the derivation of equation~\eqref{not_bottleneck_ineq}.
\end{proof}

Regular graphs are a large class of degree-constrained graphs that
often arise in practice.  Hence, we can use
Theorem~\ref{lem:no_bottleneck_degree_constrained} to prove that every
regular bipartite graph has a perfect matching.  This turns out to be
a surprisingly useful result in computer science.

\begin{definition}\label{def:5P}
A graph is said to be \emph{regular} if every node has the same degree.
\end{definition}

\begin{theorem}\label{thm:5M}
Every regular bipartite graph has a perfect matching.
\end{theorem}

\begin{proof}
  Let $G$ be a regular bipartite graph.  Since regular graphs are
  degree-constrained, we know by
  Theorem~\ref{lem:no_bottleneck_degree_constrained} that there must
  be a matching in~$G$ that covers~$\leftbi{G}$.  Such a matching is
  only possible when $\card{\leftbi{G}} \leq \card{\rightbi{G}}$.  But
  $G$ is also degree-constrained if the roles of $\leftbi{G}$ and
  $\rightbi{G}$ are switched, which implies that $\card{\rightbi{G}}
  \leq \card{\leftbi{G}}$ also.  That is, $\leftbi{G}$ and
  $\rightbi{G}$ are the same size, and any matching covering
  $\leftbi{G}$ will also cover $\rightbi{G}$.  So every node in~$G$ is
  an endpoint of an edge in the matching, and thus $G$ has a perfect
  matching.
\end{proof}

%% Bipartite Matchings Problems %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% S09.cp6r.3
% S09.cp6r.4

\begin{problems}
\classproblems
\pinput{CP_student_clubs}
\pinput{CP_latin_squares}

\examproblems
\pinput{CP_bipartite_matching_recitations}
\pinput{MQ_edge_constrained}

\homeworkproblems
\pinput{PS_cards_in_4_rows_13_columns}
\pinput{PS_bipartite_matching_virtues}
\end{problems}


\section{The Stable Marriage Problem}
\label{stablemarriagesec}

We next consider a version of the bipartite matching problem where
there are an equal number of men and women, and where each person has
preferences about who they would like to marry.  In fact, we assume
that each man has a complete list of all the women ranked according
to his preferences, with no ties.  Likewise, each woman has a ranked
list of all of the men.

The preferences don't have to be symmetric.  That is, Jennifer might
like Brad best, but Brad doesn't necessarily like Jennifer best.  The
goal is to marry everyone: every man must marry exactly one woman and
vice-versa---no polygamy.  Moreover, we would like to find a matching
between men and women that is \emph{stable} in the sense that there is
no pair of people who prefer one another to their spouses.

For example, suppose \emph{every} man likes Angelina best, and every
woman likes Brad best, but Brad and Angelina are married to other
people, say Jennifer and Billy Bob.  Now \emph{Brad and Angelina
  prefer each other to their spouses}, which puts their marriages at
risk.  Pretty soon, they're likely to start spending late nights
together working on problem sets!

This unfortunate situation is illustrated in
Figure~\ref{fig:minWtMatch2}, where the digits ``1'' and ``2'' near a
man shows which of the two women he ranks first and second,
respectively, and similarly for the women.

\begin{figure}

\graphic{minWtMatch2}

\caption{Preferences for four people.  Both men like Angelina best and
both women like Brad best.}
\label{fig:minWtMatch2}
\end{figure}

More generally, in any matching, a man and woman who are not married
to each other and who like each other better than their spouses is
called a \emph{rogue couple}.  In the situation shown in
Figure~\ref{fig:minWtMatch2}, Brad and Angelina would be a rogue
couple.

Having a rogue couple is not a good thing, since it threatens the
stability of the marriages.  On the other hand, if there are no rogue
couples, then for any man and woman who are not married to each other,
at least one likes their spouse better than the other, and so they
won't be tempted to start an affair.

\begin{definition}
  A \term{stable matching} is a matching with no rogue couples.
\end{definition}

The question is, given everybody's preferences, how do you find a
stable set of marriages?  In the example consisting solely of the four
people in Figure~\ref{fig:minWtMatch2}, we could let Brad and Angelina
both have their first choices by marrying each other.  Now neither
Brad nor Angelina prefers anybody else to their spouse, so neither
will be in a rogue couple.  This leaves Jen not-so-happily married to
Billy Bob, but neither Jen nor Billy Bob can entice somebody else to
marry them, and so there is a stable matching.

Surprisingly, there always is a stable matching among a group of men
and women.  The surprise springs in part from considering the
apparently similar ``buddy'' matching problem.  That is, if people can
be paired off as buddies, regardless of gender, then a stable matching
\emph{may not} be possible: an example of preferences among four
people where there is no stable buddy match is given in
Problem~\ref{PS_no_buddy_match}.

So getting a stable \emph{buddy} matching may not only be hard, it may
be impossible.  But when men are only allowed to marry women, and vice
versa, then it turns out that a stable matching can always be
found.\footnote{Once again, we disclaim any political statement
here---it's just the way that the math works out.}

\begin{editingnotes}
insert rest of story from gusfield book pp3--4??
\end{editingnotes}

\begin{editingnotes}
\subsection{Failed attempts}

Let's find a stable matching in one possible situation, and hope to
translate our method to a general algorithm.  The table below shows the
preferences of each woman and man in decreasing order.

\begin{eqnarray*}
men & \quad & women \\
1 : C B E A D & \quad & A : 3 5 2 1 4 \\
2 : A B E C D & \quad & B : 5 2 1 4 3 \\
3 : D C B A E & \quad & C : 4 3 5 1 2 \\
4 : A C D B E & \quad & D : 1 2 3 4 5 \\
5 : A B D E C & \quad & E : 2 3 4 1 5
\end{eqnarray*}

How about we try a ``greedy'' strategy?\footnote{``Greedy'' is not any
moral judgment.  It refers to algorithms that work by always choosing the
next state that makes the largest immediate progress.}  We simply take
each man in turn and pack him off with his favorite among the women still
available.  This gives the following assignment.

\begin{eqnarray*}
1 \rightarrow C \\
2 \rightarrow A \\
3 \rightarrow D \\
4 \rightarrow B \\
5 \rightarrow E \\
\end{eqnarray*}

To determine whether this matching is stable, we have to check whether
there are any rogue couples.  Men 1, 2, and 3 all got their top pick
among the women; none would even think of running off.  Man~4 may be a
problem because he likes woman $A$ better than his mate, but she ranks him
dead last.  However, man~4 also likes woman $C$ better than his mate, and
she rates him above her own mate.  Therefore, man~4 and woman $C$ form a
rogue couple!  The marriages are not stable.  We could try to make ad hoc
repairs, but we're really trying to develop a general strategy.

Another approach would be to use induction.  Suppose we pair Man~1
with his favorite woman, $C$, try to show that neither of these two
will be involved in a rogue couple, and then solve the remaining
problem by induction.  Clearly Man~1 will never leave his top pick,
Woman $C$.  But the problem with this approach is that we \emph{can't}
be sure that Woman $C$ won't be in a rogue couple.  Woman $C$ might very
well dump Man~1---she might even rate him last!

This turns out to be a tricky problem.  The best approach is to use a
mating ritual that is reputed to have been popular in some mythic past.
\end{editingnotes}

\subsection{The Mating Ritual}

The procedure for finding a stable matching involves a \emph{Mating
Ritual} that takes place over several days.  The following events happen
each day:

\textbf{Morning}: Each woman stands on her balcony.  Each man stands
under the balcony of his favorite among the women on his list, and he
serenades her.  If a man has no women left on his list, he stays home
and does his math homework.

\textbf{Afternoon}: Each woman who has one or more suitors serenading
her, says to her favorite among them, ``We might get engaged.  Come
back tomorrow.''  To the other suitors, she says, ``No.  I will never
marry you!  Take a hike!''

\textbf{Evening}: Any man who is told by a woman to take a hike
crosses that woman off his list.

\textbf{Termination condition}: When a day arrives in which every
woman has at most one suitor, the ritual ends with each woman marrying
her suitor, if she has one.

% Show example

There are a number of facts about this Mating Ritual that we would like to
prove:

\begin{itemize}
\item The Ritual eventually reaches the termination condition.
\item Everybody ends up married.
\item The resulting marriages are stable.
\end{itemize}


\subsection{There is a Marriage Day}

It's easy to see why the Mating Ritual has a terminal day when people
finally get married.  Every day on which the ritual hasn't terminated, at
least one man crosses a woman off his list.  (If the ritual hasn't
terminated, there must be some woman serenaded by at least two men, and at
least one of them will have to cross her off his list).  If we start with
$n$ men and $n$ women, then each of the $n$ men's lists initially has $n$
women on it, for a total of $n^2$ list entries.  Since no women ever gets
added to a list, the total number of entries on the lists decreases every
day that the Ritual continues, and so the Ritual can continue for at most
$n^2$ days.

\subsection{They All Live Happily Ever After\dots}

We still have to prove that the Mating Ritual leaves everyone in a
stable marriage.  To do this, we note one very useful fact about the
Ritual: if a woman has a favorite suitor on some morning of the
Ritual, then that favorite suitor will still be serenading her the
next morning---his list won't have changed.  So she is sure to
have today's favorite man among her suitors tomorrow.  That means she
will be able to choose a favorite suitor tomorrow who is at least as
desirable to her as today's favorite.  So day by day, her favorite
suitor can stay the same or get better, never worse.  This sounds like
an invariant, and it is.

\begin{definition}\label{def:P8}
Let $P$ be the predicate: For every woman, $w$, and every man, $m$, if
$w$ is crossed off $m$'s list, then $w$ has a suitor whom she prefers
over~$m$.
\end{definition}

\begin{lemma}\label{lem:5P}
$P$ is an invariant for The Mating Ritual.
\end{lemma}

\begin{proof}
By induction on the number of days.

\inductioncase{Base case}: In the beginning---that is, at the end of
day~0---every woman is on every list.  So no one has been crossed off, and
$P$ is vacuously true.

\inductioncase{Inductive Step}: Assume $P$ is true at the end of
day~$d$ and let $w$ be a woman that has been crossed off a man $m$'s
list by the end of day~$d + 1$.

\begin{description}

\item[Case 1:]
$w$ was crossed off $m$'s list on day $d + 1$.  Then, $w$ must have a
  suitor she prefers on day~$d+1$.

\item[Case 2:]
$w$ was crossed off $m$'s list prior to day~$d+1$.  Since $P$ is true
  at the end of day~$d$, this means that $w$ has a suitor she prefers
  to~$m$ on day~$d$.  She therefore has the same suitor or someone she
  prefers better at the end of day~$d + 1$.

\end{description}
In both cases, $P$ is true at the end of day~$d + 1$ and so $P$ must
be an invariant.
\end{proof}

With Lemma~\ref{lem:5P} in hand, we can now prove:

\begin{theorem}
Everyone is married by the Mating Ritual.
\end{theorem}

\begin{proof}
By contradiction. Assume that it is the last day of the Mating Ritual
and someone does not get married.  Since there are an equal number of
men and women, and since bigamy is not allowed, this means that at
least one man (call him Bob) and at least one woman do not get
married.

Since Bob is not married, he can't be serenading anybody and so his
list must be empty.  This means that Bob has crossed every woman off
his list and so, by invariant~$P$, every woman has a suitor whom she
prefers to Bob.  Since it is the last day and every woman still has a
suitor, this means that every woman gets married.  This is a
contradiction since we already argued that at least one woman is
\emph{not} married.  Hence, our assumption must be false and so
everyone must be married.
\end{proof}

\begin{theorem}
The Mating Ritual produces a stable matching.
\end{theorem}

\begin{proof}
Let Brad and Jen be any man and woman, respectively, that are
\emph{not} married to each other on the last day of the Mating Ritual.
We will prove that Brad and Jen are not a rogue couple, and thus that
all marriages on the last day are stable.  There are two cases to consider.
\begin{description}

\item[Case 1:] Jen is not on Brad's list by the end.  Then by invariant
  $P$, we know that Jen has a suitor (and hence a husband) that she
  prefers to Brad.  So she's not going to run off with Brad---Brad and
  Jen cannot be a rogue couple.

\item[Case 2:] Jen is on Brad's list.  But since Brad is not married to
  Jen, he must be choosing to serenade his wife instead of Jen, so he
  must prefer his wife.  So he's not going to run off with Jen---once
  again, Brad and Jen are not a rogue couple.
 \qedhere

\end{description}

\end{proof}


\subsection{\dots Especially the Men}

Who is favored by the Mating Ritual, the men or the women?  The women
\emph{seem} to have all the power: they stand on their balconies
choosing the finest among their suitors and spurning the rest.  What's
more, we know their suitors can only change for the better as the
Ritual progresses.  Similarly, a man keeps serenading the woman he
most prefers among those on his list until he must cross her off, at
which point he serenades the next most preferred woman on his list.  So
from the man's perspective, the woman he is serenading can only change
for the worse.  Sounds like a good deal for the women.

But it's not!  The fact is that from the beginning, the men are
serenading their first choice woman, and the desirability of the woman
being serenaded decreases only enough to ensure overall stability.
The Mating Ritual actually does as well as possible for all the men
and does the worst possible job for the women.

To explain all this we need some definitions.  Let's begin by
observing that while The Mating Ritual produces one stable matching,
there may be other stable matchings among the same set of men and
women.  For example, reversing the roles of men and women will often
yield a different stable matching among them.

But some spouses might be out of the question in all possible stable
matchings.  For example, given the preferences shown in
Figure~\ref{fig:minWtMatch2}, Brad is just not in the realm of
possibility for Jennifer, since if you ever pair them, Brad and
Angelina will form a rogue couple.

\begin{definition}
Given a set of preference lists for all men and women, one person is
in another person's \emph{realm of possible spouses} if there is a
stable matching in which the two people are married.  A person's
\term{optimal spouse} is their most preferred person within their
realm of possibility.  A person's \term{pessimal spouse} is their
least preferred person in their realm of possibility.
\end{definition}

Everybody has an optimal and a pessimal spouse, since we know there is at
least one stable matching, namely, the one produced by the Mating Ritual.
Now here is the shocking truth about the Mating Ritual:

\begin{theorem}\label{boyopt}
The Mating Ritual marries every man to his optimal spouse.
\end{theorem}

\begin{proof}
By contradiction.  Assume for the purpose of contradiction that some
man does not get his optimal spouse.  Then there must have been a day
when he crossed off his optimal spouse---otherwise he would still be
serenading (and would ultimately marry) her or some even more
desirable woman.

By the Well Ordering Principle, there must be a \emph{first} day when
a man (call him Keith) crosses off his optimal spouse (call her
Nicole).
According to the rules of the Ritual, Keith crosses off Nicole because
Nicole has a preferred suitor (call him Tom), so
\begin{equation}
\text{Nicole prefers Tom to Keith.} \tag{$*$}
\end{equation}

Since this is the first day an optimal woman gets crossed off, we know
that Tom had not previously crossed off his optimal spouse, and so
\begin{equation}\tag{$**$}
\text{Tom ranks Nicole at least as high as his optimal spouse.}
\end{equation}
By the definition of an optimal spouse, there must be some stable set
of marriages in which Keith gets his optimal spouse, Nicole.  But then
the preferences given in~($*$) and~($**$) imply that Nicole and Tom
are a rogue couple within this supposedly stable set of marriages
(think about it).  This is a contradiction.
\end{proof}

\begin{theorem}
The Mating Ritual marries every woman to her pessimal spouse.
\end{theorem}

\begin{proof}
Assume for the sake of contradiction that the theorem is not true.
Hence, there must be a stable set of marriages~$\mathcal{M}$ where some
woman (call her Nicole) is married to a man (call him Tom) that she
likes less than her spouse in The Mating Ritual (call him Keith).
This means that
\begin{equation}
\text{Nicole prefers Keith to Tom.} \tag{+}
\end{equation}

By Theorem~\ref{boyopt} and the fact that Nicole and Keith are married
in the Mating Ritual, we know that 
\begin{equation}\tag{++}
\text{Keith prefers Nicole to his spouse in~$\mathcal{M}$.}
\end{equation}
This means that Keith and Nicole form a rogue couple in~$\mathcal{M}$,
which contradicts the stability of~$\mathcal{M}$.
\end{proof}

\subsection{Applications}

The Mating Ritual was first announced in a paper by D. \idx{Gale} and
L.S. \idx{Shapley} in 1962, but ten years before the Gale-Shapley
paper was published, and unknown by them, a similar algorithm was
being used to assign residents to hospitals by the National Resident
Matching Program (NRMP)\footnote{Of course, there is no serenading
  going on in the hospitals---the preferences are submitted to a
  program and the whole process is carried out by a computer.}.  The
NRMP has, since the turn of the twentieth century, assigned each
year's pool of medical school graduates to hospital residencies
(formerly called ``internships''), with hospitals and graduates playing
the roles of men and women.  (In this case, there may be multiple
women married to one man, a scenario we consider in the problem
section at the end of the chapter.).  Before the Ritual-like algorithm
was adopted, there were chronic disruptions and awkward
countermeasures taken to preserve assignments of graduates to
residencies.  The Ritual resolved these problems so successfully, that
it was used essentially without change at least through
1989.\footnote{Much more about the Stable Marriage Problem can be
  found in the very readable mathematical monograph by Dan Gusfield
  and Robert W. Irving,
  \href{http://mitpress.mit.edu/catalog/item/default.asp?ttype=2&tid=7676}{The
    Stable Marriage Problem: Structure and Algorithms}, MIT Press,
  Cambridge, Massachusetts, 1989, 240 pp.}

The Internet infrastructure company Akamai also uses a variation of
the Mating Ritual to assign web traffic to its servers.  In the early
days, Akamai used other combinatorial optimization algorithms that got
to be too slow as the number of servers (over 65,000 in 2010) and
requests (over 800 billion per day) increased.  Akamai switched to a
Ritual-like approach, since a Ritual is fast and can be run in a distributed
manner.  In this case, web requests correspond to women and web
servers correspond to men.  The web requests have preferences based on
latency and packet loss, and the web servers have preferences based on
cost of bandwidth and colocation.

Not surprisingly, the Mating Ritual is also used by at least one large
online dating agency.  Even here, there is no serenading going
on---everything is handled by computer.

\begin{problems}

\practiceproblems
\pinput{CP_mating_ritual_example}
\pinput{TP_Stable_Marriage_Invariants}

\classproblems
%\pinput{CP_mating_ritual_proof}  class problem only
\pinput{CP_stable_matching_non_optimal}
\pinput{CP_matching_more_boys}

\homeworkproblems
\pinput{PS_no_buddy_match}
\pinput{PS_stable_matching_hospitals}
\pinput{PS_stable_matching_no_first_choice}
\pinput{PS_stable_matching_unlucky}

\examproblems
\pinput{FP_rogue_pair}

\begin{editingnotes}
\begin{problem*}
Add problem proving that the Mating Ritual need not proceed in
morning/afternoon/evening lock step: a woman can reject non-favorite
suitors one at a time and at any time, and a rejected man can change
the woman he serenades without waiting for the other men to change.
The proof uses the fact that single actions commute, so induction
proves that all executions are confluent---which implies all
executions end with the same man-optimal matching.  This lemma can be
cited in the planar graphs section to prove that the edges in an
embedding can be added in any order.
\end{problem*}
\end{editingnotes}

\end{problems}


\section{Coloring}\label{sec:coloring}

\begin{editingnotes}
\arm{reworded}:
\end{editingnotes}

In Section~\ref{sexam}, we used edges to indicate an affinity between a
pair of nodes.  But there are lots of situations in which edges will
correspond to \emph{conflicts} between nodes.  Exam scheduling is a
typical example.

\subsection{An Exam Scheduling Problem}

Each term, the MIT Schedules Office must assign a time slot for each
final exam.  This is not easy, because some students are taking
several classes with finals, and (even at MIT) a student can take only
one test during a particular time slot.  The Schedules Office wants to
avoid all conflicts.  Of course, you can make such a schedule by
having every exam in a different slot, but then you would need
hundreds of slots for the hundreds of courses, and the exam period
would run all year!  So, the Schedules Office would also like to keep
exam period short.

The Schedules Office's problem is easy to describe as a graph.  There
will be a vertex for each course with a final exam, and two vertices
will be adjacent exactly when some student is taking both courses.
For example, suppose we need to schedule exams for 6.041, 6.042,
6.002, 6.003 and 6.170.  The scheduling graph might appear as in
Figure~\ref{fig:5R}.

\begin{figure}

\graphic{finals-subject-labels}

\caption{A scheduling graph for five exams.  Exams connected by an
  edge cannot be given at the same time.}

\label{fig:5R}

\end{figure}

6.002 and 6.042 cannot have an exam at the same time since there are
students in both courses, so there is an edge between their nodes.  On the
other hand, 6.042 and 6.170 can have an exam at the same time if they're
taught at the same time (which they sometimes are), since no student can
be enrolled in both (that is, no student \emph{should} be enrolled in both
when they have a timing conflict).

We next identify each time slot with a color.  For example, Monday
morning is red, Monday afternoon is blue, Tuesday morning is green,
etc.  Assigning an exam to a time slot is then equivalent to coloring
the corresponding vertex.  The main constraint is that \emph{adjacent
  vertices must get different colors}---otherwise, some student has
two exams at the same time.  Furthermore, in order to keep the exam
period short, we should try to color all the vertices using as
\emph{few different colors as possible}.  As shown in Figure~\ref{fig:5S},
three colors suffice for our example.

\begin{figure}

\graphic{finals-subject-colored}

\caption{A 3-coloring of the exam graph from Figure~\ref{fig:5R}.}

\label{fig:5S}

\end{figure}

The coloring in Figure~\ref{fig:5S} corresponds to giving one final on
Monday morning (red), two Monday afternoon (blue), and two Tuesday
morning (green).  Can we use fewer than three colors?  No! We can't
use only two colors since there is a triangle in the graph, and three
vertices in a triangle must all have different colors.

This is an example of a \term{graph coloring} problem:
\index{graph!coloring problem} given a graph $G$, assign colors to each
node such that adjacent nodes have different colors.  A color assignment
with this property is called a \term{valid coloring} \index{graph!valid
  coloring} of the graph---a ``\term{coloring},'' for short.  A graph $G$
is $k$-\term{colorable} if it has a coloring that uses at most $k$ colors.
\begin{definition}
  The minimum value of $k$ for which a graph, $G$, has a valid coloring is
  called its \term{chromatic number}, \term{$\chi(G)$}.
\end{definition}
\begin{editingnotes}
\arm{added:}
\end{editingnotes}
So $G$ is $k$-colorable iff $\chi(G) \leq k$.

In general, trying to figure out if you can color a graph with a fixed
number of colors can take a long time.  It's a classic example of a
problem for which no fast algorithms are known.  In fact, it is easy to
check if a coloring works, but it seems really hard to find it. (If you
figure out how, then you can get a \$1 million Clay prize.)


\subsection{Some Coloring Bounds}

There are some simple properties of graphs that give useful bounds on
colorability. 
\begin{editingnotes}
\arm{inserted:}
\end{editingnotes}
The simplest property is being a \idx{cycle}: an even-length closed cycle
is 2-colorable, and since by definition it must have some edges, it is not
1-colorable.  So
\[
\chi(C_{\text{even}}) = 2.
\]
On the other hand, an odd-length cycle requires 3 colors, that is,
\begin{equation}\label{Codd3}
\chi(C_{\text{odd}}) = 3.
\end{equation}
You should take a moment to think about why this equality holds.
\begin{editingnotes}
\arm{FTL proof yanked from Theorem~\ref{thm:2-colorable-equiv}}

Let $G$ be a 2-colorable graph and
\begin{equation*}
    \walkv{w} \eqdef v_0, v_1, \dots, v_k
\end{equation*}
be any closed walk in~$G$.  So in any 2-coloring of~$G$, consecutive
vertices $v_i$ and $v_{i + 1}$ must be colored differently since
$\edge{v_i}{v_{i + 1}} \in \edges{G}$.  \arm{cut: for $0 \le i < k$}
Hence $v_0$, $v_2$, $v_4$, \dots, have one color and $v_1$, $v_3$,
$v_5$, \dots, have the other color.  Since $\walkv{w}$ is a closed
walk, $v_k$ is the same node as~$v_0$, and so $k$ must be an even
number.  This means that $\walkv{w}$ has even length.
\end{editingnotes}
Another simple example is a complete graph $K_n$:
\[
\chi(K_n) = n
\]
since no two vertices can have the same color.

\arm{paragraph below  and Lemma~\ref{2color-iff-bip} inserted}
Being bipartite is another property closely related to colorability.  If a
graph is bipartite, then you can color it with 2 colors using one color
for the nodes on the ``left'' and a second color for the nodes on the
``right.''  Conversely, graphs with chromatic number 2 are all bipartite
with all the vertices of one color on the ``left'' and those with the
other color on the right.  Since only graphs with no edges---the
\emph{\idx{empty graph}s}---have chromatic number 1, we have:  \iffalse
Empty graphs are
bipartite as long they have at least two vertices: a graph with only one
vertex is not bipartite because its vertex set cannot be partitioned into
two \emph{nonempty} subsets.\fi
\begin{lemma}\label{2color-iff-bip}
A graph, $G$, with at least one edge is bipartite iff $\chi(G) = 2$.
\end{lemma}

The chromatic number of a graph can also be shown to be small if the
vertex degrees of the graph are small.  In particular, if we have an
upper bound on the degrees of all the vertices in a graph, then we can
easily find a coloring with only one more color than the degree bound.

\begin{theorem}\label{thm:k+1-colorable}
A graph with maximum degree at most $k$ is $(k+1)$-colorable.
\end{theorem}

Since $k$ is the only nonnegative integer valued variable mentioned in the
theorem, you might be tempted to try to prove this theorem using induction
on~$k$.  Unfortunately, this approach leads to disaster---we don't know of
any reasonable way to do this and expect it would ruin your week if you
tried it on a problem set.  When you encounter such a disaster using
induction on graphs, it is usually best to change what you are inducting
on.  In graphs, typical good choices for the induction parameter are $n$,
the number of nodes, or $e$, the number of edges.

\begin{proof}[Proof of Theorem~\ref{thm:k+1-colorable}]
We use induction on the number of vertices in the graph, which we
denote by $n$.  Let $P(n)$ be the proposition that an $n$-vertex graph
with maximum degree at most $k$ is $(k+1)$-colorable.

\inductioncase{Base case} ($n=1$): A 1-vertex graph has maximum degree
0 and is 1-colorable, so $P(1)$ is true.

\inductioncase{Inductive step}: Now assume that $P(n)$ is true, and
let $G$ be an $(n+1)$-vertex graph with maximum degree at most $k$.
Remove a vertex $v$ (and all edges incident to it), leaving an
$n$-vertex subgraph, $H$.  The maximum degree of $H$ is at most $k$,
and so $H$ is $(k+1)$-colorable by our assumption $P(n)$.  Now add
back vertex $v$.  We can assign $v$ a color (from the set of $k + 1$
colors) that is different from all its adjacent vertices, since there
are at most $k$ vertices adjacent to~$v$ and so at least one of the
$k+1$ colors is still available.  Therefore, $G$ is $(k+1)$-colorable.
This completes the inductive step, and the theorem follows by
induction.
\end{proof}

Sometimes $k+1$ colors is the best you can do.  For example, $\chi(K_n) = n$
and every node in $K_n$ has degree $k = n - 1$ and so this is an example where
Theorem~\ref{thm:k+1-colorable} gives the best possible bound.  By a
similar argument, we can show that Theorem~\ref{thm:k+1-colorable} gives
the best possible bound for \emph{any} graph with degree bounded by
$k$ that has $K_{k+1}$ as a subgraph.

But sometimes $k+1$ colors is far from the best that you can do.
For example, the $n$-node \emph{star graph} shown in
Figure~\ref{fig:5T} has maximum degree $n - 1$ but can be colored
using just 2 colors.

\begin{figure}

\graphic{star-graph}

\caption{A 7-node star graph.}

\label{fig:5T}

\end{figure}


\subsection{Why coloring?}

One reason coloring problems frequently arise in practice is because
scheduling conflicts are so common.  For example, at Akamai, a new
version of software is deployed over each of 65,000 servers every few
days.  The updates cannot be done at the same time since the servers
need to be taken down in order to deploy the software.  Also, the
servers cannot be handled one at a time, since it would take forever
to update them all (each one takes about an hour).  Moreover, certain
pairs of servers cannot be taken down at the same time since they have
common critical functions.  This problem was eventually solved by
making a 65,000-node conflict graph and coloring it with 8 colors---so
only 8 waves of install are needed!

Another example comes from the need to assign frequencies to radio
stations.  If two stations have an overlap in their broadcast area, they
can't be given the same frequency.  Frequencies are precious and
expensive, so you want to minimize the number handed out.  This amounts to
finding the minimum coloring for a graph whose vertices are the stations
and whose edges connect stations with overlapping areas.

Coloring also comes up in allocating registers for program variables.
While a variable is in use, its value needs to be saved in a register.
Registers can be reused for different variables but two variables need
different registers if they are referenced during overlapping
intervals of program execution.  So register allocation is the
coloring problem for a graph whose vertices are the variables:
vertices are adjacent if their intervals overlap, and the colors are
registers.  Once again, the goal is to minimize the number of colors
needed to color the graph.

Finally, there's the famous map coloring problem stated in
Proposition~\ref{4colorprop}.  The question is how many colors are
needed to color a map so that adjacent territories get different
colors?  This is the same as the number of colors needed to color a
graph that can be drawn in the plane without edges crossing.  A proof
that four colors are enough for \index{planar graphs} \emph{planar}
graphs was acclaimed when it was discovered about thirty years ago.
Implicit in that proof was a 4-coloring procedure that takes time
proportional to the number of vertices in the graph (countries in the
map).

Surprisingly, it's another of those million dollar prize questions to
find an efficient procedure to tell if a planar graph really
\emph{needs} four colors, or if three will actually do the job.  A
proof that testing 3-colorability of graphs is as hard as the million
dollar SAT problem is given in Problem~\ref{PS_3color_SAT}; this turns
out to be true even for planar graphs.  (It is easy to tell if a graph
is 2-colorable, as explained in Section~\ref{subsec:odd_cycles}.)  In
Chapter~\ref{planar_graphs_chap}, we'll develop enough planar graph
theory to present an easy proof that all planar graphs are
5-colorable.

\iffalse
Planarity is another property with important colorability consequences.
The famous 4-Color Theorem says that every planar graph is 4-colorable.
This is a hard result to prove, but we will come close in
Chapter~\ref{planar_graphs_chap} where we define planar graphs and prove
that they are 5-colorable.
\fi

\begin{problems}
\classproblems
\pinput{CP_chromatic_number}
% S09.cp6r.1
% S09.cp6r.2

\homeworkproblems
\pinput{PS_TA_recitation_graph_coloring}
\pinput{PS_graph_colorable}
\pinput{PS_3color_SAT}

\examproblems
\pinput{FP_bogus_coloring_proof}

\end{problems}


%% Connectedness %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Simple Walks}\label{sec:connectedness}

\subsection{Walks, Paths, Cycles in Simple Graphs}
Walks and paths in simple graphs are esentially the same as in digraphs.
We just modify the digraph definitions using undirected edges instead of directed
ones.  For example, the formal definition of a walk in a simple graph is a virtually
the same as the Definition~\ref{def:digraph-walks} of a walk in a digraph:

\begin{definition}\label{def:simplegraph-walks}
A \term{walk in a simple graph}, $G$, is an alternating sequence of
vertices and edges that begins with a vertex, ends with a vertex, and
such that for every edge $\edge{u}{v}$ in the walk, one of the
endpoints $u$, $v$ is the element just before the edge, and the other
endpoint is the next element after the edge.  The \term{length of a
  walk} is the total number of occurrences of edges in it.

So a walk, $\walkv{v}$, is a sequence of the form
\[
\walkv{v} \eqdef v_0\ \edge{v_0}{v_1}\
v_1\  \edge{v_1}{v_2}\  v_2\  \dots\  \edge{v_{k-1}}{v_k}\  v_k
\]
where $\edge{v_i}{v_{i+1}} \in \edges{G}$ for $i \in [0,k)$.
  The walk is said to \emph{start} at $v_0$, to \emph{end} at $v_k$,
  and the \emph{length}, $\lnth{\walkv{v}}$, of the walk is
  $k$.  The walk is a \emph{path} iff all the $v_i$'s are different,
  that is, if $i \neq j$, then $v_i \neq v_j$.

A \term{closed walk} is a walk that begins and ends at the same
vertex.  A \term{cycle} is a closed walk of length three or more whose
vertices are distinct except for the beginning and end vertices.
\end{definition}
Note that a single vertex counts as a length zero path and closed
walk.  But in contrast to digraphs, a single vertex is not considered
a cycle.  A closed walk of length two---that is, going back and forth
on the same edge---is not considered to be a cycle either.

As in digraphs, the length of a walk is \emph{one less} than the
number of occurrences of vertices in it.  For example, the graph in
Figure~\ref{dg} has a length~6 path through the seven successive
vertices $abcdefg$.  This is the longest path in the graph.
\begin{figure}
\graphic{distance-graph}
\caption{\em A graph with 3 cycles: $bhecb$,
$cdec$, $bcdehb$.}
\label{dg}
\end{figure}
The graph in Figure~\ref{dg} also has three cycles through successive vertices $bhecb$,
$cdec$, and $bcdehb$.

\iffalse
The vertex sequence $bcdecb$ describes a closed walk in the graph
in Figure~\ref{dg}.  This sequence suggests indicates that the walk
begins and ends at vertex $b$, but

All the paths that describe the same closed walk have the same length
which is defined to be the \term{length of the walk}.  (Note that this
implies that going around the same walk twice is considered to be
different than going around it once.)

More precisely, a cycle is a
closed walk that can be described by a walk of length at least three whose
vertices are all different except for the beginning and end vertices.
So in contrast to \emph{paths}, the length of a \emph{cycle} is the
\emph{same} as the number of distinct vertices that appear in it.

\footnote{Technically speaking, we haven't ever defined what a cycle
\emph{is}, only how to describe it with paths.  But we won't need an
abstract definition of cycle, since all that matters about a cycle is which
paths describe it.}
\fi

\subsection{Cycles as Subgraphs}

A cycle does not really have a beginning or an end, so it can be
described by \emph{any} of the paths that go around it.  For example,
in the graph in Figure~\ref{dg}, the cycle starting at $b$ and going
through vertices $bcdehb$ can also be described as starting at $d$ and
going through $decbcd$.  Furthermore, cycles in simple graphs don't
have a direction: $dcbced$ describes the same cycle as though it
started and ended at $d$ but went in the opposite direction.

A precise way to explain which closed walks describe the same cycle is
to define cycle as a subgraph instead of as a closed walk.  Specifically, we
could define a cycle in $G$ to be a \emph{subgraph} of $G$ that looks
like a length-$n$ cycle for $n \ge 3$.

\begin{definition}\label{def:subgraph}
  A graph $G$ is said to be a \emph{subgraph} of a graph $H$ if
  $\vertices{G} \subseteq \vertices{H}$ and $\edges{G} \subseteq
  \edges{H}$.
\end{definition}

For example, the one-edge graph $G$ where
\begin{equation*}
   \vertices{G} = \set{ g, h, i } \quad \text{and}\quad  \edges{G} =
   \set{\, \edge{h}{i} \, }
\end{equation*}
is a subgraph of the graph $H$ in Figure~\ref{fig:graph-example}.  On the
other hand, any graph containing an edge~$\edge{g}{h}$ will not be a
subgraph of $H$ because this edge is not in $\edges{H}$.  Another example
is an empty graph on $n$ nodes, which will be a subgraph of an~$L_n$ with
the same set of nodes; similarly, $L_n$ is a subgraph of ~$C_n$, and ~$C_n$ is
a subgraph of ~$K_n$.

\begin{definition}
  For $n \ge 3$, let \term{$C_n$} be the graph with vertices $1,\dots, n$
  and edges
\[
\edge{1}{2},\ \ \edge{2}{3},\ \ \dots,\ \ \edge{(n-1)}{n},\ \ \edge{n}{1}.
\]

\iffalse
A graph is a \term{cycle} of length $n$ iff it is isomorphic to $C_n$
for some $n \ge 3$.
\fi

A \term{cycle of a graph}, $G$, is a subgraph of $G$ that is
isomorphic to $C_n$ for some $n \ge 3$.
\end{definition}

This definition formally captures the idea that cycles don't
have direction or beginnings or ends.

\iffalse

\begin{editingnotes}
\section{Weighted Graphs}

Sometimes we'll be interested in connections between nodes that have a
\emph{capacity} or \emph{weight}.  For example, we might be interested in
quantities such as the
\begin{itemize}

\item resistance of a wire between a pair of terminals, 

\item capacity of an Internet fiber between a pair of computers,

\item tension of a spring connecting a pair of devices in a dynamical system,

\item tension of a bond between a pair of atoms in a molecule,

\item distance of a highway between a pair of cities.

\end{itemize}
To model such cases, we associate with an edge a quantity called its
\emph{weight}.  More precisely,
\begin{definition}
  A \term{weight function} for a graph $G$ is a function $w: \edges{G} \to
  \reals$, where $w(e)$ is called the \term{weight of edge} $e$.
An \term{edge-weighted graph} consists of a simple graph along with
a weight function for the graph.
\end{definition}
We'll just say \term{weighted graph} when we mean
edge-weighted.\footnote{Vertex-weighted graphs can be defined similarly,
  but we won't need these.}
For example, Figure~\ref{fig:weighted_graph} shows a weighted graph
where the weight of edge $\edge{a}{b}$ is~5.

\begin{figure}

\graphic{Fig_5D}

\caption{A 4-node weighted graph where the edge~$\edge{a}{b}$ has
  weight~5.}
\label{fig:weighted_graph}
\end{figure}

\subsection{Adjacency Matrices}

%\begin{editingnotes}
  \textcolor{red}{replaced by ARM with the next paragraph}: There are many
  ways to represent a graph.  We have already seen two ways: you can draw
  it, as in Figure~\ref{fig:weighted_graph} for example, or you can
  represent it with sets of vertices and edges.  Another common
  representation is with an adjacency matrix.
%\end{editingnotes}

A useful way to specify a graph is with an \emph{adjacency matrix}.  The
adjacency matrix of an $n$-vertex graph $G$, is an $n \times n$ 0-1-valued
matrix whose $ij$th entry indicates whether there is an edge from the
$i$th to the $j$th vertex of $G$, where the vertices of $G$ are assumed to
be numbered from $1$ to $n$.  Sometimes it's more convenient to use the
vertices themselves to index the matrix, writing $A_{uv}$ instead of
$A_{ij}$ when $u$ and $v$ are the vertices numbered $i$ and $j$.  Several
formulas get simpler when we index the matrix entries this way.

\begin{definition}\label{def:adjacency_matrix}
The \term{adjacency matrix} for a graph~$G$ with
is the $n \by n$ matrix $A_G$  indexed by $\vertices{G}$ whose $uv$th entry is
\begin{equation*}
    (A_G)_{uv} \eqdef \begin{cases}
                1 & \text{if $\edge{u}{v} \in \edges{G}$}, \\
                0 & \text{otherwise.}
              \end{cases}
\end{equation*}
When $G$ is a weighted graph with weight function $w$, then the adjacency
matrix for~$G$ is the $n \by n$ matrix $A_G$ whose $uv$th entry is defined
to be:
\begin{equation*}
      (A_G)_{uv} \eqdef \begin{cases}
                w(\edge{u}{v}) & \text{if $\edge{u}{v} \in \edges{G}$}, \\
                \infty         & \text{otherwise.}
              \end{cases}
\end{equation*}
\end{definition}

For example, Figure~\ref{fig:adjacency_matrix}
%\begin{editingnotes}
\arm{REVISED Fig needed}: weighted graph case 0's should be $\infty$'s.
%\end{editingnotes}
displays the adjacency
matrices for the graphs shown in Figures~\ref{fig:isomorphism}(a)
and~\ref{fig:weighted_graph} where $v_1 = a$, $v_2 = b$, $v_3 = c$,
and $v_4 = d$.

\begin{figure}\redrawntrue
\normalbaselines
\subfloat[]{%
    $
       \begin{pmatrix}
           0 & 1 & 0 & 1 \\
           1 & 0 & 1 & 0 \\
           0 & 1 & 0 & 1 \\
           1 & 0 & 1 & 0
       \end{pmatrix}
   $
}
\qquad
\subfloat[]{%
   $
       \begin{pmatrix}
           \infty & 5 & \infty & \infty \\
           5 & \infty & 6 & \infty \\
           \infty & 6 & \infty & -3 \\
           \infty & \infty & -3 & \infty
       \end{pmatrix}
   $
}

\caption{Examples of adjacency matrices.  (a)~shows the adjacency
  matrix for the graph in Figure~\ref{fig:isomorphism}(a) and
  (b)~shows the adjacency matrix for the weighted graph in
  Figure~\ref{fig:weighted_graph}.  In each case, we  set $v_1
  = a$, $v_2 = b$, $v_3 = c$, and $v_4 = d$ to construct the matrix.}
\label{fig:adjacency_matrix}
\end{figure}

\subsubsection{Minimum Weight Path  Matrices}
The relation between powers of the adjacency matrix and numbers of
walks is cool (to us math nerds at least), but a much more important
problem is finding \index{graph!shortest path} shortest paths between
pairs of nodes in a graph.  For example, when you drive home for
vacation, you generally want to take the shortest-time route.  It
turns out that shortest paths---even in weighted graphs---can be
determined in pretty much the same way that numbers of paths were
counted using powers of the connection matrix.

\begin{definition}\label{def:5H}
  The \index{path!weight of}\term{weight of a walk} \index{weighted graph,
    path weight} in a \idx{weighted graph} is the sum of the weights of
  the successive edges in the walk.
\end{definition}

%\begin{editingnotes}
\arm{cut}
There is good news and bad news to report on this front.  The good
news is that it is not very hard to find a shortest path.  The bad
news is that you can't win one of those million dollar prizes for
doing it.

In fact, there are several good algorithms known for finding a shortest
path between nodes $u$ and $v$ in an $n$-node graph $G$.  The simplest to
explain (but not quite the fastest) is to compute \arm{revised to include
  stopping condition at $n$} the successive powers of $A_G$ one by one up
to the $n$th, watching for the first power at which the $uv$th entry is
nonzero.  That's because Theorem~\ref{thm:CkDm} implies that the length of
the shortest path, if any, between $u$ and~$v$ will be the smallest
value~$k$ for which $(A_G)_{uv}^k$ is nonzero, and if there is a shortest
path, its length will be $\leq n$.
%\end{editingnotes}

\begin{definition}
  The \term{minimum weight matrix} for length $k$ walks in an $n$-vertex
  graph $G$ is the $n \times n$ matrix $W$ such that for $u,v \in \vertices{G}$,
\begin{equation}\label{def:weight_matrix}
W_{uv} \eqdef
\begin{cases} w & \text{if $w$ is the minimum weight among length $k$
                            walks from $u$ to $v$},\\
              \infty & \text{if there is no length $k$ walk from $u$ to $v$}.
\end{cases}
\end{equation}
\end{definition}

So the minimum weight matrix for length $1$ walks in a weighted graph $G$
is precisely its adjacency matrix $A_G$.  Now for the purpose of finding
minimum weight walks, we'll modify the definition of matrix
multiplication, replacing multiplication of elements by addition, and the
sum of the products by the minimum.

\begin{definition}\label{def:minplus}
  The $\minplus$ product of two $n\times n$ matrices $W$ and $M$ with
  entries in $\reals\union \set{\infty}$ is the $n \times n$ matrix
  $W\minplusop M$ whose $ij$ entry is
\[
(W\minplusop M )_{ij} \eqdef \min \set{W_{ik} + M_{kj} \suchthat 1 \leq k \leq n}\, .
\]
\end{definition}

\begin{theorem}\label{thm:weightmatrix-min+}
  If $W$ is the minimum weight matrix for length $k$ walks in a weighted
  graph $G$, and $M$ is the minimum weight matrix for length $m$ walks,
  then then $W\minplusop M$ is the minimum weight matrix for length $k+m$
  walks.
\end{theorem}

\begin{proof}
  The proof is virtually the same as the proof of Theorem~\ref{thm:CkDm}
  with multiplication of elements replaced by addition, and the sum of the
  multiplications by the minimum of the additions:

  Any length $k+m$ path between vertices $u$ and $v$ begins with a length
  $k$ path starting at $u$ and ending at some vertex, $x$, followed by a
  length $m$ path starting at $x$ and ending at $v$.  So the minimum
  weight of a length $k+m$ path from $u$ to $v$ that goes through $x$ at
  the $k$th step equals the minimum weight $W_{ux}$ of length $k$ walks
  from $u$ to $x$, plus the minimum weight $M_{xv}$ of length $m$ walks
  from $w$ to $v$.  So we can get the minimum weight of length $k+m$ walks
  from $u$ to $v$ by taking the minimum over all possible vertices $x$ of
  the minimum weight of such walks that go through $w$ at the $k$th step.
  In other words,
\begin{equation}\label{ln-min+nuv}
\text{min weight of a length $n+m$ path from $u$ to $v$} =
              \min_{x \in \vertices{G}} W_{ux}+M_{xv}\, .
\end{equation}
But the right hand side of~\eqref{ln-min+nuv} is precisely the definition of
$(W\minplusop M)_{uv}$.  Thus, $W\minplusop M$ is indeed the minimum weight
matrix for walks of length $k+m$.
\end{proof}

Now Theorem~\ref{thm:weightmatrix-min+} implies that the $k$th $\minplus$ power
of $A_G$, that is,
\[
(A_G)^{k, \minplus} \eqdef \underbrace{\paren{A_G\ \minplusop\ \paren{A_G\
      \minplusop\ \paren{\cdots \paren{A_G\ \minplusop\ A_G}} }}}_{k\ A_G\text{'s}},
\]
is the minimum weight matrix for the length $k$ walks.

This takes us most of the way, but we really want the minimum weight
regardless of the lengths of the walks.  To get this, we use the fact that
as long as all weights are \emph{nonnegative}, the minimum weight walk
between two vertices will be a path; this follows by the same reasoning
used for Theorem~\ref{simplepath}.  Since $n-1$ is the longest \emph{path}
can be in an $n$-node graph, we have an upper bound on the length of
minimum weight paths we have to look at.  We could now find the minimum
weight paths by computing all the $\minplus$ powers of $A_G$ up to the
$n-1$st.  But there is another trick that dramatically cuts the number of
$\minplus$ matrix multiplications.

Namely, for any graph $G$, let $G_0$ be the same as $G$ except that
self-loops of weight zero appear at every vertex.  So a path of length $k$
in $G$ can be extended to a path in $G_0$ with the same weight but with
any desired length $ \geq k$---just repeatedly follow weight zero
self-loops after the $k$th step.  This means that $(A_{G_0})^{k, \minplus}$
is the minimum weight matrix for walks of length \emph{less than or equal}
to $k$ in $G$.  So we can choose $k = n-1$ to get a matrix with the
actual minimum weights among all walks between vertices.

\begin{theorem}\label{thm:minweightmatrix}
Let $G$ be an $n$-vertex weighted graph with nonnegative weights, and let
$D_G$ be the adjacency matrix of $G$ with the diagonal entries set to 0.
Then $(D_G)^{n-1, \minplus}$ is the minimum weight path matrix for $G$, that
is,
\[
((D_G)^{n-1, \minplus})_{uv} = \text{the minimum weight of walks in $G$ from
 $u$ to $v$}\,.
\]
\end{theorem}
Now you can use the repeated squaring trick to compute $(D_G)^{n-1,
  \minplus}$ using about $\log n$ $\minplus$ matrix multiplications
instead of $n-2$ such multiplications.

%\begin{editingnotes}
\arm{Good to add an example here}
%\end{editingnotes}

\end{editingnotes}
\fi

\section{Connectivity}

\begin{definition}\label{def:connected-vertices} %\label{def:connected-graph}
  \emph{Two vertices are} \term{connected} in a graph when there is a
  path that begins at one and ends at the other.  By convention, every
  vertex is connected to itself by a path of length zero.  A
  \emph{graph is connected} when every pair of vertices are connected.
\end{definition}

\subsection{Connected Components}

Being connected is usually a good property for a graph to have.  For
example, it could mean that it is possible to get from any node to any
other node, or that it is possible to communicate between any pair of
nodes, depending on the application.

But not all graphs are connected.  For example, the graph where nodes
represent cities and edges represent highways might be connected for
North American cities, but would surely not be connected if you also
included cities in Australia.  The same is true for communication
networks like the Internet---in order to be protected from viruses
that spread on the Internet, some government networks are completely
isolated from the Internet.

\begin{figure}[htbp]

\graphic{connectivity-graphs}

\caption{One graph with 3 connected components.}

\label{fig:3comp}
\end{figure}

Another example, is shown in Figure~\ref{fig:3comp}, which looks like a
picture of three graphs, but is intended to be a picture of \emph{one}
graph.  This graph consists of three pieces (subgraphs).  Each piece
by itself is connected, but there are no paths between vertices in
different pieces.  These connected pieces of a graph are called its
\term{connected components}.

\begin{definition}\label{def:connected-component}
A \emph{connected component} of a graph is a subgraph consisting of
some vertex and every node and edge that is connected to that vertex.
\end{definition}

So, a graph is connected iff it has exactly one connected component.
At the other extreme, the empty graph on $n$ vertices has $n$
connected components.

\subsection{$k$-Connected Graphs}

If we think of a graph as modeling cables in a telephone network, or
oil pipelines, or electrical power lines, then we not only want
connectivity, but we want connectivity that survives component
failure.  So more generally, we want to define how strongly two
vertices are connected.  One measure of connection strength is how
many links must fail before connectedness fails.  In particular, two
vertices are \term{$k$-edge connected} when it takes at least $k$
``edge-failures'' to disconnect them.  More precisely:

\begin{definition}\label{def:k-connected}
Two vertices in a graph are $k$-\term{edge connected} when they remain
connected in every subgraph obtained by deleting up to $k-1$ edges.  A
graph is $k$-edge
\index{connected!edge}\index{connected!$k$-edge}connected when it has
more than one vertex, and every subgraph obtained by deleting at most
$k-1$ edges is connected.
\end{definition}
\iffalse
every two of its vertices are $k$-edge connected.
\fi

Two vertices are connected according to
Definition~\ref{def:connected-vertices} iff they are 1-edge connected
according to Definition~\ref{def:k-connected}; likewise for any graph
with more than one vertex.

There are other kinds of connectedness, but edge-connectedness will be
enough for us, so from now on we'll drop the ``edge'' modifier and
just say ``\idx{connected}.''\footnote{There is an obvious definition
  of $k$-\idx{vertex connected}ness\index{connected!$k$-edge} based on
  deleting vertices rather than edges.  Graph theory texts usually use
  ``$k$-connected'' as shorthand for ``$k$-vertex connected.''}

For example, in the graph in Figure~\ref{dg}, vertices $c$ and~$e$ are
3 connected, $b$ and~$e$ are 2 connected, $g$ and $e$ are 1 connected,
and no vertices are 4 connected.  The graph as a whole is only 1
connected.  A complete graph, $K_n$, is $(n-1)$ connected.
\begin{editingnotes}
\arm{inserted cycles and cut edges }
\end{editingnotes}
Every cycle is 2-connected.

The idea of a \emph{cut edge} is a useful way to explain 2-connectivity.
\begin{definition}
If two vertices are connected in a graph $G$, but not connected when
an edge $e$ is removed, then $e$ is called a \term{cut edge} of $G$.
\end{definition}
So a graph with more than one vertex is 2-connected iff it is
connected and has no cut edges.  The following Lemma is
another immediate consequence of the definition:
\begin{lemma}\label{lem:cutiffcycle}
An edge is a cut edge iff it is not on a cycle.
\end{lemma}

More generally, if two vertices are connected by $k$ edge-disjoint
paths---that is, no edge occurs in two paths---then they must
be $k$ connected, since at least one edge will have to be removed from
each of the paths before they could disconnect.  A fundamental fact,
whose ingenious proof we omit, is \idx{Menger}'s theorem which
confirms that the converse is also true: if two vertices are
$k$-connected, then there are $k$ edge-disjoint paths connecting them.
It takes some ingenuity to prove this just for the case $k=2$.

\subsection{The Minimum Number of Edges in a Connected Graph}

The following theorem says that a graph with few edges must have many
connected components.
\begin{theorem}\label{th:connectivity}
Every graph, $G$, has at least $\card{\vertices{G}} - \card{\edges{G}}$
connected components.
\end{theorem}
Of course for Theorem~\ref{th:connectivity} to be of any use, there must
be fewer edges than vertices.

\begin{proof}
We use induction on the number, $k$, of edges.  Let $P(k)$ be the
proposition that
\begin{quote}
every graph, $G$, with $k$ edges has at least $\card{\vertices{G}}-k$
connected components.
\end{quote}

\inductioncase{Base case} ($k=0$): In a graph with 0 edges, each
vertex is itself a connected component, and so there are exactly
$\card{\vertices{G}} = \card{\vertices{G}} - 0$ connected components.
So $P(0)$ holds.

\inductioncase{Inductive step}:

\iffalse
Now we assume that the induction hypothesis holds for every $k$-edge
graph in order to prove that it holds for every $(k+1)$-edge graph,
where $k \geq 0$.
\fi

Let $G_e$ be the graph that results from removing an edge, $e \in
\edges{G}$.  So $G_e$ has $k$ edges, and by the induction hypothesis
$P(k)$, we may assume that $G_e$ has at least $\card{\vertices{G}} -
k$ connected components.  Now add back the edge $e$ to obtain the
original graph $G$.  If the endpoints of $e$ were in the same
connected component of $G_e$, then $G$ has the same sets of connected
vertices as $G_e$, so $G$ has at least $\card{\vertices{G}} - k >
\card{\vertices{G}} - (k+1)$ components.  Alternatively, if the
endpoints of $e$ were in different connected components of $G_e$, then
these two components are merged into one component in~$G$, while all
other components remain unchanged, so that $G$ has one fewer connected
component than $G_e$.  That is, $G$ has at least $(\card{\vertices{G}}
- k) - 1 = \card{\vertices{G}} - (k+1)$ connected components.  So in
either case, $G$ has at least $\card{\vertices{G}} - (k+1)$
components, as claimed.

This completes the inductive step and hence the entire proof by
induction.
\end{proof}

\begin{corollary}
\label{cor:n-1}
Every connected graph with $n$ vertices has at least $n - 1$ edges.
\end{corollary}

A couple of points about the proof of Theorem~\ref{th:connectivity}
are worth noticing.  First, we used induction on the number of edges
in the graph.  This is very common in proofs involving graphs, as is
induction on the number of vertices.  When you're presented with a
graph problem, these two approaches should be among the first you
consider.

The second point is more subtle.  Notice that in the inductive step,
we took an arbitrary $(k+1)$-edge graph, threw out an edge so that we
could apply the induction assumption, and then put the edge back.
You'll see this shrink-down, grow-back process very often in the
inductive steps of proofs related to graphs.  This might seem like
needless effort: why not start with an $k$-edge graph and add one more
to get an $(k+1)$-edge graph?  That would work fine in this case, but
opens the door to a nasty logical error called \term{buildup error},
illustrated in Problem~\ref{CP_bogus_pos_deg_but_not_connected}.

\iffalse

\subsubsection{Build-Up Error}

\begin{falseclm*}
If every vertex in a graph has degree at least~1, then the graph is
connected.
\end{falseclm*}

There are many counterexamples; for example, see Figure~\ref{fig:5Z}.

\begin{figure}

\graphic{Fig_5Z}

\caption{A counterexample graph to the False Claim.}

\label{fig:5Z}
\end{figure}

\begin{bogusproof}
We use induction.  Let $P(n)$ be the proposition that if every vertex
in an $n$-vertex graph has degree at least~1, then the graph is
connected.

\inductioncase{Base case} ($n=1$): There is only one graph with a
single vertex and it has degree~0.  Therefore, $P(1)$ is vacuously true,
since the if-part is false.

\inductioncase{Inductive step}: We must show that $P(n)$ implies
$P(n+1)$ for all $n \ge 1$.  Consider an $n$-vertex graph in which
every vertex has degree at least~1.  By the assumption~$P(n)$, this
graph is connected; that is, there is a path between every pair of
vertices.  Now we add one more vertex~$x$ to obtain an $(n+1)$-vertex
graph as shown in Figure~\ref{fig:5Y}.

\begin{figure}

\graphic{false-connect-pic}

\caption{Adding a vertex~$x$ with degree at least~1 to a connected
  $n$-node graph.}

\label{fig:5Y}

\end{figure}

All that remains is to check that there is a path from $x$ to every
other vertex~$z$.  Since $x$ has degree at least one, there is an edge
from~$x$ to some other vertex; call it~$y$.  Thus, we can obtain a
path from~$x$ to~$z$ by adjoining the edge $\edge{x}{y}$ to the path
from~$y$ to~$z$.  This proves $P(n + 1)$.

By the principle of induction, $P(n)$ is true for all  $n \ge 1$,
which proves the theorem
\end{bogusproof}

Uh-oh\dots this proof looks fine!  Where is the bug?  It turns out
that the faulty assumption underlying this argument is that
\emph{every $(n + 1)$-vertex graph with minimum degree~1 can be
obtained from an $n$-vertex graph with minimum degree~1 by adding 1
more vertex}.  Instead of starting by considering an arbitrary $(n +
1)$-node graph, this proof only considered $(n + 1)$-node graphs
that you can make by starting with an $n$-node graph with minimum
degree~1.

The counterexample in Figure~\ref{fig:5Z} shows that this assumption
is false; there is no way to build the 4-vertex graph in
Figure~\ref{fig:5Z} from a 3-vertex graph with minimum degree~1.
Thus the first error in the proof is the statement ``This proves
$P(n + 1)$.''

This kind of flaw is known as ``build-up error.''  Usually, build-up
error arises from a faulty assumption that every size $n + 1$ graph
with some property can be ``built up'' from a size~$n$ graph with the
same property.  (This assumption is correct for some properties, but
incorrect for others---such as the one in the argument above.)

One way to avoid an accidental build-up error is to use a ``shrink
down, grow back'' process in the inductive step, namely, start with a
size $n+1$ graph, remove a vertex (or edge), apply the inductive
hypothesis $P(n)$ to the smaller graph, and then add back the vertex
(or edge) and argue that $P(n + 1)$ holds.  Let's see what would have
happened if we'd tried to prove the claim above by this method:

\inductioncase{Revised inductive step}: We must show that $P(n)$
implies $P(n + 1)$ for all $n \ge 1$.  Consider an $(n + 1)$-vertex
graph~$G$ in which every vertex has degree at least~1.  Remove an
arbitrary vertex~$v$, leaving an $n$-vertex graph~$G_e$ in which every
vertex has degree\dots\ uh oh!

The reduced graph~$G_e$ might contain a vertex of degree~0, making the
inductive hypothesis $P(n)$ inapplicable!  We are stuck---and
properly so, since the claim is false!

Always use shrink-down, grow-back arguments and you'll never fall into
this trap.

%S08, cp6m, S06 cp5f

%S06 cp5f
\fi

%% Connectedness Problems %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problems}
\classproblems
\pinput{CP_n_dim_hypercube}
\pinput{CP_graph_maximal_connected}
\pinput{CP_Kn_is_very_connected}
\pinput{CP_bogus_pos_deg_but_not_connected}

\homeworkproblems
\pinput{PS_shortest_undirected_closed_walk}
\pinput{PS_Euler_circuits}

% S09.cp6m.2
% S09.cp6t.1

\homeworkproblems
\pinput{PS_tangled_and_mangled_graphs}
\pinput{PS_circuit_graph_with_crossbars}

\examproblems
\pinput{MQ_graph_state_machine}

\end{problems}

\section{Odd Cycles and 2-Colorability}\label{subsec:odd_cycles}

We have already seen that determining the chromatic number of a graph is a
challenging problem.  There is one special case where this problem is very
easy, namely, when the graph is 2-colorable.

\begin{theorem}\label{thm:2-colorable-equiv}
The following graph properties are equivalent:

\begin{enumerate}

\item\label{has-odd-cycle}
The graph contains an odd length cycle.

\item\label{not-2-color}
The graph is not 2-colorable.

\item\label{has-odd-closed-walk}
The graph contains an odd length closed walk.

\end{enumerate}
\end{theorem}
In other words, if a graph has any one of the three properties above, then
it has all of the properties.

We will show the following implications among these properties:
\[
\text{\ref{has-odd-cycle}.} \QIMPLIES \text{\ref{not-2-color}.} \QIMPLIES
\text{\ref{has-odd-closed-walk}.} \QIMPLIES
\text{\ref{has-odd-cycle}}.
\]
So each of these properties implies the other two,
 which means they all are equivalent.
\iffalse
\footnote{Mutual
  implication follows from transivity of implication,
  Rule~\ref{rule:transitivity} in Section~\ref{sec:logical_deduction}}
\fi


\begin{description}

\item[\ref{has-odd-cycle} \QIMPLIES\ \ref{not-2-color}]
\begin{proof}
This follows from equation~\ref{Codd3}.
\end{proof}

\item[\ref{not-2-color} \QIMPLIES\ \ref{has-odd-closed-walk}]

  If we prove this implication for connected graphs, then it will hold
  for an arbitrary graph because it will hold for each
  connected component.  So we can assume that $G$ is connected.
\begin{proof}

  Pick an arbitrary vertex $r$ of $G$.  Since $G$ is connected, for every
  node $u \in \vertices{G}$, there will be a walk $\walkv{w}_u$ starting
  at $u$ and ending at $r$.  Assign colors to vertices of $G$ as follows:
\[
\text{color}(u) = \begin{cases}
                   \text{black}, & \text{if $\lnth{\walkv{w}_u}$ is even},\\
                   \text{white}, & \text{otherwise}.
\end{cases}
\]
Now since $G$ is not colorable, this can't be a valid coloring.  So there
must be an edge between two nodes $u$ and $v$ with the same color.  But in
that case
\[
%\catv{\catv{\walkv{w}_u}{r}{\text{reverse}(\walkv{w}_v)}}{v}{vu}
%\merge{\catv{\walkv{w}_u}{r}{\text{reverse}(\walkv{w}_v)}}{\edge{v}{u}}
\merge{\merge{\walkv{w}_u}{\text{reverse}(\walkv{w}_v)}}{\edge{v}{u}}
\]
is a closed walk starting and ending at $u$, and its length is
\[
\lnth{\walkv{w}_u} + \lnth{\walkv{w}_v} + 1.
\]
This length is odd, since $\walkv{w}_u$ and $\walkv{w}_v$ are both even
length or are both odd length.
\end{proof}

\item[\ref{has-odd-closed-walk} \QIMPLIES\ \ref{has-odd-cycle}]

\begin{proof}
  Since there is an odd length closed walk, the WOP implies there is an odd
  length closed walk $\walkv{w}$ of minimum length.  We claim $\walkv{w}$
  must be a cycle.  To show this, assume to the contrary that there is
  vertex $x$ that appears twice on the walk, so $\walkv{w}$ consists of a
  closed walk from $x$ to $x$ followed by another such walk.  That is,
\[
\walkv{w} = \catv{\walkv{f}}{x}{\walkv{r}}
\]
for some positive length walks $\walkv{f}$ and $\walkv{r}$ that begin and
end at $x$.  Since
\[
\lnth{\walkv{w}} =  \lnth{\walkv{f}}+ \lnth{\walkv{r}}
\]
is odd, exactly one of $\walkv{f}$ and $\walkv{g}$ must have odd length,
and that one will be an odd length closed walk shorter than $\walkv{w}$, a
contradiction.

This completes the proof of Theorem~\ref{thm:2-colorable-equiv}.
\end{proof}
\end{description}


\begin{editingnotes}
\arm{Here's cleaned up version of FTL's direct proof that~\ref{not-2-color}
implies~\ref{has-odd-cycle}.  It's here for editing, but really should be
put in a problem (if it's used at all).}

But we're going to present an interesting direct proof that

\ref{not-2-color} $\QIMPLIES$~\ref{has-odd-cycle}

based on the triangle inequality, Lemma~\ref{lem:tri-ineq}.

\begin{proof}
  If we prove this implication for connected graphs, then it will hold
  for an arbitrary graph because it will hold for each connected
  component.  So we can assume that $G$ is connected.

  Pick an arbitrary vertex $r$ of $G$ and assign colors to vertices
  as follows:
\begin{equation}\label{colorurule}
\text{color}(u) \eqdef
             \begin{cases}
                   \text{black}, & \text{if $\dstuv{u}{r}$ is even},\\
                   \text{white}, & \text{otherwise}.
             \end{cases}
\end{equation}
Since $G$ is not supposed to be 2-colorable, this can't be a valid
coloring, that is, there must be an edge $\edge{u}{v}$ between two nodes
with the same color.

Because of the edge $\edge{u}{v}$, the distance between $u$ and $v$ is
1.  Because $G$ is connected, $\dstuv{u}{r}$ and $\dstuv{v}{r}$ are
both finite.  Therefore, the distance from $u$ to $r$ differs by at
most 1 from the distance from $v$ to $r$, by the triangle inequality.
But $u$ and $v$ have the same color, so their distances to $r$ can
only differ by an even number.  Of course, 0 is the only nonnegative
integer that both most 1 and even.  So they can't differ at all:
\begin{equation}\label{dstur=vr}
\dstuv{u}{r} = \dstuv{v}{r}.
\end{equation}

Here's how we find the odd cycle: given any path from $u$ to $r$ and
any path from $v$ to $r$, the vertex $r$ will be on both, by
definition,.  So by WOP, given any shortest path from $u$ to $r$ and
any shortest path from $v$ to $r$, there is a vertex $x$ on both paths
whose distance to $u$ is a minimum.  Now a shortest path from $u$ to
$x$ and a shortest path from $v$ to $x$ can \emph{only} have vertex
$x$ in common, since any other vertex they had in common would be
closer to $u$ than $x$ was.  Therefore, a shortest path from $u$ to
$x$ together with a shortest path from $v$ to $x$ and the edge
$\edge{u}{v}$ form a cycle of length
\begin{equation}\label{uxvx1}
\dstuv{u}{x}+  \dstuv{v}{x} +1.
\end{equation}

But since $x$ is on these shortest paths, Lemma~\ref{lem:tri-ineq} implies
\begin{align*}
\dstuv{u}{r} & = \dstuv{u}{x} + \dstuv{x}{r}\\
\dstuv{v}{r} & = \dstuv{v}{x} + \dstuv{x}{r},
\end{align*}
and these equalities together with equation~\eqref{dstur=vr},
imply
\[
\dstuv{v}{x} = \dstuv{u}{x}.
\]
So the cycle length~\ref{uxvx1} equals the odd number $2\dstuv{u}{x}+1$.
\end{proof}

\end{editingnotes}

Theorem~\ref{thm:2-colorable-equiv} turns out to be useful, since bipartite
graphs come up fairly often in practice.  We'll see examples when we talk
about planar graphs in Chapter~\ref{planar_graphs_chap}. 

\begin{editingnotes}
\textbf{and also in networks if that chapter gets moved later}:

and about packet routing in communication networks
in Chapter~\ref{comm_net_chap}.

\end{editingnotes}


\begin{editingnotes}
\subsection{Euler Tours}

Can you walk every hallway in the Museum of Fine Arts \emph{exactly
  once}?  If we represent hallways and intersections with edges and
vertices, then this reduces to a question about graphs.  For example,
could you visit every hallway exactly once in a museum with the
floor plan in Figure~\ref{fig:5BC}?

\begin{figure}

\gnote{Add a ``real'' floor-plan?}

\graphic{euler-tour}

\caption{A possible floor plan for a museum. Can you find a walk that
  includes every edge exactly once?}

\label{fig:5BC}

\end{figure}

The entire field of graph theory began when Euler asked whether the seven
bridges of K\"onigsberg could all be crossed exactly once---essentially
the same question we asked about the Museum of Fine Arts.  In his honor,
an \term*{Euler walk} \index{Euler!walk} is a defined to be a walk that
includes every edge in a graph exactly once.  Similarly, an \emph{Euler
  tour}\index{Euler!tour} is a closed Euler walk, that is an Euler walk that
  starts and finishes at the same vertex.  Graphs with Euler tours and
  Euler walks both have simple characterizations.
\begin{theorem}\label{thm:euler-tour}
A connected graph has an Euler tour if and only if every vertex has
even degree.
\end{theorem}

\begin{proof}
  We first show that if a graph has an Euler tour, then every vertex has
  even degree.  Assume that a graph $G$ has an Euler tour $v_0$, $v_1$,
  \dots, $v_k$ where $v_k = v_0$.  Since every edge occurs once in
  the tour, $k = \card{\edges{G}}$ and the degree of a node~$u$ in~$G$ is
  twice the number of times that node~$u$ appears in the sequence $v_0$,
  $v_1$, \dots, $v_{k-1}$.  We multiply by two since if $u = v_i$ for
  some~$i$ where $0 < i < k$, then both $\edge{v_{i - 1}}{v_i}$ and
  $\edge{v_i}{v_{i + 1}}$ are edges incident to~$u$ in~$G$.  If $u = v_0 =
  v_k$, then both $\edge{v_{k - 1}}{v_k}$ and $\edge{v_0}{v_1}$ are edges
  incident to~$u$ in~$G$.  Hence, the degree of every node is even.

We next show that if the degree of every node is even in a graph
$G$, then there is an Euler tour.  Let
\[
\walkv{w} \eqdef v_0, v_1, \dots, v_k
\]
be the longest walk in~$G$ that includes \emph{no edge more than
  once}.\footnote{Did you notice that we are using a variation of the
  Well Ordering Principle here when we implicitly assume that a
  longest walk exists?  This is ok since the length of a walk where no
  edge is used more than once is at most~$\card{\edges{G}}$, so the
  length, $n$, of the longest walk is the one where $\card{\edges{G}}
  - n$ takes its minimum value.}  The walk $\walkv{w}$ must include
every edge incident to~$v_k$; otherwise the walk could be extended and
$\walkv{w}$ would not be the longest walk that includes all edges at
most once.  Moreover, it must be that $v_k = v_0$ and that
$\walkv{w}$ is a closed walk, since otherwise $v_k$ would have odd
degree in~$\walkv{w}$, and hence in~$G$, which is not possible by
assumption.

We conclude the argument with a proof by contradiction.  Suppose that
$\walkv{w}$ is not an Euler tour.  Because $G$ is a connected graph,
we can find an edge not in $\walkv{w}$ but incident to some vertex in
$\walkv{w}$.  Call this edge $\edge{u}{v_i}$.  But then we can
construct a walk $\walkv{w}'$ that is longer than~$\walkv{w}$ but
that still uses no edge more than once:
\[
   \walkv{w}' ::= u, v_i, v_{i + 1}, \dots, v_k, v_1, v_2, \dots, v_i
\]
contradicts the definition of $\walkv{w}$, so $\walkv{w}$ must be an
Euler tour after all.
\end{proof}

It is not difficult to extend Theorem~\ref{thm:euler-tour} to prove that a
connected graph~$G$ has an Euler walk if and only if precisely 0 or~2
nodes in~$G$ have odd degree.  Hence, we can conclude that the graph
shown in Figure~\ref{fig:5BC} has an Euler walk but not an Euler tour
since the graph has precisely two nodes with odd degree.

Although the proof of Theorem~\ref{thm:euler-tour} does not explicitly
define a method for finding an Euler tour when one exists, it is not
hard to modify the proof to produce such a method.  The idea is to
grow a tour by continually splicing in closed walks until all the
edges are consumed.

\subsection{Hamiltonian Cycles}

Hamiltonian cycles are the unruly cousins of Euler tours.

\begin{definition}\label{def:hamiltonian-cycle}
A \emph{Hamiltonian cycle} in a graph~$G$ is a cycle that visits every
\emph{node} in~$G$ exactly once.  Similarly, a \emph{Hamiltonian} path
is a path in~$G$ that visits every node exactly once.
\end{definition}

Although Hamiltonian cycles sound similar to Euler tours---one visits
every node once while the other visits every edge once---finding a
Hamiltonian cycle can be a lot harder than finding an Euler tour.  The
same is true for Hamiltonian paths.  This is because no one has
discovered a simple characterization of all graphs with a Hamiltonian
cycle.  In fact, determining whether a graph has a Hamiltonian cycle
is the same category of problem as the SAT problem of
Section~\ref{SAT_sec} and the coloring problem in
Section~\ref{sec:coloring}: you get a million dollars for finding an
efficient way to determine when a graph has a Hamiltonian cycle---or
proving that no procedure works efficiently on all graphs.

\subsection{The Traveling Salesperson Problem}

As if the problem of finding a Hamiltonian cycle is not hard enough,
when the graph is weighted, we often want to find a Hamiltonian cycle
that has least possible weight.  This is a very famous optimization
problem known as the Traveling Salesperson Problem.

\begin{definition}
Given a weighted graph~$G$, the \emph{weight} of a cycle in~$G$ is
defined as the sum of the weights of the edges in the cycle.
\end{definition}

For example, consider the graph shown in Figure~\ref{fig:5AL} and
suppose that you would like to visit every node once and finish at the
node where you started.  Can you find  way to do this by with a
cycle with weight~15?

\begin{figure}

\graphic{Fig_5AL}

\caption{A weighted graph.  Can you find a cycle with weight~15 that
  visits every node exactly once?}

\label{fig:5AL}
\end{figure}

Needless to say, if you can figure out a fast procedure that finds the
optimal cycle for the traveling salesperson, let us know so that we
can win a million dollars.

\arm{Maybe include subsection on TSP within a small factor of minimal when
distances are Euclidean?  This may already be in an old problem (not yet in repository).}

\end{editingnotes}

\section{Forests \& Trees}\label{trees-sec}
We've already made good use of digraphs without cycles, but
\emph{simple} graphs without cycles are arguably the most important
graphs in computer science.

\iffalse
As we have just seen, finding good cycles in a graph can be trickier than
you might first think.  But what if a graph has no cycles at all?  Sounds
pretty dull.
  But graphs without cycles, called \emph{acyclic graphs}, are
probably the most important graphs of all when it comes to computer
science.\fi

\subsection{Leaves, Parents \& Children}

\begin{definition}\label{def:tree}
An acyclic graph is called a \emph{forest}.  A connected acyclic graph
is called a \emph{tree}.
%\begin{definition}\label{def:forest}
\end{definition}

The graph shown in Figure~\ref{fig:5I} is a forest.  Each of its
connected components is by definition a tree.

\begin{figure}

\graphic{Fig_5I}

\caption{A 6-node forest consisting of 2 component trees.}
\label{fig:5I}
\end{figure}

One of the first things you will notice about trees is that they tend
to have a lot of nodes with degree one.  Such nodes are called
\emph{leaves}.

\begin{definition}
A degree~1 node in a forest is called a \term{leaf}.
\end{definition}

The forest in Figure~\ref{fig:5I} has 4 leaves.  The tree in
Figure~\ref{fig:5H} has 5 leaves.
\begin{figure}

\graphic{tree-example}

\caption{A 9-node tree with 5 leaves.}

\label{fig:5H}
\end{figure}

Trees are a fundamental data structure in computer science.  For
example, information is often stored in tree-like data structures, and
the execution of many recursive programs can be modeled as the
traversal of a tree.  In such cases, it is often useful to arrange the
nodes in levels, where the node at the top level is identified as
the \emph{root} and where every edge joins a \emph{parent} to a
\emph{child} one level below.  Figure~\ref{fig:5JJ} shows the tree of
Figure~\ref{fig:5H} redrawn in this way.  Node~$d$ is a child of
node~$e$ and the parent of nodes $b$ and~$c$.

\begin{figure}

\graphic{Fig_5JJ}

\caption{The tree from Figure~\ref{fig:5H} redrawn with node~$e$ as
  the root and the other nodes arranged in levels.}

\label{fig:5JJ}
\end{figure}

\begin{editingnotes}
\textbf{THESE ARE NOT USED IN THE TEXT:}

In the special case of \emph{ordered binary trees}, every node is the
parent of at most 2 children and the children are labeled as being a
left-child or a right-child.
\end{editingnotes}

\subsection{Properties}

Trees have many unique properties.  We have listed some of them in the
following theorem.

\begin{theorem}\label{th:treeprops}
Every tree has the following properties:

\begin{enumerate}

\item Every connected subgraph is a tree.\label{treeprops:asub}

\item There is a unique path between every pair of vertices.\label{treeprops:uniquepath}

\item Adding an edge between nonadjacent nodes in a tree creates a
  graph with a cycle.

\item Removing any edge disconnects the graph.  That is, every edge is
  a cut edge.

\item If the tree has at least two vertices, then it has at least two
  leaves.

\item\label{treeprops:v=e+1} The number of vertices in a tree is one larger than the number
  of edges.

\end{enumerate}
\end{theorem}

\begin{editingnotes}
It would be more interesting and useful for spanning tree proofs below
to separate the implications from the equivalences, and include the
equivalence of Lemma~\ref{lem:iffe=v-1}).  The equivalences are
another chance to use the cycle-of-implications proof organization.
\end{editingnotes}

\begin{proof}
\begin{enumerate}

\item A cycle in a subgraph is also a cycle in the whole graph, so any
  subgraph of an acyclic graph must also be acyclic.  If the subgraph
  is also connected, then by definition, it is a tree.

\item Since a tree is connected, there is at least one path between
  every pair of vertices.  Suppose for the purposes of contradiction,
  that there are two different paths between some pair of vertices.
  Then there are two distinct paths $\walkv{p} \neq \walkv{q}$ between
  the same two vertices with minimum total length $\lnth{\walkv{p}}+
  \lnth{\walkv{q}}$.  If these paths shared a vertex, $w$,
  other than at the start and end of the paths, then the parts of
  $\walkv{p}$ and $\walkv{q}$ from start to $w$, or the parts of
  $\walkv{p}$ and $\walkv{q}$ from $w$ to the end, must be
    distinct paths between the same vertices with total length less than
   $\lnth{\walkv{p}}+ \lnth{\walkv{q}}$, contradicting the minimality
    of this sum.  Therefore,  $\walkv{p}$ and $\walkv{q}$ have no
        vertices in common besides their endpoints, and so
        $\merge{\walkv{p}}{\text{reverse}(\walkv{q})}$ is a cycle.

\iffalse
  Beginning at $u$, let $x$ be the first vertex where
  the paths diverge, and let $y$ be the next vertex they share.  (For
  example, see Figure~\ref{fig:5L}.)  Then there are two paths from
  $x$ to~$y$ with no common edges, which defines a cycle.  This is a
  contradiction, since trees are acyclic.  Therefore, there is
  exactly one path between every pair of vertices.

\begin{figure}

\graphic{unique-path}

\caption{If there are two paths between $u$ and~$v$, the graph must
  contain a cycle.}

\label{fig:5L}
\end{figure}
\fi

\item An additional edge $\edge{u}{v}$ together with the unique path
  between $u$ and $v$ forms a cycle.

\item Suppose that we remove edge $\edge{u}{v}$.  Since the tree
  contained a unique path between $u$ and $v$, that path must have
  been $\edge{u}{v}$.  Therefore, when that edge is removed, no path
  remains, and so the graph is not connected.

\item
\begin{editingnotes}
\arm{rephrased}
\end{editingnotes}

  Since the tree has at least two vertices, the longest path in the
  tree will have different endpoints $u$ and $v$.  We claim $u$ is a
  leaf.  This follows because, since by definition of endpoint, $u$ is
  incident to at most one edge on the path.  Also, if $u$ was incident to
  an edge not on the path, then the path could be lengthened by adding
  that edge, contradicting the fact that the path was as long as
  possible.  It follows that $u$ is incident only to a single edge,
  that is $u$ is a leaf.  The same hold for $v$.

\item We use induction on the proposition
\[
P(n) \eqdef \text{there are $n - 1$ edges in any $n$-vertex tree}.
\]

\inductioncase{Base case} ($n = 1$): $P(1)$ is true since a tree with
1 node has 0 edges and $1 - 1 = 0$.

\inductioncase{Inductive step}: Now suppose that $P(n)$ is true and
consider an $(n+1)$-vertex tree, $T$.  Let $v$ be a leaf of the tree.
You can verify that deleting a vertex of degree 1 (and its incident
edge) from any connected graph leaves a connected subgraph.  So by
Theorem~\ref{th:treeprops}.\ref{treeprops:asub}, deleting $v$ and its
incident edge gives a smaller tree, and this smaller tree has $n - 1$
edges by induction.  If we re-attach the vertex, $v$, and its incident
edge, we find that $T$ has $n = (n + 1) - 1$ edges.  Hence, $P(n + 1)$
is true, and the induction proof is complete.  \qedhere

\end{enumerate}

\end{proof}

Various subsets of properties in Theorem~\ref{th:treeprops} provide
alternative characterizations of trees.  For example,

\begin{lemma}\label{lem:iffe=v-1}
A graph $G$ is a tree iff $G$ is a forest and $\card{\vertices{G}} =
\card{\edges{G}} +1$.
\end{lemma}

The proof is an easy consequence of
Theorem~\ref{th:connectivity}.\ref{treeprops:v=e+1}.

\begin{editingnotes}
Left to right is given in
Theorem~\ref{th:connectivity}.\ref{treeprops:v=e+1}.  Right to left
follows by applying
Theorem~\ref{th:connectivity}.\ref{treeprops:v=e+1} to each connected
component, and summing vertices \& edges across the components, to
conclude $v=e-\#components$.  So $\#components$ must be 1, namely, the
forest is connected.  \arm{make sure to add this proof problem.}
\end{editingnotes}

\subsection{Spanning Trees}\label{spantree_subsec}

Trees are everywhere.  In fact, every connected graph contains a
subgraph that is a tree with the same vertices as the graph.  This is
called a \term{spanning tree} for the graph.  For example,
Figure~\ref{fig:5LL} is a connected graph with a spanning tree
highlighted.

\begin{figure}

\graphic{spanning-tree}

\caption{A graph where the edges of a spanning tree have been
  thickened.}

\label{fig:5LL}

\end{figure}

\begin{definition}
Define a \term{spanning subgraph} of a graph, $G$, to be a subgraph
containing all the vertices of $G$.
\end{definition}

\begin{theorem}
Every connected graph contains a spanning tree.
\end{theorem}

\begin{proof}
\begin{editingnotes}
\arm{rephrased as a DIRECT PROOF}
\end{editingnotes}
Suppose~$G$ is a connected graph, so the graph $G$ itself is a
connected, spanning subgraph.  So by WOP, $G$ must have a minimum-edge
connected, spanning subgraph, $T$.  We claim $T$ is a spanning tree.
Since $T$ is a connected, spanning subgraph by definition, all we have
to show is that $T$ is acyclic.

But suppose to the contrary that $T$ contained a cycle $C$.  By
Lemma~\ref{lem:cutiffcycle}, an edge $e$ of $C$ will not be a cut
edge, so removing it would leave a connected, spanning subgraph that
was smaller than $T$, contradicting the minimality to $T$.
\end{proof}

\subsection{Minimum Weight Spanning Trees}\label{MST_subsec}

Spanning trees are interesting because they connect all the nodes of a
graph using the smallest possible number of edges.  For example the
spanning tree for the 6-node graph shown in Figure~\ref{fig:5LL} has 5
edges.

In many applications, there are numerical costs or weights associated
with the edges of the graph.  For example, suppose the nodes of a
graph represent buildings and edges represent connections between
them.  The cost of a connection may vary a lot from one pair of
buildings or towns to another.  Another example is where the nodes
represent cities and the weight of an edge is the distance between
them: the weight of the Los~Angeles/New~York~City edge is much higher
than the weight of the NYC/Boston edge.  The weight of a graph is
simply defined to be the sum of the weights of its edges.  For
example, the weight of the spanning tree shown in Figure~\ref{fig:5KA}
is~19.

\begin{figure}

\subfloat[]{%
    \graphic{Fig_5KA-a}
}
%
\qquad
%
\subfloat[]{%
    \graphic{Fig_5KA-b}
}

\caption{A spanning tree (a) with weight 19 for a graph~(b).}

\label{fig:5KA}

\end{figure}

\iffalse
The goal, of course, is to find the spanning tree with minimum weight,
called the minimum weight spanning tree (MST for short).
\fi

\begin{definition}
A \term{minimum weight spanning tree} (\textup\term{MST}\textup) of
an edge-weighted graph~$G$ is a spanning tree of~$G$ with the
smallest possible sum of edge weights.
\end{definition}

Is the spanning tree shown in Figure~\ref{fig:5KA}(a) an MST of the
weighted graph shown in Figure~\ref{fig:5KA}(b)?  It actually isn't,
since the tree shown in Figure~\ref{fig:5KB} is also a spanning tree
of the graph shown in Figure~\ref{fig:5KA}(b), and this spanning tree
has weight~17.

\begin{figure}

\graphic{Fig_5KB}

\caption{An MST with weight~17 for the graph in
  Figure~\ref{fig:5KA}(b).}
\label{fig:5KB}

\end{figure}

What about the tree shown in Figure~\ref{fig:5KB}?  It seems to be an
MST, but how do we prove it?  In general, how do we find an MST for a
connected graph $G$?  We could try enumerating all subtrees of $G$,
but that approach would be hopeless for large graphs.

\begin{editingnotes}
\arm{all new material replacing FTL's draft}
\end{editingnotes}
There actually are many good ways to find MST's based on a property of
some subgraphs of $G$ called \term*{pre-MST}'s.

\begin{definition}
A \term{pre-MST} for a graph $G$ is a spanning
subgraph of $G$ that is also a subgraph of some MST of $G$.
\end{definition}
So a pre-MST will necessarily be a forest.

For example, the empty graph with the same vertices as $G$ is guaranteed
to be a pre-MST of $G$, and so is any actual MST of $G$.

 \iffalse In the rest of this section, subgraphs and forests will
 always be spanning forests and spanning subgraphs of $G$, that is
 they will have the same vertices as $G$.\fi

If $e$ is an edge of $G$ and $S$ is a spanning subgraph, we'll write
$S+e$ for the spanning subgraph with edges $\edges{S} \union \set{e}$.
\begin{definition}
If $F$ is a pre-MST and $e$ is a new edge, that is $e \in
\edges{G}-\edges{F}$, then $e$ \term{extends $F$} when $F+e$ is also a
pre-MST.
\end{definition}
So being a pre-MST is contrived to be an invariant under addition of
extending edges, by the definition of extension.

The standard methods for finding MST's all start with the empty
spanning forest and build up to an MST by adding one extending edge
after another.  Since the empty spanning forest is a pre-MST, and
being a pre-MST is, by definition, invariant under extensions, every
forest built in this way will be a pre-MST.  But no spanning tree can
be a subgraph of a different spanning tree.  So when the pre-MST
finally grows enough to become a tree, it will be an MST.  By
Lemma~\ref{lem:iffe=v-1}, this happens after exactly
$\card{\vertices{G}}-1$ edge extensions.

So the problem of finding MST's reduces to the question of how to tell
if an edge is an extending edge.  Here's how:

\begin{definition}
Let $F$ be a pre-MST, and color the vertices in each connected
component of $F$ either all black or all white.  At least one
component of each color is required.  Call this a \term{solid
  coloring}\index{coloring!solid} of $F$.  A \term{gray edge} of a
solid coloring is an edge of $G$ with different colored endpoints.
\end{definition}

Any path in $G$ from a white vertex to a black vertex obviously must
include a gray edge, so for any solid coloring, there is guaranteed to
be at least one gray edge.  In fact, there will have to be at least as
many gray edges as there are components with the same color.  Here's
the punchline:

\begin{lemma}\label{lem:edgeextends}
An edge extends a pre-MST $F$ if it is a minimum weight gray edge in
some solid coloring of $F$.
\end{lemma}

\begin{editingnotes}
I think the converse can be proved by coloring the ends of an
extending edge different colors, but this needs to be checked.  Could
be a nice pset problem.  Would also imply uniqueness of MST when
weights are different, since there is only one way to grow the tree
using MST1 or MST2.
\end{editingnotes}

So to extend a pre-MST, choose any solid coloring, find the gray
edges, and among them choose one with minimum weight.  Each of these
steps is easy to do, so it is easy to keep extending and arrive at an
MST.  For example, here are three known algorithms that are explained
by Lemma~\ref{lem:edgeextends}:

\begin{algorithm}\label{alg:MST1}[Prim]
  Grow a tree one edge at a time by adding a minimum weight edge
  among the edges that have exactly one endpoint in the tree.
\end{algorithm}

This is the algorithm that comes from coloring the growing tree white
and all the vertices not in the tree black.  Then the gray edges are
the ones with exactly one endpoint in the tree.

\begin{algorithm}\label{alg:MST2}[Kruskal]
  Grow a forest one edge at a time by adding a minimum weight edge
  among the edges with endpoints in different connected components.
\end{algorithm}

An edge does not create a cycle iff it connects different components.
The edge chosen by Kruskal's algorithm will be the minimum weight gray
edge when the components it connects are assigned different colors.

\iffalse  %earlier version
The edges between different components are exactly the edges that are
gray under some solid coloring, namely any coloring where the
components it connects have different colors.
\fi

For example, in the weighted graph we have been considering, we might
run Algorithm~\ref{alg:MST1} as follows.  Start by choosing one of the
weight~1 edges, since this is the smallest weight in the graph.
Suppose we chose the weight~1 edge on the bottom of the triangle of
weight~1 edges in our graph.  This edge is incident to the same vertex
as two weight~1 edges, a weight~4 edge, a weight~7 edge, and a
weight~3 edge.  We would then choose the incident edge of minimum
weight.  In this case, one of the two weight~1 edges.  At this point,
we cannot choose the third weight~1 edge: it won't be gray because its
endpoints are both in the tree, and so are both colored white.  But we
can continue by choosing a weight~2 edge.  We might end up with the
spanning tree shown in Figure~\ref{fig:5KC}, which has weight~17, the
smallest we've seen so far.

\begin{figure}

\graphic{Fig_5KC}

\caption{A spanning tree found by Algorithm~\ref{alg:MST1}.}

\label{fig:5KC}

\end{figure}

Now suppose we instead ran Algorithm~\ref{alg:MST2} on our graph.  We
might again choose the weight~1 edge on the bottom of the triangle of
weight~1 edges in our graph.  Now, instead of choosing one of the
weight~1 edges it touches, we might choose the weight~1 edge on the
top of the graph.  This edge still has minimum weight, and will be
gray if we simply color its endpoints differently, so
Algorithm~\ref{alg:MST2} can choose it.  We would then choose one of
the remaining weight~1 edges.  Note that neither causes us to form a
cycle.  Continuing the algorithm, we could end up with the same
spanning tree in Figure~\ref{fig:5KC}, though this will depend on how
the tie breaking rules used to choose among gray edges with the same
minimum weight.  For example, if the weight of every edge in $G$ is
one, then all spanning trees are MST's with weight
$\card{\vertices{G}}-1$, and both of these algorithms can arrive at
each of these spanning trees by suitable tie-breaking.

\begin{editingnotes}
Verify that Prim \& Kruskal can create every MST.
\end{editingnotes}

The coloring that explains Algorithm~\ref{alg:MST1} also justifies a more
flexible algorithm which has Algorithm~\ref{alg:MST1} as a special case:
\begin{algorithm}\label{alg:MST3}
  Grow a forest one edge at a time by picking any component and adding a
  minimum weight edge among the edges leaving that component.
\end{algorithm}
This algorithm allows components that are not too close to grow in
parallel and independently, which is great for ``distributed'' computation
where separate processors share the work with limited communication
between processors.

\begin{editingnotes}
ref Lynch's book.
\end{editingnotes}

These are examples of greedy approaches to optimization.  Sometimes
greediness works and sometimes it doesn't.  The good news is that it
does work to find the MST.  Therefore, we can be sure that the MST for
our example graph has weight~17, since it was produced by
Algorithm~\ref{alg:MST2}.  Furthermore we have a fast algorithm for
finding a minimum weight spanning tree for any graph.

Ok, to wrap up this story, all that's left is the proof that minimal
gray edges are extending edges.  This might sound like a chore, but it
just uses the same reasoning we used to be sure there would be a gray
edge when you need it.

\begin{proof} (of Lemma~\ref{lem:edgeextends})

  Let $F$ be a pre-MST that is a subgraph of some MST $M$ of $G$, and
  suppose $e$ is a minimum weight gray edge under some solid coloring of
  $F$.  We want to show that $F+e$ is also a pre-MST.

  If $e$ happens to be an edge of $M$, then $F+e$ remains a subgraph of
  $M$, and so is a pre-MST.

  The other case is when $e$ is not an edge of $M$.  In that case,
  $M+e$ will be a connected, spanning subgraph.  Also $M$ has a path
  $\walkv{p}$ between the different colored endpoints of $e$, so $M+e$
  has a cycle consisting of $e$ together with $\walkv{p}$.  Now
  $\walkv{p}$ has both a black endpoint and a white one, so it must
  contain some gray edge $g \neq e$.  The trick is to remove $g$ from
  $M+e$ to obtain a subgraph $M+e-g$.  Since gray edges by definition
  are not edges of $F$, the graph $M+e-g$ contains $F+e$.  We claim
  that $M+e-g$ is an MST, which proves the claim that $e$ extends $F$.

\begin{editingnotes}
  CLR illustrate $M+e-g$ in a figure, but I don't think the figure helped
  --ARM.
\end{editingnotes}

   To prove this claim, note that $M+e$ is a connected, spanning
   subgraph, and $g$ is on a cycle of $M+e$, so by
   Lemma~\ref{lem:cutiffcycle}, removing $g$ won't disconnect
   anything.  Therefore, $M+e-g$ is still a connected, spanning
   subgraph.  Moreover, $M+e-g$ has the same number of edges as $M$,
   so Lemma~\ref{lem:iffe=v-1} implies that it must be a spanning
   tree.  Finally, since $e$ is minimum weight among gray
   edges,\iffalse $w(e) \leq w(g)$, and therefore\fi
   \[
   w(M+e-g) = w(M) + w(e) - w(g) \leq w(M).
   \]
   This means that $M+e-g$ is a spanning tree whose weight is at most
   that of an MST, which implies that $M+e-g$ is also an MST.
\end{proof}

\begin{editingnotes}
  Verify that the converse of Lemma~\ref{lem:edgeextends} is true.
  That is, every extending edge is a minimal gray edge for some
  coloring.
\end{editingnotes}

Another interesting fact falls out of the proof of Lemma~\ref{lem:edgeextends}:
\begin{corollary}\label{cor:uniqMST}
If all edges in a weighted graph have distinct weights, then the graph has
a \emph{unique} MST.
\end{corollary}

The proof of Corollary~\ref{cor:uniqMST} is left to Problem~\ref{PS_unique_MST}.

\begin{editingnotes}
  Another approach to proving uniqueness: show that any MST can be the
  result of Algorithm~\ref{alg:MST1} (also true for
  Algorithm~\ref{alg:MST2}).  But Algorithm~\ref{alg:MST1} is
  deterministic when there are no ties, so the unique tree its
  produces must be all the trees there are.
\end{editingnotes}

\begin{editingnotes}
  CLR have lots of great exercises about all this.
\end{editingnotes}

\iffalse  FTL's earlier draft

It's a little easier
to prove it for Algorithm~\ref{alg:MST2}, so we'll do that one here.

\begin{theorem}\label{thm:MST2}
For any connected, weighted graph~$G$, Algorithm~\ref{alg:MST2}
produces an MST for~$G$.
\end{theorem}

\begin{proof}
The proof is a bit tricky.  We need to show the algorithm terminates,
namely, if we have selected fewer than $n - 1$ edges, then we can
always find an edge to add that does not create a cycle.  We also need
to show the algorithm creates a tree of minimum weight.

The key to doing all of this is to show that the algorithm never gets
stuck or goes in a bad direction by adding an edge that will keep us
from ultimately producing an MST\@.  The natural way to prove this is
to show that the set of edges selected at any point is contained in
some MST, in other words, we can always get to where we need to be.
We'll state this as a lemma.

\begin{lemma}\label{lemma:MST2}
  For any $m \ge 0$, let $S$ consist of the first $m$ edges selected by
  Algorithm~\ref{alg:MST2}.  Then there exists some MST~$T$ for~$G$ such
  that $S \subseteq \edges{T}$, that is, the set of edges that we are
  growing is always contained in some MST\@.
\end{lemma}

We'll prove this momentarily, but first let's see why it helps prove
the theorem.  Assume the lemma is true.  Then how do we know
Algorithm~\ref{alg:MST2} can always find an edge to add without
creating a cycle?  Well, as long as there are fewer than $n - 1$ edges
picked, there exists some edge in $\edges{T} - S$ and so there is an
edge that we can add to~$S$ without forming a cycle.  Next, how do we
know that we get an MST at the end?  Well, once $m = n - 1$, we know
that $S$ will
\begin{editingnotes}
\arm{inserted: the edges of}
\end{editingnotes}
be the edges of an MST.

Ok, so the theorem is an easy corollary of the lemma.  To prove the
lemma, we'll use induction on the number of edges chosen by the
algorithm so far.  This is very typical in proving that an algorithm
preserves some kind of invariant condition---induct on the number of
steps taken, namely, the number of edges added.

Our inductive hypothesis $P(m)$ is the following: for any $G$ and any
set~$S$ of $m$ edges initially selected by Algorithm~\ref{alg:MST2},
there exists an MST $T$ of~$G$ such that $S \subseteq \edges{T}$.

For the base case, we need to show $P(0)$.  In this case, $S =
\emptyset$, so $S \subseteq \edges{T}$ holds trivially for any MST
$T$.

For the inductive step, we assume $P(m)$ holds and show that it
implies $P(m + 1)$.  Let $e$ denote the $(m+1)$st edge selected by
Algorithm~\ref{alg:MST2}, and let $S$ denote the first $m$ edges
selected by Algorithm~\ref{alg:MST2}.  Let $T^*$ be the
MST such that $S \subseteq \edges{T^*}$, which exists by the inductive
hypothesis.  There are now two cases:
\begin{description}

\item[Case 1:] $e \in \edges{T^*}$, in which case $S \union \{e\}
  \subseteq \edges{T^*}$, and thus $P(m+1)$ holds.

\item[Case 2:]
$e \notin \edges{T^*}$, as illustrated in Figure~\ref{fig:5KD}.  Now we need
  to find a different MST that contains $S$ and~$e$.

\begin{figure}

\graphic{Fig_5KD}

\caption{The graph formed by adding $e$ to $\edges{T^*}$.  Edges of~$S$ are
  denoted with solid lines and edges of $\edges{T^*} - S$ are denoted with
  dashed lines.}

\label{fig:5KD}
\end{figure}

\end{description}

What happens when we add $e$ to~$\edges{T^*}$?  Since $T^*$ is a tree,
we get a cycle.  (Here we used part~3 of Theorem~\ref{th:treeprops}.)
Moreover, the cycle cannot only contains edges in~$S$, since $e$ was
chosen so that together with the edges in~$S$, it does not form a
cycle.  This implies that $\set{e} \union \edges{T^*}$ contains a
cycle that contains an edge $e'$ of $\edges{T^*} - S$.  For example,
such an $e'$ is shown in Figure~\ref{fig:5KD}.

Note that the weight of~$e$ is at most that of~$e'$.  This is because
Algorithm~\ref{alg:MST2} picks the minimum weight edge that does not
make a cycle with~$S$.  Since $e' \in \edges{T^*}$, edge $e'$ cannot
make a cycle with~$S$, and if the weight of~$e$ were greater than the
weight of~$e'$, Algorithm!\ref{alg:MST2} would no have selected~$e$
ahead of~$e'$.

Okay, we're almost done.  Now we'll make an MST that contains $S
\union \set{e}$.  Let $T^{**}$ be the graph with
\begin{align*}
\vertices{T^{**}} & \eqdef \vertices{T},\\
\edges{T^{**}} & \eqdef (\edges{T^*} - \set{e'}) \union \set{e}.
\end{align*}
That is, we swap $e$ and~$e'$ in~$\edges{T^*}$.

\begin{claim}\label{claim:MST2}
$T^{**}$ is an MST.
\end{claim}

\begin{proof}[Proof of claim]
We first show that $T^{**}$ is a spanning tree.  $T^{**}$ is acyclic
because it was produced by removing an edge from the only cycle in
$T^{*} \union \set{e}$.  $T^{**}$ is connected since the edge we
deleted from $\edges{T^*} \union \set{e}$ was on a cycle.  Since
$T^{**}$ contains all the nodes of~$G$, it must be a spanning tree
for~$G$.

Now let's look at the weight of~$T^{**}$.  Well, since the weight
of~$e$ was at most that of~$e'$, the weight of~$T^{**}$ is at most
that of~$T^*$, and thus $T^{**}$ is an MST for~$G$.
\end{proof}

Since $S \union \set{e} \subseteq \edges{T^{**}}$, we have shown that
  $P(m + 1)$ holds.  Thus, Algorithm~\ref{alg:MST2} must eventually
  produce an MST\@.  This will happens when it adds $n - 1$ edges to
  the subgraph it builds.
\end{proof}
\fi

%% Trees Problems %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problems}
  \practiceproblems
  \pinput{TP_average_degree_of_tree_and_simple_path}

  \examproblems
  \pinput{MQ_hypercube_nocount}
  \pinput{FP_graphs_short_answer}

  \classproblems
  \pinput{CP_graph_edge_mark}
  \pinput{CP_spanning_tree_proc}
  \pinput{CP_tree_characterizations}
  \pinput{CP_min_weight_edge}
  \pinput{CP_build_MSTs}
  \pinput{CP_no_odd_length_cycles}
  %\pinput{CP_23_high_priority_servers}

  \homeworkproblems
  \pinput{PS_unique_MST}
  % S09.cp6t.2
  % S09.cp6t.3
\end{problems}

\section{References}

\cite{MR1633290},
\cite{Diestel2000},
\cite{GoodaireP2001},
\cite{HartsfieldR2003}

\endinput
