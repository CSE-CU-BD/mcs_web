\newcommand{\sharetree}{\text{ST}}
\newcommand{\rectree}{\text{RT}}
\newcommand{\ubt}{\text{UT}}
\newcommand{\Searcht}{\text{ST}}
\newcommand{\leafset}{\text{Leaves}}
\newcommand{\leafp}[1]{\text{leaf?}(#1)}
\newcommand{\rightsub}[1]{\text{right}(#1)}
\newcommand{\leftsub}[1]{\text{left}(#1)}
\newcommand{\subtr}[1]{\text{sbtrs}(#1)}
\newcommand{\psubtr}[1]{\text{propsbtrs}(#1)}
%\newcommand{\vec}[1]{\vec{#1}}


\section{Search Trees}

Searching through data may be the most common of all computations, and
\term{search trees} are a widely used data structure that supports
efficient search.

The basic idea behind search trees is simple.  Assuming the data to be
searched have some kind of order relation on them---like numerical order
for numbers or alphabetical order for words---the data is laid out in
a kind of branching ``tree'' structure illustrated in
Figure~\ref{searchtree1}.  In this example, there are two branches at
each branch point, with all the values in the left branch less than
the value at the branch point, and all the values in the right branch
greater than the value at the branch point.  This makes it easy to
search for a given value in the tree: starting at the topmost
branchpoint, compare the given value to the value at the branchpoint.
If the given value---call it $g$---is less than the value at the
branchpoint---call it $b$---then continue searching in the left
branch; if $g$ is greater than $b$ continue searching in the right
branch; if $g = b$ then the given value has been found, and the search
ends successfully.  Finally, if there are no more branches to search,
then $g$ is not there, so the search ends unsuccessfully.

\begin{figure}

%\graphic{}

\begin{verbatim}
                6.8
          pi            8  
      3       4.9     7   9 
    1  3.1  3.7  5
          3.2  4 
\end{verbatim}

\caption{A binary search tree.}

\label{searchtree1}

\end{figure}

For example, to search for 3.7 in the tree in Figure~\ref{searchtree1},
we compare 3.7 to the value 6.8 at the topmost branch.  Since $3.7 <
6.8$, we go left and compare $3.7$ to the new top value $\pi$.  Since
$3.7 > \pi$, go right comparing 3.7 to 4.9, go left again, and arrive
at 3.7. So the search ends successfully.

Organizing the data in this way means you can search for a value
without having to scan through all the values in the data set.  In
fact, if the all the top-to-bottom paths through the tree don't differ
too much in length, then with maximum path length $n$, the search tree
will hold up to $2^n$ items.  Since each search simply follows some
path, this means that searching for a value will take
\emph{exponentially less time} than it would to search through all the
data.  That's why search trees are a big win.

\begin{figure}

%\graphic{}

\begin{verbatim}
                0
            .5     1
               1.5    2
                  2.5    3
                     3.5   .
                        .    .
                          .    .
\end{verbatim}   

\caption{An unbalanced search tree.}

\label{unbalanced}

\end{figure}

Of course it is possible that the tree has paths that are not short.
An extreme example is illustrated in Figure~\ref{unbalanced} where
there is a path containing half the values.  For this tree, the
average search for a value requires searching halfway down the path,
and the exponential savings evaporates.

By treating search trees as a recursive data type, we will be able to
describe simple recursive procedures for tree management, and we also
will have a powerful inductive proof method for proving properties of
these trees and procedures.  This will allow simple explanations of
how to grow search trees whose top-to-bottom paths are close to the
same length, and how to maintain this property as the data evolves
through adding and removing values.

\subsection{Abstract Binary Trees}

The data structure that underlies search trees are branching tree
structures.  For simplicity, we'll stick to trees with exactly two
branches at each branchpoint, as in the examples above.  These are
called \term{binary trees}.

A binary tree is either a single ``leaf node'' with no branching, or a
branchpoint node connected to a left subtree and a right subtree.
There are lots of ways to represent binary trees as a computer data
structure or a mathematical set, but we will take an abstract approach
that will enable us, largely, to understand trees without worrying
about how they are represented.

Let's begin by assuming we have some domain \sharetree\ of things
whose elements are called \emph{``shared'' binary trees}.  Don't worry
about what's shared for now; we'll explain shortly.  Now any
representation of binary trees has to allow a way to determine if a
given tree is a leaf or not.  We can abstract this property by
assuming there is a ``leaf predicate'' $\leafp{}$ on \sharetree\ that
determines whether an element is a leaf.  We \emph{define} the leaves
to be elements that this predicate picks out:
\[
\leafset \eqdef \set{T \in \sharetree \suchthat \leafp{T}}.
\]
So the official definition of ``leaf'' is ``element of \leafset.''

The remaining binary trees are the ones that branch into left and
right subtrees.  Any representation of binary trees has to allow a way
to select the left subtree of a branching tree and a way to select the
right subtree.  We abstract this property by having \term{selector
  functions} that produce the left and right subtrees of a non-leaf
tree.  That is, we simply stipulate that there are total functions
\[
\leftsub{}: (\sharetree - \leafset) \to \sharetree\quad \text{and} \quad
\rightsub{}: (\sharetree - \leafset) \to \sharetree.
\]

The subtrees of a binary tree are all the trees you can reach by
starting at the top and following some path down.  A path can be
described by the sequence of left and right branches you select, like
$(\leftsub{},\leftsub{},\rightsub{})$.  We can formalize this as
follows:

\begin{definition}
If $T\in\sharetree$, a \term{selector path} $\vec{P}$ from $T$ is a
finite sequence of selector functions defined recursively along with
its \term{result}:

\inductioncase{Base case}: \emptystring is selector path for $T$ and
its result is $T$.

\inductioncase{Constructor case}: If $\vec{P}$ is a selector path
for $T$ with result $S \in \sharetree$ and $S$ is not a leaf, then
\begin{itemize}
\item $\leftsub{} \vec{P}$ is a selector path
for $T$ with result $\leftsub{S}$.

\item $\rightsub{} \vec{P}$ is a selector path
for $T$ with result $\rightsub{S}$.
\end{itemize}

The \term{subtrees} $\subtr{T}$ of $T$ and \term{proper subtrees}
$\psubtr{T}$ of $T$ are defined by:
\begin{align*}
\psubtr{T} & \eqdef \set{R \suchthat R\ \text{is the result of some
    \textbf{positive length} selector path of}\ T},\\
\subtr{T} & \eqdef \set{R \suchthat R\ \text{is the result of some possibly empty
    selector path of}\ T}\\
          & = \psubtr{T} \union \set{T}.
\end{align*}
\end{definition}

Now if you go down from the top of $T$ to some subtree $S$, and then
continue down from $S$ to some subtree $R$, then $R$ is a subtree of
\emph{both} $T$ and $S$.  As an exercise in being completely formal,
we state:

\begin{lemma}\label{}
If $\vec{P}$ is a selector path for $T$ with result $S$, and
$\vec{Q}$ is a selector path for $S$ with result $R$, then
$\vec{Q}\vec{P}$ is a selector path of $T$ with result $R$.

Therefore, if $S$ is a subtree of $T$, and $R$ is a subtree of $S$,
then $R$ is a subtree of $T$; if either $S$ is a proper subtree of
$T$, or $R$ is a proper subtree of $S$, then $R$ is a proper subtree
of $T$.
\end{lemma}

Now this abstract setup allows for some weird stuff like allowing
trees to be infinite.

  For example, suppose we use nonnegative
integers to represent binary trees, and define 0 to be the only leaf.
If we define $\leftsub{n} \eqdef 2n$ and $\rightsub{n} \eqdef 2n+1$ we
get the infinite tree indicated in Figure~\ref{inftree123}.  Notice
that this infinite tree has no leaves.

\begin{figure}

%\graphic{}

\begin{verbatim}
                  1
           2            3
        4     5      6      7
       8 9  10 11  12 13  14 15
       .          .             . 
      .           .              .
     .            .               . 

\end{verbatim}

\caption{An infinite tree with no leaves.}

\label{inftree123}

\end{figure}

\iffalse
This abstract setup also allows some weird ``circular'' trees which
are proper subtrees of themselves.  Fortunately, all we need are the
recursively defined binary trees \rectree\ where all this weirdness
gets ruled out.
\fi

\begin{definition}
\rectree is a set of binary trees defined recursively as follows:

\inductioncase{Base case}:  Any leaf is in \rectree.

\inductioncase{Constructor case}: If $T \in \sharetree$ is not a leaf,
and $\leftsub{T}$ and $\rightsub{T}$ are in \rectree, then $T$ is in
\rectree.
\end{definition}

Now the subtrees function on \rectree\ has a simple recursive
definition.

\begin{definition}
The function $\subtr{}: \rectree \to \power(\rectree)$ is defined recursively as follows:

\inductioncase{Base case}: If $T$ is a leaf, then $\subtr{T} \eqdef
\set{T}$.

\inductioncase{Constructor case}: If $T \in \rectree$ is not a leaf,
then
\[
\subtr{T} \eqdef \set{T} \union \subtr{\leftsub{T}} \union
\subtr{\rightsub{T}}.
\]

The \term{proper subtrees} of $T$ are defined to be
\[
\subtr{\leftsub{T}} \union \subtr{\leftsub{T}}.
\]
\end{definition}

\begin{lemma}\label{}
No tree in \rectree\ is a proper subtree of itself.
\end{lemma}

\begin{proof}
The proof is by structural induction on the definition of \rectree.

\inductioncase{Base case}: If $T$ is a leaf, then $T$ has no proper
subtrees.

\inductioncase{Constructor case}: $T \in \rectree$ is not a leaf, then
let $L \eqdef \leftsub{T}$.  By induction hypothesis, $L$ is not a
proper subtree of itself.  Now $T$ cannot be a subtree of $L$, because
if it was, $L$ would be a proper subtree of a subtree of itself, and
therefore $L$ would be a proper subtree of itself.  Likewise, $T$
cannot be a subtree of $\rightsub{T}$.  Hence $T$ is not a proper
subtree of itself.
\end{proof}

\iffalse
\begin{lemma}\label{lem:finsubtrees}
Every tree in \rectree\ has only a finite number of subtrees.
\end{lemma}

\begin{proof}
The proof is by structural induction on the definition of \rectree.

\inductioncase{Base case}: If $T$ is a leaf, then $T$ has only one
subtree, namely, itself.

\inductioncase{Constructor case}: If $T \in \rectree$ is not a leaf,
then $\card{\subtr{\leftsub{T}}}$ and $\card{\subtr{\rightsub{T}}}$ are
finite by induction hypothesis.  Therefore
\[
\card{\subtr{T}} \leq 1 + \card{\subtr{\leftsub{T}}} +
\card{\subtr{\rightsub{T}}}.
\]
\end{proof}
\fi

\begin{definition}
$\text{depth}(T)$ for $T \rectree$.
\end{definition}

\begin{lemma}\label{}
\[
\card{\subtr{T}} \leq 2^{\text{depth}(T)}
\]
for all $T \in \rectree$
\end{lemma}

\iffalse
How come we have ``$\leq$'' instead of ``$=$'' in the proof of
Lemma~\ref{lem:finsubtrees}?  The answer is that the definition of
\rectree\ allows lots of sharing of subtrees.

Though there is no infinite weirdness left in \rectree, there may be
some unexpected \emph{sharing} of subtrees.  It is actually is
possible to have a $\rectree$ with whose left and right subtrees are
the same.  It is also possible for all the different top to bottom
paths end at the \emph{same} leaf.

Sharing of subtrees can be a very useful in getting a compact
representation of a tree, but it seriously complicates adding or
removing values from search trees.  So we will finally restrict
ourselves to the set \ubt\ of \term{unsharing} recursive binary trees
\fi


\begin{definition}
\ubt\ is a set of binary trees defined recursively as follows:

\inductioncase{Base case}:  Any leaf is in \ubt.

\inductioncase{Constructor case}: If $T \in \ubt$ is not a leaf,
$\leftsub{T}, \rightsub{T} \in \ubt$, and these two trees
have no subtree in common, that is,
\[
\leftsub{T} \intersect \rightsub{T} = \emptyset,
\]
then $T$ is in \ubt.
\end{definition}

\iffalse
Now we can replace the `$\leq$'' in the proof of
Lemma~\ref{lem:finsubtrees}, namely,
\[
\card{\subtr{T}} = 1 + \card{\subtr{leftsub{T}}} + \card{\subtr{leftsub{T}}}.
\]
for all $T \in \ubt$.
\fi

\subsection{The Structure of Binary Trees}

The leaves of a \rectree\ are its subtrees that are leaves.  That is
\[
\text{leaves}(T) \eqdef \subtr{T} \intersect \leafset.
\]
The nonleaf subtrees are called ``internal.''  That is,
\[
\text{internal}(T) \eqdef \subtr{T} - \text{leaves}(T).
\]

There is always one more leaf than there are internal subtrees:

\begin{lemma}\label{}
If $T \in \ubt$, then
\[
\card{\text{leaves}(T)} = 1 + \card{\text{internal}(T)}.
\]
\end{lemma}
\begin{proof}
The proof is by structural induction on the definition of \ubt.

\TBA{rest of proof}
\end{proof} 

Define \term{balanced tree} as length of any two paths differs by at
most one.

\begin{lemma}\label{}
If $B$ balanced, then
\[
\card{\subtr{B}} > 2^{\text{depth}(B)}.
\]
\end{lemma}

Define \term{AVL tree} depth of $\leftsub{T}$ and $\rightsub{T}$
differ by at most one.

\begin{lemma}\label{}
If $A$ is AVL, then
\[
\card{\subtr{A}} \geq 2^{\text{depth}(A)/3}???
\]
\end{lemma}

\begin{definition}
\term{Labelled tree} is \sharetree\ with a total function
$\text{label}:\sharetree \to \text{Labels}$.

The \term{search trees}, \Searcht, are the labelled trees $T$ such that
\[
\text{label}(\leftsub{S}) < \text{label}(S) < \text{label}(\rightsub{S})
\]
for all $S \in \text{internal}{T}$.
\end{definition}

These also have recursive def where $S$ above is simply replaced by
$T$.

Define $\text{search}: \Searcht \to \set{L,R}^*$

%% look up notation for star

  \endinput
