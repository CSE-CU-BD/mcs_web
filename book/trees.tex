\newcommand{\brnch}{\text{BBTr}}
\newcommand{\leafp}[1]{\text{leaf?}#1}
\newcommand{\brnchng}{\text{Branching}}
\newcommand{\leafset}{\text{Leaves}}
\newcommand{\rightsub}[1]{\text{right}#1}
\newcommand{\leftsub}[1]{\text{left}#1}
\newcommand{\rslt}[2]{\text{subtree}_{#1}#2}
\newcommand{\subbrn}[1]{\text{Subtrs}(#1)}
\newcommand{\propbrn}[1]{\text{PropSubtrs}(#1)}

\newcommand{\fintr}{\text{FinTr}}

\newcommand{\rectr}{\text{RecTr}}

\newcommand{\trdpth}[1]{\text{depth}(#1)}
\newcommand{\sizetr}[1]{\text{size}(#1)}

\newcommand{\freetr}{\text{FreeTr}}

%\newcommand{\subtr}[1]{\text{subtrs}(#1)}
%\newcommand{\psubtr}[1]{\text{psubtrs}(#1)}
\newcommand{\srchtr}[1]{\text{srch}#1}

%\newcommand{\selpath}[1]{\vec{#1}}


\section{Search Trees}

Searching through data may be the most common of all computations, and
\term{search trees} are a widely used data structure that supports
efficient search.

The basic idea behind search trees is simple.  Assuming the data to be
searched have some kind of order relation on them---like numerical order
for numbers or alphabetical order for words---the data is laid out in
a kind of branching ``tree'' structure illustrated in
Figure~\ref{searchtree1}.  In this example, there are two branches at
each branch point, with all the values in the left branch less than
the value at the branch point, and all the values in the right branch
greater than the value at the branch point.  This makes it easy to
search for a given value in the tree: starting at the topmost
branchpoint, compare the given value to the value at the branchpoint.
If the given value---call it $g$---is less than the value at the
branchpoint---call it $b$---then continue searching in the left
branch; if $g$ is greater than $b$ continue searching in the right
branch; if $g = b$ then the given value has been found, and the search
ends successfully.  Finally, if there are no more branches to search,
then $g$ is not there, so the search ends unsuccessfully.

For example, to search for 3.7 in the tree in Figure~\ref{searchtree1},
we compare 3.7 to the value 6.8 at the topmost branch.  Since $3.7 <
6.8$, we go left and compare $3.7$ to the new top value $\pi$.  Since
$3.7 > \pi$, go right comparing 3.7 to 4.9, go left again, and arrive
at 3.7. So the search ends successfully.

\begin{figure}

%\graphic{}
\begin{center}
\begin{verbatim}
                6.8
          pi             8  
     3          4.9    7   9 
  0.5  3.1    3.7  5
.4  .6       3.2 4 
\end{verbatim}
\end{center}

\caption{A binary search tree.}

\label{searchtree1}

\end{figure}

Organizing the data in this way means you can search for a value
without having to scan through all the values in the data set.  In
fact, if the all the top-to-bottom paths through the tree don't differ
too much in length, then with maximum path length $n$, the search tree
will hold up to $2^n$ items.  Since each search simply follows some
path, this means that searching for a value will take
\emph{exponentially less time} than it would to search through all the
data.  That's why search trees are a big win.

Of course it is possible that the tree has paths that are not short.
An extreme example is illustrated in Figure~\ref{unbalanced} where
there is a path containing half the values.  For this tree, the
average search for a value requires searching halfway down the path,
and the exponential savings evaporates.

\begin{figure}

%\graphic{}
\begin{center}
\begin{verbatim}
                0
            .5     1
               1.5    2
                  2.5    3
                     3.5   .
                        .    .
                          .    .
\end{verbatim}   
\end{center}

\caption{An unbalanced search tree.}

\label{unbalanced}

\end{figure}

By treating search trees as a recursive data type, we will be able to
describe simple recursive procedures for tree management, and we also
will have a powerful inductive proof method for proving properties of
these trees and procedures.  This will allow simple explanations of
how to grow search trees whose top-to-bottom paths are close to the
same length, and how to maintain this property as the data evolves
through adding and removing values.

\subsection{Binary Branching}

The trees in the examples above have either a single ``leaf'' with no
branching, or a binary (two-way) branch to the left and right.
Allowing more than two branches is important in some applications, but
binary branching is most common and is enough to illustrate all the
important ideas.

There are lots of ways to represent trees as a computer data
structure---or a mathematical set---but we will take an abstract
approach that will enable us, largely, to understand binary trees
without worrying about how they are represented.

We can begin by assuming only that we have some set \brnch\ of things
that represent \emph{binary branching trees}.  A crucial property of a
binary branching tree is whether or not it is a leaf.  In any
representation, there has to be way to test this.  So there has to be
a \term{leaf predicate} $\leafp{}$ that does the job.  That is, a
binary branching tree $T \in \brnch$ is a leaf when $\leafp{T}$ is
true.

\iffalse
 We define the
\term{leaves} to be elements that $\leafp{}$ picks out:
\[
\leafset \eqdef \set{T \in \brnch \suchthat \leafp{(T)}}.
\]

So the official definition of ``leaf'' is ``element of the set \leafset.''
\fi

Let \brnchng\ be the trees in \brnch\ that actually branch to the left
and right.  In any representation there has to be a way to select
these branches.  So there have to be \term{selector functions}
$\leftsub{}$ and $\rightsub{}$ that produce the left and right
branches of non-leaf elements of \brnch.  That is, let
\[
\brnchng \eqdef \set{T \in \brnch \suchthat \QNOT(\leafp{T})}.
\]
Then there have to be total functions
\begin{align*}
\leftsub{}: & \brnchng \to \brnch,\\
\rightsub{}:& \brnchng \to \brnch,
\end{align*}
where $\leftsub{(T)}$ is the tree on the left branch of $T$ and
$\rightsub{(T)}$ is the one on the right.

\subsubsection{Subtrees}

In the example search trees we started with, if you start at the top
and follow some path down, you arrive at a subtree that is also a
search tree.  Any such path can be described by the sequence of left
and right branches you select.  For example in the tree given in
Figure~\ref{searchtree1}, the sequence
\begin{equation}\label{lslsrs}
(\leftsub{},\leftsub{},\rightsub{}).
\end{equation}
describes the path that starts at the top (6.8).  The selectors are
applied in right-to-left order, so we first go to $\rightsub{(6.8)} =
\pi$.  Then we take the left branch to $\leftsub{(\pi)} = 3$, and take a
final left branch to end with the subtree $\leftsub{(3)} = 0.5$.  That
is, the subtree at the end of the path given by the sequence~\eqref{lslsrs} is
\[
\leftsub{(\leftsub{(\rightsub{(6.8)})})} = 0.5.
\]

Let $\vec{P}$ be a finite sequence of selector functions.  For $T \in
\brnch$, let $\rslt{T}{(\vec{P})}$ be the subtree at the end of the
path described by $\vec{P}$.  Notice that if the path tries to
continue past a leaf of $T$, there won't be any subtree at the end.
That is, $\rslt{T}{(\vec{P})}$ may not exist.

To formalize this idea of following a path $\vec{P}$ down a tree, we
can give an inductive definition of $\rslt{T}{(\vec{P})}$.  To do
this, we'll use the notation
\[
f \cdot \vec{P}
\]
for the sequence that starts with $f$ followed by the successive
elements of $\vec{P}$.  For example, if $\vec{P}$ is the length three
sequence in~\eqref{lslsrs}, then
\[
\rightsub{} \cdot \vec{P}
\]
is the length four sequence
\[
(\rightsub{}, \leftsub{},\leftsub{},\rightsub{}).
\]

\begin{definition}
Supppose $T \in \brnch$ and $\vec{P}$ is a finite sequence of selector
functions.  The subtree $\rslt{T}{(\vec{P} )}$ of $T$ at the \term{end
  of the path} given by $\vec{P}$ will be defined by induction on
the length of the sequence as follows:

\inductioncase{Base case}: ($\vec{P} = \emptystring$).
Then
\[
\rslt{T}{(\vec{P})} \eqdef T.
\]

\inductioncase{Constructor case}: ($\vec{P} = f \cdot \vec{Q}$).  If
$\rslt{T}{(\vec{Q})}$ is defined and equals a tree in \brnchng, then
\[
\rslt{T}{(\vec{P})} \eqdef f(\rslt{T}{(\vec{Q})}).
\]
Otherwise $\rslt{T}{(\vec{P})}$ is undefined.
\end{definition}

The \term{subtrees} $\subbrn{T}$ of $T$ are all the trees you can get
to by following paths starting at $T$.  More precisely,
\[
\subbrn{T} \eqdef \set{S \in \brnch \suchthat S =
  \rslt{T}{(\vec{P})}\ \text{for some selector sequence}\ \vec{P}}.
\]
The \term{proper subtrees} $\propbrn{T}$ are the subtrees that you get
to by a nonempty path, that is, the trees that are actually ``below''
$T$.
\[
\propbrn{T} \eqdef \set{S \in \brnch \suchthat S =
  \rslt{T}{(\vec{P})}\ \text{for some \emph{nonempty} selector
    sequence}\ \vec{P}}.
\]
By definition, we have
\[
\subbrn{T} = \propbrn{T} \union \set{T}.
\]

Notice that if $f \cdot \vec{Q}$ is a path that gets to a subtree of
$T$, then $\vec{Q}$ is a path in $f(T)$ that gets to the same subtree.
This implies the following:
\begin{corollary}\label{unionLR}
For $T \in \brnch$,
\begin{align*}
\propbrn{T} = \subbrn{\leftsub{(T)}} \union \subbrn{\rightsub{(T)}}.
\end{align*}
\end{corollary}

Now suppose you follow a path $\vec{P}$ in $T$ to get to subtree $S$
of $T$, and then follow a path $\vec{Q}$ in $S$ to get to the subtree
$R$ of $S$, as in Figure~\ref{PQdown}.  Then $R$ is also a subtree of
$T$ because the path $\vec{Q}\vec{P}$ in $T$ will get to $R$.

\begin{figure}

%\graphic{}

\begin{center}
\begin{verbatim}
              T
               \
               /    } P
              /
             S
            /
     Q {   /
           \
            R
\end{verbatim}   
\end{center}

\caption{A subbranch $S$ of $T$ and  a subbranch $R$ of $S$.}

\label{PQdown}

\end{figure}

This observation implies:
\begin{corollary}\label{propsubbranch}
\[
 S \in \propbrn{T}\ \QIMP\ \subbrn{S} \subseteq \propbrn{T}.
\]
\end{corollary}


\subsection{Binary Trees}
Although we've called the elements of \brnch\ binary branching
``trees,'' the abstract way we defined \brnch\ allows some weird stuff
to happen.  One weirdness is that nothing forbids ``circular'' trees
that are proper subtrees of themselves.
\iffalse
For example, it is entirely
possible that there is a structure $T \in \brnch$ such that
\textcolor{red}{
\[
\leftsub{(T)} = T = \rightsub{(T)}.
\]}

This weird binary branching structure doesn't even have any leaves.
\fi
And even if we forbid circular trees, there are still infinite
trees.  For example, suppose we choose \brnch\ to be the nonnegative
integers and define $\leftsub{n} \eqdef 2n+1$ and $\rightsub{n} \eqdef
2n+2$.  Now we get the infinite binary tree indicated in
Figure~\ref{inftree123}.

%, which is another example with no leaves.

\begin{figure}

%\graphic{}

\begin{verbatim}
                  0
           1            2
        3     4      5      6
       7 8   9 10  11 12  13 14
       .          .             . 
      .           .              .
     .            .               . 

\end{verbatim}

\caption{An infinite tree with no leaves.}

\label{inftree123}

\end{figure}

The problem with both circular structures and infinite ones is that
they will have infinite paths that you might keep searching down
without ever finishing.  By forbidding infinite paths we ensure that
searches will end, and we also stop all the circular and infinite
weirdness.

Paths that result in subtrees are by definition finite, so we should
be clear about the definition of an infinite path.

\begin{definition}
A infinite path in $T \in \brnch$ is an infinite sequence
\[
\dots,f_n,\dots,f_1,f_0
\]
of selector functions such that
\[
\rslt{T}{(\vec{P})} \in \brnchng
\]
for every finite suffix
\[
\vec{P} = (f_n,\dots, f_1,f_0).
\]
\end{definition}

But there's still a problem.  Even if they
have no infinite paths, a tree in \brnch\ may have some unexpected
\emph{sharing} of subtrees.  For example, it is is possible to have a
tree in \brnch\ whose left and right subtrees are the same, or
another whose top to bottom paths all end at the \emph{same} leaf.

To be precise
\begin{definition}
A tree $T \in \brnch$ \emph{shares subtrees} if there are two different
finite sequences $\vec{P} \neq \vec{Q}$ of selector functions such that
$\rslt{T}{(\vec{P})}$ and $\rslt{T}{(\vec{Q})}$ are both defined, and
\[
\rslt{T}{(\vec{P})}=\rslt{T}{(\vec{Q})}.
\]
\end{definition}
Sharing of subtrees can be very useful in getting a compact
representation of a tree, but it seriously complicates adding or
removing values from search trees, so we will forbid sharing as well.

Finally, we now arrive at \fintr, the familiar trees that underlie
search trees.
\begin{definition}
\[
\fintr \eqdef \set{T \in \brnch \suchthat T\ \text{has no infinite path and
  does not share subtrees}}.
\]
\end{definition}

Now it is both very useful,l and very cool, to realize that $\fintr$
has a simple recursive definition.

\begin{definition}
The set \rectr\ of \term{recursive trees} is defined recursively.  For
$T \in \brnch$,

\inductioncase{Base case}: ($T$ is a leaf).  $T \in \rectr$.

\inductioncase{Constructor case}: ($T \in \brnchng$).
If $\leftsub{(T)}, \rightsub{(T)} \in \rectr$, and these two trees
have no subtree in common, that is,
\[
\subbrn{\leftsub{(T)}} \intersect \subbrn{\rightsub{(T)}} = \emptyset,
\]
then $T$ is in \rectr.
\end{definition}

The trees with no infinite paths and no shared subtrees are actually
the same as the recursively defined trees.

\begin{theorem}\label{fundthmrec}(Fundamental Theorem for Recursive Trees)
\[
\fintr = \rectr.
\]
\end{theorem}

We first prove
\begin{equation}\label{rectrsubfintr}
\rectr \subseteq \fintr,
\end{equation}
that is, no recursive tree $T$ has an infinite path or a shared subtree.

\begin{proof}
The proof follows by structural induction on the
definition of \rectr:

\inductioncase{Base case}: ($T$ is a leaf).  $T$ has no infinite path
or shared subtree because it has no proper subtrees at all.

\inductioncase{Constructor case}: ($T \in \brnchng$).  In this case,
$\leftsub{(T)}$ and $\rightsub{(T)}$ are defined and in \rectr.  By
induction hypothesis, neither $\leftsub{(T)}$ nor $\rightsub{(T)}$ has an
infinite path nor sharing of subtrees.

We first prove by contradiction that $T$ has no infinite path.
Namely, suppose that $T$ had an infinite path
\[
\dots,f_n,\dots f_2,f_1,f_0.
\]
Now if $f_0 = \leftsub$, then
\begin{equation}\label{dfnf2f1}
\dots,f_n,\dots,f_2,f_1
\end{equation}
would be an infinite path in $\leftsub{(T)}$, a contradiction.  Likewise
if $f_0 = \rightsub$, then~\eqref{dfnf2f1} would be an infinite path
in $\rightsub{(T)}$, a contradiction.  So we get a contradiction in any
case, which implies that $T$ cannot have an infinite path.

Since $T$ has no infinite path, $T$ cannot be a subtree of
$\leftsub{(T)}$ or $\rightsub{(T)}$, and so will not itself be a
shared subtree.  Since there are no shared subtrees within
$\leftsub{(T)}$ or $\rightsub{(T)}$, the only remaining possibility
would be a subtree that was in $\leftsub{(T)}$ and $\rightsub{(T)}$,
which is not possible since $\subbrn{\leftsub{(T)}}$ and
$\subbrn{\rightsub{(T)}}$ have no tree in common by definition of
\rectr.
\end{proof}

Second, we prove
\begin{equation}\label{fintrsubrectr}
\fintr \subseteq \rectr.
\end{equation}
Taking the contrapositive, we want to prove that if $T \in \brnch$ is
\emph{not} a recursive tree, then it has an infinite path or it has a
shared subtree.

\begin{proof}
If $T \notin \rectr$, then $T$ cannot be a leaf.  If $\leftsub{(T)}$
and $\rightsub{(T)}$ have a subtree in common, then this subtree is
shared in $T$, proving the claim.  So we may assume that
$\leftsub{(T)}$ and $\rightsub{(T)}$ have no subtree in common.  Now
if both $\leftsub{(T)}$ and $\rightsub{(T)}$ were in \rectr, then $T$
would by definition be in \rectr.  Therefore $\leftsub{(T)}$ and $\rightsub{(T)}$
cannot both be in \rectr.

Let $f_0$ be a selector such that $f_0(T) \notin \rectr$.  Now if
$\leftsub{(f_0(T))}$ and $\rightsub{(f_0(T))}$ have a shared subtree, this
will also be a shared subtree of $T$, proving the claim.  So by the
same reasoning as for $T$, $\leftsub{(f_0(T))}$ and $\rightsub{(f_0(T))}$
cannot both be in \rectr.  So let $f_1$ be a selector such that
$f_1(f_0(T)) \notin \rectr$.  Similarly, if there is no sharing in
$f_1(f_0(T))$, there is a selector $f_2$ such that $f_2(f_1(f_0(T)))
\notin \rectr$.  Continuing in this way, we either find a shared subtree of $T$ of we
find an infinite path
\[
\dots,f_n,\dots f_2,f_1,f_0
\]
in $T$.
\end{proof}

With the recursive definition of trees, we can now recursively define
some important, basic functions on trees.  For example,

\begin{definition}
The \term{depth} of $T \in \rectr$ is defined by:

\inductioncase{Base case}: ($T$ is a leaf).
\[
\trdpth{T} \eqdef 0.
\]

\inductioncase{Constructor case}: ($T$ is not a leaf).
\[
\trdpth{T} \eqdef \max\set{\trdpth{\leftsub{(T)}}, \trdpth{\rightsub{(T)}}} + 1.
\]
\end{definition}

\begin{problem}
Prove that if $T$ is a recursive tree \rectr, then $\trdpth{T}$ is the
length of the longest path in $T$.
\begin{solution}
 \TBA{TBA}
\end{solution}
\end{problem}

\begin{definition}
The \emph{size} of $T \in \rectr$ is defined by:

\inductioncase{Base case}: ($T$ is a leaf).
\[
\sizetr{T} \eqdef 1.
\]

\inductioncase{Constructor case}: ($T$ is not a leaf).
\[
\sizetr{T} \eqdef 1 + \sizetr{\leftsub{(T)}} + \sizetr{\rightsub{(T)}}.
\]
\end{definition}

\begin{problem} Prove that for $T \in \rectr$, 
\begin{equation}\label{size=subbr}
\sizetr{T} = \card{\subbrn{T}}.
\end{equation}

%TP finger exercise

\begin{solution}
By Corollary~\ref{unionLR},
\[
\subbrn{T} = \set{T} \union \subbrn{leftsub{(T)}} \union \subbrn{rightsub{(T)}}.
\]
for $T \in \brnch$.  Now if $T \in \fintr$, these three sets are disjoint, so
\[
\card{\subbrn{T}} = 1 + \card{\subbrn{leftsub{(T)}}} + \card{\subbrn{rightsub{(T)}}}.
\]
Now~\eqref{size=subbr} follows immediately from the definition of $\sizetr$.
\end{solution}
\end{problem}


We can now prove a basic relation between size and depth of recursive
trees:
                    \begin{theorem}\label{szT2d1}
For all $T \in \rectr$,
\[
\sizetr{T} \leq 2^{\trdpth{T}+1} - 1.
\]
\end{theorem}

There is an easy way to understand this inequality: if there were
paths of different lengths starting with the tree and ending at
leaves, then there is a bigger tree with the same depth---just attach
two new leaves to the shorter path.  So the biggest tree with depth
$d$ will be the \term{complete tree} $T$ in which all paths have depth
$d$.  So there must be two paths of length one in $T$ that branch into
four paths of length two, continuing into $2^d$ paths of length $d$.
So
\[
\sizetr{T} = 2^0 + 2^1 + 2^2 + \cdots + 2^d = 2^{d+1}-1.
\]

On the other hand, there is a less ingenious but routine proof by
structural induction:
\begin{proof} (of Theorem~\ref{szT2d1})

The proof is by structural induction on the definition of \rectr:

\inductioncase{Base case}: ($T$ is a leaf).
\[
\sizetr{T} \eqdef 1 = 2^1 - 1 = 2^{\trdpth{T}+1} - 1.
\]

\inductioncase{Constructor case}: ($T$ is not a leaf).
\begin{align*}
\sizetr{T}
& = 1 + \sizetr{\leftsub{(T)}} + \sizetr{\rightsub{(T)}}
              & \text{(def. $\sizetr{T}$)}\\
& \leq 1 + (2^{\trdpth{\leftsub{(T)}}+1} -1)  + (2^{\trdpth{\rightsub{(T)}}+1} -1)
              & \text{(ind. hypothesis)}\\
& \leq  2\cdot 2^{\max\set{\trdpth{\leftsub{(T)}}+1,\trdpth{\rightsub{(T)}}+1}} - 1\\
& = 2\cdot 2^{1+\max\set{\trdpth{\leftsub{(T)}},\trdpth{\rightsub{(T)}}}} - 1\\
& = 2\cdot 2^{\trdpth{T}} - 1
              & \text{(def of $\trdpth{T}$)}\\
& =  2^{\trdpth{T}+1} - 1.
\end{align*}
\end{proof}

Let
\begin{align*}
\text{leaves}(T)   & \eqdef \set{S \in \subbrn{T} \suchthat \leafp{(S)}}\\
\text{internal}(T) & \eqdef \set{S \in \subbrn{T} \suchthat \QNOT(\leafp{(S)})}\\
\end{align*}

In a recursive tree there is always one more leaf than there are
internal subtrees:

\begin{lemma}\label{}
If $T \in \rectr$, then
\[
\card{\text{leaves}(T)} = 1 + \card{\text{internal}(T)}.
\]
\end{lemma}

\begin{proof}
The proof is by structural induction on the definition of \rectr.

\TBA{rest of proof}
\end{proof} 

A $T \in \rectr$ is \term{balanced} when all paths whose
results are leaves have length at least $\trdpth{T} -1$.

\begin{lemma}\label{b>2d}
If $B \in \rectr$ is balanced, then
\[
\sizetr{B} > 2^{\text{depth}(B)}.
\]
\end{lemma}

\begin{problem}
Prove Lemma~\ref{b>2d} by structural induction on the definition of \rectr.

\begin{solution}
\TBA{TBA}
\end{solution}
\end{problem}

\begin{problem}
Prove Lemma~\ref{b>2d} by reasoning about the complete tree as in the
argument following Theorem~\ref{szT2d1}.

\begin{solution}
\TBA{TBA}
\end{solution}
\end{problem}

An \term{AVL tree} is a tree $T\in \rectr$ such that
\[
\abs{\trdpth{\leftsub{S}} - \trdpth{\rightsub{S}}} \leq 1
\]
for all subtrees $S \in \subbrn{T}$.

\begin{lemma}\label{}
If $T$ is AVL, then
\[
\sizetr{T} \geq 2^{\text{depth}(T/3)}???
\]
\end{lemma}

The search tree examples above have a label on each subtree.
Abstractly, we model binary branching trees with labels by assuming
there is a total function
\[
\text{label}:\brnch \to \text{Labels}.
\]

\begin{definition}
The \term{Search trees} are the labelled trees $T$ with no infinite
paths and with real number labels such that
\[
\text{label}(\leftsub{S}) < \text{label}(S) < \text{label}(\rightsub{S})
\]
for all $S \in \text{internal}(T)$.
\end{definition}

\begin{problem}
Prove that every Search tree is a labelled recursive tree.

\begin{solution}
By Theorem~\ref{fundthmrec}, it is enough to prove that Search trees
have no shared subtrees.  This follows immediately from the way Search
trees are labelled.
\end{solution}
\end{problem}

Now we can define a recursive procedure that searches for a label that
matches any given number.  If it finds the number, it returns the
selector sequence that leads to it.

\begin{definition}

The function
\[
\srchtr{}: \text{(Search trees)} \times \reals \to
\strings{\set{\leftsub{},\rightsub{}}} \union \set{\textbf{fail}}
\]
is defined as follows:

If $r = \text{label}(T)$, then
\[
\srchtr{(T,r)} \eqdef \emptystring.
\]

If $r \neq \text{label}(T)$, then $\srchtr{(T,r)}$ is defined recursively

\inductioncase{Base case}: ($T$ is a leaf).
\[
\srchtr{(T,r)} = \textbf{fail}.
\]

\inductioncase{Constructor case}:
\[
\srchtr{(T,r)} = \begin{cases} 
\leftsub{}\cdot \srchtr{(\leftsub{(T)},r)} & \text{if $r < \text{label}(T)$},\\
\rightsub{}\cdot \srchtr{(\rightsub{(T)},r)} & \text{if $r > \text{label}(T)$}.
\end{cases}
\]
\end{definition}

\begin{theorem}
Let
\[
\text{labels}(T) \eqdef \set{\text{label}(S) \suchthat S \in \subbrn{T}}.
\]

If $r \notin \text{labels}(T)$, then $\srchtr{(T,r)} = \textbf{fail}$.  

If $r \in \text{labels}(T)$, then $\srchtr{(T,r)}$ is a sequence of
selectors and
\[
\text{label}(\rslt{T}{(\srchtr{(T,r)})}) = r.
\]
\end{theorem}

\begin{proof}

\TBA{By induction on the definition of \srchtr{}.}

\end{proof}

\subsection{Insertions \& Deletions}

Rotations of AVL trees.


  \endinput
