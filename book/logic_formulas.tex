\chapter{Logical Formulas}\label{logicform_chap}
%\label{propform_chap}

It is amazing that people manage to cope with all the ambiguities in the
English language.  Here are some sentences that illustrate the issue:
%
\begin{itemize}
\item ``You may have cake, or you may have ice cream.''
\item ``If pigs can fly, then you can understand the Chebyshev bound.''
\item ``If you can solve any problem we come up with, then you get an
  \emph{A} for the course.''
\item ``Every American has a dream.''
\end{itemize}
%
What \emph{precisely} do these sentences mean?  Can you have both
cake and ice cream or must you choose just one dessert?  Pigs can't
fly, so does the second sentence say anything about your understanding
the Chebyshev bound? If you can solve some problems we come up with,
can you get an \emph{A} for the course?  And if you can't solve a
single one of the problems, does it mean you can't get an \emph{A}?
Finally, does the last sentence imply that all Americans have the same
dream ---say of owning a house ---or might different Americans have
different dreams ---say, Eric dreams of designing a killer software
application, Tom of being a tennis champion, Albert of being able to
sing?

Some uncertainty is tolerable in normal conversation.  But when we need to
formulate ideas precisely---as in mathematics and programming---the
ambiguities inherent in everyday language can be a real problem.  We can't
hope to make an exact argument if we're not sure exactly what the
statements mean.  So before we start into mathematics, we need to
investigate the problem of how to talk about mathematics.

To get around the ambiguity of English, mathematicians have devised a
special language for talking about logical relationships.  This language
mostly uses ordinary English words and phrases such as ``or,''
``implies,'' and ``for all.''  But mathematicians give these words precise
and unambiguous definitions.  \iffalse A pitfall to watch out for is
confusing ordinary language with mathematical language that sounds
ordinary but isn't.\fi

Surprisingly, in the midst of learning the language of logic, we'll come
across the most important open problem in computer science---a problem
whose solution could change the world.


\section{Propositions from Propositions}\label{propform_sec}

In English, we can modify, combine, and relate propositions with words
such as ``not,'' ``and,'' ``or,'' ``implies,'' and ``if-then.''
For example, we can combine three propositions into one like this:
%
\begin{center}
\textbf{If} all humans are mortal \textbf{and} all Greeks are human,
\textbf{then} all Greeks are mortal.
\end{center}

For the next while, we won't be much concerned with the internals of
propositions---whether they involve mathematics or Greek mortality---but
rather with how propositions are combined and related.  So we'll
frequently use variables such as $P$ and $Q$ in place of specific
propositions such as ``All humans are mortal'' and ``$2 + 3 = 5$.''  The
understanding is that these \term{propositional variables}, like
propositions, can take on only the values \true~(true) and \false~(false).
Propositional variables are also called \term{Boolean variables} after
their inventor, the nineteenth century mathematician George---you guessed
it---Boole.

\subsection{\QNOT, \QAND, and \QOR}
Mathematicians use the words $\QNOT$, $\QAND$, and $\QOR$
for operations that change or combine propositions.  The precise
mathematical meaning of these special words can be specified by
\term{truth tables}.  For example, if $P$ is a proposition,
then so is ``$\QNOT(P)$,'' and the truth value of the proposition
``$\QNOT(P)$'' is determined by the truth value of $P$ according to the
following truth table:
%
\[
\begin{array}{c|c}
P & \QNOT(P) \\ \hline
\true & \false \\
\false & \true \\
\end{array}
\]
%
The first row of the table indicates that when proposition $P$ is true,
the proposition ``$\QNOT(P)$'' is false.  The second line indicates that
when $P$ is false, ``$\QNOT(P)$'' is true.  This is probably what you
would expect.

In general, a truth table indicates the true/false value of a proposition
for each possible set of truth values for the variables.  For example, the
truth table for the proposition ``$P \QAND Q$'' has four lines, since
there are four settings of truth values for the two variables:
%
\[
\begin{array}{cc|c}
P & Q & P \QAND Q \\ \hline
\true & \true & \true \\
\true & \false & \false \\
\false & \true & \false \\
\false & \false & \false
\end{array}
\]
%
According to this table, the proposition ``$P \QAND Q$'' is true only when
$P$ and $Q$ are both true.  This is probably the way you ordinarily think
about the word ``and.''

There is a subtlety in the truth table for ``$P \QOR Q$'':
%
\[
\begin{array}{cc|c}
P & Q & P \QOR Q \\ \hline
\true & \true & \true \\
\true & \false & \true \\
\false & \true & \true \\
\false & \false & \false
\end{array}
\]
%
The first row of this table says that ``$P \QOR Q$'' is true even if
\textit{both} $P$ and $Q$ are true.  This isn't always the intended
meaning of ``or'' in everyday speech, but this is the standard definition
in mathematical writing.  So if a mathematician says, ``You may have cake,
or you may have ice cream,'' he means that you \textit{could} have both.

If you want to exclude the possibility of both having and eating, you
should combine them with the \term{exclusive-or} operation, $\QXOR$:
%
\[\begin{array}{cc|c}
P & Q & P \QXOR Q \\ \hline
\true & \true & \false \\
\true & \false & \true \\
\false & \true & \true \\
\false & \false & \false
\end{array}
\]

\subsection{\QIMPLIES}

The combining operation with the least intuitive technical meaning is
``implies.''  Here is its truth table, with the lines labeled so we can
refer to them later.
%
\[
\begin{array}{cc|cr}
    P  &   Q    & \parbox[b]{13ex}{$P \QIMP Q$} \\ \hline
\true  & \true  & \true & \text{(tt)}\\
\true  & \false & \false  & \text{(tf)}\\
\false & \true  & \true  & \text{(ft)}\\
\false & \false & \true  & \text{(ff)}
\end{array}
\]
Let's experiment with this definition.  For example, is the following
proposition true or false?
%
\begin{center}
``If Goldbach's Conjecture is true, then $x^2 \geq 0$ for every real
number $x$.''
\end{center}
%
Now, we already mentioned that no one knows whether Goldbach's Conjecture,
Proposition~\ref{Goldbach}, is true or false.  But that doesn't prevent
you from answering the question!  This proposition has the form $P
\QIMP Q$ where the \term{hypothesis}, $P$, is ``Goldbach's Conjecture
is true'' and the \term{conclusion}, $Q$, is ``$x^2 \geq 0$ for every real
number $x$.''  Since the conclusion is definitely true, we're on either
line~(tt) or line~(ft) of the truth table.  Either way, the proposition as
a whole is \textit{true}!

One of our original examples demonstrates an even stranger side of
implications.
\begin{center}
``If pigs fly, then you can understand the Chebyshev bound.''
\end{center}
Don't take this as an insult; we just need to figure out whether this
proposition is true or false.  Curiously, the answer has \textit{nothing}
to do with whether or not you can understand the Chebyshev bound.  Pigs do
not fly, so we're on either line (ft) or line (ff) of the truth table.  In
both cases, the proposition is \textit{true}!

In contrast, here's an example of a false implication:
%
\begin{center}
``If the moon shines white, then the moon is made of white cheddar.''
\end{center}
%
Yes, the moon shines white.  But, no, the moon is not made of white
cheddar cheese.  So we're on line (tf) of the truth table, and the
proposition is false.

The truth table for implications can be summarized in words as
follows:
%
\textbox{
An implication is true exactly when the if-part is false or the
then-part is true.
}
%
This sentence is worth remembering; a large fraction of all
mathematical statements are of the if-then form!

\subsection{If and Only If}

Mathematicians commonly join propositions in one additional way that
doesn't arise in ordinary speech.  The proposition ``$P$ if and only
if $Q$'' asserts that $P$ and $Q$ have the same truth value, that is,
either both are true or both are false.
%
\[
\begin{array}{cc|c}
P & Q & P \QIFF Q \\ \hline
\true & \true & \true \\
\true & \false & \false \\
\false & \true & \false \\
\false & \false & \true
\end{array}
\]
For example, the following if-and-only-if statement is true for every real
number $x$:
%
\[
x^2 - 4 \geq 0 \QIFF |x| \geq 2.
\]
%
For some values of $x$, \textit{both} inequalities are true.  For
other values of $x$, \textit{neither} inequality is true.  In every
case, however, the \QIFF\ proposition as a whole is true.

\begin{problems}
\practiceproblems
\pinput{TP_Basic_Propositions}
\pinput{TP_Predicate_Logic}

\classproblems
\pinput{CP_differentiable_implies_continuous}

\homeworkproblems
\pinput{PS_printout_binary_strings}
\end{problems}


\section{Propositional Logic in Computer Programs}\label{propositions_in_programs_sec}

Propositions and logical connectives arise all the time in computer
programs.  For example, consider the following snippet, which could be
either C, C++, or Java:
%
\begin{tabbing}
\hspace{1in} \= \quad\quad \= \quad\quad \= \quad\quad \= \kill
\> \texttt{if ( x > 0 || (x <= 0 \&\& y > 100) )} \\
\> \> \vdots\\
\> \textit{(further instructions)}
\end{tabbing}
%
Java uses the symbol \texttt{||} for ``\QOR,'' and the
symbol \texttt{\&\&} for ``\QAND.''  The \textit{further instructions}
are carried out only if the proposition following the word \texttt{if}
is true.  On closer inspection, this big expression is built from two
simpler propositions.  Let $A$ be the proposition that \texttt{x > 0},
and let $B$ be the proposition that \texttt{y > 100}.  Then we can
rewrite the condition as
\begin{equation}\label{ANAB}
A \QOR (\QNOT(A) \QAND B).
\end{equation}

\subsection{Truth Table Calculation}
A truth table calculation reveals that the more complicated
expression~\ref{ANAB} always has the same truth value as
\begin{equation}\label{AOB}
A \QOR B.
\end{equation}
Namely, we begin with a table with just the truth values of $A$ and $B$:
\[
\begin{array}{cc|ccccc|c}
A      & B      & A  & \QOR  & (\QNOT(A)& \QAND & B) & A \QOR  B \\ \hline
\true  & \true \\
\true  & \false\\
\false & \true \\
\false & \false                       
\end{array}
\]
These values are enough to fill in two more columns:
\[
\begin{array}{cc|ccccc|c}
A      & B      & A & \QOR  & (\QNOT(A) & \QAND & B) & A \QOR  B \\ \hline
\true  & \true  &   &       & \ \false   &       &    & \lgtrue \\
\true  & \false &   &       & \ \false   &       &    & \lgtrue \\
\false & \true  &   &       & \ \true    &       &    & \lgtrue \\
\false & \false &   &       & \ \true    &       &    & \lgfalse\\
\end{array}
\]
Now we have the values needed to fill in the \QAND\ column:
\[
\begin{array}{cc|ccccc|c}
A      & B      & A & \QOR  & (\QNOT(A) & \QAND   & B) & A \QOR  B \\ \hline
\true  & \true  &   &       & \ \false   &  \false &    & \lgtrue \\
\true  & \false &   &       & \ \false   &  \false &    & \lgtrue \\
\false & \true  &   &       & \ \true    &  \true  &    & \lgtrue \\
\false & \false &   &       & \ \true    &  \false &    & \lgfalse\\
\end{array}
\]
and this provides the values needed to fill in the remaining column for the first \QOR:
\[
\begin{array}{cc|ccccc|c}
A      & B      & A & \QOR     &(\QNOT(A) & \QAND   & B) & A \QOR  B \\ \hline
\true  & \true  &   & \lgtrue  & \false &    \false &    & \lgtrue \\
\true  & \false &   & \lgtrue  & \false &    \false &    & \lgtrue \\
\false & \true  &   & \lgtrue  & \true  &    \true  &    & \lgtrue \\
\false & \false &   & \lgfalse & \true  &    \false &    & \lgfalse\\
\end{array}
\]
Expressions whose truth values always match are called \term{equivalent}.
Since the (highlighted) columns of truth values of the two expressions are
the same, they are equivalent.  So we can simplify the code snippet
without changing the program's behavior by replacing the complicated
expression with an equivalent simpler one:
%
\begin{tabbing}
\hspace{1in} \= \quad\quad \= \quad\quad \= \quad\quad \= \kill
\> \texttt{if ( x > 0 || y > 100 )} \\
\> \> \vdots\\
\> \emph{(further instructions)}
\end{tabbing}

The equivalence of~\eqref{ANAB} and~\eqref{AOB} can also be confirmed
reasoning by cases:
\begin{itemize}
\item[$A$ is \true.]  An expression of the form $(\true \QOR
  \text{anything})$ is equivalent to \true.  Since $A$ is \true\
  both~\eqref{ANAB} and~\eqref{AOB} in this case are of this form, so they
  have the same truth value, namely, \true.

\item[$A$ is \false.]  An expression of the form $(\false \QOR
  \textit{anything})$ will have same truth value as \emph{anything}.
  Since $A$ is \false,~\eqref{AOB} has the same truth value as $B$.

   An expression of the form $(\true \QAND \textit{anything})$ is
   equivalent to \emph{anything}, as is any expression of the form
   $\false \QOR \emph{anything}$.  So in this case $A \QOR (\QNOT(A)
   \QAND B)$ is equivalent to $(\QNOT(A) \QAND B)$, which in turn is
   equivalent to $B$.

   Therefore both~\eqref{ANAB} and~\eqref{AOB} will have the same truth
   value in this case, namely, the value of $B$.
\end{itemize}

Simplifying logical expressions has real practical importance in
computer science.  Expression simplification in programs like the one
above can make a program easier to read and understand, and can also
make it faster since fewer operations are needed.  In hardware,
simplifying expressions can decrease the number of logic gates on a
chip.  That's because digital circuits can be described by logical
formulas (see Problems~\ref{CP_binary_adder_logic}
and~\ref{PS_faster_adder_logic}), and minimizing the logical formulas
corresponds to reducing the number of gates in the circuit.  The
payoff of gate minimization is potentially enormous: a chip with fewer
gates is smaller, consumes less power, has a lower defect rate, and is
cheaper to manufacture.

\subsection{Cryptic Notation}
Java uses symbols like ``$\&\&$'' and ``$||$'' in place of \QAND\ and
\QOR.  Circuit designers use ``$\cdot$'' and ``$+$,'' and actually refer
to \QAND\ as a product and \QOR\ as a sum.  Mathematicians use still
other symbols given in the table below.
%
\begin{center}
\begin{tabular}{ll}
\textbf{English} & \textbf{Symbolic Notation} \\[1ex]
$\QNOT(P)$ & $\neg P$ \quad (alternatively, $\bar{P}$) \\
$P \QAND Q$ & $P \land Q$ \\
$P \QOR Q$ & $P \lor Q$ \\
$P \QIMP Q$ & $P \implies Q$ \\
if $P$ then $Q$ & $P \implies Q$ \\
$P \QIFF Q$ & $P \iff Q$\\
$P \QXOR Q$ & $P \oplus Q$
\end{tabular}
\end{center}
%
For example, using this notation, ``If $P \QAND \QNOT(Q)$, then $R$''
would be written:
%
\[
    (P \land \bar{Q}) \implies R.
\]

The mathematical notation is concise but cryptic.  Words such as
``$\QAND$'' and ``$\QOR$'' are easier to remember and won't get
confused with operations on numbers.  We will often use $\bar{P}$ as
an abbreviation for $\QNOT(P)$, but aside from that, we mostly stick
to the words---except when formulas would otherwise run off the page.

\begin{problems}
\classproblems
\pinput{CP_binary_adder_logic}

\homeworkproblems
\pinput{PS_faster_adder_logic}

\examproblems
\pinput{MQ_truth_table_case_reasoning}
\end{problems}

\section{Equivalence and Validity}\label{equiv_valid_sec}
%\label{sec:logical_equivalence}

\subsection{Implications and Contrapositives}\label{implication_sec}
Do these two sentences say the same thing?
%
\begin{center}
If I am hungry, then I am grumpy. \\
If I am not grumpy, then I am not hungry.
\end{center}
%
We can settle the issue by recasting both sentences in terms of
propositional logic.  Let $P$ be the proposition ``I am hungry'' and $Q$
be ``I am grumpy.''  The first sentence says ``$P \QIMPLIES Q$'' and the
second says ``$\QNOT(Q) \QIMP \QNOT(P)$.''  Once more, we can compare
these two statements in a truth table:
%
\[
\begin{array}{c|c|c|ccc}
   P   &   Q    & (P  \QIMP  Q) & (\QNOT(Q) & \QIMP & \QNOT(P)) \\ \hline
\true  & \true  &     \lgtrue   &  \false   & \lgtrue  &  \false\\
\true  & \false &     \lgfalse  &  \true    & \lgfalse &  \false\\
\false & \true  &     \lgtrue   &  \false   & \lgtrue  &  \true \\
\false & \false &     \lgtrue   &  \true    & \lgtrue  &  \true \\
\end{array}
\]
%
Sure enough, the highlighted columns showing the truth values of these two
statements are the same.  A statement of the form ``($\QNOT Q) \QIMPLIES
(\QNOT P)$'' is called the \term{contrapositive} of the implication ``$P
\QIMPLIES Q$.''  The truth table shows that an implication and its
contrapositive are equivalent---they are just different ways of saying
the same thing.

In contrast, the \term{converse} of ``$P \QIMPLIES Q$'' is the statement
``$Q \QIMPLIES P$.''  In terms of our example, the converse is:
%
\begin{center}
If I am grumpy, then I am hungry.
\end{center}
%
This sounds like a rather different contention, and a truth table
confirms this suspicion:
%
\[
\begin{array}{c|c|c|c}
P & Q &
    P \QIMPLIES Q &
    Q \QIMPLIES P \\ \hline
\true & \true & \lgtrue & \lgtrue \\
\true & \false & \lgfalse & \lgtrue \\
\false & \true & \lgtrue & \lgfalse \\
\false & \false & \lgtrue & \lgtrue
\end{array}
\]
%
Now the highlighted columns differ in the second and third row, confirming
that an implication is generally \textit{not} equivalent to its converse.

One final relationship: an implication and its converse together are
equivalent to an iff statement, specifically, to these two statements
together.  For example,
%
\begin{center}
If I am grumpy then I am hungry, and if I am hungry then I am grumpy.
\end{center}
%
are equivalent to the single statement:
%
\begin{center}
I am grumpy iff I am hungry.
\end{center}
%
Once again, we can verify this with a truth table.  

\iffalse
We begin with a table with just the truth values of $P$ and $Q$:
%
\[
\begin{array}{c|c|ccc|c}
P & Q & (P \QIMP Q) &\QAND & (Q  \QIMP  P) & P \QIFF Q \\
\hline
\true  &  \true  &&&&\\
\true  &  \false &&&&\\
\false &  \true  &&&&\\
\false &  \false &&&&
\end{array}
\]
These truth values are enough to fill in three more columns:
\[
\begin{array}{c|c|ccc|c}
P & Q & (P \QIMP Q) &\QAND & (Q  \QIMP  P) & P \QIFF Q \\
\hline
\true  &  \true  &\true  &&\true & \lgtrue \\
\true  &  \false &\false &&\true & \lgfalse\\
\false &  \true  &\true  &&\false& \lgfalse\\
\false &  \false &\true  &&\true & \lgtrue 
\end{array}
\]
Finally, now using the first two of the filled in columns, we can fill in
the fourth column:
\fi

\[
\begin{array}{c|c|ccc|c}
P & Q & (P \QIMP Q) &\QAND & (Q  \QIMP  P) & P \QIFF Q \\
\hline
\true  &  \true  &\true  &\lgtrue &\true & \lgtrue \\
\true  &  \false &\false &\lgfalse&\true & \lgfalse\\
\false &  \true  &\true  &\lgfalse&\false& \lgfalse\\
\false &  \false &\true  &\lgtrue &\true & \lgtrue
\end{array}
\]
The fourth column giving the truth values of 
\[
(P \QIMP Q) \QAND (Q \QIMP P)
\]
is the same as the sixth column giving the truth values of $P \QIFF
Q$, which confirms that the \QAND\ of the implications is equivalent
to the \QIFF\ statement.

\subsection{Validity and Satisfiability}
A \term{valid} formula is one which is always true.  The simplest example is
\[
P \QOR \QNOT(P).
\]

You can think about valid formulas as capturing fundamental logical
truths.  For example, a property of implication that we take for
granted is that if one statement implies a second one, and the second
one implies a third, then the first implies the third.  The following
valid formula confirms the truth of this property of implication.
\[
[(P \QIMP Q) \QAND (Q \QIMP R)] \QIMP (P \QIMP R).
\]

Equivalence of formulas is really a special case of validity.  Namely,
statements $F$ and $G$ are equivalent iff the statement $(F \QIFF G)$ is
valid.  For example, the equivalence of the expressions~\ref{AOB}
and~\ref{ANAB} means that
\[
(A \QOR B) \QIFF (A \QOR (\QNOT(A) \QAND B))
\]
is valid.  Of course, validity can also be viewed as an aspect of
equivalence.  Namely, a formula is valid iff it is equivalent
to \true.

A \term{satisfiable} formula is one which can sometimes be true.  One
way satisfiability comes up is when there are a collection of system
specifications.  The job of the system designer is to come up with a
system that follows all the specs.  This means that the \QAND\ of all
the specs had better be satisfiable or the system will be impossible
(see Problem~\ref{CP_file_system_functioning_normally}).

There is also a close relationship between validity and
satisfiability, namely, a statement $P$ is valid iff its negation
$\QNOT(P)$ is \emph{not} satisfiable.

\begin{problems}
\practiceproblems
\pinput{TP_valid_sat_multiple_choice}

\classproblems
\pinput{CP_valid_vs_satisfiable}
\pinput{CP_file_system_functioning_normally}
\end{problems}


\section{The Algebra of Propositions}

\subsection{Propositions in Normal Form}
Every propositional formula is equivalent to a ``sum-of-products''
or \term{disjunctive form}.  More precisely, a disjunctive form is
simply an \QOR\ of \QAND-terms, where each \QAND-term is an \QAND\ of
variables or negations of variables, for example, 
\begin{equation}\label{ANBOANC}
(A \QAND B) \QOR (A \QAND C).
\end{equation}

You can read a disjunctive form for any propositional formula directly
from its truth table.  For example, the formula
\begin{equation}\label{ANBRC}
A \QAND (B \QOR C)
\end{equation}
has truth table:
\[\begin{array}{c|c|c|ccc}
A      & B      & C       & A & \QAND & (B \QOR C)\label{ANBRCTT}\\
\hline \true  & \true  & \true   &   &  \true\\
\true  & \true  & \false  &   &  \true\\
\true  & \false & \true   &   &  \true\\
\true  & \false & \false  &   &  \false\\
\false & \true  & \true   &   &  \false\\
\false & \true  & \false  &   &  \false\\
\false & \false & \true   &   &  \false\\
\false & \false & \false  &   &  \false
\end{array}\]
The formula~\eqref{ANBRC} is true in the first row when $A$, $B$, and
$C$ are all true, that is, where $A \QAND B \QAND C$ is true.  It is
also true in the second row where $A \QAND B \QAND \bar{C}$ is true,
and in the third row when $A \QAND \bar{B} \QAND C$ is true, and
that's all.  So~\eqref{ANBRC} is true exactly when
\begin{equation}\label{ABCDNF}
(A \QAND B \QAND C) \QOR (A \QAND B \QAND \bar{C}) \QOR
  (A \QAND \bar{B} \QAND C)
\end{equation}
is true.  So~\eqref{ANBRC} and~\eqref{ABCDNF} are equivalent.

The expression~\eqref{ABCDNF} is a disjunctive form where each
\QAND-term is an \QAND\ of \emph{every one} of the variables or
their negations in turn.  An expression of this form is called
a \term{disjunctive normal form} (\term{DNF}).  A DNF formula can
often be simplified into a smaller disjuctive form.  For example, the
DNF~\eqref{ABCDNF} further simplifies to the equivalent disjunctive
form~\eqref{ANBOANC} above.

Incidentally, this equivalence of $A \QAND (B \QOR C)$ and $(A \QAND
B) \QOR (A \QAND C)$ is called the \term{distributive law} of
\QAND\ over \QOR\ because of its obvious resemblance to the
distributivity of multiplication over addition for numbers.

Applying the same reasoning to the \false\ entries of a truth table
yields a \term{conjunctive form} for any formula, namely an \QAND\
of \QOR-terms, where the \QOR-terms are \QOR's only of variables or
their negations.  For example, formula~\eqref{ANBRC} is false in the
fourth row of its truth table~\eqref{ANBRCTT} where $A$ is \true, $B$
is \false\ and $C$ is \false.  But this is exactly the one row where
$(\bar{A} \QOR B \QOR C)$ is \false!  Likewise, the~\eqref{ANBRC} is
false in the fifth row which is exactly where
$(A \QOR \bar{B} \QOR \bar{C})$ is \false.  This means
that~\eqref{ANBRC} will be \false\ whenever the \QAND\ of these
two \QOR-terms is false.  
\iffalse
$(\bar{A} \QOR B \QOR C) \QAND (A \QOR \bar{B} \QOR \bar{C})$ is \false.
\fi
Continuing in this way with the \QOR-terms corresponding to the
remaining three rows where~\eqref{ANBRC} is false, we get a
\term{conjunctive normal form} (\term{CNF}) that is equivalent to~\eqref{ANBRC}, namely,
\[\begin{array}{l}
(\bar{A} \QOR B \QOR C)  \QAND (A \QOR \bar{B} \QOR \bar{C}) 
        \QAND (A \QOR \bar{B} \QOR C)  \QAND \\
(A \QOR B \QOR \bar{C}) \QAND (A \QOR B \QOR C)
\end{array}\]

The methods above can obviously be applied to any truth table, which implies
\begin{theorem}
Every propositional formula is equivalent to both a disjunctive normal
form and a conjunctive normal form.
\end{theorem}

\subsection{Proving Equivalences}\label{propositional_equivalences_sec}
A check of equivalence or validity by truth table runs out of steam
pretty quickly: a proposition with $n$ variables has a truth table
with $2^n$ lines, so the effort required to check a proposition
grows \idx{exponentially} with the number of variables.  For a
proposition with just 30 variables, that's already over a billion
lines to check!

An alternative approach that \emph{sometimes} helps is to use algebra
to prove equivalence.  A lot of different operators may appear in a
propositional formula, so a useful first step is to get rid of all but
three: \QAND, \QOR, and \QNOT.  This is easy because each of the
operators is equivalent to a simple formula using only these three.
For example, $A \QIMPLIES B$ is equivalent to $\QNOT(A) \QOR
B$.  \QAND, \QOR, \QNOT\ formulas for the remaining operators are left
to Problem~\ref{TP_only_and_or_not}.


We list below a bunch of equivalence axioms with the symbol
``$\corresp$'' between equivalent formulas.  These axioms are
important because they are all that's needed to prove every possible
equivalence.  We'll start with some equivalences for \QAND's that look
like the familiar ones for multiplication of numbers:
\begin{align}
A \QAND B           &\corresp B \QAND A
         & \text{commutativity of \QAND}\label{commutqand}\\
(A \QAND B)\QAND C  & \corresp A \QAND (B \QAND C)
         & \text{associativity of \QAND}\label{assocqand}\\
\true \QAND A           &\corresp A
         & \text{identity for \QAND}\\
\false \QAND A           &\corresp \false
         & \text{zero for \QAND}
\end{align}
Three axioms that don't directly correspond to number properties are
\begin{align}
A \QAND A       &\corresp A
         & \text{idempotence for \QAND}\\
A \QAND \bar{A} & \corresp \false
         & \text{contradiction for \QAND}\\
\QNOT(\bar{A})  & \corresp A
         & \text{double negation}\\
\end{align}
It is associativity~\eqref{assocqand} that justifies writing $A \QAND
B \QAND C$ without specifying whether it is parenthesized as $A \QAND
(B \QAND C)$ or $(A \QAND B) \QAND C$.  That's because both ways of
inserting parentheses yield equivalent formulas.

There are a corresponding set of equivalences for $\QOR$ which we
won't bother to list, except for the \QOR\ rule corresponding to
contradiction for \QAND:
\begin{align}
A \QOR \bar{A} & \corresp \true
         & \text{validity for \QOR}\\
\end{align}

There is also a familiar rule connecting \QAND\ and \QOR:
\begin{align}
A \QAND (B \QOR C) & \corresp (A \QAND B) \QOR (A \QAND C)\label{qand-distributivity}\\
       &\qquad \text{distributivity of \QAND\ over \QOR}\notag
\end{align}

Finally, there are \term{DeMorgan's Laws} which explain how to
distribute \QNOT's over \QAND's and \QOR's:
\begin{align}\label{demorgan}
\QNOT(A \QAND B) &\corresp \bar{A} \QOR \bar{B} & \text{DeMorgan for \QAND} \\
\QNOT(A \QOR B) &\corresp \bar{A} \QAND \bar{B} & \text{DeMorgan for \QOR}\label{DeMQOR} 
\end{align}
All these axioms can be verified easily with truth tables.

These axioms are all that's needed to convert any formula to a
disjunctive normal form.  We can illustrate how they work by applying
them to turn the negation of formula~\eqref{ANBRC}, namely,
\begin{equation}\label{NANBRC}
\QNOT((A \QAND B) \QOR (A \QAND C)).
\end{equation}
into disjunctive normal form.

We start by applying DeMorgan's Law for \QOR\ to~\eqref{NANBRC} in
order to move the \QNOT\ deeper into the formula.  This gives
\[
\QNOT(A \QAND B) \QAND \QNOT(A \QAND C).
\]
Now applying Demorgan's Law for \QAND\ to the two
innermost \QAND-terms, gives
\begin{equation}\label{NAONBANAONC}
(\bar{A} \QOR \bar{B}) \QAND (\bar{A} \QOR \bar{C}).
\end{equation}
At this point \QNOT\ only applies to variables, and we won't need
Demorgan's Laws any further.

Now we will repeatedly apply the distributivity of \QAND\ over \QOR\ to
turn~\eqref{NAONBANAONC} into a disjunctive form.  To start, we'll distribute
$(\bar{A} \QOR \bar{B})$ over \QAND\ to get
\[
((\bar{A} \QOR \bar{B}) \QAND \bar{A}) \QOR ((\bar{A} \QOR \bar{B}) \QAND \bar{C}).
\]
Using distributivity over both \QAND's we get
\[
((\bar{A} \QAND \bar{A}) \QOR (\bar{B} \QAND \bar{A})) \QOR 
((\bar{A} \QAND \bar{C}) \QOR (\bar{B} \QAND \bar{C})).
\]
By the way, we've implicitly used commutativity~\eqref{commutqand}
here to justify distributing over an \QAND\ from the right.  Now
applying idempotence to remove the duplicate occurrence of $\bar{A}$ we
get
\[
(\bar{A} \QOR (\bar{B} \QAND \bar{A})) \QOR 
((\bar{A} \QAND \bar{C}) \QOR (\bar{B} \QAND \bar{C})).
\]
Associativity now allows dropping the parentheses around the terms
being \QOR'd to yield the following disjunctive form for~\eqref{NANBRC}:
\begin{equation}\label{DFNAONBANAONC}
\bar{A} \QOR
(\bar{B} \QAND \bar{A}) \QOR 
(\bar{A} \QAND \bar{C}) \QOR
(\bar{B} \QAND \bar{C}).
\end{equation}

The last step is to turn each of these \QAND-terms into a disjunctive
normal form with all three variables $A$, $B$, and $C$.  We'll
illustrate how to do this for the second \QAND-term
$(\bar{B} \QAND \bar{A})$.  This term needs to mention $C$ to be in
normal form.  To introduce $C$, we use validity for \QOR\ and
identity for \QAND\ to conclude that
\[
(\bar{B} \QAND \bar{A}) \iff (\bar{B} \QAND \bar{A}) \QAND (C \QOR \bar{C}).
\]

\iffalse
$\bar{B} \QAND \bar{A}$
is equivalent to
\[
(\bar{B} \QAND \bar{A}) \QAND (C \QOR \bar{C}).
\]
\fi

Now distributing $(\bar{B} \QAND \bar{A})$ over the \QOR\ yields the
disjunctive normal form
\[
(\bar{B} \QAND \bar{A} \QAND C) \QOR
(\bar{B} \QAND \bar{A} \QAND \bar{C}).
\]
Doing the same thing to the other \QAND-terms in~\eqref{DFNAONBANAONC}
finally gives a disjunctive normal form for~\eqref{ANBRC}:
\[\begin{array}{l}
(\bar{A} \QAND B \QAND C) \QOR (\bar{A} \QAND B \QAND \bar{C})\ \QOR\\
(\bar{A} \QAND \bar{B} \QAND C) \QOR  (\bar{A} \QAND \bar{B} \QAND \bar{C})\ \QOR\\
(\bar{B} \QAND \bar{A} \QAND C) \QOR  (\bar{B} \QAND \bar{A} \QAND \bar{C})\ \QOR\\
(\bar{A} \QAND \bar{C} \QAND B) \QOR  (\bar{A} \QAND \bar{C} \QAND \bar{B})\ \QOR\\
(\bar{B} \QAND \bar{C} \QAND A) \QOR  (\bar{B} \QAND \bar{C} \QAND \bar{A}).
\end{array}\]
Using commutativity to sort the term and \QOR-idempotence to remove
duplicates, finally yields a unique sorted DNF:
\[\begin{array}{l}
(A \QAND \bar{B} \QAND \bar{C})\ \QOR\\
(\bar{A} \QAND B \QAND C)\ \QOR\\
(\bar{A} \QAND B \QAND \bar{C})\ \QOR\\
(\bar{A} \QAND \bar{B} \QAND C)\ \QOR\\
(\bar{A} \QAND \bar{B} \QAND \bar{C}).
\end{array}\]

This example illustrates a strategy for applying these equivalences to
convert any formula into disjunctive normal form, and conversion to
conjunctive normal form works similarly, which explains:
\begin{theorem}\label{completeDNF}
Any propositional formula can be transformed into \idx{disjunctive
  normal form} or a \idx{conjunctive normal form} using the
equivalences listed above.
\end{theorem}

What has this got to do with equivalence?  That's easy: to prove that
two formulas are equivalent, convert them both to disjunctive normal
form over the set of variables that appear in the terms.  Then use
commutativity to sort the variables and \QAND-terms so they all appear
in some standard order.  We claim the formulas are equivalent iff they
have the same sorted disjunctive normal form.  This is obvious if they
do have the same disjunctive normal form.  But conversely, the way we
read off a disjunctive normal form from a truth table shows that two
different sorted DNF's over the same set of variables correspond to
different truth tables and hence to inequivalent formulas.  This
proves

\begin{theorem}[Completeness of the propositional equivalence axioms]
\label{complete_equivalence}
Two propositional formula are equivalent iff they can be proved
equivalent using the equivalence axioms listed above.
\end{theorem}

The benefit of the axioms is that they leave room for ingeniously
applying them to prove equivalences with less effort than the truth
table method.  Theorem~\ref{complete_equivalence} then adds the
reassurance that the axioms are guaranteed to prove every equivalence,
which is a great punchline for this section.  But we don't want to
mislead you: it's important to realize that using the strategy we gave
for applying the axioms involves essentially the same effort it would
take to construct truth tables, and there is no guarantee that applying the
axioms will generally be any easier than using truth tables.

\begin{problems}
\practiceproblems
\pinput{TP_only_and_or_not}

\classproblems
\pinput{CP_CNF_from_DNF}

\homeworkproblems
\pinput{PS_find_dnf}

\end{problems}

\section{The SAT Problem}\label{SAT_sec}
Determining whether or not a more complicated proposition is
satisfiable is not so easy.  How about this one?
%
\[
(P \QOR Q \QOR R) \QAND (\bar P \QOR \bar Q)
                  \QAND (\bar P \QOR \bar R)
                  \QAND (\bar R \QOR \bar Q)
\]

The general problem of deciding whether a proposition is \idx{satisfiable}
is called \term{SAT}.  One approach to SAT is to construct a truth table
and check whether or not a $\true$ ever appears, but as for validity, this
approach quickly bogs down for formulas with many variables
because truth tables grow \idx{exponentially} with the number of
variables.

Is there a more \idx{efficient solution} to SAT?  In particular, is
there some, presumably very ingenious, procedure that determines in a
number of steps that grows \emph{\index{polynomial
    growth}{polynomially}}---like $n^2$ or $n^{14}$---instead of
exponentially, whether any given proposition is satisfiable or not?
No one knows.  And an awful lot hangs on the answer.  It turns out
that an efficient solution to SAT would immediately imply efficient
solutions to many, many other important problems involving packing,
scheduling, routing, and circuit verification, among other things.
This would be wonderful, but there would also be worldwide chaos.
Decrypting coded messages would also become an easy task, so online
financial transactions would be insecure and secret communications
could be read by everyone.  Why this would happen is explained in
Section~\ref{SAT_RSA_sec}.

Of course, the situation is the same for validity checking, since you
can check for validity by checking for satisfiability of negated
formula.  This also explains why the simplification of formulas
mentioned in Section~\ref{propositions_in_programs_sec} would be
hard---validity testing is a special case of determining if a formula
simplifies to \true.

Recently there has been exciting progress on \term{SAT-solvers} for
practical applications like digital circuit verification.  These
programs find satisfying assignments with amazing efficiency even for
formulas with millions of variables.  Unfortunately, it's hard to
predict which kind of formulas are amenable to SAT-solver methods, and
for formulas that are \emph{un}satisfiable, SAT-solvers generally get
nowhere.

So no one has a good idea how to solve SAT in polynomial time, or how
to prove that it can't be done---researchers are completely stuck.
The problem of determining whether or not SAT has a polynomial time
solution is known as the ``\textbf{P} vs.\, \textbf{NP}''
problem.\footnote{\textbf{P} stands for problems whose instances can
be solved in time that grows polynomially with the size of the
instance.  \textbf{NP} stands
for \textbf{n}ondeterministic \textbf{p}olynomial time, but we'll
leave an explanation of what that is to texts on the theory of
computational complexity.}  It is the outstanding unanswered question
in theoretical computer science.  It is also one of the
seven \href{http://www.claymath.org/millennium/}{Millenium Problems}:
the Clay Institute will award you \$1,000,000 if you solve
the \textbf{P} vs.\, \textbf{NP} problem.

\begin{problems}

\homeworkproblems
\pinput{PS_equisatisfiable_3CNF}

\end{problems}

\section{Predicate Formulas}\label{predicate_sec}
%\label{logic_chap}

\subsection{Quantifiers}\label{quantifier_sec}
The ``for all'' notation, $\forall$, already made an early appearance in
Section~\ref{prop_sec}.  For example, the predicate
%
\[
\text{``$x^2 \geq 0$''}
\]
%
is always true when $x$ is a real number.  That is,
\[
\forall x \in \reals.\, x^2 \geq 0
\]
is a true statement.  On the other hand, the predicate
%
\[
\text{``$5x^2 - 7 = 0$''}
\]
%
is only sometimes true; specifically, when $x = \pm \sqrt{7/5}$.
There is a ``there exists'' notation, $\exists$, to indicate that a
predicate is true for at least one, but not necessarily all objects.
So 
\[
\exists x \in \reals.\, 5x^2 - 7 = 0
\]
is true, while
\[
\forall x \in \reals.\, 5x^2 - 7 = 0
\]
is not true.

There are several ways to express the notions of ``always true'' and
``sometimes true'' in English.  The table below gives some general
formats on the left and specific examples using those formats on the
right.  You can expect to see such phrases hundreds of times in
mathematical writing!
%
\begin{center}
\begin{tabular}{ll}
\multicolumn{2}{c}{\textbf{Always True}} \\[1ex]
For all $x \in D$, $P(x)$ is true. & For all $x \in \reals$, $x^2 \geq 0$. \\
$P(x)$ is true for every $x$ in the set, $D$. & $x^2 \geq 0$ for every $x \in \reals$. \\[2ex]
\multicolumn{2}{c}{\textbf{Sometimes True}} \\[1ex]
There is an $x \in D$ such that $P(x)$ is true. & There is an $x \in \reals$ such that $5x^2 - 7 = 0$.\\
$P(x)$ is true for some $x$ in the set, $D$. & $5x^2 - 7 = 0$ for some $x \in \reals$.\\
$P(x)$ is true for at least one $x \in D$. & $5x^2-7=0$ for at least one $x \in \reals$.
\end{tabular}
\end{center}

All these sentences quantify how often the predicate is true.
Specifically, an assertion that a predicate is always true is called a
\term{universal} quantification, and an assertion that a predicate is
sometimes true is an \term{existential} quantification.  Sometimes the
English sentences are unclear with respect to quantification:
%
\begin{align}
  \text{If you can solve any problem we come up with,}\notag\\
  \text{then you get an \emph{A} for the course.}\label{solvegetA}
\end{align}
%
The phrase ``you can solve any problem we can come up with'' could
reasonably be interpreted as either a universal or existential
quantification:
\begin{equation}\label{solve_every}
\text{you can solve \emph{every} problem we come up with,}
\end{equation}
or maybe
\begin{equation}\label{solve_atleastone}
\text{you can solve \emph{at least one} problem we come up with.}
\end{equation}

\iffalse
In any case, notice that this quantified phrase appears inside a
larger if-then statement.  This is quite normal; quantified statements
are themselves propositions and can be combined
with \QAND, \QOR, \QIMPLIES, etc., just like any other proposition.
\fi
To be precise, let $\probs$ be the set of problems we come up with,
$\solves(x)$ be the predicate ``You can solve problem $x$,'' and $G$
be the proposition, ``You get an \emph{A} for the course.''  Then the
two different interpretations of~\eqref{solvegetA}
can be written as follows:
%
\[
(\forall x \in \probs.\, \solves(x)) \QIMP G,
\]
for~\eqref{solve_every}, and
\[
(\exists x \in \probs.\, \solves(x)) \QIMP G.
\]
for~\eqref{solve_atleastone}.

\subsection{Mixing Quantifiers}

Many mathematical statements involve several quantifiers.  For
example, we already described
%
\begin{quote}
 \idx{Goldbach's Conjecture}~\ref{Goldbach}: Every even integer
 greater than 2 is the sum of two primes.
\end{quote}
Let's write this out in more detail to be precise about the
quantification:
%
\begin{quote}
For every even integer $n$ greater than 2,
there exist primes $p$ and $q$ such that $n = p + q$.
\end{quote}
%
Let $\even$ be the set of even integers greater than 2, and let $\primes$ be the
set of primes.  Then we can write Goldbach's Conjecture in logic
notation as follows:
%
\[
\underbrace{\forall n \in \even.}_{\substack
    {\text{for every even} \\
     \text{integer $n > 2$}}}
\
\underbrace{\exists p \in \primes.\ \exists q \in \primes.}_{\substack
    {\text{there exist primes} \\
     \text{$p$ and $q$ such that}}}
\ n = p + q.
\]

\subsection{Order of Quantifiers}

Swapping the order of different kinds of quantifiers (existential or
universal) usually changes the meaning of a proposition.  For example,
let's return to one of our initial, confusing statements:
\begin{center}
``Every American has a dream.''
\end{center}

This sentence is ambiguous because the order of quantifiers is
unclear.  Let $A$ be the set of Americans, let $D$ be the set of
dreams, and define the predicate $H(a, d)$ to be ``American $a$ has
dream $d$.''  Now the sentence could mean there is a single dream
that every American shares---such as the dream of owning their own
home:
\[
\exists\, d \in D.\, \forall a \in A.\, H(a, d)
\]

Or it could mean that every American has a personal dream:
\[
\forall a \in A.\, \exists\, d \in D.\, H(a, d)
\]
For example, some Americans may dream of a peaceful retirement, while
others dream of continuing practicing their profession as long as they
live, and still others may dream of being so rich they needn't think
about work at all.

Swapping quantifiers in \idx{Goldbach's Conjecture} creates a patently false
statement that every even number $\geq 2$ is the sum of \emph{the same}
two primes:
\[
\underbrace{\exists\, p \in \primes.\ \exists\, q \in \primes.}_{\substack
    {\text{there exist primes} \\
     \text{$p$ and $q$ such that}}}
\
\underbrace{\forall n \in \even.}_{\substack
    {\text{for every even} \\
     \text{integer $n > 2$}}}
\ n = p + q.
\]

\subsection{Variables Over One Domain}
When all the variables in a formula are understood to take values from the
same nonempty set, $D$, it's conventional to omit mention of $D$.  For
example, instead of $\forall x \in D.\, \exists y \in D.\, Q(x,y)$ we'd
write $\forall x \exists y.\, Q(x,y)$.  The unnamed nonempty set that $x$
and $y$ range over is called the \term{domain of discourse}, or just plain
\term{domain}, of the formula.

It's easy to arrange for all the variables to range over one domain.  For
example, \idx{Goldbach's Conjecture} could be expressed with all variables
ranging over the domain $\naturals$ as
\[
\forall n.\, n \in \even \QIMP (\exists\, p.\, \exists\, q.\, p \in \primes \QAND
q \in \primes \QAND n = p + q).
\]

\subsection{Negating Quantifiers}

There is a simple relationship between the two kinds of quantifiers.  The
following two sentences mean the same thing:
%
\begin{quote}

Not everyone likes ice cream.

There is someone who does not like ice cream.

\end{quote}
The equivalence of these sentences is a instance of a general
equivalence that holds between predicate formulas:
%
\begin{equation}\label{notforall}
\QNOT(\forall x.\, P(x))
\quad \text{is equivalent to} \quad
\exists x.\, \QNOT(P(x)).
\end{equation}
%
Similarly, these sentences mean the same thing:
%
\begin{quote}
There is no one who likes being mocked.

Everyone dislikes being mocked.
\end{quote}
The corresponding predicate formula equivalence is
\begin{equation}\label{nE}
\QNOT(\exists x.\, P(x))
\quad \text{is equivalent to} \quad
\forall x.\, \QNOT(P(x)).
\end{equation}
The general principle is that \emph{moving a \QNOT\ across a
  quantifier changes the kind of quantifier.}  Note that~\eqref{nE}
follows from negating both sides of~\eqref{notforall}.

\iffalse
Logicians have worked very hard to define strict rules for the
use of logic notation so that ideas can be expressed with absolute rigor.
It's all quite charming and clever.  However, the sad irony is that
applied mathematicans usually use their beloved notation as a crude
shorthand, breaking the rules and abusing the notation willy-nilly ---sort
of like pounding nails with fine china.
\fi

\subsection{Validity for Predicate Formulas}

\iffalse
A propositional formula is called \term{valid} when it evaluates to \true\
no matter what truth values are assigned to the individual propositional
variables.  For example, the propositional version of the \idx{Distributive Law}
is that $P \QAND (Q \QOR R)$ is equivalent to $(P \QAND Q) \QOR (P \QAND
R)$.  This is the same as saying that
\[
[P \QAND (Q \QOR R)] \QIFF [(P \QAND Q) \QOR (P \QAND R)]
\]
is valid.
\fi

The idea of validity extends to predicate formulas, but to be valid, a
formula now must evaluate to true no matter what values its variables
may take over any unspecified domain, and no matter what
interpretation a predicate variable may be given.  For example, we
already observed that the rule for negating a quantifier is captured
by the valid assertion~\eqref{nE}.

Another useful example of a valid assertion is
\begin{equation}\label{eaimpliesae}
\exists x \forall y.\, P(x,y) \QIMP \forall y \exists x.\, P(x,y).
\end{equation}

Here's an explanation why this is valid:

\begin{quote}
Let $D$ be the domain for the variables and $P_0$ be some
\idx{binary predicate}\footnote{That is, a predicate that depends on two variables.}
on $D$.  We need to show that if
\begin{equation}\label{exayp0}
\exists x \in D.\, \forall y \in D.\, P_0(x,y)
\end{equation}
holds under this interpretation, then so does
\begin{equation}\label{ayexp0}
\forall y \in D.\, \exists x \in D.\, P_0(x,y).
\end{equation}
So suppose~\eqref{exayp0} is true.  Then by definition of $\exists$, this
means that some element $d_0 \in D$ has the property that
\[
\forall y \in D.\, P_0(d_0, y).
\]
By definition of $\forall$, this means that
\[
P_0(d_0,d)
\]
is true for all $d \in D$.  So given any $d \in D$, there is an element in
$D$, namely, $d_0$, such that $P_0(d_0,d)$ is true.  But that's exactly
what~\eqref{ayexp0} means, so we've proved that~\eqref{ayexp0} holds under
this interpretation, as required.
\end{quote}

We hope this is helpful as an explanation, but we don't really want to
call it a ``proof.''  The problem is that with something as basic
as~\eqref{eaimpliesae}, it's hard to see what more elementary axioms
are ok to use in proving it.  What the explanation above did was
translate the logical formula~\eqref{eaimpliesae} into English and
then appeal to the meaning, in English, of ``for all'' and ``there
exists'' as justification.

\iffalse
So this wasn't a proof, just an explanation intended to make 
what~\eqref{eaimpliesae} means, it becomes obvious.
\fi

In contrast to~\eqref{eaimpliesae}, the formula
\begin{equation}\label{aenotimplyea}
\forall y \exists x.\, P(x,y)\ \QIMP\ \exists x \forall y.\, P(x,y).
\end{equation}
is \emph{not} valid.  We can prove this just by describing an
interpretation where the hypothesis, $\forall y \exists x.\, P(x,y)$, is
true but the conclusion, $\exists x \forall y.\, P(x,y)$, is not true.
For example, let the domain be the integers and $P(x,y)$ mean $x > y$.
Then the hypothesis would be true because, given a value, $n$, for $y$ we
could choose the value of $x$ to be $n+1$, for example.  But under this
interpretation the conclusion asserts that there is an integer that is
bigger than all integers, which is certainly false.  An interpretation
like this which falsifies an assertion is called a \term{counter model} to
the assertion.

\begin{problems}

\practiceproblems
\pinput{TP_Propositions_with_Quantifiers}
\pinput{TP_Quantifiers}
\pinput{TP_counter_model_EimpA}
\pinput{TP_counter_model_EEandE}

\classproblems
\pinput{CP_logic_news_network}
\pinput{CP_assertions_about_binary_strings}
\pinput{CP_domain_of_discourse}
\pinput{CP_counter_model}

\homeworkproblems
\pinput{PS_predicate_calculus_power_of_prime}
\pinput{PS_emailed_exactly_2_others}

\examproblems
\pinput{MQ_swapping_quantifiers_morning}
\pinput{FP_line_up_quantifiers}

\end{problems}

\iffalse
\section{Rules for Quantifiers}

\subsection{Prenex Form}
\fi

\endinput
