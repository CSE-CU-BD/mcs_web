\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{PS_Markov_with_bounded_RVs}
   \pcomment{by Kazerani 4/30/11 w/ARM minor edits}
\end{pcomments}

\pkeywords{
  Markov_bound
  deviation
  expectation
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
If $R$ is a nonnegative random variable, then Markov's Theorem gives
an upper bound on $\pr{R \geq x}$ for any real number $x >
\expect{R}$.  If a constant $b\geq 0$ is a lower bound on $R$, then
Markov's Theorem can also be applied to $R-b$ to obtain a possibly
different bound on $\pr{R \geq x}$.

\iffalse
\footnote{The less demanding constraint $x > 0$ would still
  allow Markov's Theorem to be used, but the resulting bound would be
  useless if $x\leq\expect{R}$.}, direct application of Markov's
Theorem gives
\begin{equation}\label{MarkovBound}
\pr{R\geq x}\leq\frac{\expect{R}}{x}
\end{equation}
\begin{problemparts}
\fi

\bparts \ppart\label{boundpart} Show that if $b>0$, applying Markov's
Theorem to $R-b$ gives a smaller upper bound on $\pr{R \geq x}$ than
simply applying Markov's Theorem directly to $R$.

\begin{solution}
Define
\[
T\eqdef R-b.
\]
Then $T$ is a nonnegative random variable and Markov's Theorem can
therefore be applied to $T$ to give
\[
\prob{T \geq x - b} \leq \frac{\expect{T}}{x - b} = \frac{\expect{R} - b}{x - b}.
\]
But the event $[T \geq x - b]$ is the same as $[R \geq x]$, so
\[
\prob{R \geq x} \leq \frac{\expect{R} - b}{x - b}.
\]

So we want to show that
\[
\frac{\expect{R} - b}{x - b} < \frac{\expect{R}}{x}.
\]
Since $x$, $b$, and $x-b$ are all positive, therefore
\begin{align*}
\frac{\expect{R} - b}{x - b} &< \frac{\expect{R}}{x} \qquad{\text{iff}}\\
x\expect{R} - bx &< x\expect{R} - b\expect{R}\qquad{\text{iff}}\\
-bx &< -b\expect{R}\qquad{\text{iff}}\\
x &> \expect{R}.
\end{align*}
But $x$ \emph{is} larger than $\expect{R}$, so
\[
\frac{\expect{R} - b}{x - b} < \frac{\expect{R}}{x},
\]
as required.
\end{solution}

\ppart What value of $b\geq 0$ in part~\eqref{boundpart} gives the
best bound?

\begin{solution}
With $b\geq 0$, $R-b$ is nonnegative iff $b\in[0,\text{glb}(\range{R})]$.\footnote{$\text{glb}(S)$ 
denotes the \emph{greatest lower bound} (or \emph{infimum}) of a set $S\subseteq\reals$.
When $S$ is nonempty and bounded below, $\text{glb}(S)$ is just the largest real number that is no larger than any of
the elements of $S$.}  So for any such $b$, applying Markov's Theorem to $R-b$ gives
\[
\prob{R \geq x} \leq \frac{\expect{R} - b}{x - b}.
\]
Differentiating this upper bound with respect to $b$ gives
\[
\frac{d}{db}\paren{\frac{\expect{R} - b}{x - b}}=\frac{\expect{R}-x}{\paren{x-b}^2}.
\]
Since $x>\expect{R}$ and $x\neq b$, therefore this derivative is negative -- and so the bound as a function of $b$ 
is strictly decreasing -- for all $b\in[0,\text{glb}(\range{R})]$.
Hence, the best (smallest) upper bound is given by choosing $b=\text{glb}(\range{R})$.

\textbf{Note:} To prove that the bound is strictly decreasing on the interval of interest without using 
calculus, let $b_1,b_2\in[0,\text{glb}(\range{R})]$.  Since $x-b_1>0$, $x-b_2>0$, and $x>\expect{R}$, 
therefore
\begin{align*}
\frac{\expect{R} - b_1}{x - b_1} &< \frac{\expect{R} - b_2}{x - b_2}\qquad{\text{iff}}\\
x\expect{R} - b_1x - b_2\expect{R} + b_1b_2 &< x\expect{R} - b_1\expect{R} - b_2x + 
b_1b_2\qquad{\text{iff}}\\
(b_1-b_2)\expect{R} &< (b_1-b_2)x\qquad{\text{iff}}\\
b_1-b_2&>0\qquad{\text{iff}}\\
b_1&>b_2.
\end{align*}

\iffalse
Let $m$ denote the minimum value of $R$.  Since $R$ is nonnegative and
nonzero, therefore $m > 0$.  We demanded that $l > 0$ and $R-l$ be
nonnegative.  These requirements are met iff $l\in(0,m]$.

Choose $l_1,l_2\in(0,m]$ such that $l_1<l_2$.  Now, we know from
  parts~\eqref{boundpart} that Markov's Theorem can
  be applied to $R-l_1$ to give $\prob{R \geq x}\leq\frac{\expect{R} -
    l_1}{x - l_1}$, and to $R-l_2$ to give $\prob{R \geq
    x}\leq\frac{\expect{R} - l_2}{x - l_2}$, both of which give
  tighter bounds than is obtained by applying Markov's Theorem to $R$
  directly.

Let $R_1=R-l_1$, $\Delta l = l_2-l_1$, and $x_1=x-l_1$.  Clearly, $R_1$ is nonnegative, as is $R_1-\Delta l=R_2$.  Also,
$\Delta l > 0$ and $x_1 = x - l_1 > \expect{R} - l_1 = \expect{R-l_1} = \expect{R_1}$.  So we can apply our approach and results
here: Markov's Theorem on $R_1-\Delta l$ gives $\prob{R_1 \geq x_1}\leq\frac{\expect{R_1} - \Delta l}{x_1 - \Delta l}$, and
this bound is tighter than that given by $\prob{R_1 \geq x_1}\leq\frac{\expect{R_1}}{x_1}$.
Now, $\pr{R_1 \geq x_1}=\pr{R - l_1 \geq x - l_1}=\pr{R \geq x}$, $\frac{\expect{R_1} - \Delta l}{x_1 - \Delta l}=\frac{\expect{R} - l_2}{x - l_2}$, and
$\frac{\expect{R_1}}{x_1}=\frac{\expect{R-l_1}}{x-l_1}$.  Thus we have that $\pr{R \geq x}\leq\frac{\expect{R} - l_2}{x - l_2}$
gives a tighter upper bound for  $\pr{R \geq x}$ than $\pr{R \geq x}\leq\frac{\expect{R} - l_1}{x - l_1}$ does.  
Therefore, applying Markov's Theorem to $R-l_2$ yields a tighter upper bound on the probability of interest than does applying
Markov's Theorem to $R-l_1$.  

So to get the tightest possible upper bound by this approach, we must choose the largest possible $l > 0$ that keeps $R-l$ nonnegative -- that is,
the largest possible $l\in(0,m]$.  So $l=m$ gives the tightest bound.
\fi
\end{solution} 

\end{problemparts}

\end{problem} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
% Problem ends here 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
