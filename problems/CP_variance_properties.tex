\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{CP_variance_properties}
  \pcomment{S02.cp12f}
  \pcomment{from Velleman by Ashish, May 2, 2002}
\end{pcomments}

\pkeywords{
  variance
  expectation
  random_variable
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Let $R$ be a nonnegative integer valued random variable.
\begin{problemparts}

\problempart

Let $T \eqdef cR$ for some constant~$c$.  Prove that
\[
\variance{T} = c^2\variance{R}\ .
\]

\begin{solution}
\begin{align*}
\variance{T} 
& = \expect{T^2} - \expectsq{T}\\
& = \expect{(cR)^2} - \expectsq{cR}\\
& = \expect{c^2R^2} - \paren{c\expect{R}}^2\\
& = c^2\expect{R^2} - c^2\expectsq{R}\\
& = c^2 \variance{R} 
\end{align*}
\end{solution}

\problempart
If $\expect{R}=1$, how large can $\variance{R}$ be?

\begin{solution}
The variance of $R$ is unbounded.  For example, suppose $R_n$ is a
random variable that equals $n$ with probability $1/n$ and equals 0
otherwise.  So $\expect{R_n} = n/n = 1$ as required.  However,
\[
\variance{R_n} = \expect{R_n^2} - \expectsq{R_n}= \frac{n^2}{n} - 1 = n-1.
\]
So $\variance{R_n}$ grows unboundedly.

In fact, there are nonnegative integer valued random variables with
expectation 1 and infinite variance (see
Problem~\bref{CP_infinite_variance}).

\iffalse
Let $S$ be a random variable
\begin{align*}
\prob{R=i} & = \frac{1}{i^3\zeta(2)} & \text{(for all $i\geq 1$)}\\
\prob{R=0} & = 1-\frac{\zeta(3)}{\zeta(2)},
\end{align*}
where $\zeta$ is the Reimann Zeta function,
\[
\zeta(k) \eqdef \sum_{i=1}^\infty\frac{1}{i^k}\ .
\]
It's easy to see that this sum converges for $k>1$ and is strictly
decreasing in $k$, so $\frac{\zeta(3)}{\zeta(2)}<1$.  (Incidentally
$\zeta(2)=\frac{\pi^2}{6}=1.644...$ and $\zeta(3)=1.202...$).

$R$ is a well defined random variable since
\begin{align*}
\sum_{i=0}^\infty\prob{R=i}
&= \prob{R=0}+\sum_{i=1}^\infty\prob{R=1}\\
&= 1-\frac{\zeta(3)}{\zeta(2)}+\sum_{i=1}^\infty\frac{1}{i^3\zeta(2)}\\
&= 1-\frac{\zeta(3)}{\zeta(2)}+\frac{\zeta(3)}{\zeta(2)}=1
\end{align*}
Also
\begin{align*}
\expect{R}
& = \sum_{i=0}^\infty i\prob{R=i}\\
& = 0 \paren{1-\frac{\zeta(3)}{\zeta(2)}} + \sum_{i=1}^\infty\frac{i}{i^3\zeta(2)}\\
& = 0 + \frac{1}{\zeta(2)}\sum_{i=1}^\infty\frac{1}{i^2} = 1.
\end{align*}
But
\begin{align*}
\variance{R}
&= \expect{(R-\expect{R})^2}\\
&= \sum_{i=0}^\infty (i-1)^2\prob{R=i}\\
&> \sum_{i=2}^\infty (i-1)^2\prob{R=i}=\sum_{i=2}^\infty \frac{(i-1)^2}{i^3\zeta(2)}\\
&> \sum_{i=2}^\infty\frac{(i-1)^2}{(i-1)^3\zeta(2)}
&= \frac{1}{\zeta(2)}\sum_{i=2}^\infty\frac{1}{i-1} = \infty
\end{align*}
From divergence of the harmonic series.
\fi

\end{solution}

\problempart
If $R$ is always positive (nonzero), how large can $\expect{1/R}$ be?

\begin{solution}

$\expect{1/R}$ is maximized at 1 when $R = 1$ with probability $1$.
Intuitively, this can be seen by trying to shift some of the
probability mass away from $1$.  No matter how you do it, you will
always wind up with an expectation that is less than $1$.

Formally, we can prove this as follows. Suppose $\prob{R=1} = 1-\delta$
for some $\delta > 0$. Then
\begin{align*}
\expect{R}
& = 1\cdot(1-\delta) + \sum_{i=2}^{\infty}\frac{1}{n}\cdot \prob{R=n}\\
& \leq 1\cdot(1-\delta) + \sum_{i=2}^{\infty}\frac{1}{2}\cdot \prob{R=n}\\
& \leq 1\cdot(1-\delta) + \frac{1}{2}\sum_{i=2}^{\infty}\prob{R=n}\\
& \leq 1\cdot(1-\delta) + \frac{1}{2}\cdot\delta\\
& \leq 1-\delta\cdot\frac{3}{2}.
\end{align*}

So, for any positive $\delta$, $\expect{R}$ is less than 1.
Therefore, the given distribution maximizes $\expect{1/R}$.
\end{solution}

\end{problemparts}
\end{problem}

\endinput
