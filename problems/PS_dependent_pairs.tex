\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{PS_dependent_pairs}
  \pcomment{sequel to PS_equal_birthdays}
  \pcomment{by ARM 4/28/11; corrected with complete soln 8/12/12}
\end{pcomments}

\pkeywords{
  random_variable
  independence
  mutual
  pairwise
  uniform
  distribution
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Let $R$, $S$, and $T$ be mutually independent indicator variables.
Problem~\bref{PS_equal_birthdays} showed that if $R$ or $T$ is
uniform ---that is,
\[
\pr{R=1} = \pr{T=1} =\frac{1}{2},
\]
then the events
\begin{center}
$[R=S]$ and $[S=T]$ are independent.
\end{center}


\bparts

\ppart Give an example of $R$, $S$, and $T$ such that the events
$[R=S]$ and $[S=T]$ are \emph{not} independent.

\begin{solution}
Suppose without loss of generality that both $R$ and $T$ are more
likely to equal 1 than to equal 0.  For simplicity, also suppose $S$
is uniform.

Now we can reason informally (but correctly) as follows.  Since $S$ is
equally likely to be 0 or 1, it as likely as not to equal $T$, that
is, $\pr{S=T} = 1/2$.  But since $R$ is more likely to be 1 than 0,
knowing that $R=S$ makes it more likely that $S=1$, and knowing that
$S=1$, makes it more likely that $S=T$.  So knowing that $R=S$ makes
it more likely that $S=T$.  That is,
\[
\prcond{S=T}{R=S} > \frac{1}{2} = \pr{S=T}.
\]
This means that $S=T$ is not independent of $R=T$.

We can illustrate this with a numerical example.  Let $\pr{R=1} =
\pr{T=1} = 2/3$, so
\begin{align*}
\lefteqn{\prcond{S=T}{R=S}}\\
& = \frac{\pr{R=S=T=1} + \pr{R=S=T=0}}{\pr{R=S=1} + \pr{R=S=0}}\\
& = \frac{2/3\ \ 1/2\ \ 2/3 + 1/3\ \ 1/2\ \ 1/3}{2/3\ \ 1/2 + 1/3\ \ 1/2}\\
& = \frac{5}{9} > \frac{1}{2} = \pr{S=T}.
\end{align*}
\end{solution}


\ppart Generalize your example to prove conversely that the events
$[R=S]$ and $[S=T]$ are independent iff either $R$ is uniform, or $T$
is uniform, or $S$ is constant\footnote{That is, $\pr{S=1}$ is one or
  zero.}.

\begin{solution}
Let $r,s,t$ be the probabilities that $R=1, S=1, T=1$, respectively.
Then
\begin{align*}
\pr{R=S} & = rs + (1-r)(1-s)\\
\pr{S=T} & = st + (1-s)(1-t)\\
\pr{R=S \QAND S=T} & = rst + (1-r)(1-s)(1-t).
\end{align*}
So $[R=S]$ and $[S=T]$ are independent iff
\begin{equation}\label{rs+1-r.1-s}
[rs + (1-r)(1-s)][st + (1-s)(1-t)] = rst + (1-r)(1-s)(1-t).
\end{equation}
Subtracting the left from the right hand side of this equation and
factoring, we find that~\eqref{rs+1-r.1-s} holds iff
\[
s(s-1)(2r-1)(2t-1) = 0,
\]
namely, iff $s=0$ or $s=1$ or $r=1/2$ or $t=1/2$.  That is,
independence holds iff $S$ is constant or $R$ or $T$ is uniform.
\end{solution}

\eparts

\end{problem}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
