\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{FP_chebyshev_pq}
  \pcomment{generalizes TP_Flipping_coins}
  \pcomment{ARM 5/10/16}
  \pcomment{use last part for CP? 
    Suspicious: current answer shows arbitrarily much harder to estimate large $p$ than small}
\end{pcomments}

\begin{problem}
You have a biased coin which flips Heads with probability $p$.  You
flip the coin $n$ times.  The coin flips are all mutually independent.

\bparts

\ppart\label{expected} Write a simple expression in terms of $p$ and
$n$ for the expected number of Heads.

\begin{center}
\exambox{0.7in}{0.4in}{0in}
\end{center}

\examspace[0.2in]

\begin{solution}
$\mathbf{np}$.

Let $X$ denote the number of Heads.  Let $X_{i}$ be the indicator
variable that is 1 if and only if the $i$th coin flip comes out Heads (and 0 otherwise). Then
\begin{equation*}
    X = X_{1} + X_{2} + \dots + X_{n}.
\end{equation*}

Hence, by linearity of expectation, 
\[
\expect{X}
    = \expect{X_{1} + X_{2} + \cdots + X_{n}}
    = \expect{X_{1}} + \cdots + \expect{X_{n}}.
\]
The expectation of an indicator variable is the probability it
equals~1\inbook{ by Lemma~\bref{expindic}}.  Hence, $\expect{X_{i}} =
p$.  We conclude that $\expect{X} = n \cdot p$.
\end{solution}

\ppart What upper bound can we derive directly from Markov's Theorem
for the probability that the number of Heads is at least 25\% larger
than expected?

\begin{center}
\exambox{0.7in}{0.4in}{0in}
\end{center}

\examspace[0.5in]

\begin{solution}
\textbf{1/1.25 = 0.8}.

The Markov for being $a$ times the mean is $1/a$.  Note that this does
not depend on $n$ or $p$.
\end{solution}

\ppart Write a simple expression in terms of $p$ and $n$ for the
variance of the number of Heads.

\begin{center}
\exambox{0.7in}{0.4in}{0in}
\end{center}

\examspace[0.75in]

\begin{solution}
$\mathbf{np(1-p)}$.

By the independence of the $X_{i}$, we know
\[
\Var[X] = 
\Var[X_{1} + \cdots  + X_{n}] = 
\Var[X_{1}]+ \cdots  + \Var[X_{n}].
\]
Finally, we know \inbook{by Corollary~\bref{bernoulli-variance}} the
variance of an indicator with expectation $p$ is $p(1-p)$.
\end{solution}

\ppart\label{C25bnd} Write a simple expression in terms of $p$ and $n$
for the upper bound Chebyshev's Theorem gives for the probability that
the number of Heads differs from the expected number by at least 1\%?

\begin{center}
\exambox{0.7in}{0.4in}{0in}
\end{center}

\begin{solution}
\[
100^2\frac{1-p}{np}
\]

Now, Chebyshev's Theorem says that the probability that $X$ deviates
from its expected value by at least 1/100 times the expected value
$\mu$, is at most
\[
\frac{\variance {X}}{(\mu/100)^2} = \frac{np(1-p)}{(np/100)^2} =
100^2\frac{(1-p)}{np}.
\]
\end{solution}

\iffalse

\ppart According to the bound in part~\eqref{C25bnd}, how big must $n$
be to ensure that there is a 95\% chance that the average number of
Heads is within 1\% of $p$?

\begin{solution}
We need
\[
100^2\frac{1-p}{np} \leq \frac{1}{20},
\]
so
\[
n \geq 20\cdot 100^2\frac{1-p}{p}
\]
\end{solution}
\fi

\eparts

\end{problem}

\endinput
