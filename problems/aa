%CP_10_and_15_cent_stamps_by_WOP.tex

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{same as F09: cp2m with 10 replacing 6}
\end{pcomments}

\pkeywords{
  well-ordering
  WOP
  postage_stamps
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problems start here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
  The proof below uses the Well Ordering Principle to prove that every
  amount of postage that can be paid exactly, using only 10 cent and 15
  cent stamps, is divisible by 5.  Let $S(n)$ mean that exactly $n$ cents
  postage can be paid using only 10 and 15 cent stamps.  Then the proof
  shows that
%
\begin{equation}\tag{*}
S(n)\ \QIMPLIES\ 5 \divides n, \quad \text{for all nonnegative integers $n$}.
\end{equation}
Fill in the missing portions (indicated by ``\dots'') of the following
proof of~(*).

\begin{quote}
Let $C$ be the set of \emph{counterexamples} to~(*), namely
\[
C \eqdef \set{n \suchthat \dots \instatements{\brule{4in}}}
\]

\begin{solution}
 $n$ is a counterexample to~(*) if $n$ cents postage can be
  made and $n$ is not divisible by 5, so the predicate
\[
S(n)\text{ and } \QNOT(5 \divides n)
\]
defines the set, $C$, of counterexamples.
\end{solution}

Assume for the purpose of obtaining a contradiction that $C$ is
nonempty.  Then by the WOP, there is a smallest number, $m \in C$.
This $m$ must be positive because\dots

\vspace{0.3in}
\instatements{\brule{6in}}

\begin{solution}
\dots $5 \divides 0$, so 0 is not a counterexample.
\end{solution}

But if $S(m)$ holds and $m$ is positive, then $S(m-10)$ or $S(m-15)$
must hold, because\dots.

\vspace{0.3in}
\instatements{\brule{6in}}

\begin{solution}
\dots if $m>0$ cents postage is made from 10 and 15 cent
  stamps, at least one stamp must have been used, so removing this
  stamp will leave another amount of postage that can be made.
\end{solution}

So suppose $S(m-10)$ holds.  Then $5 \divides (m-10)$, because\dots

\vspace{0.3in}
\instatements{\brule{6in}}

\begin{solution}
\dots if $\QNOT(5 \divides (m-10))$, then $m-10$ would be
  a counterexample smaller than $m$, contradicting the minimality of
  $m$.
\end{solution}

But if $5 \divides (m-10)$, then obviously $5 \divides m$,
contradicting the fact that $m$ is a counterexample.

Next suppose $S(m-15)$ holds.  Then the proof for $m-10$ carries over
directly for $m-15$ to yield a contradiction in this case as well.
Since we get a contradiction in both cases, we conclude that\dots

\vspace{0.3in}
\instatements{\brule{6in}}

\begin{solution}
\dots $C$ must be empty.  That is, there are no
  counterexamples to~(*),
\end{solution}

which proves that (*) holds.

\end{quote}
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problems end here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{1.3in}
\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: F09.mq3}
  \pcomment{similar to CP_10_and_15_cent_stamps_by_WOP but slightly different and uses induction}
\end{pcomments}

\pkeywords{
  induction
  strong_induction
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}

  Find all possible (nonzero) amounts of postage that can be paid 
  exactly using 5 and 3 cent stamps. Use induction to prove that
  your answer is correct.
  
  \hint Let $S(n)$ mean that exactly $n$ cents of postage can be
  paid using only 5 and 3 cent stamps. Prove that the following 
  proposition is true as part of your solution.
  \[ 
    \forall n.\ ( n \geq 8 ) \QIMPLIES\ S(n).
  \]
    
% \ppart
% 
%   Let $S(n)$ mean that exactly $n$ cents of postage can be paid using 
%   only 5 and 3 cent stamps. 
%   
%   Find the smallest $k$ such that the following 
%   proposition is true.
%   \[ 
%   \forall n.\ ( n \geq k ) \QIMPLIES\ S(n).
%   \]
%   
% \vspace{1in}
  % Use induction to prove that your answer to the previous problem 
  % part is correct. 
  
\begin{solution}
  
  \begin{proof}
    The following proof is by strong induction on $n$.
    
    We can begin by observing that the following postage amounts can 
    be made by 5 and 3 cent stamps:

    \begin{align*}
    3 & = 3 \\
    5 & = 5 \\
    8 & = 3 + 5 \\
    9 & = 3 + 3 + 3 \\
    10 & = 5 + 5
    \end{align*}

    The 3 consecutive postage values $8, 9, 10$ will be our base cases 
    for the induction proof.

    \textbf{Base cases:} $S(8)$, $S(9)$ and $S(10)$ are shown to hold
    by explicit calculations.

    \textbf{Inductive step:} For all $n \geq 10$, we assume that $P(8)$,
    $\dots$, $P(n)$ are true in order to prove that $P(n+1)$ is true.

    By the assumption that $P(n-2)$ is true, we know that the postage value
    $n - 2$ can be paid with 3 and 5 cent stamps. By adding one 3 cent
    stamp to that postage, we will be able to pay for a postage of 
    $n - 2 + 3 = n + 1$ cents, showing that $P(n+1)$ is true. It follows
    by strong induction that $P(n)$ holds for all $n \geq 10$.
    
    We have therefore shown that all postage values $ \geq 8 $
    can be paid by 3 and 5 cent stamps.
  \end {proof}
  
  Therefore, we have shown that the postage amounts 3, 5, and any 
  $k \geq 8$ can be paid by 5 and 3 cent stamps.
  
  Note that we have actually seen a proof for this using WOP in the 
  \href{http://courses.csail.mit.edu/6.042/fall09/slides2m.pdf}{Well Ordering Principle}
  lecture.

\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S04.ps7, S09.cp8t}
  \pcomment{Commented out in S09 - review before using.}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  number_theory 
  Eulers_theorem 
  modular_arithmetic
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}

At one time, the Guiness Book of World Records reported that the
``greatest human calculator'' was a guy who could compute 13th roots of
100-digit numbers that were powers of 13.  What a curious choice of
tasks \dots.

\bparts

\ppart Prove that 
\begin{equation}\label{d13}
d^{13} \equiv d \pmod {10}
\end{equation}
for $0 \leq d < 10$.

\begin{solution}
Since $n^{13} = ((n^2)^2)^3 n$, we can verify~\eqref{d13}
exhaustively without too much effort.  It obviously hold for $d=0,1,5$, and

\begin{align*}
2^{13} & =  ((2^2)^2)^3 \cdot 2 \equiv 16^3 \cdot 2 \equiv 6^3
 \cdot 2 \equiv 6 \cdot 2 \equiv 2 \pmod {10}\\
3^{13} & =  ((3^2)^2)^3 \cdot 3 \equiv 81^3 \cdot 3 \equiv 1^3 \cdot 3
           = 3 \pmod {10}\\
4^{13} & =  (2^2)^{13} \equiv (2^{13})^2 \equiv 2^2 = 4 \pmod {10}\\
6^{13} & = 2^{13} 3^{13} \equiv 2 \cdot 3 = 6 \pmod {10}\\
7^{13} & =  ((7^2)^2)^3 \cdot 7 \equiv (9^2)^3 \cdot \equiv 1^3 \cdot 7 =
 7 \pmod {10}\\
8^{13} & =  2^{13} 4^{13} \equiv 2 \cdot 4 = 8 \pmod {10}\\
9^{13} & =  3^{13} 3^{13} \equiv 3 \cdot 3 = 9 \pmod {10}
\end{align*}
\end{solution}

\ppart Now  prove that 
\begin{equation}\label{n13}
n^{13} \equiv n \pmod {10}
\end{equation}
for all $n$.

\begin{solution}
We have
\begin{align*}
n^{13}
    & \equiv  (\rem{n}{10})^{13} \pmod{10} & \text{(by Lemma~\ref{facts}.\ref{cp8m.aran})}\\
    & \equiv  \rem{n}{10} \pmod{10} & \text{(by~\eqref{d13} since $0 \leq \rem{n}{10} < 10$)}\\
    & \equiv  n \pmod{10} & \text{(by Lemma~\ref{facts}.\ref{cp8m.aran})}
\end{align*}

\iffalse
An alternative approach uses Euler's Theorem.  Say $n = 2^a 5^b c$, where
$c$ is not divisible by 2 or 5.  Then $c$ is relatively prime to 10.
Since $\phi(10) = 4$, we have $c^{4} \equiv 1 \pmod{10}$ by Euler's
Theorem.  Therefore, $c^{13} \equiv (c^{4})^3 \cdot c \equiv c \pmod{10}$.
Now we can reason as follows:
\begin{align*}
n^{13}
    & = (2^{13})^a (5^{13})^b c^{13}\\
    & \equiv 2^a 5^b c \pmod{10} & \text{(using~\eqref{d13} for $d=2,5$)}\\
    & = n
\end{align*}
\fi
\end{solution}

\iffalse

\ppart Find an integer $c > 1$ such that $n$ and $n^c$ agree in the
last {\em two digits} whenever $n$ is a positive number relatively
prime to 100.

\begin{solution}
  Finding a $c$ such that for all $k$ relatively prime to 100, $k^c
  \equiv k \pmod{100}$ would satisfy the requirement.  From Euler's
  theorem, we know $c = \Phi(100)+1$ satisfies this equation. Thus $c =
  \Phi(100)+1 = 41$.
\end{solution}
\fi

\eparts

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp6t}
\end{pcomments}

\pkeywords{
  graphs
  connectivity
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
There is a network of web-servers connected by optical cables that go
between servers.  Even when there is no direct cable between two servers,
it is possible to transmit data from one to the other indirectly along
cables through other servers.

The network company regularly has to disconnect cables for inspection and
repair, but there are 23 high priority servers which must always be able to
transmit data to each other.

In the best of networks, there is a smallest number of cables that
the company would have to keep connected in order for the 23 servers to
communicate.  What is this number?  Explain why a much bigger number might
be necessary in some networks.

\begin{solution}
22 cables is the absolute minimum.

The network can be modeled as a graph whose vertices are the servers, with
an edge between two servers when there is a direct cable connection between
them.  The fact that data transmission is possible between any two servers
means the graph is connected.

The minimum edge subgraph needed to maintain connections among 23 vertices
will be a tree which includes these 23 vertices, so it must have at least
22 edges.  But many more edges may be needed, for example, if the only
connection between two of the servers was through long sequence of cables,
then all the cables in the sequence would have to remain connected.
\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp4t}
\end{pcomments}

\pkeywords{
  well-ordering
  WOP
  lexicographic
  fun_game
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}\label{nngame}

  In the \term{2D Origin Game}, two players make alternate moves in a
  game played on nonnegative integer points in the plane.  A move
  consists of a pair $(x,y)$ of nonnegative integers, subject to the
  constraint that none of the previous moves may simultaneously be
  below and to the left of the current move.  That is, if $(x,y)$ is
  the current move and $(x',y')$ is any previous move, then either
  $x<x'$ (so the previous move is to the right of the current one) or
  $y<y'$ (so the previous move is above the previous one).  A player
  who moves to the origin $(0,0)$ is the loser.

  For example, the Player 1 might choose (5,6), after which Player 2
  can move to any point $(n,m)$ such that $n<5$ or $m<6$, for example,
  (4,12).  Now the players might move successsively to (4,11), (29,5),
  (1,1), (0,54), (0,1).  At this point it's Player 2's turn, and he
  can move to (1,0).  Then it is Player 1's move, and the only
  available move is to the origin (0,0), so Player 1 loses this play
  of the game.

\bparts 

\ppart\label{winstrat} Identify a winning strategy for the first
player, and argue its correctness.

\begin{solution}

The first player essentially has two winning strategies:

{\bf Strategy 1:} The first player starts with $(1,1)$.  Then the
second player can only pick $(0,n)$ or $(n,0)$ for some $n$.  The
first player then responds with, $(n,0)$ or $(0,n)$, respectively.  By
symmetry, the first player will always have a move whenever the second
player had a move, except when the second player picks $(0,0)$ and
loses.

{\bf Strategy 2:} The second winning strategy is slightly more tricky:
The first player starts by picking $(2,0)$,\footnote{Of course,
  picking $(0,2)$ would be equivalent, and the following argument will
  hold for it as well, with x and y coordinates replaced.} and then:

\begin{itemize}
\item
If the 2nd player picks $(0,n)$ for any $n\geq{1}$, 1st player
responds with $(1,n-1)$.

\item
If the 2nd player picks $(1,n)$ for any $n\geq{0}$, 1st player
responds with $(0,n+1)$.
\end{itemize}
The above procedure should be repeated for all consecutive moves.
Notice that if Player 2 had a valid move, so does Player 1, unless
Player 2 picked $(0,0)$ and lost.

\end{solution}

\ppart Does your strategy guarantee any bound on the number of game
moves?

\begin{solution}

  No.  For the first strategy, for example, a possible length
  $2n+1$ play using the first strategy is $(1,1)
  (0,n),(n,0),(0,n-1),(n-1,0)\dots,(0,0)$.

\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp4t}
  \pcomment{this should probably be combined with CP_2D_origin_game}
\end{pcomments}

\pkeywords{
  well-ordering
  WOP
  fun_game
  chains_and_antichains
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
This is an informative problem that no one got to in class, so we're
adding it to pset 5.

\bparts \ppart Even if the players in Problem~\ref{nngame} conspire to
keep the game going as long as possible, it will necessarily come to an
end.  Prove this as follows:

\item[i.] At any point in the game, let $x_m$ be the minimum of the $x$
  coordinates of all of the previous moves, and likewise, $y_m$ be the
  minimum of the $y$ coordinates of all of the previous moves.  Verify
  that after any move, the value of $x_m+y_m$ is the same or a smaller
  nonnegative integer.

\iffalse
\begin{solution}
That's because min's cannot increase as more moves are made, so
  neither can their sum.  
\end{solution}
\fi

\item[ii.] Suppose $a$ is the least number such that a move $(x_m,a)$
  has been made, and likewise $b$ is the least number such that a move $(b,y_m)$
  has been made.  The \emph{bounded moves} are defined to be the
  possible moves in the rectangle with corners at $(x_m,a)$ and
  $(b,y_m)$.  Explain why the only moves that do not decrease
  $x_m+y_m$ must be bounded moves.

\hint Draw a picture of the bounded-move rectangle after a few moves
have been made.

\iffalse
\begin{solution}
Moves North of the rectangle are not allowed because they
  would be coordinatewise larger than $(x_m,a)$, moves East of the
  rectangle are not allowed because they would be coordinatewise
  larger than $(b,y_m)$, and moves Northeast would be bigger than
  both.  Moves South of the rectangle decrease the minimum value of
  $y$, moves West decrease the minimum $x$, and moves Southwest
  decrease both.  That leaves only moves within the rectangle as
  possibly allowed moves that do not decrease $x_m+y_m$.
\end{solution}
\fi

\item[iii.] Define the \term{size}, $\sigma$, of a game position to be
  $(x_m+y_m,k)$ where $k$ is the number of bounded moves.  Explain why
  every move makes $\sigma$ decrease under lexicographic order,
  $\lex<$.\footnote{\term{Lexicographic order}, $\lex<$, on $\naturals^2$
    is defined by the rule:
\[
(x,y) \lex< (x',y') \qiff x < x'\ \QOR\ [x = x'\ \QAND\ y < y'].
\]} 
  Conclude that the game always comes to an end.
\iffalse

\begin{solution}
Week 3 Notes explained that lexicographic order on $\naturals^2$
  is a well-founded total order, and so it has no infinite decreasing
  sequences.  So the sizes of all the positions reached in any game must
  have a minimum value.  Since any further move would decrease this value,
  the position with such a minimum value must be one from which no move is
  possible, namely the final position at the origin.
\end{solution}
\fi

\iffalse

\ppart \emph{(Optional)} Is there a winning strategy for the first player
that guarantees a bound on the number of game moves?

\begin{solution}
No, because neither of the winning strategies described in the
  solution to part~\eqref{winstrat} guarantees a bound, and there are no
  other winning strategies.

To see this, suppose Player 1 starts with any legal move other than
the ones above. Player 2 will be able to adopt one of the two winning
strategies for himself and win for sure:
\begin{itemize}
\item
If Player 1 picks some $(m,n)$ where $m,n\geq{1}$ and
$(m,n)\neq(1,1)$, then Player 2 can pick $(1,1)$ next, and then use
the first strategy to win against Player 1.
\item
If Player 1 picks some $(0,n)$ or $(n,0)$ where $n\geq{3}$, then
Player 2 can respectively pick $(0,2)$ or $(2,0)$ next, and then use
the second strategy to win against Player 1.
\item
If Player 1 picks $(1,0)$ or $(0,1)$ then Player 2 picks the other one
and wins.
\end{itemize}

\end{solution}
\fi

\ppart Conclude that there is no infinite antichain 
 under the coordinatewise partial order on $\naturals^2$.\footnote
{\term{Coordinatewise partial order}, $\coordle$, on $\naturals^2$
is defined by the rule:
\[
(x,y) \coordle (x',y') \qiff [x \leq x'\ \QAND\ y \leq y'].
\]}

\iffalse
\begin{solution}
The elements of an antichain, listed in any order, is an allowed
  sequence of moves.  So an infinite antichain would describe a
  nonterminating game, contradicting the fact that the game must
  terminate.
\end{solution}
\fi

\ppart Show that for each $n>1$, there is an antichain of size $n$ under the
coordinatewise partial order on $\naturals^2$.

\iffalse
\begin{solution}
$(0,n-1),(1,n-2),(2,n-3),\dots,(n-1,0)$ 
\end{solution}
\fi

\ppart Instead of using lexicographic order, a simpler way to prove that
all game plays must end would be to assign to each position a nonnegative
integer-valued ``size'' that decreases with each move.  Explain why this is
impossible.

\iffalse
\begin{solution}
If the size of a game position was $\nu \in \naturals$, and size
  decreased with each move, then from that position, the game would have
  to end after at most $\nu$ moves.  But for any starting position besides
  the origin, play can continue for any finite number of moves, so no
  bound, $\nu$, is possible.
\end{solution}
\fi

\eparts

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%CP_6_and_15_cent_stamps

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp4t, S08.cp4m}
\end{pcomments}

\pkeywords{
  well-ordering
  WOP
  postage_stamps
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problems start here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
  The proof below uses the Well Ordering Principle to prove that every
  amount of postage that can be paid exactly using only 6 cent and 15 cent
  stamps, is divisible by 3.  Let the notation ``$j \divides k$'' indicate
  that integer $j$ is a divisor of integer $k$, and let $S(n)$ mean that
  exactly $n$ cents postage can be paid using only 6 and 15 cent
  stamps.  Then the proof shows that
%
\begin{equation}\tag{*}
S(n)\ \QIMPLIES\ 3 \divides n, \quad \text{for all nonnegative integers $n$}.
\end{equation}
Fill in the missing portions (indicated by ``\dots'') of the following
proof of~(*).

\begin{quote}
Let $C$ be the set of \emph{counterexamples} to~(*), namely\footnote{The
  notation ``$\set{n \suchthat \dots}$ means ``the set of elements, $n$,
  such that \dots.''}

\[
C \eqdef \set{n \suchthat \dots}
\]

\begin{solution}
 $n$ is a counterexample to~(*) if $n$ cents postage can be
  made and $n$ is not divisible by 3, so the predicate
\[
S(n)\text{ and } \QNOT(3 \divides n)
\]
defines the set, $C$, of counterexamples.
\end{solution}

Assume for the purpose of obtaining a contradiction that $C$ is
nonempty.  Then by the WOP, there is a smallest number, $m \in C$.
This $m$ must be positive because\dots.

\begin{solution}
\dots $3 \divides 0$, so 0 is not a counterexample.
\end{solution}

But if $S(m)$ holds and $m$ is positive, then $S(m-6)$ or $S(m-15)$
must hold, because\dots.

\begin{solution}
\dots if $m>0$ cents postage is made from 6 and 15 cent
  stamps, at least one stamp must have been used, so removing this
  stamp will leave another amount of postage that can be made.
\end{solution}

So suppose $S(m-6)$ holds.  Then $3 \divides (m-6)$, because\dots
\begin{solution}
\dots if $\QNOT(3 \divides (m-6))$, then $m-6$ would be
  a counterexample smaller than $m$, contradicting the minimality of
  $m$.
\end{solution}

But if $3 \divides (m-6)$, then obviously $3 \divides m$,
contradicting the fact that $m$ is a counterexample.

Next suppose $S(m-15)$ holds.  Then the proof for $m-6$ carries over
directly for $m-15$ to yield a contradiction in this case as well.
Since we get a contradiction in both cases, we conclude that\dots

\begin{solution}
\dots $C$ must be empty.  That is, there are no
  counterexamples to~(*),
\end{solution}

which proves that (*) holds.

\end{quote}
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problems end here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp5r}
  \pcomment{from: F03.ps4}
  \pcomment{edited S09 by ARM}
\end{pcomments}

\pkeywords{
  state_machines
  unreachable_states
  increasing_decreasing_variables
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Start with 102 coins on a table, 98 showing heads and 4 showing tails.
There are two ways to change the coins:
\begin{enumerate}
\item[(i)] flip over any ten coins, or

\item[(ii)] let $n$ be the number of heads showing.  Place $n+1$
  additional coins, all showing tails, on the table.
\end{enumerate}

For example, you might begin by flipping nine heads and one tail,
yielding 90 heads and 12 tails, then add 91 tails, yielding 90 heads and
103 tails.

\bparts
\ppart
Model this situation as a state machine, carefully defining the set of
states, the start state and the possible state transitions.

\begin{solution}
This can be modeled by a state machine.  The state of the
  machine is the number of heads and tails.  The start state is $(98,4)$,
  and the transitions are:
\[
(h,t) \to 
\begin{cases}
(h-a+(10-a),t+a-(10-a)) &\mbox{for } 10 \leq h+t \& 
                         0\leq a\leq \min{10,h}.\\
(h,t+h+1).
\end{cases}
\]

%\vskip0.5in
%{\bf Comment:} Most students forgot to specify the range of $a$ precisely
%for the first transition.

\end{solution}

\ppart Explain how to reach a state with exactly one tail showing.

\begin{solution}
One way is to:
\begin{enumerate}

\item Do operation 2 three times, yielding $(98, 4+3\cdot99)= (98,301)$.

\item Repeat 30 times: Do operation 1 to flip 10 tails into heads. This
will result in the state $(398,1)$, which is the desired state.
\end{enumerate}

\end{solution}

\ppart
Define the following derived variables:
\begin{eqnarray*}
 C & \eqdef & \mbox{ the number of coins on the table},\\
 H & \eqdef & \mbox{ the number of heads},\\
 T & \eqdef & \mbox{ the number of tails},\\
 C_2 & \eqdef & \mbox{remainder}(C/ 2),\\
 H_2 & \eqdef & \mbox{remainder}(H/ 2),\\
 T_2 & \eqdef & \mbox{remainder}(T/ 2).
\end{eqnarray*}

Which of these variables is
\begin{enumerate}

\item strictly increasing \begin{solution}
NONE
\end{solution}
\item weakly increasing \begin{solution}
$C$, $H_2$
\end{solution}
\item strictly decreasing \begin{solution}
NONE
\end{solution}
\item weakly decreasing \begin{solution}
$H_2$
\end{solution}
\item constant \begin{solution}
$H_2$
\end{solution}
\end{enumerate}

\begin{solution}
{\bf Comment:} Notice that a constant variable like $H_2$ is
also weakly decreasing and weakly increasing, by definition.
\end{solution}

\ppart Prove that it is not possible to reach a state in which there is
exactly one head showing.


\begin{solution}

We claimed above that $H_2$ is an invariant value, that is, it does not
change under state transitions.  To prove this, let $(h,t)$ be a state
with $h$ even.  For the next state, we have two cases to consider:
\begin{enumerate}
\item The first operation is executed:
$(h,t)\rightarrow(h-2a+10,t+2a-10)$.  Since $-2a+10$ is even, $H_2((h,t))=
H_2(h-2a+10, t+2a-10)$.

\item The second operation is executed: $(h,t)\rightarrow(h,t+h+1)$. The
number of heads does not change in this case, so $H_2$ does not change.
\end{enumerate}
Since the initial number of heads, 98, is even, that is, $H_2((98,4))=0$,
the Invariant Method now implies that the number of heads in a reachable
state is always even.  But since one is odd, it is not possible to reach a
state in which there is exactly one head showing.

\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp1r}
%  \pcomment{}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  root_2
  irrational
  well-ordering
  WOP
  contradiction
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Here is a different proof that $\sqrt{2}$ is irrational, taken from the
American Mathematical Monthly, v.116, \#1, Jan. 2009, p.69:

\begin{proof}
  Suppose for the sake of contradiction that $\sqrt{2}$ is rational, and
  choose the least integer, $q>0$, such that $\paren{\sqrt{2}-1}q$ is a
  nonnegative integer.  Let $q' \eqdef \paren{\sqrt{2}-1}q$.  Clearly $0<
  q' < q$.  But an easy computation shows that $\paren{\sqrt{2}-1}q'$ is a
  nonnegative integer, contradicting the minimality of $q$.
\end{proof}

\bparts

\ppart This proof was written for an audience of college teachers, and is
a little more concise than desirable at this point in 6.042.  Write out a
more complete version which includes an explanation of each step.

\begin{solution}
The points that need justification are:

\begin{enumerate}
\item Why is there a postive integer, $q$, such that $\paren{\sqrt{2}-1}q$
  is a nonnegative integer?  \emph{Answer:} Since $\sqrt{2}$ is rational,
  so is $\sqrt{2}-1$.  So $\sqrt{2}-1$ can be expressed as an integer
  quotient with positive denominator; now just let $q$ be that
  denominator.

\item Why is there such a \emph{least} positive integer, $q$?
  \emph{Answer:} As long as there is one such positive integer, there has
  to be a least one.  This obvious fact is known as the
  \emph{Well-Ordering Principle}.

\item Why is $0< q' < q$?  \emph{Answer:} We know that $1 < \sqrt{2} < 2$,
  so $0 < \sqrt{2}-1 < 1$.  Therefore, $0 < \paren{\sqrt{2}-1}r < r$ for any
  real number $r>0$.

\item Why is $(\sqrt{2}-1)q'$ a nonnegative integer?  \emph{Answer:} It's
  actually positive, because it is a product of positive numbers.  It's
  integer because
  \[
  \paren{\sqrt{2}-1}q' = \paren{\sqrt{2}-1}^2q = 2q - 2q\sqrt{2} + q =
  q-2\cdot\brac{\paren{\sqrt{2}-1}q}
  \]
  and the last term is of the form
  $\ang{\text{integer}-2 \cdot \brac{\text{integer}}}$.

\end{enumerate}
\end{solution}

\ppart Now that you have justified the steps in this proof, do you have a
preference for one of these proofs over the other?  Why?  Discuss these
questions with your teammates for a few minutes and summarize your team's
answers on your whiteboard.

\begin{solution}
Both proofs seem about equally easy to understand.  The previous
  problems shows that the first proof generalizes pretty directly from
  square roots to $k$th roots, which doesn't seems as clear for the this
  second proof.  On the other hand, the first proof requires appeal to
  Unique Prime Factorization, while the second just uses simple algebra.
\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp7t}
\end{pcomments}

\pkeywords{
  networks
  Halls_Theorem
  bipartite_matching
  graph_coloring
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
The Bene\u{s} network has a max congestion of 1; that is, every
permutation can be routed in such a way that a single packet passes
through each switch.  Let's work through an example.  A Bene\u{s} network
of size $N = 8$ is attached.

\bparts

\ppart Within the Bene\u{s} network of size $N = 8$, there are two
subnetworks of size $N = 4$.  Put boxes around these.  Hereafter,
we'll refer to these as the \textit{upper} and \textit{lower}
subnetworks.

\begin{solution}
\mfigure{!}{2in}{figures/benes-decomp}

\end{solution}

\ppart Now consider the following permutation routing problem:
%
\begin{align*}
\pi(0) & = 3 & \pi(4) & = 2 \\
\pi(1) & = 1 & \pi(5) & = 0 \\
\pi(2) & = 6 & \pi(6) & = 7 \\
\pi(3) & = 5 & \pi(7) & = 4
\end{align*}
%
Each packet must be routed through either the upper subnetwork or the
lower subnetwork.  Construct a graph with vertices 0, 1, \ldots, 7 and
draw a \textit{dashed} edge between each pair of packets that can not
go through the same subnetwork because a collision would occur in the
second column of switches.

\begin{solution}
\mfigure{!}{2in}{figures/rec-const1}

\end{solution}

\ppart Add a \textit{solid} edge in your graph between each pair of
packets that can not go through the same subnetwork because a
collision would occur in the next-to-last column of switches.

\begin{solution}
\mfigure{!}{2in}{figures/rec-const2}

\end{solution}

\ppart Color the vertices of your graph red and blue so that adjacent
vertices get different colors.  Why must this be possible, regardless
of the permutation $\pi$?

\begin{solution}
This must be possible, because edges in a cycle are
alternately dashed and solid.  Thus, every cycle has even length,
which implies that the graph is bipartite or, equivalently,
2-colorable.

\mfigure{!}{2in}{figures/rec-const3}

\end{solution}

\ppart Suppose that red vertices correspond to packets routed through
the upper subnetwork and blue vertices correspond to packets routed
through the lower subnetwork.  On the attached copy of the Bene\u{s}
network, highlight the first and last edge traversed by each packet.

\begin{solution}
\mfigure{!}{3in}{figures/rec-benes1}

\end{solution}

\ppart All that remains is to route packets through the upper and
lower subnetworks.  One way to do this is by applying the procedure
described above recursively on each subnetwork.  However, since the
remaining problems are small, see if you can complete all the paths 
on your own.

\begin{solution}
\mfigure{!}{3in}{figures/rec-benes2}

\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp3t}
  \pcomment{This problem could use a bit of ``text reduction.''}
  \pcomment{Jay: the proof of Schroeder-Bernstein must be preceeded by the 
            definition of ``as small as'' in CP_relational_properties_table.
            My intuition says this problem can be reworked in terms of 
            ``as big as'' to remove the dependence and neaten it up a bit.}
\end{pcomments}

\pkeywords{
  relations
  relational_properties
  mapping_lemma
  functions
  injections
  surjections
  bijections
  Schroeder_Bernstein
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Suppose sets $A$ and $B$ have no elements in common, and
\begin{itemize}

\item $A$ is as small as $B$ because there is a total injective function
$f:A \to B$, and

\item  $B$ is as small as $A$ because there is a total injective
function $g:B \to A$.
\end{itemize}

Picturing the diagrams for $f$ and $g$, there is \emph{exactly one} arrow
\emph{out} of each element ---a left-to-right $f$-arrow if the element in
$A$ and a right-to-left $g$-arrow if the element in $B$.  This is because
$f$ and $g$ are total functions.  Also, there is \emph{at most one} arrow
\emph{into} any element, because $f$ and $g$ are injections.

So starting at any element, there is a unique, and unending path of arrows
going forwards.  There is also a unique path of arrows going backwards,
which might be unending, or might end at an element that has no arrow into
it.  These paths are completely separate: if two ran into each other,
there would be two arrows into the element where they ran together.

This divides all the elements into separate paths of four kinds:
\renewcommand\theenumi {\roman{enumi}}
\begin{enumerate}

\item paths that are infinite in both directions,
\item paths that are infinite going forwards starting from some element of
  $A$.
\item paths that are infinite going forwards starting from some element of
  $B$.
\item\label{cycle}  paths that are unending but finite.
\end{enumerate}
\renewcommand\theenumi {enumi}

\bparts

\ppart What do the paths of the last type~\eqref{cycle} look like?

\begin{solution}

An even-length cycle of alternating $f$- and $g$-arrows.

\end{solution}

\ppart Show that for each type of path, either
\begin{itemize}

\item the $f$-arrows define a bijection between the $A$ and $B$ elements
  on the path, or 
\item the $g$-arrows define a bijection between $B$ and $A$ elements on
  the path, or

\item both sets of arrows define bijections.

\end{itemize}
For which kinds of paths do both sets of arrows define bijections?

\begin{solution}
 For paths that start at a point in $A$, there will be an
  $f$-arrow out of every point on the path, so the $f$-arrows will define
  a bijection from the $A$ elements to the $B$ elements on the path.  The
  $g$-arrows don't define a bijection the other way, because they don't
  hit the starting point.

For paths that start at a point in $B$, the $g$-arrows will define a bijection from
the $B$ elements to the $A$ elements, by the same reasoning.

For the other two types of path, every point $B$ element has exactly one
$f$-arrow coming in, so these arrows define a bijection from the $A$
elements to be $B$ elements.  Likewise, the $g$-arrows define a bijectin
the other way.

\end{solution}

\ppart Explain how to piece these bijections together to prove that $A$
and $B$ are the same size.
\begin{solution}

Define $h:A \to B$ by the rule:
\[
h(x) \eqdef
\begin{cases}
\inv{g}(a) & \text{if $a$'s path starts at a point in $B$},\\
f(a) &  \text{otherwise}.
\end{cases}
\]


\end{solution}

\eparts

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp7r}
  \pcomment{from: F06.cp5m}
  \pcomment{commented out in S09 - proofread before using}
  \pcomment{This problem could potentially be revised to use the
            positive path relation and strict partial orders instead
            or in addition to the path relation and weak POs.}
\end{pcomments}

\pkeywords{
  DAGs
  partial_orders
  transitive_closure
  digraphs
  relations
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Prove that if $R$ is the graph of a DAG, then the path relation, $R^*$, is
a weak partial order on the vertices.

\begin{solution}
\emph{reflexive}: Every vertex, $a$, is connected to itself by
a 0-length path, so $aR^*a$ holds for all $a$.

\emph{antisymmetric}: Suppose $a\neq b$ and $aR^*b$, that is, there is a
(necessarily positive length) path from $a$ to $b$.  If $bR^*a$ also held,
then there is also a path from $b$ to $a$, and the two paths would be a
cycle (though not necessarily a simple cycle).  Since the graph is
acyclic, we conclude that $\neg(bR^*a)$, which proves antisymmetry.

\emph{transitive}: $aR^*b$ means there is a path from $a$ to $b$, and
likewise, $bR^*c$ means there is a path from $b$ to $c$.  Then the first
path followed by the second would form a path from $a$ to $c$, proving
that $aR^*c$, which proves transitivity.
\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp5m}
%  \pcomment{}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  recursive_data
  structural_induction
  functions
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{problem}
%
The Elementary 18.01 Functions ($\EF$'s) are the set of functions of
one real variable defined recursively as follows:

\textbf{Base cases:}
\begin{itemize}
\item The identity function, $\ide(x) \eqdef x$ is an $\EF$,
\item any constant function is an $\EF$,
\item the sine function is an $\EF$,
\end{itemize}

\textbf{Constructor cases:}

If $f,g$ are $\EF$'s, then so are
\begin{enumerate}
\item $f + g$, $fg$, $e^g$ (the constant $e$),\label{+-}
\item the inverse function $f^{-1}$,\label{inversefunc}
\item the composition $f \compose g$.\label{cmp}
\end{enumerate}

\bparts

\ppart\label{1over} Prove that the function $1/x$ is an $\EF$.

\textbf{Warning:} Don't confuse $1/x = x^{-1}$ with the inverse,
$\ide^{-1}$ of the identity function $\ide(x)$.  The inverse
$\ide^{-1}$ is equal to $\ide$.

\begin{solution}
$\log x$ is the inverse of $e^x$ so $\log x \in \EF$.  Therefore
  so is $c\cdot \log x$ for any constant $c$, and hence $e^{c \log x} =
  x^c \in \EF$.  Now let $c = -1$ to get $x^{-1} = 1/x \in
  \EF$.\footnote{There's a little problem here: since $\log x$ is not
    real-valued for $x \leq 0$, the function $f(x) \eqdef 1/x$ constructed
    in this way is only defined for $x >0$.  To get an $\EF$ equal to
    $1/x$ defined for all $x \neq 0$, use $\paren{x/\abs{x}}\cdot
    f(\abs{x})$, where $\abs{x} = \sqrt{x^2}$.}
\end{solution}

\ppart Prove by Structural Induction on this definition that the
Elementary 18.01 Functions are \emph{closed under taking derivatives}.
That is, show that if $f(x)$ is an $\EF$, then so is $f^{\prime} \eqdef
df/dx$.  (Just work out 2 or 3 of the most interesting constructor cases;
you may skip the less interesting ones.)

\begin{solution}

\begin{proof}
By Structural Induction on def of $f \in \EF$.  The induction hypothesis
is the above statement to be shown.

\item[Base Cases:] We want to show that the derivatives of all the
  base case functions are in $\EF$.

  This is easy: for example, $d\, \ide(x)/dx = 1$ is a constant function,
  and so is in $\EF$. Similarly, $d\, \sin(x)/dx = \cos(x)$ which is
  also in $\EF$ since $\cos(x) = \sin(x+\pi/2) \in \EF$ by rules for
  constant functions, the identity function, sum, and composition with
  sine.

This proves that the induction hypothesis holds in the Base cases.

\item[Constructor Cases:] ($f^{-1}$).  Assume $f, df/dx \in \EF$ to prove
  $d\, f^{-1}(x)/dx \in \EF$.
Letting $y = f(x)$, so $x=f^{-1}(y)$, we know from Leibniz's rule in
calculus that
\begin{equation}\label{Leib}
df^{-1}(y)/dy = dx/dy = \frac{1}{dy/dx}.
\end{equation}
For example,
\[
d \sin^{-1}(y)/dy = 1/(d \sin(x)/dx) = 1/\cos(x) = 1/\cos(\sin^{-1}(y)).
\]
Stated as in ~(\ref{Leib}), this rule is easy to remember, but can easily
be misleading because of the variable switching between $x$ and $y$.  It's
more clearly stated using variable-free notation:
\begin{equation}\label{Leib2}
(f^{-1})' = (1/f') \compose f^{-1}.
\end{equation}
Now, since $f' \in \EF$ (by assumption), so is $1/f'$ (by
part~\eqref{1over}) and $f^{-1}$ (by constructor rule~\ref{inversefunc}.),
and therefore so is their composition (by rule~\ref{cmp}).  Hence the
righthand side of equation~(\ref{Leib2}) defines a function in $\EF$.

\item[Constructor Case:] ($f \compose g$).  Assume $f, g, df/dx, dg/dx \in \EF$
to prove $d(f \compose g)(x)/dx \in \EF$.

The Chain Rule states that
\[
\frac{d(f(g(x)))}{dx} = \frac{d f(g)}{dg}\cdot\frac{dg}{dx}.
\]
Stated more clearly in variable-free notation, this is
\[
(f \compose g)' = (f' \compose g) \cdot g'.
\]
The righthand side of this equation defines a function in $\EF$ by
constructor rules~\ref{cmp}.\ and~\ref{+-}.

The other Constructor cases are similar, so we conclude that the induction
hypothesis holds in all Constructor cases.

This completes the proof by structural induction that the statement holds
for all $f \in \EF$.
\end{proof}

\end{solution}
\eparts
\end{problem}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp6m}
  \pcomment{from: S06.cp5w}
\end{pcomments}

\pkeywords{
  handshaking
  degree
  graphs
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}

\bparts

\ppart Prove that in every graph, there are an even number of vertices of
odd degree.

\hint The Handshaking Theorem.

\begin{solution}
\begin{proof}
Partitioning the vertices into those of even degree and those of odd
degree, we know
\[
{\sum_{v \in V} d(v)}\ =
\sum_{d(v) \mbox{ {\scriptsize is even}}} d(v)\ +\
\sum_{d(v) \mbox{ {\scriptsize is odd}}} d(v)
\]
By the Handshaking Theorem, the value of the lefthand side of this
equation equals twice the number of edges, and so is even.  The first
summand on the righthand side is even since it is a sum of even
values.  So the second summand on the righthand side must also be even.
But since it is entirely a sum of odd values, it must must contain an even
number of terms.  That is, there must be an even number of vertices with
odd degree.
\end{proof}
\end{solution}

\ppart\label{oddnumeven} Conclude that at a party where some people shake
hands, the number of people who shake hands an odd number of times is an
even number.

\begin{solution}
We can represent the people at the party by the vertices of a
graph.  If two people shake hands, then there is an edge between the
corresponding vertices.  So the degree of a vertex is the number of
handshakes the corresponding person performed.  The result in the first
part of this problem now implies that there are an even number of
odd-degree vertices, which translates into an even number of people who
shook an odd number of hands.
\end{solution}

\ppart Call a sequence of two or more different people at the party a
\emph{handshake sequence} if, except for the last person, each person in
the sequence has shaken hands with the next person in the sequence.

Suppose George was at the party and has shaken hands with an odd number of
people.  Explain why, starting with George, there must be a handshake
sequence ending with a different person who has shaken an odd number of
hands.

\hint Just look at the people at the ends of handshake sequences that
start with George.

\begin{solution}
The handshake graph between just the people at the ends of
  handshake sequences that start with George is a graph, so by
  part~\eqref{oddnumeven}, it must have an even number of people who shake
  an odd number of hands.  In particular, there must be at least one other
  person besides George, call him Harry, who has also shaken an odd number
  of hands.  So the handshake sequence from George that ends with Harry is
  what we were looking for.
\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp7m}
\end{pcomments}

\pkeywords{
  planar_graphs
  Eulers_formula
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}

\bparts

\ppart Show that if a connected planar graph with more than two vertices
is bipartite, then
\begin{equation}\label{2v}
e \leq 2v -4.
\end{equation}

\hint Similar to the proof that $e \leq 3v-6$\inhandout{ (see the Appendix)}.  
Use Problem~\ref{structind}.

\begin{solution}
By Problem~\ref{structind}.\ref{structind-face-length}, every
face is of length at least 3.  But all cycles in a bipartite graph are of
even length, and so every face of an embedding must be of length at least
4.

Each edge is traversed by exactly two faces, so
\begin{equation}\label{4f}
2e = \sum_{f \in\text{ faces}} \text{length}(f) \geq
\sum_{f \in\text{ faces}} 4 = 4f.
\end{equation}
By Euler's formula, $f = e-v+2$, so
substituting for $f$ in~\eqref{4f}, yields
\[
2e \geq 4(e-v+2),
\]
which simplifies to~\eqref{2v}.

\end{solution}

\ppart Conclude that that $K_{3,3}$ is not planar.  ($K_{3,3}$ is the
graph with six vertices and an edge from each of the first three vertices
to each of the last three.)

\begin{solution}
$K_{3,3}$ is bipartite and connected. Also, it has 9 edges and 6
vertices, and since $9 > 8 = 2 \cdot 6 - 4$, it does not
satisfy~\eqref{2v}, and so cannot be planar.
\end{solution}

\eparts

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp6t}
\end{pcomments}

\pkeywords{
  connectivity
  graphs
  complete_graphs
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Prove that $K_n$ is $(n-1)$-edge connected for $n > 1$.

\begin{solution}
\begin{proof}
  Consider any two distinct vertices $u$ and $v$ in $K_n$.  For each of the
  other $n-2$ vertices in $K_n$, there is a length 2 path from $u$ to $v$
  via that vertex.  This gives us a total of $n-1$ edge disjoint paths
  between $u$ and $v$, namely the the $n-2$ length 2 paths above and the
  length 1 path directly from $u$ to $v$.  This implies it takes at least
  $n-1$ edge deletions to disconnect any 2 vertices, meaning that $K_n$ is
  $(n-1)$-edge connected.
\end{proof}
\end{solution}

\bparts

\ppart Let $M_n$ be a graph defined as follows: begin by taking $n$ graphs
with non-overlapping sets of vertices, where each of the $n$ graphs is
$(n-1)$-edge connected (they could be disjoint copies of $K_n$, for
example).  These will be subgraphs of $M_n$.  Then pick $n$ vertices, one
from each subgraph, and enough edges between pairs of picked vertices that
the subgraph of the $n$ picked vertices and the edges between them is also
$(n-1)$-edge connected.

Explain why $M_n$ is $(n-1)$-edge connected.

\begin{solution}
Remove $(n-2)$ edges from $M_n$ to obtain a subgraph, $G$, of
$M_n$ with the same vertices.

Since each of the $n$ subgraphs are $(n-1)$-edge connected, the vertices
within each copy will remain connected in $G$.  Hence, if all the picked
vertices still are connected in $G$, then $G$ will be connected.  But the
subgraph of picked vertices is also $(n-1)$-edge connected, so will still
be connected after removal of $(n-2)$ edges.  So $M_n$ remains connected
after removal of $n-2$ edges, and hence is indeed $(n-1)$-edge connected.
\end{solution}

\eparts

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp6t}
  \pcomment{commented out in S09 so check/revise before using}
\end{pcomments}

\pkeywords{
  trees
  spanning_trees
  state_machines
  graphs
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Procedure $Mark$ starts with a connected, simple graph with all edges
unmarked and then marks some edges.  At any point in the procedure a path
that traverses only marked edges is called a \emph{fully marked} path, and
an edge that has no fully marked path between its endpoints is called
\emph{eligible}.

Procedure $Mark$ simply keeps marking eligible edges, and terminates when
there are none.

Prove that $Mark$ terminates, and that when it does, the set of marked
edges forms a spanning tree of the original graph.

\begin{solution}
As a state machine, the start state of $Mark$ is some given
connected graph, $G$.  The rest of the states are copies of $G$ with some
edges marked.

$Mark$ terminates because the number of unmarked edges decreases by one at
each transition, so this number is a strictly decreasing nonnegative
integer-valued variable, which we know implies termination.  (A common
mistake in arguing termination of $Mark$ was to instead say that the number
of eligible edges was strictly decreasing, without any additional
reasoning.  This is true, but can't be taken for granted: you have to
explain why removing an eligible edge does not result in new edges becoming
eligible.)

To prove partial correctness, we show if $Mark$ terminates, the marked
edges of the final state form a spanning tree of $G$.  So we must show
that the marked edges form an acyclic connected graph with the same set of
vertices as $G$.

To do this we verify the invariant:
\begin{quote}
The marked edges form an acyclic graph.  (*)
\end{quote}

To verify~(*) is an invariant, consider a step $H\to H'$, where $H$
satisfies~(*).  This means that $H$ has no fully marked cycles, and $H'$
is the same as $H$ with an edge, $e$, that was one eligible in $H$, now
marked in $H'$.  But in $H'$, the only fully marked path between the
endpoints of $e$ must be the edge $e$ itself, by definition of
``eligible.''  So $e$ is not on a fully marked simple cycle in $H'$.
Since $H$ and $H'$ are otherwise the same, there is no fully marked simple
cycle elsewhere in $H'$.  That is, $H'$ satisfies~(*).

Since the start state $G$ has no marked edges, it satisfies~(*) trivially.
Hence, by the Invariant Principle, any final state of $Mark$
satisfies~(*).

We also claim that in any final state, there is a fully marked path
between any two vertices.  To prove this assume to the contrary that there
were two vertices, $u$ and $v$, with no fully marked path between them.
Since there is a path in $G$ between $u$ and $v$, there must be a path
between $u$ and $v$ traversing the smallest number of unmarked edges, and
this path must contain at least one unmarked edge, $e$.  Now if there was
a fully marked path between the endpoints of $e$, we could replace $e$ by
this path to obtain a path between $u$ and $v$ with fewer unmarked edges.
So there can't be a fully marked path between the endpoints of $e$, which
means that $e$ is eligible, contradicting the fact the state was final.

So in any final state, the marked edges determine an acyclic, connected
graph on the vertices of $G$.  That is, the marked edges determine a
spanning tree of $G$.

\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09}
  \pcomment{ARM renamed something else PorQorR by accident, 9/11/09 5:25PM}
\end{pcomments}

\pkeywords{
Proposition
equivalence
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problems start here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{problem}
Prove that the propositional formulas
\[
P \QOR Q \QOR R
\]
and
\[
(P \QAND \QNOT Q) \QOR (Q \QAND \QNOT R) \QOR (R \QAND \QNOT P) \QOR (P \QAND Q \QAND R).
\]
are equivalent.

\begin{solution}
  We compare $P \QOR Q \QOR R$ and $K = (P \QAND \QNOT(Q)) \QOR (Q \QAND
  \QNOT R) \QOR (R \QAND \neg P) \QOR (P \QAND Q \QAND R)$ using a truth
  table:

\begin{center}
\begin{tabular}{ c c c | c | c c c c | c }
  $P$ & $Q$ & $R$ & $P  \vee  Q  \vee  R$ & $P  \wedge  \neg Q & Q  \wedge  \neg R &  R  \wedge  \neg P & P  \wedge  Q  \wedge  R & K$\\
  \hline
  T & T & T & \textbf{T} & F & F & F & T & \textbf{T} \\
  T & T & F & \textbf{T} & F & T & F & F & \textbf{T} \\
  T & F & T & \textbf{T} & T & F & F & F & \textbf{T} \\
  T & F & F & \textbf{T} & T & F & F & F & \textbf{T} \\
  F & T & T & \textbf{T} & F & F & T & F & \textbf{T} \\
  F & T & F & \textbf{T} & F & T & F & F & \textbf{T} \\
  F & F & T & \textbf{T} & F & F & T & F & \textbf{T} \\
  F & F & F & \textbf{F} & F & F & F & F & \textbf{F} \\
\end{tabular}
\end{center}

Both $P  \vee  Q  \vee  R$ and K have identical truth tables, thus the two statements are equivalent.

\end{solution}
\end{problem}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problems end here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp8r, S06.cp7w}
%  \pcomment{}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  number_theory
  modular_arithmetic
  primes
  RSA
  Pulverizer
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Let's try out RSA!  There is a complete description of the algorithm at
the bottom of the page.  You'll probably need extra paper.  \textbf{Check
your work carefully!}

\bparts

\ppart As a team, go through the \textbf{beforehand} steps.

\begin{itemize}

\item Choose primes $p$ and $q$ to be relatively small, say in the
range 10-40.  In practice, $p$ and $q$ might contain several hundred
digits, but small numbers are easier to handle with pencil and paper.

\item Try $e = 3, 5, 7, \ldots$ until you find something that works.
Use Euclid's algorithm to compute the gcd.

\item Find $d$ (using the Pulverizer ---see appendix for a reminder on how
the Pulverizer works ---or Euler's Theorem).

\end{itemize}

When you're done, put your public key on the board.  This lets another
team send you a message.

\ppart Now send an encrypted message to another team using their
public key.  Select your message $m$ from the codebook below:

\begin{itemize}

\item 2 = Greetings and salutations!

\item 3 = Yo, wassup?

\item 4 = You guys are slow!

\item 5 = All your base are belong to us.

\item 6 = Someone on {\em our} team thinks someone on {\em your} team
is kinda cute.

\item 7 = You {\em are} the weakest link.  Goodbye.

\end{itemize}

\ppart Decrypt the message sent to you and verify that you received
what the other team sent!

\eparts

\TBA{Should the algorithm appear here or somewhere else?}

\begin{center}
RSA Public Key Encryption
\fbox{
\begin{minipage}[t]{6in}
\vspace{0.1cm}
\begin{description}

\item[Beforehand] The receiver creates a public key and a secret key
as follows.

\begin{enumerate}

\item Generate two distinct primes, $p$ and $q$.

\item Let $n = pq$.

\item Select an integer $e$ such that $\gcd(e, (p-1)(q-1)) = 1$.\\ The
{\em public key} is the pair $(e, n)$.  This should be distributed
widely.

\item Compute $d$ such that $de \equiv 1 \pmod{(p-1)(q-1)}$.\\ The
{\em secret key} is the pair $(d, n)$.  This should be kept hidden!

\end{enumerate}

\item[Encoding] The sender encrypts message $m$, where $0 \leq m < n$, to
  produce $m^\prime$ using the public key:
\[
m' = \rem{m^e}{n}.
\]

\item[Decoding] The receiver decrypts message $m'$ back to message $m$
using the secret key:
\[
m = \rem{(m')^d}{n}.
\]

\end{description}

\vspace{0.1cm}
\end{minipage}
}
\end{center}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp8r}
%  \pcomment{}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  number_theory
  modular_arithmetic
  primes
  RSA
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
  A critical question is whether decrypting an encrypted message always
  gives back the original message!  That is, whether $\rem{(m^{d})^e}{pq}
  =m$.  This will follow from something slightly more general:
\begin{lemma}\label{npdp}
Let $n$ be a product of distinct primes and $a \equiv 1 \pmod {\phi(n)}$
for some nonnegative integer, $a$.  Then
\begin{equation}\label{ma}
m^a \equiv m \pmod n.
\end{equation}
\end{lemma}

\bparts


\ppart Explain why Lemma~\ref{npdp} implies that $k$ and $k^5$ have the
same last digit.  For example:
%
\[
\underline{2}^5 = 3\underline{2}
\hspace{1in}
7\underline{9}^5 = 307705639\underline{9}
\]
\hint What is $\phi(10)$?

\begin{solution}
Two nonnegative integers have the same last digit iff they are
$\equiv \pmod {10}$.  Now $\phi(10) = \phi(2)\phi(5) = 4$ and $5 \equiv 1 \pmod 4$,
so by Lemma~\ref{npdp},
\[
k^5 \equiv k \pmod {10}.
\]
\end{solution}

\ppart Explain why Lemma~\ref{npdp} implies that the original message,
$m$, equals $\rem{(m^e)^d}{pq}$.

\begin{solution}
 To apply Lemma~\ref{npdp} to RSA, note that the first condition
  of the Lemma is that $n$ be a product of primes.  In RSA, $n=pq$ so this
  condition holds.

  For $n=pq$, the Euler function equations (see the
  Appendix) imply that $\phi(n) = (p-1)(q-1)$.  So when $d$ and $e$ are
  chosen according to RSA, $de \equiv 1 \pmod {\phi(n)}$.  So $a \eqdef
  de$ satisfies the second condition of the Lemma.

  Now, from equation~\eqref{ma} with $n=pq$ and $a=de$, we have
\[
(m^e)^d = m^{de} \equiv m \pmod {pq}.
\]
Hence,
\[
\rem{(m^e)^d}{pq} = \rem{m}{pq},
\]
but $\rem{m}{pq} = m$, since $0\leq m<pq$.
\end{solution}

\eparts

\bparts

\ppart\label{pma} Prove that if $p$ is prime, then
\begin{equation}\label{mp}
m^a \equiv m \pmod{p}
\end{equation}
for all nonnegative integers $a \equiv 1 \pmod {p-1}$.

\begin{solution}

If $p \divides m$, then equation~\eqref{mp} holds since both sides of the
congruence are $\equiv 0 \pmod p$.

So assume $p$ does not divide $m$.  Now if $a \equiv 1 \pmod {p-1}$,
then $a = 1 + (p-1)k$ for some $k$, so
\begin{align*}
m^a & = m^{1+ (p-1)k}\\
    & = m\cdot \paren{m^{p-1}}^k\\
    & \equiv m\cdot \paren{1}^k \pmod p
            & \text{(by Fermat's Little Thm.)}\\
    & \equiv m \pmod p.
\end{align*}
\end{solution}

\iffalse

\ppart\label{abk} Show that for any positive integers $j,k$,
if $a \equiv b \pmod k$ and $j \divides k$, then $a \equiv b \pmod j$

\begin{solution}

$a \equiv b \pmod k$ iff $k \divides (a-b)$.  But if $k \divides (a-b)$
and $j \divides k$, then also $j \divides (a-b)$, which implies $a \equiv
b \pmod j$.

\end{solution}
\fi

\ppart\label{abp}
Prove that if $n$ is a product of distinct primes, and $a \equiv b
\pmod p$ for all prime factors, $p$, of $n$, then $a \equiv b
\pmod n$.

\begin{solution}
 By definition of congruence, $a \equiv b \pmod k$ iff $k
\divides (a-b)$.  So if $a \equiv b \pmod p$ for each prime factor, $p$,
of $n$, then $p \divides (a-b)$ for each prime factor, $p$, and hence, so
does their product (by the Unique Factorization Theorem).  That is, $n
\divides (a-b)$, which means $a \equiv b \pmod n$.
\end{solution}

\iffalse

\ppart\label{phip} Verify that for any $n>1$ and any prime divisor, $p$,
of $n$,
\[
\phi(p) \divides \phi(n).
\]

\begin{solution}
Let $p$ be a prime factor of $n$ and factor $n$ as $m\cdot p^k$
where $p$ does not divide $m$.  By the Euler function equations,
$\phi(n)=\phi(m)\phi(p^k)$, so $\phi(p^k) \divides \phi(n)$.  But
$\phi(p) = (p-1)$ which divides $(p-1)p^{k-1} = \phi(p^k)$.
\end{solution}
\fi


\ppart Combine the previous parts to complete the proof of
Lemma~\ref{npdp}.  \begin{solution}
Suppose $n$ is a product of distinct primes,
  $p_1p_2\cdots p_k$.  Then from the formulas for the Euler function,
  $\phi$, we have
\[
\phi(n) = (p_1 -1)(p_2 -1)\cdots (p_k-1).
\]

Now suppose $a \equiv 1 \pmod {\phi(n)}$, that is, $a$ is 1 plus a
multiple of $\phi(n)$, so it is also 1 plus a multiple of $p_i-1$.  That
is,
\[
a \equiv 1 \pmod {p_i-1}.
\]
Hence, by part~\eqref{pma},
\[
m^a \equiv m \pmod{p_i}
\]
for all $m$.  Since this holds for all factors, $p_i$, of $n$, we conclude
from part~\eqref{abp} that
\[
m^a \equiv m \pmod{n},
\]
which proves Lemma~\ref{npdp}.
\end{solution}

\eparts

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps1}
  \pcomment{from: S07.ps1}
  \pcomment{from: F05.ps1}
  \pcomment{commented out in S09}
  \pcomment{class problem only: done in the notes --- better...}
\end{pcomments}

\pkeywords{
  set_theory
  Russells_paradox
  bijections
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}  %revised from fall 05 ps1:

If a set, $A$, is finite, then $\card{A} < 2^{\card{A}} =
\card{\power(A)}$, and so there is no bijection from $\power(A)$ to $A$.
Show that this is still true if $A$ is infinite.  \hint Remember Russell's
paradox and consider
\[
\set{f(B) \in A \suchthat B \subseteq A\text{ and }f(B) \notin B}
 \]
where $f$ is such a bijection.

\begin{solution}
We prove there is no bijection by contradiction: suppose there
was a bijection $f: \power(A) \to A$ for some set $A$.  Because $f$ is a
bijection, for any element $a \in A$ there is a unique subset $B_a
\subseteq A$ such that $f(B_a) =a$.  So consider the set 
\[
W \eqdef \set{a \in A \suchthat a \notin B_a} .
\]  
By the definition of this set, we know that for all $a \in A$:
\begin{equation}\label{xw}
(a \in W) \iff (a \notin B_a) .
\end{equation}
But $W \subseteq A$ (by the definition of $W$), and hence $W$ is a member
of $\power(A)$.  So $f(W) \in A$ and $W=B_{f(W)}$.  So we have
from~\eqref{xw}, that
\begin{equation}\label{xf}
(a \in B_{f(W)}) \iff (a \notin B_a)
\end{equation}
for all $a \in A$.  Substituting $f(W)$ for $a$ in~\eqref{xf} yields a
contradiction, proving that there cannot be such an $f$.
\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp8t, F04.ps3}
  \pcomment{commented out in S09 - proofread before using}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  modular_arithmetic
  number_theory
  series
  primes
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%F04 ps3

\begin{problem}
Let $S_k = 1^k + 2^k + \ldots + (p-1)^k$, where $p$ is an odd prime
and $k$ is a positive multiple of $p - 1$.  Use Fermat's theorem to
prove that $S_k \equiv -1 \pmod{p}$.

\begin{solution}
Fermat's theorem says that $x^{p-1} \equiv 1 \pmod{p}$
when $1 \leq x \leq p - 1$.  Since $k$ is a multiple of $p-1$,
raising each side to a suitable power proves that $x^k \equiv 1
\pmod{p}$.  Thus:
%
\begin{align*}
1^k + 2^k + \ldots + (p-1)^k
    & \equiv \underbrace{1 + 1 + \ldots + 1}_{\text{$p-1$ terms}} \pmod{p} \\
    & \equiv p - 1 \pmod{p} \\
    & \equiv - 1 \pmod{p}
\end{align*}

\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp9t}
  \pcomment{from: F03.ps6}
\end{pcomments}

\pkeywords{
  asymptotics
  Stirlings_formula
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
\bparts

\ppart Give an elementary proof (without appealing to Stirling's formula)
that $\log (n!) = \Theta(n\log n)$.

\begin{solution}
An elementary proof goes as follows:

First,
\begin{align*}
\log (n!) &= \sum_{i=1}^n \log i\\
&< \sum_{i=1}^n \log n\\
&=n\log n. 
\end{align*}

On the other hand, 
\begin{align*}
\log (n!) &= \sum_{i=1}^n \log i\\
 & > \sum_{i=\ceil{(n+1)/2}}^n \log i\\
    & > \sum_{i=\ceil{(n+1)/2}}^n \log (n/2)\\
    & > \frac{n}{2} \cdot \log (n/2)\\
    & = \frac{n ((\log n) -1)}{2}\\
    & = \frac{n \log n}{2} - \frac{n}{2}\\
    & > \frac{n \log n}{2} -\frac{n \log n}{6} & \text{for $n>8$.}\\
    & = \frac{1}{3} \cdot n \log n.
\end{align*}

Therefore, $(1/3)n \log n < \log(n!) <n\log n$ for $n>8$, proving that
$\log(n!)=\Theta(n\log n)$.
\end{solution}

\ppart Use Stirling's formula to prove that in fact
\[
\log (n!) \sim n \log n
\]
\hint $f \sim g$ for $f,g \geq 1$ implies $\log f \sim \log g$.

\begin{solution}
Taking logs of both sides of Stirling's formula and using the hint, we
  have
\begin{align*}
\log (n!)
& \sim n \log\paren{\frac{n}{e}} + \log \sqrt{2 \pi n}\\
& = n \log n - n \log e + \log \sqrt{2 \pi n}\\
& \sim n \log n.
\end{align*}

The final step follows from the fact that
\begin{align*}
\lim_{n \to \infty} \frac{n \log n - n \log e + \log \sqrt{2 \pi n}}{n \log n} & =
\lim_{n \to \infty} \paren{\frac{n \log n}{n \log n} - \frac{n \log e}{n \log n}
+ \frac{\log \sqrt{2 \pi n}}{n \log n}}\\
& = 1 - \lim_{n \to \infty} \frac{\log e}{\log n} + \lim_{n \to \infty}
\frac{\log \sqrt{2 \pi n}}{n \log n}\\
& = 1 - 0 - 0 = 1.
\end{align*}

\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp2t}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  quantifiers
  predicate_calculus
  translating_english_statements
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem} 
When the Poet says ``There is a season for every purpose under heaven.''
Which of the following does he mean:
\begin{equation}\label{EA}
\exists s \in {\text{Season}}\,\forall p \in \text{Purpose}.\ s \text{ is
for }p
\end{equation}
or
\begin{equation}\label{AE}
\forall p \in \text{Purpose}\,\exists s \in \text{Season}.\
s \text{ is for }p
\end{equation}
Briefly explain.

\begin{solution}
 This poetic statement is meant to offer solace: this may be a
  bad season for you now, but be hopeful, a season that suits your purpose
  will come.  So the appropriate translation would be formula~\eqref{AE},
  namely that given your Purpose, you can find a season that's good for
  it.  For example, if your purpose is planting, take heart: even though
  it's Winter now, Spring is coming.

Formula~\eqref{EA} says you can find a single season, say Spring, that's
good for every possible Purpose like skiiing, leaf watching, \dots.  This
is false, so it's clearly not what the Poet meant.  But even though he
really meant~\eqref{AE}, he used his poetic license to express~\eqref{AE}
in a way that mechanically would translate into~\eqref{EA}.

Note that a similar statement, ``There is a man for all seasons,'' is
famously used to describe one extraordinarily versatile man, Sir Thomas
More.  So this statement would actually best be translated as
\[
\exists x \in\, \text{men}\; \forall s \in\, \text{seasons}.\
x\ \text{is (good) for}\ s
\]

\end{solution}
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
%CP_assertions_about_binary_strings

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp2t}
  \pcomment{There are a few parts commented out that could use review to
            decide whether to include or cut them.}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  translating_english_statements
  binary strings
  logic
  quantifiers
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
The goal of this problem is to translate some assertions about binary
strings into logic notation.  The domain of discourse is the set of all
finite-length binary strings: $\lambda$, 0, 1, 00, 01, 10, 11, 000, 001,
\ldots.  (Here $\lambda$ denotes the empty string.)  In your translations,
you may use all the ordinary logic symbols (including \texttt{=}),
variables, and the binary symbols \texttt{0}, \texttt{1} denoting 0, 1.

A string like $\mathtt{01}x\mathtt{0}y$ of binary symbols and variables
denotes the \emph{concatenation} of the symbols and the binary strings
represented by the variables.  For example, if the value of $x$ is
\texttt{011} and the value of $y$ is \texttt{1111}, then the value of
$\mathtt{01}x\mathtt{0}y$ is the binary string \texttt{0101101111}.

Here are some examples of formulas and their English translations.  Names
for these predicates are listed in the third column so that you can reuse
them in your solutions (as we do in the definition of the predicate
{\sc no-1s} below).

\begin{center}
\begin{tabular}{lclcl}
Meaning & \hspace{0.25in} & Formula & \hspace{0.25in} & Name \\ \hline
$x$ is a prefix of $y$ & & $\exists z\ (xz = y)$ & & \sc{prefix}($x, y$) \\
$x$ is a substring of $y$ & & $\exists u \exists v\ (uxv = y)$ & & \sc{substring}($x, y$) \\
$x$ is empty or a string of 0's & & $\neg \text{\sc{substring}}(\mathtt{1},x)$
 & & \sc{no-1s}($x$)
\end{tabular}
\end{center}

\bparts

\ppart $x$ consists of three copies of some string.

\begin{solution}

$\exists y\ (x = yyy)$

\end{solution}

\ppart $x$ is an even-length string of 0's.

\begin{solution}

$\text{\sc{no-1s}}(x) \conj \exists y\ (x = yy)$

\end{solution}

\ppart $x$ does not contain both a 0 and a 1.

\begin{solution}

$\QNOT [\text{\sc{substring}}(\mathtt{0}, x) \QAND \text{\sc{substring}}(\mathtt{1}, x)]$

\iffalse
Another solution is
\[
\text{\sc{no-1s}}(x) \disj \text{\sc{no-0s}}(x).
\]
\fi

\end{solution}

\ppart $x$ is the binary representation of $2^k + 1$ for some
integer $k \geq 0$.

\begin{solution}
 $(x = \mathtt{10}) \QOR (\exists y\ (x = \mathtt{1}y\mathtt{1}
\QAND \text{\sc{no-1s}}(y)))$ 
\end{solution}


\ppart An elegant, slightly trickier way to define $\text{\sc{no-1s}}(x)$
is:
\begin{equation}\tag{*}
\text{\sc{prefix}}(x, \mathtt{0}x).
\end{equation}
Explain why~(*) is true only when $x$ is a string of 0's.

\iffalse
Explain why can't we define ``$x$ is an even-length string of 0's,'' by
\begin{equation}\tag{**}
\text{\sc{prefix}}(x, \mathtt{00}x).
\end{equation}
\fi

\begin{solution}
Prefixing $x$ with 0 rightshifts all the bits.  So the $n$th
symbol of $x$ shifts into the $(n+1)$st symbol of $0x$.  Now for $x$ to be
a prefix of $0x$, the $n+1$st symbol of $0x$ must match the $(n+1)$st
symbol of $x$.  So if $x$ satisfies~(*), the $n$th and $(n+1)$st symbols
of $x$ must match.  This holds for all $n>0$ up to the length of $x$, that
is, \emph{all} the symbols of $x$ must be the same.  In addition, if
$x\neq \lambda$, it must start with 0.  Therefore, if $x$ satisfies~(*),
all its symbols must be 0's.

Note that it's easy to see, conversely, that if $x = \lambda$ or $x$ is
all 0's, then of course it satisfies~(*).
\end{solution}

\eparts

\end{problem}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp9m}
\end{pcomments}

\pkeywords{
  asymptotics
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
  Let $f$, $g$ be real-valued functions such that $\lim_{x \to \infty}
  f(x) = \infty$ and $f \sim g$.

\bparts

\ppart Give an example of $f,g$ such that $2^f \not\sim 2^g$.

\begin{solution}
\begin{align*}
f(n) & \eqdef n+1\\
g(n) & \eqdef n.
\end{align*}

Then $f \sim g$ since $\lim (n+1)/n = 1$, but $2^f= 2^{n+1} = 2\cdot 2^n =
2\cdot 2^g$ so
\[
\lim \frac{2^f}{2^g} = 2 \neq 1.
\]

\end{solution}

\ppart Prove that $\log f \sim \log g$.

\begin{solution}
\begin{align*}
\lim \frac{\log f}{\log g}
& = \lim \frac{(\log f)'}{(\log g)'} 
       & \text{(L'Hospital's rule)}\\
& = \lim \frac{1/f}{1/g} \\
& =  \lim \frac{1}{f/g} \\
& =  \frac{1}{\lim (f/g)} \\
& = 1/1 = 1.
\end{align*}

\iffalse
\begin{align*}
\lim \frac{f}{g} & = 1\\
\log \lim \frac{f}{g} & = \log 1\\
\lim \log\paren{\frac{f}{g}} & = 0\\
\lim \paren{\log f - \log g} & = 0\\
TBA
\end{align*}\fi


\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%CP_axiom_of_choice_formula

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{9/23/09 by ARM, from logic notesproblem}
\end{pcomments}

\pkeywords{
 Choice
 Set Theory
 ZFC
 member
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{problem} 
  The Axiom of Choice can say that if $s$ is a set whose members are
  nonempty sets, no two of which have any element in common, then there is
  a set, $c$, consisting of exactly one element from each set in $s$.

 In formal logic, we could describe $s$ with the formula,
\[
\text{pairwise-disjoint}(s) \eqdef\quad
\forall x,y \in s.\, x \neq \emptyset \QAND x \intersect y = \emptyset.
\]
Similarly we could describe $c$ with the formula
\[
\text{choice-set}(c,s) \eqdef \quad \forall x \in s.\, \exists! z.\ z \in c
\intersect x.
\]
Here ``$\exists! z.$" is fairly standard notation for ``there exists a
\emph{unique} $z$.

Now we can give the formal definition:
\begin{definition*}[Axiom of Choice]
\[
\forall s.\, \text{pairwise-disjoint}(s) \QIMPLIES \exists c.\,
\text{choice-set}(c,s).
\]
\end{definition*}

The only issue here is that Set Theory is technically supposed to be
expressed in terms of \emph{pure} formulas in the language of sets, which
means formula that uses only the membership relation, $\in$, propositional
connectives, and the two quantifies $\forall$ and $\exists$.  Verify that
the Axiom of Choice can be expressed as a pure formula, by explaining how
to replace all impure subformulas above with equivalent pure formulas.

For example, the formula $x = y$ could be replaced with the pure formula
$\forall z.\, z \in x \QIFF z \in y$.

\begin{solution}
\[
x \neq \emptyset \to \exists y/\, y \in x.
\]

\[
[x \intersect y = \emptyset] \to \QNOT(\exists z.\, z \in x \QAND z \in y).
\]

\[
[z \in x \intersect y] \to z \in x \QAND z \in y.
\]

\[
\exists! z.\, P(z) \to  \exists z.\, P(z) \QAND \forall w.\, P(w)
\QIMPLIES w = z.
\]
This last formula is not pure because it uses $=$, but this is ok since we
know it can be replaced by a pure formula.

\end{solution}
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
%PS_basic_partial_orders

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps3}
\end{pcomments}

\pkeywords{
  relations
  relational_properties
  partial_orders
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
For each of the binary relations below, state whether it is a strict
partial order, a weak partial order, or neither.  If it is not a partial
order, indicate which of the axioms for partial order it violates.

\iffalse
If it is a partial order, state whether or not it is a total order and
identify its maximal and minimal elements, if any.
\fi

\bparts \ppart The superset relation, $\supseteq$ on the power set
$\power{\set{1, 2, 3, 4, 5}}$.

\begin{solution}
This is a weak partial order, but not a total one.  For example, 
the sets of size 3 form an antichain.
\end{solution}

\ppart The relation between any two nonegative integers, $a$, $b$ that the
remainder of $a$ divided by 8 equals the remainder of $b$ divided by 8.

\begin{solution}
Violates antisymmetry: $8 \mrel{R} 16$ and $16 \mrel{R} 8$ but $8$ does
not equal $16$.  It is transitive, though.

\end{solution}

\ppart The relation between propositional formulas, $G$, $H$, that $G
\QIMPLIES H$ is valid.

\begin{solution}
  Violates antisymmetry: $P$ and $\QNOT(\QNOT(P))$ imply each other but
  are different expressions.  It is transitive, though.  \iffalse
  This does define a p.o. between
  equivalence classes, if we consider the set of all statements that are
  logically equivalent instead of the individual statements.\fi
\end{solution}

\ppart The relation 'beats' on Rock, Paper and Scissor (for those who don't
know the game Rock, Paper, Scissors, Rock beats Scissors, Scissors beats
Paper and Paper beats Rock).

\begin{solution}
Violates transitivity: obviously.
\end{solution}

\ppart The empty (no ``arrows'') relation, on the set of real numbers.
\begin{solution}
  It's vacuously asymmetric and transitive, so it's a strict partial
  order.  It's not reflexive because elements don't have self-looping
  arrows.
\end{solution}

\eparts

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
%CP_beaver_flu

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp5r}
  \pcomment{from: F06.ps2}
  \pcomment{revised S09 by ARM}
\end{pcomments}

\pkeywords{
  state_machines
  unreachable_states
  increasing_decreasing_variables
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
  In some terms when 6.042 is not taught in a TEAL room, students sit in a
  square arrangement during recitations.  An outbreak of beaver flu
  sometimes infects students in recitation; beaver flu is a rare variant
  of bird flu that lasts forever, with symptoms including a yearning for
  more quizzes and the thrill of late night problem set sessions.

  Here is an example of a $6 \times 6$ recitation arrangement with the
  locations of infected students marked with an asterisk.

\[
\begin{array}{|c|c|c|c|c|c|}
\hline
\ast& & & &\ast& \\ \hline
 &\ast& & & & \\ \hline
& &\ast&\ast& & \\ \hline
& & & & & \\ \hline
& &\ast& & & \\ \hline
& & &\ast& &\ast \\ \hline
\end{array}
\]

Outbreaks of infection spread rapidly step by step.  A student is infected
after a step if either

\begin{itemize}
\item the student was infected at the previous step (since beaver flu
  lasts forever), or

\item the student was adjacent to \textit{at least two} already-infected
  students at the previous step.

\end{itemize}
Here \textit{adjacent} means the students' individual squares share an
edge (front, back, left or right, but \emph{not} diagonal).  Thus, each
student is adjacent to 2, 3 or 4 others.

In the example, the infection spreads as shown below.
%
\[
\begin{array}{|c|c|c|c|c|c|}
\hline
\ast& & & &\ast& \\ \hline
 &\ast& & & & \\ \hline
& &\ast&\ast& & \\ \hline
& & & & & \\ \hline
& &\ast& & & \\ \hline
& & &\ast& &\ast \\ \hline
\end{array}
\Rightarrow
\begin{array}{|c|c|c|c|c|c|}
\hline
\ast&\ast& & &\ast& \\ \hline
\ast&\ast&\ast& & & \\ \hline
&\ast&\ast&\ast& & \\ \hline
& &\ast& & & \\ \hline
& &\ast&\ast& & \\ \hline
& &\ast&\ast&\ast&\ast \\ \hline
\end{array}
\Rightarrow
\begin{array}{|c|c|c|c|c|c|}
\hline
\ast&\ast&\ast& &\ast& \\ \hline
\ast&\ast&\ast&\ast& & \\ \hline
\ast&\ast&\ast&\ast& & \\ \hline
&\ast&\ast&\ast& & \\ \hline
& &\ast&\ast&\ast& \\ \hline
& &\ast&\ast&\ast&\ast \\ \hline
\end{array}
\]
%
In this example, over the next few time-steps, all the students in class
become infected.

\begin{theorem*}
  If fewer than $n$ students among those in an $n \times n$ arrangment are
  initially infected in a flu outbreak, then there will be at least one
  student who never gets infected in this outbreak, even if students
  attend all the lectures.
\end{theorem*}

Prove this theorem.

\hint Think of the state of an outbreak as an $n \times n$ square above,
with asterisks indicating infection.  The rules for the spread of
infection then define the transitions of a state machine.  Try to derive a
weakly decreasing state variable that leads to a proof of this Theorem.

\begin{solution}
\begin{proof}
  Define the \term{perimeter} of an infected set of students to be the
  number of edges with infection on exactly one side.  Let $\nu$ be size
  (number of edges) in the perimeter.

  We claim that $\nu$ is a weakly decreasing variable.  This follows
  because the perimeter changes after a transition only because some
  squares became newly infected.  By the rules above, each newly-infected
  square is adjacent to at least two previously-infected squares.  Thus,
  for each newly-infected square, at least two edges are removed from the
  perimeter of the infected region, and at most two edges are added to
  the perimeter.  Therefore, the perimeter of the infected region cannot
  increase.

  Now if an $n \times n$ grid is completely infected, then the perimeter
  of the infected region is $4n$.  Thus, the whole grid can become
  infected only if the perimeter is initially at least $4n$.  Since each
  square has perimeter 4, at least $n$ squares must be infected initially
  for the whole grid to become infected.
\end{proof}

\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp9t}
  \pcomment{from: F02.quiz2}
  \pcomment{has a lot of commented out material}
\end{pcomments}

\pkeywords{
  asymptotics
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Recall that for functions $f,g$ on the natural numbers,
$\naturals$, $f = O(g)$ iff
\begin{equation}\label{Oh}
\exists c \in \naturals\, \exists n_0 \in \naturals\,
\forall n \geq n_0\quad c \cdot g(n) \geq \abs{f(n)}.
\end{equation}

For each pair of functions below, determine whether $f = O(g)$ and whether
$g = O(f)$.  In cases where one function is O() of the other, indicate the
\emph{smallest natural number}, $c$, and for that smallest $c$, the
\emph{smallest corresponding natural number $n_0$} ensuring that
condition~\eqref{Oh} applies.

\begin{problemparts}

\problempart $f(n) = n^2, g(n) = 3n$.

$f = O(g)$ \hspace{.5in}YES \hspace{.5in}NO \hspace{.5in} 
If YES, $c =$ \brule{.5in}, $n_0$ = \brule{.5in}

\begin{solution}
NO.
\end{solution}

$g = O(f)$ \hspace{.5in}YES \hspace{.5in}NO \hspace{.5in} 
If YES, $c =$ \brule{.5in}, $n_0$ = \brule{.5in}

\begin{solution}
YES, with $c = 1$, $n_0 = 3$, which works
because $3^2 = 9$, $3 \cdot 3 = 9$.
\end{solution}

\problempart $f(n) = (3n - 7) / (n + 4), g(n) = 4$

$f = O(g)$ \hspace{.5in}YES \hspace{.5in}NO \hspace{.5in} 
If YES, $c =$ \brule{.5in}, $n_0$ = \brule{.5in}

\begin{solution}
YES, with $c = 1, n_0 = 0$  (because $\abs{f(n)}< 3$).
\end{solution}

$g = O(f)$ \hspace{.5in}YES \hspace{.5in}NO \hspace{.5in} 
If YES, $c =$ \brule{.5in}, $n_0$ = \brule{.5in}

\begin{solution}
YES, with $c =2, n_0 = 15.$

Since $\lim_{n \to \infty} f(n) = 3$, the smallest possible $c$ is 2.
For $c = 2$, the smallest possible $n_0 = 15$ which follows from the
requirement that $2f(n_0) \ge 4$.
\end{solution}

\iffalse

\problempart  (NOT USED) $f(n) = 2^{(n + 2 \sin(n))}, g(n) = 2^n$

$f = O(g)$ \hspace{.5in}YES \hspace{.5in}NO \hspace{.5in} 
If yes, $c =$ \brule{.5in} $n_0$ = \brule{.5in}

$g = O(f)$ \hspace{.5in}YES \hspace{.5in}NO \hspace{.5in} 
If yes, $c =$ \brule{.5in} $n_0$ = \brule{.5in}


\begin{solution}
$f = O(g)$    YES

$c = 4, n_0 = 0$    (because $2 \sin (n)$ contributes at worst $-2$ to the power)

$g = O(f)$    YES

$c = 4, n_0 = 0$    (because the $2 \sin (n)$ contributes at worst $+2$ to the power)

\end{solution}

\fi

\problempart $f(n) = 1 + (n \sin(n\pi/2))^2, g(n) = 3n$

$f = O(g)$ \hspace{.5in}YES \hspace{.5in}NO \hspace{.5in} 
If yes, $c =$ \brule{.5in} $n_0$ = \brule{.5in}

\begin{solution}
NO, because $f(2n)=1$, which rules out $g =
O(f)$ since $g=\Theta(n)$.
\end{solution}

$g = O(f)$ \hspace{.5in}YES \hspace{.5in}NO \hspace{.5in} 
If yes, $c =$ \brule{.5in} $n_0$ = \brule{.5in}

\begin{solution}
NO, because $f(2n+1) = n^2+1 \neq O(n)$ which rules out
$f = O(g)$.
\end{solution}

\end{problemparts}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp7t}
\end{pcomments}

\pkeywords{
  networks
  binary_trees
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
A \emph{binary-tree network} has $n$ inputs and $n$ outputs, where $n$ is
a power of 2.  Each input is connected to the root of a binary tree with
$n/2$ leaves and with edges pointing away from the root.  Likewise, each
output is connected to the root of a binary tree with $n/2$ leaves and
with edges pointing toward the root.

Two edges point from each leaf of an input tree, and each of these edges
points to a leaf of an output tree.  The matching of leaf edges is
arranged so that for every input and output tree, there is an edge from a
leaf of the input tree to a leaf of the output tree, and every output tree
leaf has exactly two edges pointing to it.

\bparts
\ppart Draw such a binary-tree net for $n=4$.

\begin{solution}
\mfigure{!}{3in}{figures/binnet}

\end{solution}



\ppart Fill in the table, and explain your entries.

{\large
\[
\begin{array}{c|c|c|c}
\text{\# switches} &
\text{switch size} &
\text{diameter} &
\text{max congestion} \\ \hline
&&&\\ \hline
\end{array}
\]
}

\begin{solution}
{\large
\[
\begin{array}{c|c|c|c}
\text{\# switches} &
\text{switch size} &
\text{diameter} &
\text{max congestion} \\ \hline
2n(n-1)& 1 \times 2, 2 \times 1 & 1+ 2\log n & 1\\ \hline
\end{array}
\]
}

\iffalse
\begin{align*}
\text{\# switches } & = 2n(n-1)\\
\text{switch size} & = 1 \times 2, 2 \times 1\\
\text{diameter} & =  1+ 2\log n\\
\text{max congestion} & =1
\end{align*}
\fi

These formulas were gotten as follows: a binary tree with $n/2$ leaves has
$n-1$ nodes (switches), and there are $2n$ trees.

Each node of an input tree has one edge in and two out; the opposite
for nodes of output trees.

The distance from any input to any output is 1 from input to tree root,
$(\log n)-1$ from root to leaf, 1 from input leaf to output leaf, $(\log
n)-1$ from output leaf to output root, and 1 to output, for a total of $1+
2\log n$.

The path from any input to any output is unique, and paths from two inputs
to different outputs don't overlap, so at most one packet goes through any
switch.
\end{solution}

\eparts

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp2m}
%  \pcomment{}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  circuits
  logic
  boolean
  binary
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
  Propositional logic comes up in digital circuit design using the
  convention that \true\ corresponds to 1 and \false\ to 0.  A simple
  example is a 2-bit half-adder circuit.  This circuit has $3$ binary
  inputs, $a_1,a_0$ and $b$, and $3$ binary outputs, $c, o_1,o_0$.  The
  2-bit word $a_1a_0$ gives the binary representation of an integer, $s$
  between 0 and 3.  The 3-bit word $co_1o_0$ gives the binary
  representation of $s+b$.
  The output $c$ is called the \emph{final carry bit}.

  So if $s$ and $b$ were both 1, then the value of $a_1a_0$ would be
  \texttt{01} and the value of the output $co_1o_0$ would
  $\texttt{010}$, namely, the 3-bit binary representation of $1+1$.

  In fact, the final carry bit equals 1 only when all three binary inputs
  are 1, that is, when $s=3$ and $b=1$.  In that case, the value of
  $co_1o_0$ is \texttt{100}, namely, the binary representation of $3+1$.

  This 2-bit half-adder could be described by the following formulas:
\begin{align*}
c_0 & = b \\
o_0 & = a_0\ \QXOR\ c_0\\
c_1 & = a_0\ \QAND\ c_0  & \text{the carry into  column 1}\\
o_1 & = a_1\ \QXOR\ c_1\\
c_2 & = a_1\ \QAND\ c_1 & \text{the carry into column 2}\\
c   & = c_2.
\end{align*}

\bparts

\ppart\label{CP_binary_adder_logic:anb} Generalize the above construction 
of a 2-bit half-adder to an $n+1$ bit half-adder with inputs $a_n,\dots, 
a_1, a_0$ and $b$ for arbitrary $n \geq 0$.  That is, give simple formulas 
for $o_{i}$ and $c_{i}$ for $0 \leq i \leq n+1$, where $c_i$ is the carry 
into column $i$ and $c=c_{n+1}$.

\begin{solution}
 The $n+1$-bit word $a_n \dots a_1 a_0$ will be the binary
  representation of an integer, $s$, between 0 and $2^{n+1}-1$.  The
  circuit will have $n+2$ outputs $c, o_n, \dots, o_1, o_0$ where the
  $n+2$-bit word $c o_n \dots o_1 o_0$ gives the binary representation of
  $s+b$.

Here are some simple formulas that define such a half-adder:
\begin{align*}
c_0 & = b,\\
o_{i} & = a_{i}\ \QXOR\ c_{i}  & \text{for } 0 \leq i \leq n,\\
c_{i+1} &= a_i\ \QAND\ c_i & \text{for } 0 \leq i \leq n,\\
c & = c_{n+1}.
\end{align*}

\end{solution}

\ppart\label{CP_binary_adder_logic:anbn} Write similar definitions for 
the digits and carries in the sum of two $n+1$-bit binary numbers 
$a_n\dots a_1a_0$ and $b_n\dots b_1b_0$.

\begin{solution}
Define
\begin{align*}
c_0     & =  0\\
o_{i}   & = a_{i}\ \QXOR\ b_{i}\ \QXOR\ c_{i}
                & \text{for } 0 \leq i \leq n,\\
c_{i+1} & = (a_i\ \QAND\ b_i)\ \QOR\\
       &\qquad  (a_i\ \QAND\ c_i) \QOR (b_i\ \QAND\ c_i)
                & \text{for } 0 \leq i \leq n,\\
c      & = c_{n+1}.
\end{align*}

\end{solution}

\eparts

Visualized as digital circuits, the above adders consist of a sequence of
single-digit half-adders or adders strung together in series.  These
circuits mimic ordinary pencil-and-paper addition, where a carry into a
column is calculated directly from the carry into the previous column, and
the carries have to ripple across all the columns before the carry into
the final column is determined.  Circuits with this design are called
``ripple-carry'' adders.  Ripple-carry adders are easy to understand and
remember and require a nearly minimal number of operations.  But the
higher-order output bits and the final carry take time proportional to $n$
to reach their final values.

\bparts 
\ppart How many of each of the propositional operations does your adder
from part~\eqref{CP_binary_adder_logic:anbn} use to calculate the sum?

\begin{solution}
The scheme given in the solution to 
part~\eqref{CP_binary_adder_logic:anbn} uses
  $3(n+1)$ AND's, $2(n+1)$ XOR's, and $2(n+1)$ OR's for a total of
  $7(n+1)$ operations.\footnote{Because $c_{0}$ is always 0, you could
    skip all the operations involving it.  Then the counts are $3n+1$
    AND's, $2n+1$ XOR's, and $2n$ OR's for a total of $7n+2$ operations.}

\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp4m}
  \pcomment{A bit messy - could use some revision to remove the ellipses.}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  binary
  relations
  relational_properties
  partial_orders
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
How many binary relations are there on the set $\set{0,1}$?

How many are there that are transitive?, \dots asymmetric?, \dots reflexive?,
\dots irreflexive?, \dots strict partial orders?, \dots weak partial
orders?

\hint There are easier ways to find these numbers than listing all
the relations and checking which properties each one has.

\begin{solution}
There are $2^4 = 16$ such relations, since in any such relation
  there are four possible arrows between $\set{0,1}$ and itself, each of
  which may or may not be there.

There are 3 \textbf{in}transitive transitive relations, because the only
way transitivity can fail in a relation on two elements is when there is
an arrow in both directions between the elements, but one or the other or
both the elements are missing a \term{self-loop}, that is, an arrow that
starts and ends at the element.  So there are $13=16-3$ transitive
relations.

There are 3 asymmetric relations.  Asymmetry implies no self-loops, and at
most one of the two possible arrows between 0 and 1.  So the only
3 possibilities are no arrows, arrow from 0 to 1, arrow from 1 to 0.

There are 4 reflexive relations, because two of the four possible arrows
(the self-loops) must be present, the remaining two arrows can be either
present or not present, which yields $2^2$ relations.  There are 4
irreflexive relations for the same reason.

There are 3 strict partial orders, because the 3 asymmetric relations are
all transitive.

There are 3 weak partial orders, because the 3 strict partial orders
remain distinct after adding self-loops to both elements.

\end{solution}
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp4m}
  \pcomment{A bit messy - could use some revision to remove the ellipses.}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  binary
  relations
  relational_properties
  partial_orders
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem} 

\mbox{}

\bparts

\ppart For each row in the following table, indicate whether the binary relation $aRb$ on the set $A$ is a weak partial order or a total order by filling in the appropriate entries with either Y = YES or  N = NO. 
In addition, list the minimal and maximal elements for each relation. 

\renewcommand\arraystretch{2}
\begin{center}
  \begin{tabular*}{\textwidth}{@{\extracolsep{\fill}} | c | c | c | c | c | c |}
    \hline
    {\bf $A$} & {\bf $aRb$} & {\bf weak partial order} & {\bf total order} & {\bf minimal(s)} & {\bf maximal(s)} \\ \hline
    $\mathbb{R} - \mathbb{R}^+$ & $a | b$ & & & & \\ \hline
    $P(\{1, 2, 3\})$ & $a\subseteq b$ & & & &  \\ \hline
    $\mathbb{N} \cup \{i\}$ & $a> b$ & & & &  \\
    \hline
  \end{tabular*}
\end{center}

\begin{solution}
TBA
\end{solution}

\vspace{0.5in}

\ppart What is the longest {\em chain} on the subset relation, $\subseteq$, on $P(\{1, 2, 3\})$? (If there is more than one, provide ONE of them.) 

\vspace{1.5in}

\begin{solution}
TBA
\end{solution}

\ppart What is the longest {\em anti-chain} on the subset relation, $\subseteq$, on $P(\{1, 2, 3\})$? (If there is more than one, provide ONE of them.) 

\begin{solution}
TBA
\end{solution}

\eparts

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp5m}
  \pcomment{Commented out in S09 - check before using.}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  recursive_data
  trees
  binary_trees
  induction
  structural_induction
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}

\begin{definition*}
 The recursive data type, $\btg$, of \term{binary trees} with
 leaf labels, $L$, is defined recursively as follows:

\begin{itemize}

\item \textbf{Base case:}
$\ang{\texttt{leaf},l} \in \btg$, for all labels $l\in L$.

\item \textbf{Constructor case:} If $G_1,G_2 \in \btg$, then
\[
\ang{\texttt{bintree},G_1,G_2} \in \btg.
\]
\end{itemize}


The \emph{size}, $\card{G}$, of $G \in \btg$ is defined recursively on
this definition by:

\begin{itemize}
\item \textbf{Base case:}
\[
\card{\ang{\texttt{leaf}, l}} \eqdef 1, \quad \text{ for all } l \in L.
\]

\item \textbf{Constructor case:}
\[
\card{\ang{\texttt{bintree}, G_1, G_2}} \eqdef \card{G_1}+ \card{G_2} + 1.
\]
\end{itemize}

\end{definition*}

For example, for the size of the $\btg$, $G$, pictured in
Figure~\ref{CP_binary_trees:small-tree}, is 7.

\begin{figure}[htbp]
\centering \includegraphics[height=3in]{figures/binary-game-tree.pdf}
\caption{\emph{A picture of a binary tree $w$.}}
\label{CP_binary_trees:small-tree}
\end{figure}

\bparts
\ppart Write out (using angle brackets and labels \texttt{bintree},
\texttt{leaf}, etc.) the $\btg$, $G$, pictured in 
Figure~\ref{CP_binary_trees:small-tree}.

\begin{solution}
\begin{equation}
\begin{split}
\langle\texttt{bintree}, & \langle\texttt{bintree}, \ang{\texttt{leaf, win}},\\
  & \hspace{5em} \ang{\texttt{bintree}, \ang{\texttt{leaf, lose}}, 
       \ang{\texttt{leaf, win}}}\rangle,\\
  & \ang{\texttt{leaf, win}}\rangle
\end{split}
\end{equation}

\end{solution}

\eparts

The value of $\text{flatten}(G)$ for $G \in \btg$ is the sequence of
labels in $L$ of the leaves of $G$.  For example, for the $\btg$, $G$,
pictured in Figure~\ref{CP_binary_trees:small-tree},
\[
\text{flatten}(G) = (\texttt{win}, \texttt{lose}, \texttt{win}, \texttt{win}).
\]  %Need updating for general labels

\bparts

\ppart
Give a recursive definition of flatten.  (You may use the operation of
\emph{concatenation} (append) of two sequences.)

\begin{solution}
Define flatten recursively on the definition of $\btg$.

\begin{itemize}

\item \textbf{Base case:}
\begin{align*}
a\text{flatten}(\ang{\texttt{leaf}, \texttt{win}}) & \eqdef (\texttt{win}),\\
\text{flatten}(\ang{\texttt{leaf}, \texttt{lose}})& \eqdef (\texttt{lose}).
\end{align*}

\item \textbf{Constructor case:}
\[
\text{flatten}(\ang{\texttt{bintree}, G_1, G_2}) \eqdef
\text{flatten}(G_1)\text{flatten}(G_2)
\] 
where $\text{flatten}(G_1)\text{flatten}(G_2)$ is the concatenation of the
the two sequences of leaf labels, that is the sequence of labels in
$\text{flatten}(G_1)$ followed by the labels in $\text{flatten}(G_2)$.
\end{itemize}

\end{solution}

\ppart Prove by structural induction on the definitions of flatten and
size that
\begin{equation}\label{CP_binary_trees:2gg1}
2\cdot \text{length}(\text{flatten}(G)) = \card{G}+1.
\end{equation}

\begin{solution}
The proof is by structural induction on the given function
  definitions.  The induction hypothesis is the equation~\eqref{CP_binary_trees:2gg1}.

\begin{itemize}
\item \textbf{Base cases:}
\[2 \cdot \text{length}(\text{flatten}(\ang{\texttt{leaf},
    \text{label}})) = 2\cdot \text{length}((\text{label})) = 2 \cdot 1 =
  2 = 1 + 1 = \card{\ang{\texttt{leaf}, \text{label}}} + 1.
\]
So~\eqref{CP_binary_trees:2gg1} holds in the base cases.

\item \textbf{Constructor case:}
Say $G = \ang{\texttt{bintree}, G_1, G_2}$ where we assume the Structural
Induction hypothesis that $G_1$ and $G_2$ satisfy~\eqref{CP_binary_trees:2gg1}.  Now,
\begin{align*}
\lefteqn{2\cdot \text{length}(\text{flatten}(G))}\\
  & = 2 \cdot \text{length}(\text{flatten}(\ang{\texttt{bintree}, G_1, G_2}))\\
  & = 2\cdot \text{length}(\text{flatten}(G_1)\text{flatten}(G_2))
        & \text{(def of flatten)}\\
  & = 2\cdot \text{length}(\text{flatten}(G_1))+
     2 \cdot \text{length}(\text{flatten}(G_2))
        & \text{(length of a string)}\\
  & = (\card{G_1}+1) + \card{G_2}+1 & \text{(Structural Induction hyp.)}\\
  & = (\card{G_1} + \card{G_2}+1) +1\\
  & = \card{\ang{\texttt{bintree}, G_1, G_2}} + 1
           & \text{(def. of $\card{\ang{\text{bintree},\dots}}$)}\\
  & = \card{G} +1,
\end{align*}
proving that~\eqref{CP_binary_trees:2gg1} holds for $G$.
This completes the proof for the Constructor cases.
\end{itemize}

We conclude by Structural Induction that equation~\eqref{CP_binary_trees:2gg1} 
holds for all $G \in \btg$.
\end{solution}

\eparts

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09 notes}
%  \pcomment{}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  induction
  strong_induction
  potential
  invariance
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Define the \term{potential}, $p(S)$, of a stack, $S$, of blocks to be
$k(k-1)/2$ where $k$ is the number of blocks in $S$.  Define the
potential, $p(A)$, of a set, $A$, of stacks to be the sum of the
potentials of the stacks in $A$.

Generalize Theorem~\ref{stacking} about scores in the stacking game to
show that for any set, $A$, of stacks, if a sequence of moves starting
with $A$ leads to another set, $B$, of stacks, then $p(A) \geq p(B)$, and
the score for this sequence of moves is $p(A)-p(B)$.

\hint By induction on the number of moves to get from $A$ to $B$.

\begin{solution}
\begin{proof}

The proof is by ordinary induction on the number, $n$, of moves.
The induction hypothesis will be $P(n) \eqdef$
\begin{quote}
If $n$ moves from a set, $A$, of stacks leads to a set $B$ of stacks, then
$p(A) \geq p(B)$ and the score for these $n$ moves is $p(A)-p(B)$.
\end{quote}

\textbf{Base case:} ($n$ = 0)  This means no moves have been made and
$B=A$, so it's obvious that $P(0)$ holds.

\textbf{Inductive step:} Assume that $P(n)$ is true for some $n \in
\naturals$, and suppose $A$ leads to $B$ in $n+1$ moves.  This means that
$A$ leads to some set of stacks, $A_1$, and $A_1$ leads to $B$ in $n$
steps.  So inductive hypothesis $P(n)$ implies that $p(A_1) \geq p(B)$ and
the score for going from $A_1$ to $B$ is $p(A_1)-p(B)$.

So all we have to do is show that and the score for the single move from
$A$ to $A_1$ is $p(A)-p(A_1) > 0$.  The only difference between $A$ and
$A_1$ is that some stack $S \in A$ of size $k>1$ splits into two stacks of
sizes $k_1,k_2 \geq 1$ where $k = k_1+k_2$.  Now the score for such a move
is $k_1k_2$.  Also,
\[
p(S) = \frac{(k_1+k_2)((k_1+k_2)+1)}{2} =
\frac{(k_1^1+ 2k_1k_2+k_2^2)+(k_1 + k_2)}{2},
\]
and the potential of the two stack sets is the sum of their potentials, namely,
\[
\frac{k_1(k_1+1) + k_2(k_2+1)}{2} = \frac{k_1^2 + k_2^2 +k_1 + k_2}{2},
\]
So the difference between these potentials equals $k_1k_2>0$, and this is
indeed equal to the score of the move.

\end{proof}

\end{solution}

\end{problem}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp1t}
%  \pcomment{}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  faulty_reasoning
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Identify exactly where the bugs are in each of the following bogus
proofs.\footnote{From Stueben, Michael and Diane Sandford. \emph{Twenty
Years Before the Blackboard}, Mathematical Association of America, 
\copyright 1998.}

\bparts

\problempart \textbf{Bogus Claim}: $1/8 > 1/4.$
\begin{bogusproof}
\begin{align*}
    3 &> 2 \\
    3 \log_{10} (1/2) &> 2 \log_{10}(1/2) \\
    \log_{10} (1/2)^3 &> \log_{10} (1/2)^2 \\
    (1/2)^3 &> (1/2)^2,
\end{align*}
and the claim now follows by the rules for multiplying fractions.
\end{bogusproof}

\begin{solution}
$\log x < 0$, for $0<x<1$, so since both sides of the inequality
``$3 > 2$'' are being multiplied by the negative quantity
$\log_{10}(1/2)$, the ``$>$'' in the second line should have been
``$<$.''
\end{solution}

\ppart \emph{Bogus proof}: $1 \mbox{\textcent} = \$0.01 = (\$0.1)^2 = (10\mbox{\textcent})^2 =
100\mbox{\textcent} = \$1.\qed$

\begin{solution}
$\$0.01 = \$(0.1)^2 \neq (\$0.1)^2$ because the units $\$^2$ and
$\$$ don't match (just as in physics the difference between $sec^2$ and
$sec$ indicates the difference between acceleration and velocity).
Similarly, $(10\mbox{\textcent})^2 \neq 100$\textcent.

\end{solution}

%FALSE PROOF ARITHMETIC, from Spring94 revised ARM 9/3/01

\ppart \textbf{Bogus Claim}: If $a$ and $b$ are two equal real numbers,
then $a=0$.
\begin{bogusproof}
\begin{eqnarray*}
a&=&b \\
a^2&=&ab \\
a^2-b^2&=&ab-b^2 \\
(a-b)(a+b)&=&(a-b)b\\ % \label{cancel}\\
a+b&=&b\\ % \label{bug}\\
a&=&0.
\end{eqnarray*}
\end{bogusproof}

\begin{solution}
The bug is at the fifth line:
\iffalse~(\ref{bug})\fi
one cannot cancel $(a-b)$ from
both sides of the equation on the fourth line
\iffalse~(\ref{cancel})\fi
because $a-b = 0$.
\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp6r}
  \pcomment{from: S07.cp6m}
\end{pcomments}

\pkeywords{
  chromatic_number
  graph_coloring
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Let $G$ be the graph below\footnote{From \emph{Discrete Mathematics},
Lov\'asz, Pelikan, and Vesztergombi. Springer, 2003.  Exercise 13.3.1}.
Carefully explain why $\chi(G)=4$.
\mfigure{!}{2in}{figures/4-chromatic}
\begin{solution}
Four colors are sufficient:
\begin{figure}[h]\centering 
\includegraphics[height=2in]{figures/4-chromatic-colored}
\caption{A 4-coloring of the Graph}\label{fig:4-coloring}
\end{figure}
so
\begin{equation}\label{chileq4}
\chi(G) \leq 4.
\end{equation}

Now assume $\chi(G)=3$. We may assume the top vertex is colored red. The top
two triangles require 3 colors each, and since they share the top red
vertex, they must have the other two colors, white and blue, at their
bases, as in Figure~\ref{fig:4-coloring}.  Now the bottom two vertices are
both adjacent to vertices colored white and blue, and cannot have the same
color since they are adjacent, so there is no alternative but to color one
with a third color and the other with a fourth color, contradicting the
assumption that 3 colors are enough.  Hence, $\chi(G)>3$.  This together
with~\eqref{chileq4} implies that $\chi(G)=4$.
\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%CP_class_scheduling

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: F04.rec9, revised by ARM 10/1/09}
\end{pcomments}

\pkeywords{
  partial_orders
  scheduling
  chain
  antichain
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}

  The table below lists some prerequisite information for some subjects in
  the MIT Computer Science program (in 2006).  This defines an indirect
  prerequisite relation, $\prec$, that is a strict partial order on these
  subjects.
%
\begin{align*}
18.01 & \to 6.042 & 18.01 & \to 18.02 \\
18.01 & \to 18.03 & 6.046 & \to 6.840 \\
8.01 & \to 8.02 & 6.001 & \to 6.034 \\
6.042 & \to 6.046 & 18.03, 8.02 & \to 6.002 \\
6.001, 6.002 & \to 6.003 & 6.001, 6.002 & \to 6.004 \\
6.004 & \to 6.033 & 6.033 & \to 6.857
\end{align*}

\bparts
\iffalse

\ppart Draw a Hasse diagram for the corresponding partially-ordered
set.  (A \term{Hasse diagram} is a way of representing a poset $(A,
\prec)$ as a directed acyclic graph.  The vertices are the element
of $A$, and there is generally an edge $u \to v$ if $u \prec v$.
However, self-loops and edges implied by transitivity are omitted.)
You'll need this diagram for all the subsequent problem parts, so be
neat!

\begin{solution}

\mfigure{!}{2.5in}{rec9-hasse}
\end{solution}
\fi

\ppart\label{sixterms} Explain why exactly six terms are required to finish all these
subjects, if you can take as many subjects as you want per term.
Using a \emph{greedy} subject selection strategy, you should take as many
subjects as possible each term.  Exhibit your complete class schedule each
term using a greedy strategy.

\begin{solution}
It helps to have a diagram of the direct prerequisite relation:

\mfigure{!}{2.5in}{rec9-hasse}

There is a $\prec$-chain of length six:
\[
8.01 \prec 8.02 \prec 6.002 \prec 6.004 \prec 6.033 \prec 6.857
\]
So six terms are necessary, because at most one of these
subjects can be taken each term.

There is no longer chain, so with the greedy strategy you will take six terms.
Here are the subjects you take in successive terms.
\begin{center}
\begin{tabular}{lccccc}
1: & 6.001 &  8.01 & 18.01 \\
2: & 6.034 & 6.042 & 8.02 & 18.02 &  18.03\\
3: & 6.002 & 6.046 \\
4: & 6.003 & 6.004 & 6.840 \\
5: & 6.033\\
6: & 6.857
\end{tabular}
\end{center}

\end{solution}

\ppart In the second term of the greedy schedule, you took five subjects
including 18.03.  Identify a set of five subjects not including 18.03 such that
it would be possible to take them in one term (using some nongreedy schedule).
Can you figure out how many such sets there are?

\begin{solution}
We're looking for an antichain in the $\prec$ relation that does not
include 18.03.  Every such antichain will have to include 18.02 6.003,
6.034.  Then a fourth subject could be any of 6.042, 6.048, and 6.840.
The fifth subject could then be any of 6.004, 6.033, and 6.857.  This
gives a total of nine antichains of five subjects.
\end{solution}


\ppart Exhibit a schedule for taking all the courses ---but only one per term.

\begin{solution}
We're asking for a topological sort of $\prec$.  There are many.  One is 18.01,
8.01, 6.001, 18.02, 6.042, 18.03, 8.02, 6.034, 6.046, 6.002, 6.840,
6.004, 6.003, 6.033, 6.857.
\end{solution}

\ppart Suppose that you want to take all of the subjects, but can
handle only two per term.  Exactly how many terms are required to
graduate?  Explain why.
\begin{solution}

There are $\ceil{15/2} =8$ terms necessary.  The schedule below
shows that 8 terms are sufficient as well:

\begin{center}
\begin{tabular}{rcc}
1: & 18.01 & 8.01 \\
2: & 6.001 & 18.02 \\
3: & 6.042 & 18.03 \\
4: & 8.02 & 6.034 \\
5: & 6.046 & 6.002 \\
6: & 6.840 & 6.004 \\
7: & 6.003 & 6.033 \\
8: & 6.857
\end{tabular}
\end{center}

\end{solution}

\ppart What if you could take three subjects per term?

\begin{solution}
  From part~\eqref{sixterms} we know six terms are required even if there
  is no limit on the number of subjects per term.  Six terms are also
  sufficient, as the following schedule shows:

\begin{center}
\begin{tabular}{rccc}
1: & 18.01 & 8.01 & 6.001 \\
2: & 6.042 & 18.03 & 8.02 \\
3: & 18.02 & 6.046 & 6.002 \\
4: & 6.004 & 6.003 & 6.034 \\
5: & 6.840 & 6.033 \\
6: & 6.857 \\
\end{tabular}
\end{center}

\end{solution}

\eparts

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
%\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp4m}
%  \pcomment{}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  partial_orders
  scheduling
  chains_and_antichains
}

\newcommand{\Jay}{Rajeev}
\newcommand{\Rongrong}{Jodyann}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
A pair of 6.042 TAs, \Jay\  and \Rongrong,
have decided to devote some of their spare time this term to
establishing dominion over the entire galaxy.  Recognizing this as an
ambitious project, they worked out the following table of tasks on the
back of \Rongrong's copy of the lecture notes.

\begin{enumerate}
\item {\bf Devise a logo} and cool imperial theme music - 8 days.
\item {\bf Build a fleet} of Hyperwarp Stardestroyers out of eating
  paraphernalia swiped from Lobdell - 18 days.
\item {\bf Seize control} of the United Nations - 9 days, after task \#1.
\item {\bf Get shots} for \Jay's cat, Tailspin - 11 days, after task \#1.
\item {\bf Open a Starbucks chain} for the army to get their caffeine - 10 
days, after task \#3.
\item {\bf Train an army} of elite interstellar warriors by dragging
people to see {\em The Phantom Menace} dozens of times - 4 days, after
tasks \#3, \#4, and \#5.
\item {\bf Launch the fleet} of Stardestroyers, crush all sentient
alien species, and establish a Galactic Empire - 6 days, after tasks \#2 and
\#6.
\item {\bf Defeat Microsoft} - 8 days, after tasks \#2 and \#6.
\end{enumerate}

We picture this information in Figure~\ref{fig:tasks} below by drawing a
point for each task, and labelling it with the name and weight of the
task.  An edge between two points indicates that the task for the higher
point must be completed before beginning the task for the lower one.
    \begin{figure}[htbp]
    \begin{center}
    \unitlength=0.047pt
    \input{figures/ps4-1.latex}
    \end{center}
    \caption{Graph representing the task precedence constraints.}
    \label{fig:tasks}
    \end{figure}

\bparts

\ppart Give some valid order in which the tasks might be
completed.

\begin{solution}
We can easily find several of them. The most natural one is valid, too:
\#1, \#2, \#3, \#4, \#5, \#6, \#7, \#8.

\end{solution}
\eparts

\Jay\  and \Rongrong\  want to complete all these tasks in the
shortest possible time. However, they have agreed on some constraining
work rules.
\begin{itemize}

\item Only one person can be assigned to a particular task; they can
not work together on a single task.

\item Once a person is assigned to a task, that person must work
exclusively on the assignment until it is completed.  So, for example,
\Jay\  cannot work on building a fleet for a few days, run to get shots
for Tailspin, and then return to building the fleet.

\end{itemize}

% For each task, the table above lists the time required for completion
% and which other tasks must be finished before the given task is begun.

\bparts

\ppart \Jay\  and \Rongrong\  want to know how long conquering the
galaxy will take.  \Rongrong\  suggests dividing the total number of days of
work by the number of workers, which is two.  What lower bound on the time
to conquer the galaxy does this give, and why might the actual time
required be greater?

\begin{solution}
\begin{eqnarray*}
\frac{8 + 18 + 9 + 11 + 10 + 4 + 6 + 8}{2} & = & 37 \text{ days}
\end{eqnarray*}

If working together and interrupting work on a task were permitted, then
this answer would be correct.  However, the rules may prevent \Jay\  and
\Rongrong\  from both working all the time.  For example, suppose the only task
was building the fleet.  It will take 18 days, not 18/2 days, to complete,
because only one person can work on it and the other must sit idle.
\end{solution}

\ppart \Jay\  proposes a different method for determining the
duration of their project.  He suggests looking at the duration of
the ``critical path'', the most time-consuming sequence of tasks
such that each depends on the one before.  What lower bound does this
give, and why might it also be too low?

\begin{solution}
The longest sequence of tasks is devising a logo (8 days),
seizing the U.N. (9 days), opening a Starbucks (10 days), training
the army (4 days), and then defeating Microsoft (8 days).  Since these
tasks must be done sequentially, galactic conquest will require at
least 39 days.

If there were enough workers, this answer would be correct; however, with
only two workers, \Jay\  and \Rongrong\  may be unable to make progress on the
critical path every day.  For example, suppose there were only four
tasks: devise logo, build fleet, seize control, get shots.  Now the
critical path consists of two critical tasks: devise logo, get shots,
which take 19 days.  But to get through this path in 19 days, some worker
must be working on a critical task at all times for the 19 days.  This
leaves only one worker free to complete building the fleet and seizing
control, which will take at least 27 days.  So in fact, 27 days is the
minimum time for two workers to complete these four tasks.
\end{solution}

\ppart What is the minimum number of days that \Jay\  and \Rongrong\ 
need to conquer the galaxy?  No proof is required.

\begin{solution}
40 days.  Tasks could be divided as follows:

\Rongrong: \#1 (days 1-8), \#3 (days 9-17), \#4 (days 18-28), \#8 (days
33-40).

\Jay: \#2 (days 1-18), \#5 (days 19-28), \#6 (days 29-32), \#7 (days
33-38).  

It takes some care to verify that 40 days is the best you can do.  If
someone comes up with a simple proof of this, tell the course staff.

\end{solution}
\eparts
\end{problem} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp2t}
%  \pcomment{}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  counter_model
  quantifiers
  predicate_calculus
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Show that
\[
(\forall x \exists y.\; P(x,y)) \implies \forall z.\; P(z,z)
\]
is not valid by describing a counter-model.

\begin{solution}
Let $P(x,y)$ mean $x \neq y$.  Then the conclusion $\forall z.\; z \neq z$
is always false, but in any domain with two or more elements, the
hypothesis is true.
\end{solution}
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp9r}
\end{pcomments}

\pkeywords{
  counting
  counting_rules
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
A license plate consists of either:

\begin{itemize}

\item 3 letters followed by 3 digits (standard plate)

\item 5 letters (vanity plate)

\item 2 characters -- letters or numbers (big shot plate)


\end{itemize}

Let $L$ be the set of all possible license plates.

\bparts

\ppart Express $L$ in terms of
%
\begin{align*}
{\cal A} & = \set{ A, B, C, \dots, Z} \\
{\cal D} & = \set{ 0, 1, 2, \dots, 9} \\
\end{align*}
%
using unions ($\cup$) and set products ($\times$).

\begin{solution}
\[
L = (A^3 \times D^3) \union A^5 \union (A\union D)^2
\]

\end{solution}

\ppart Compute $\card{L}$, the number of different license plates,
using the sum and product rules.

\begin{solution}
\begin{align*}
\card{L}
  & = \card{(A^3 \times D^3) \union A^5 \union (A\union D)^2} \\
  & = \card{(A^3 \times D^3)} + \card{A^5} + \card{(A\union D)^2}  &  \text{Sum Rule} \\
    & = \card{A}^3 \cdot \card{D}^3 + \card{A}^5 + \card{A\union D}^2 & \text{Product Rule} \\ 
    & = \card{A}^3 \cdot \card{D}^3 + \card{A}^5 + (\card{A}+\card{D})^2 & \text{Sum Rule} \\ 
    & = 26^3 \cdot 10^3 + 26^5 + 36^2 = 29458672
\end{align*}

\end{solution}

\eparts

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp4r SUBSUMED BY NOTES}
%  \pcomment{}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  induction
  ordinary_induction
  recursive procedure
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
\bparts

\ppart Prove by induction that a $2^n \times 2^n$ courtyard with a $1
\times 1$ statue of Bill in {\em any position} can be covered with
$L$-shaped tiles.

\begin{solution}
Let $P(n)$ be the proposition that for every location of Bill in
a $2^n \times 2^n$ courtyard, there exists a tiling of the remainder.

\textbf{Base case:} $P(0)$ is true because Bill fills the whole courtyard.

\textbf{Inductive step:} Assume that $P(n)$ is true for some
$n \geq 0$; that is, for every location of Bill in a $2^n \times 2^n$
courtyard, there exists a tiling of the remainder.  Divide the
$2^{n+1} \times 2^{n+1}$ courtyard into four quadrants, each $2^n
\times 2^n$.  One quadrant contains Bill (\textbf{B} in the diagram
below).  Place a temporary Bill (\textbf{X} in the diagram) in each of
the three central squares lying outside this quadrant:

\begin{center}
\begin{picture}(148,148)(-20,-20)
\thinlines
\put(0,0){\line(1,0){128}}
\put(0,0){\line(0,1){128}}
\put(128,128){\line(-1,0){128}}
\put(128,128){\line(0,-1){128}}
\put(64,0){\line(0,1){128}}
\put(0,64){\line(1,0){128}}
\put(56,72){\makebox(0,0){\textbf{X}}}
\put(56,56){\makebox(0,0){\textbf{X}}}
\put(72,56){\makebox(0,0){\textbf{X}}}
\put(48,80){\line(1,0){16}}
\put(48,48){\line(1,0){32}}
\put(80,48){\line(0,1){16}}
\put(48,48){\line(0,1){32}}
\put(96,96){\framebox(16,16){\textbf{B}}}
\put(32,-10){\makebox(0,0){$2^n$}}
\put(96,-10){\makebox(0,0){$2^n$}}
\put(-10,32){\makebox(0,0){$2^n$}}
\put(-10,96){\makebox(0,0){$2^n$}}
\end{picture}
\end{center}

Now we can tile each of the four quadrants by the induction assumption.
Replacing the three temporary Bills with a single L-shaped tile completes
the job.  This proves that $P(n)$ implies $P(n+1)$ for all $n \geq 0$.
The theorem follows as a special case.

This proof has two nice properties.  First, not only does the argument
guarantee that a tiling exists, but also it gives a recursive procedure
for finding such a tiling.  Second, we have a stronger result: if Bill
wanted a statue on the edge of the courtyard, away from the pigeons, we
could accommodate him!
\end{solution}

\ppart {\em (Discussion Question)} In part~(a) we saw that it can be
easier to prove a stronger theorem.  Does this surprise you?  How would
you explain this phenomenon?

\begin{solution}
It might seem that it ought to be harder to prove a more general
theorem than a less general one, but sometimes not.  For example, the more
general result might actually be easier because it involves fewer
assumptions, and this can help in avoiding the complications of unnecessary
hypotheses.

But for an induction proof in particular, using a more general induction
hypothesis means we can make a stronger \emph{assumption} in the induction
step (namely, we can assume a stronger $P(n)$), which can make it easier
to prove the conclusion of the induction step (namely, $P(n+1)$).
\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
%CP_courtyard_tiling_corner

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{adapted from: S09.cp4r which was subsumed by Notes}
%  \pcomment{}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  induction
  ordinary_induction
  recursive procedure
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
\bparts

\ppart\label{cornertile_induction} Prove by induction that a $2^n \times
2^n$ courtyard with a $1 \times 1$ statue of Bill in {\em a corner} can be
covered with L-shaped tiles.  (Do not assume or reprove the (stronger)
result in the Notes that Bill can be placed anywhere.  The point of this
problem is to show a different induction hypothesis that works.)
\begin{solution}

Let $P(n)$ be the proposition Bill can be placed in a corner of
 $2^n \times 2^n$ courtyard with a proper tiling of the remainder with
L-shaped tiles.

\textbf{Base case:} $P(0)$ is true because Bill fills the whole courtyard.

\textbf{Inductive step:} Assume that $P(n)$ is true for some
$n \geq 0$; that is, there exists a tiling of the $2^n \times 2^n$
courtyard leaving Bill in a corner.

Divide the $2^{n+1} \times 2^{n+1}$ courtyard into four quadrants, each
$2^n \times 2^n$.  One quadrant will contain the corner designated for
Bill.  By induction hypothesis, we can get Bill into some corner of the
quadrant, which means we can actually get him into \emph{any} desired
corner of the quadrant by rotating the tiling of the quadrant.  So place
Bill in the designated corner of the quandrant, and tile the rest of the
quadrant.

Now tile the remaining three quadrants leaving a space for Bill the
quadrant corners that are in the middle of the whole $2^{n+1} \times
2^{n+1}$ courtyard (as in the diagram in the Notes).  These three spaces
for an L-shape that that can be filled with a single L-shaped tile,
completing the full courtyard tiling.  This proves $P(n+1)$, completing
the proof by induction that a courtyard with side length any power of 2
can be tiled with Bill in a corner.

\end{solution}

\ppart Use the result of part~\eqref{cornertile_induction} to prove the
original claim that there is a tiling with Bill in the middle.
\begin{solution}
To put Bill in the middle, tile each of the four quadrants leaving empty
the quadrant corner in the midde of the full courtyard.  This leaves the
four central squares of the full courtyard empty, so fill three of these
squares with an L-shaped tile.  This leaves a single central square
untiled for Bill.
\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp7r}
  \pcomment{from: S07.cp7r}
\end{pcomments}

\pkeywords{
  relations
  digraphs
  covering_edges
  transitive_closure
  DAGs
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Let $D$ be a finite Directed Acyclic Graph (DAG),

\bparts

\ppart Explain in one (maybe two) sentences why the positive path relation
of $D$ is obviously a strict partial order.
\eparts

If $a$ and $b$ are distinct nodes of a digraph, then $a$ is said to
\emph{cover} $b$ if there is an edge from $a$ to $b$ and every path from
$a$ to $b$ traverses this edge.  If $a$ covers $b$, the edge from $a$ to
$b$ is called a covering edge.

\bparts

\ppart Describe two graphs with vertices $\set{1,2}$ which have the same
set of covering edges, but not the same positive path relation (\hint They
can't be DAG's.)

\begin{solution}
Let one graph have edges $\set{(1,2), (1,1)}$ and the other
$\set{(1,1),(2,1)}$.  They have the same set of covering edges, namely,
none.  The reason is that if a vertex is on a positive length cycle, then
no edge incident to it can be a covering edge.
\end{solution}

\ppart\label{+path=} Show that if two DAG's have the same positive path
relation, then they have the same set of covering edges.

\begin{solution}
Suppose two DAG's have the same positive path relation, and
consider any covering edge in the first DAG.  By definition of covering,
it is the unique path between its endpoints in \emph{both} DAG's, since
they agree on positive length paths.  But this implies it is a covering
edge in the second DAG as well.
\end{solution}

\ppart\label{cover-ok} Let $\widehat{D}$ be the subgraph of $D$ consisting
of only the covering edges.  Show that $\widehat{D}$ has the same
positive path relation, that is,
\[
D^+ = \widehat{D}^+
\]

\begin{solution}
What we need to show is that if there is a path in $D$ between
vertices $a \neq b$, then there is a path consisting only of covering
edges from $a$ to $b$.  But since $D$ is a finite DAG, there must be a
\emph{longest} path from $a$ to $b$.  Now every edge on this path must be a
covering edge or it could be replaced by a path of length 2 or more,
yielding a longer path from $a$ to $b$.
\end{solution}

\ppart Conclude $\widehat{D}$ is the unique DAG with the smallest number
of edges among all digraphs with the same positive path relation as $D$.

\begin{solution}
By part~\ref{+path=}, any DAG with the same positive path relation as
$D$ must contain all the edges of $\widehat{D}$, so the unique minimality
of $\widehat{D}$ follows immediately from part~\ref{cover-ok}.

\end{solution}

\iffalse

\ppart Show that the previous result is not true in general infinite
DAG's.

\hint Consider the DAG for the total order on the rational numbers.

\begin{solution}
In the DAG for $<$ on the $\rationals$, there are no covering
edges, so $\widehat{<}$ has no edges.
\end{solution}
\fi

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp4r}
%  \pcomment{}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  induction
  ordinary_induction
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
%
Use induction to prove that
\begin{equation}\label{CP_cubic_series:P}
1^3 + 2^3 + \cdots + n^3  =  \paren{\frac{n(n+1)}{2}}^2.
\end{equation}
for all $n \geq 1$.

\iffalse
(1 + 2 + \cdots + n)^2.
\hint
\href{http://theory.csail.mit.edu/classes/6.042/fall05/ln2.pdf}
{Week 2 Notes} includes a proof that $(1 + 2 + \cdots + n)^2 =
\paren{\frac{n(n+1)}{2}}^2$.  You may assume this in your proof here.
\fi

Remember to formally 
\begin{enumerate}
\item Declare proof by induction.
\item Identify the induction hypothesis $P(n)$.
\item Establish the base case.
\item Prove that $P(n)\Rightarrow P(n+1)$.
\item Conclude that $P(n)$ holds for all $n\geq 1$.  
\end{enumerate}
as in the five part template.  

\begin{solution}
We proceed by induction.  The induction hypothesis, $P(n)$, will
be the equation~\eqref{CP_cubic_series:P}.

\textbf{Base case:} First, we must show that $P(1)$ is true.  This is 
immediate, since:

\begin{eqnarray*}
1^3 & = & \left(\frac{1 (1+1)}{2}\right)^2
\end{eqnarray*}

\textbf{Inductive step:} Next, we must show that $P(n)$ implies $P(n + 1)$
for all $n \geq 1$.  Assuming that $P(n)$ is true, we can reason as
follows:

\begin{eqnarray*}
1^3 + 2^3 + \cdots + n^3 + (n + 1)^3
    & = & \paren{\frac{n(n+1)}{2}}^2 + (n + 1)^3 \\
    & = & \paren{\frac{(n + 1)(n+2)}{2}}^2
\end{eqnarray*}

The first step uses the assumption $P(n)$, and the second
uses only algebra.  This shows that $P(n + 1)$ is true.  
Therefore, $P(n)$ is true for all $n \geq 1$ by induction.
\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp7r}
  \pcomment{commented out in S09 but should be in pretty good shape}
\end{pcomments}

\pkeywords{
  digraphs
  Euler_circuit
  binary
  strings
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}

  A $3$-bit string is a string made up of $3$ characters, each a $0$
  or a $1$.  Suppose you'd like to write out, in one string, all eight
  of the 3-bit strings in any convenient order.  For example, if you
  wrote out the $3$-bit strings in the usual order starting with
  000 001 010\dots, you could concatenate them together to get a
  length $3\cdot 8 = 24$ string that started 000001010\dots.

  But you can get a shorter string containing all eight $3$-bit
  strings by starting with 00010\dots.  Now $000$ is present as bits
  $1$ through $3$, $001$ is present as bits $2$ through $4$, $010$ is
  present as bits $3$ through $5$, \dots.

\bparts

\ppart Take a few moments to see how short a string you can make that
contains every $3$-bit string as $3$ consecutive bits somewhere in it.
Can you see why $10$ bits is the absolute minimum length for such a
string?

\begin{solution}
$0001110100$ does it with $10$ bits and you can't do better:
  there must be two bits to start and each additional bit can yield at
  most one new $3$-bit string.
\end{solution}

\mfigure{!}{3in}{figures/debruijn}

\ppart Imagine that the labels on the vertices of the graph above
represent the last two digits in a string you build by adding one bit
at a time.  Convince yourself that the graph completely describes how
the last two digits of your string can change throughout this process.


\begin{solution}
No matter what the last two bits of your current string $x$
  are, say $ab$, there is a vertex representing that.  And, no matter
  what bit you want to use to extend $x$, say $c$, there is an edge
  directed from your current state, $ab$, to the vertex $bc$ that
  represents your new state, the last two bits of $xc$.  Furthermore,
  these are the only types of vertices and edges in the graph.  As a
  bonus, every edge $(s,s')$ is also labeled with the bit that was
  added to the string when going from the state $s$ to $s'$.
\end{solution}


\ppart Find a directed path in this graph starting at some vertex, $v$,
that traverses every edge exactly once.  Note that vertices will have to
be used more than once and the path wil have to end in $v$.

\begin{solution}
Many: $00,00,01,11,11,10,01,10,00$ is one.
\end{solution}

\ppart Explain how such a path provides a shortest possible solution
to the original problem.

\begin{solution}
Build a solution $x$ using the path.  Start with $x$ equal
  to the two digits in the label of the first vertex on the path.
  Then for every edge used after that, add on the bit labelling that
  edge to the string.  For example, the path given in last part's
  solution, yields the string $x=0001110100$.
  
  Sincce there are $8$ edges, the string will be of length $10$, the
  minimum possible.

  Furthermore, the label of the first vertex of the graph, followed by
  the label of the first edge, give the first $3$-bit substring in
  $x$. The next vertex and edge, give the next $3$-bit substring, and
  so on.  Since all possible $2$-bit vertex labels appear exactly
  once, and each vertex has a $1$ edge and a $0$ edge departing from
  it, every $3$-bit string corresponds to a unique vertex/out-edge
  combination.  The path uses every possible vertex/out-edge
  combination exactly once, so the string contains every $3$-bit
  sequence exactly once.
\end{solution}

\ppart What about $k$-bit substrings, $k = 4, 5, \ldots$?  Can you define
the appropriate generalization of the useful graph above?  (They're called
de Bruijn graphs.) If you do it sucessfully, you should be able to see
that the in-degree (as well as the out-degree) of every vertex is $2$.

It is a theorem that if the in-degree is equal to the out-degree at
every vertex of a digraph (and if the graph is connected when all the
edges are considered undirected edges) then a directed path can be
drawn in that digraph that uses every edge exactly once.  You might
want to think about why this should be true or how you might find such
a path.

But if you do believe it, you should be able to see why all $2^k$
$k$-bit strings can be written as substrings of a string of length
$2^k + k-1$.  (These strings are essentially de Bruijn strings.)

\eparts

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp7m}
  \pcomment{from: S07.cp7m}
\end{pcomments}

\pkeywords{
  planar_graphs
  isomorphisms
  planar_embeddings
  recursive_data
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Figures 1--4 show different pictures of planar graphs.

\mfigure{!}{6in}{figures/cp7mfigs-new}
        
\bparts

\ppart For each picture, describe its discrete faces (simple cycles that
define the region borders).

\begin{solution}
Figs 1 \& 2: abda, bcdb, abcda.
Fig 3: abcdea, adea,abda,bcdb.  Fig 4: abcda, abdea, bdcb, adea.

\end{solution}

\ppart Which of the pictured graphs are isomorphic?  Which pictures
represent the same \emph{planar embedding}? -- that is, they have the same
discrete faces.

\begin{solution}
Figs 1 \& 2 have the same faces, so are different pictures of the
\emph{same} planar drawing.  Figs 3 \& 4 both have four faces, but they are
different, for example, Fig 3 has a face with 5 edges, but the
longest face in Fig 4 has 4 edges.
\end{solution}

\ppart Describe a way to construct the embedding in Figure 4 according to
the recursive definition of planar embedding (in the Appendix).

\begin{solution}
Here's one way.  By PS6, Problem 1, these steps could be done in
any order.

\[\begin{array}{ccr}
\text{recursive step} & & \text{faces}\\\hline
\text{vertex } a & \text{(base case)} & a\\
\text{vertex } b & \text{(base)} & b\\
\edge{a}{b} & \text{(bridge)} & aba\\
\text{vertex } c & \text{(base)} & c\\
\edge{b}{c} & \text{(bridge)} & abcba\\
\text{vertex } d & \text{(base)} & d\\
\edge{c}{d} & \text{(bridge)} & abcdcba\\
\edge{a}{d} & \text{(split)} & dabcd,\ dabcd\\
\edge{b}{d} & \text{(split)} & dabd,\ dbcd,\  abcda\\
\text{vertex } e & \text{(base)} & e\\
\edge{d}{e} & \text{(bridge)} & dedabd,\ dbcd,\  abcda\\
\edge{a}{e} & \text{(split)}  & abdea,\ adea,\ dbcd,\ abcda\\
\end{array}\]

\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp2m}
%  \pcomment{}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  translating_english_statements
  logic
  implies
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
When the Mathematician says to his student ``If a function is not
continuous, then it is not differentiable,'' then letting $D$ stand for
``differentiable'' and $C$ for continuous, the only proper translation of the
Mathematician's statement would be
\[
\QNOT(C)\ \QIMP\ \QNOT(D),
\]
or equivalently,
\[
D\ \QIMP\ C.
\]

But when a Mother says to her son, ``If you don't do your homework, then
you can't watch TV,'' then letting $T$ stand for ``watch TV'' and $H$ for
``do your homework'', a sensible transation of the Mother's statement would
be
\[
\QNOT(H)\ \QIFF\ \QNOT(T),
\]
or equivalently,
\[
H\ \QIFF\ T.
\]

Explain why it is reasonable to translate these two IF-THEN statements in
different ways into propositional formulas.

\begin{solution}
We know that a differentiable function must be continuous, so
  when a function is not continuous, it is also not differentiable.  Now
  Mathematicians use $\QIMP$ in the technical way given by its truth table.
  In particular, if a function \emph{is} continuous then to a
  Mathematician, the implication
\[
\QNOT(C)\ \QIMP\ \QNOT(D),
\]
is automatically true since the hypothesis (left hand side of the IMPLIES)
is false.  So whether or not continuity holds, the Mathematician could
comfortably assert the $\QIMP$ statement knowing it is correct.

And of course a Mathematician does \emph{not} mean $\QIFF$, since she
knows a function that is not differentiable may well be continuous.

On the other hand, while the Mother certainly means that her son cannot
watch TV if he does not do his homework, both she and her son \emph{most
  likely} understand that if he \emph{does} do his homework, then he
\emph{will} be allowed watch TV.  In this case, even though the Mother
uses an IF-THEN phrasing, she really means $\QIFF$.

On the other hand, circumstances in the household might be that the boy may
watch TV when he has not only done his homework, but \emph{also} cleaned up
his room.  In this case, just doing homework would not imply being allowed
to watch TV --the boy won't be allowed to watch TV if he hasn't cleaned his
room, even if he has done his homework.

The general point here is that semantics (meaning) trumps syntax (sentence
structure): even though the Mathematician's and Mother's statements have
the same structure, their meaning may warrant different translations into
precise logical language.

\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp7r}
\end{pcomments}

\pkeywords{
  digraphs
  cycles
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
\bparts

\ppart Give an example showing that two vertices in a digraph may be on
the same cycle, but \emph{not} necessarily on the same \emph{simple}
cycle.

\begin{solution}
Let the vertices be $a,b,c$ and edges be $(a,b), (b,a), (b,c),
(c,b)$.  Now $a$ and $c$ are on the cyle $a,b,c,b,a$, but every cycle from
$a$ to $c$ must go through $b$ at least twice, and so will not be simple.
\end{solution}

\ppart Prove that if two vertices in a digraph are connected, then they are
connected by a simple path.  \hint the shortest path.

\begin{solution}
Consider a shortest path from $a$ to $b \neq a$:
\[
a=a_0,a_1,\dots,a_i,\dots, a_j, \dots ,a_k=b,
\]
and suppose this path is not simple.  That is, suppose $a_i=a_j$ for some
$i,j$.  Then
\[
a=a_0,a_1,\dots,a_i, a_{j+1}, \dots ,a_k=b.
\]
is a shorter path from $a$ to $b$, a contradiction.

\end{solution}

\eparts


\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% fall 07 ps2, variant of S05, ps2
%revised by ARM to use WOP
\begin{problem}
We showed in lecture that set union distributes over intersection:
%
\begin{equation}\label{distr}
A \union (B_1 \intersect B_2) = (A \union B_1) \intersect (A \union B_2)
\end{equation}
%
Use this and the Well-ordering Principle to prove the following
extension of~\eqref{distr} to a Distributive Law for $n \geq 2$ sets:
%
\begin{equation}\label{AUBn}
  A \union (B_1 \intersect \cdots  \intersect B_{n-1} \intersect B_n)
  = (A \union B_1)  \intersect \cdots \intersect (A \union B_{n-1} ) \intersect (A \union B_n)
\end{equation}
%
Extending formulas to an arbitrary number of terms is a common (if
mundane) application of the WOP.

\begin{solution}

The proof is by contradiction.

Suppose to the contrary that~\eqref{AUBn} was not true for some $n \geq 2$ and
sets $A,B_1,\dots,B_n$.   Then by the WOP, there is a least such $m \in
\naturals$.  Now $m > 2$ by~\eqref{distr}.  Since $m> m-1 \geq 2$, we
have~\eqref{AUBn} at $m-1$, namely,
\begin{equation}\label{AUBm-1}
A \union (B_1 \intersect \cdots  \intersect B_{m-2} \intersect B_{m-1})
    = (A \union B_1) \intersect \cdots \intersect  (A \union B_{m-2})
    \intersect (A \union B_{m-1}).
\end{equation}
for all $A,B_1,\dots,B_{m-1}$.  But now

\begin{align*}
\lefteqn{A \union (B_1 \intersect \cdots \intersect B_{m-1} \intersect B_m)}\\
    & = A \union (B_1 \intersect \cdots \intersect B_{m-2} \intersect (B_{m-1} \intersect B_m)) & \text{(by def of $\intersect$)}\\
    & = A \union (B_1 \intersect \cdots
\intersect B_{m-2}\intersect C_{m-1}) & (\text{for } C_{m-1} \eqdef B_{m-1} \intersect B_m)\\
    & = (A \union B_1) \intersect \cdots
    \intersect (A \union B_{m-2}) \intersect (A \union C_{m-1}) &
    \text{(by~\eqref{AUBm-1} with $B_{m-1} = C_{m-1}$)}\\
    & = (A \union B_1) \intersect \cdots \intersect (A \union B_{m-2})
    \intersect (A \union (B_{m-1} \intersect B_m)) & \text{(def of $C_{m-1}$)}\\
    & = (A \union B_1) \intersect \cdots \intersect (A \union B_{m-2})
    \intersect ((A \union B_{m-1}) \intersect (A \union B_m)) & \text{(by~\eqref{distr})}\\
    & = (A \union B_1)  \intersect \cdots \intersect (A \union B_{m-1})
    \intersect (A \union B_m) & \text{(def of $\intersect$)}.
\end{align*}
This proves that~\eqref{AUBn} does hold for $n = m$, contradicting the
definition of $m$.

This contradiction implies that there cannot be an  $n \geq 2$ for
which~\eqref{AUBn} fails.  That is~\eqref{AUBn} holds for all $n \geq 2$.

\end{solution}
\end{problem}
%CP_divisibility_partial_order

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{9/254/09 from partial order notes problem, edited by ARM}
\end{pcomments}

\pkeywords{
 partial_order
 divisibility
 antisymmetry
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problems start here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%CP_divisibility_partial_order

\begin{problem}
\bparts

\ppart
Verify that the divisibility relation on the set of nonnegative integers is
a weak  partial order.
\begin{solution}

\TBA{TBA}

\end{solution}

\ppart What about the divisibility relation on the set of integers?

\begin{solution}
Divisibility is not antisymmetric on the integers, since $n \divides -n$.
\end{solution}

\eparts

\end{problem}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problems end here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

%CP_domain_of_discourse.tex

\begin{pcomments}
  \pcomment{from: S09.cp2t}
%  \pcomment{}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  quantifiers
  predicate_calculus
  domain_of_discourse
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
For each of the logical formulas, indicate whether or not it is true when
the domain of discourse is $\naturals$ (the nonnegative integers 0, 1, 2,
\dots), $\integers$ (the integers), $\rationals$ (the rationals), $\reals$
(the real numbers), and $\complexes$ (the complex numbers).

\[\begin{array}{rrrcl}
          & \exists x & (x^2 & = & 2)\\
\forall x & \exists y & (x^2 & = & y)\\
\forall y & \exists x & (x^2 & = & y)\\
\forall x\neq 0 & \exists y & (xy & = & 1)\\
\exists x & \exists y & (x + 2y & = & 2) \wedge (2 x + 4 y = 5)
\end{array}\]

\begin{solution}
\[
\begin{array}{llllll}
Statement & \naturals & \integers & \rationals & \reals & \complexes\\
\exists x\ (x^2=2) & f & f & f & t\ (x=\sqrt{2}) & t\\
\forall x \exists y\ (x^2 = y) & t & t & t & t\ (y=x^2)& t\\
\forall y \exists x\ (x^2=y) & f & f & f & f\ (\text{take }y<0) & t\\
\forall x\neq 0\exists y\ (xy=1) & f & f & t & t\ (y=1/x) & t\\
\exists x \exists y\ (x + 2y = 2) \wedge (2 x + 4 y = 5) & f & f & f & f & f
\end{array}
\]

\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
%CP_erasable_strings

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp5m}
  \pcomment{related to: S09.cp5m}
\end{pcomments}

\pkeywords{
  induction
  matching_parentheses
  recursive_data
  strings
  structural_induction
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
%
Let $p$ be the string $\mtt{()}$.  A string of parentheses is said to be
\term{erasable} iff it can be reduced to the empty string by repeatedly
erasing occurrences of $p$.  For example, here's how to erase the string
$\mtt{((())())()}$:
\[
\mtt{((())())()}
\rightarrow \mtt{(())}
\rightarrow \mtt{()}
\rightarrow \emptystring.
\]
On the other hand the string $\mtt{())((((())}$ is not erasable because
when we try to erase, we get stuck at $\mtt{)(((}$:
\[
\mtt{())((((())}
\rightarrow \mtt{)(((()}
\rightarrow \mtt{)(((}
\not\rightarrow
\]

Let $\ES$ be the set of erasable strings of parentheses.  Let $\RM$ be the
recursive data type of strings of \emph{matched} parentheses. 

% (The definition of $\RM$ is repeated in the Appendix.)

\bparts

\ppart Use structural induction to prove that
\[
\RM \subseteq \ES.
\]

\begin{solution}
\begin{proof}
We prove by structural induction on the definition of $\RM$ that
  the predicate
\[
P(x) \eqdef x \in \ES
\]
is true for all $x \in \RM$.

\textbf{Base case}: [$x = \emptystring$] The empty string is erasable by
definition of $\ES$ -- it can be reduced to itself by erasing the
substring $\mtt{()}$ 0 times.

\textbf{Constructor case}: [$x = \mtt{(}s\mtt{)}t$] for $s,t \in \RM$.  By
structural induction hypothesis, we may assume that $s,t \in \ES$.  So to
erase $x$, erase $s$ and then erase $t$ to be left with the substring
$\mtt{()}$, and one more erasure leads to the empty string.

This completes the proof by structural induction, so we conclude that
\[
\forall x.\ x\in \RM.\ \QIMPLIES\ x \in \ES
\]
which by definition means that $\RM \subseteq \ES$.

\end{proof}
\end{solution}

\ppart\label{RMES} Supply the missing parts of the following proof that
\[
\ES \subseteq \RM.
\]

\begin{proof}

We prove by induction on the length, $n$, of strings, $x$, that if $x \in
\ES$, then $x \in \RM$.  The induction predicate is
\[
P(n) \eqdef \forall x \in \ES.\, [\lnth{x} \leq n\ \QIMPLIES\ x \in \RM]
\]

\textbf{Base case}:

\textbf{ What is the base case?  Prove that $P$ is true in this case.}

\begin{solution}
The base case is [$n = 0$].  Now $P(0)$ is true because the
  empty string is the only string of length 0, and it is in $\RM$ by the
  base case of the recursive definition of $\RM$.
\end{solution}

\textbf{Inductive step}: To prove $P(n+1)$, suppose $\lnth{x} \leq n+1$
and $x \in \ES$.  We need only show that $x \in \RM$.  Now if $\lnth{x} <
n+1$, then the induction hypothesis, $P(n)$, implies that $x \in \RM$, so we
only have to deal with $x$ of length exactly $n+1$.

Let's say that a string $y$ is an \emph{erase} of a string $z$ iff $y$ is
the result of erasing a single occurrence of $p$ in $z$.

Since $x \in \ES$ and has positive length, there must be an erase, $y \in
\ES$, of $x$.  So $\lnth{y} = n-1$, and since $y \in \ES$, we may assume
by induction hypothesis that $y \in \RM$.

Now we argue by cases:

\textbf{Case} [$y$ is the empty string].

\textbf{Prove that $x \in \RM$ in this case.}

\begin{solution}
In this case $x = p \in \RM$.
\end{solution}

\textbf{Case} [$y = \mtt{(}s\mtt{)}t$ for some strings $s, t \in \RM$.]
Now we argue by subcases.
\begin{itemize}

\item \textbf{Subcase} [$x$ is of the form $\mtt{(}s'\mtt{)}t$ where $s$
  is an erase of $s'$].

  Since $s \in \RM$, it is erasable by part~\eqref{RMES}, which implies
  that $s'\in \ES$.  But $\lnth{s'} < \lnth{x}$, so by induction
  hypothesis, we may assume that $s' \in \RM$.  This shows that $x$ is
  the result of the constructor step of $\RM$, and therefore $x \in \RM$.

\item \textbf{Subcase} [$x$ is of the form $\mtt{(}s\mtt{)}t'$ where $t$ is an
  erase of $t'$].

  \textbf{Prove that $x \in \RM$ in this subcase.}

\begin{solution}
The proof is essentially identical to the previous case, with
  $t,t'$ in place of $s,s'$:

  Now $t$ is erasable by part~\eqref{RMES}, so $t'\in \ES$.  But
  $\lnth{t'} < \lnth{x}$, so by induction hypothesis, we may assume that
  $t' \in \RM$.  This proves that $x$ is the result of the constructor
  step of $\RM$ and therefore $x \in \RM$.

\end{solution}

\item \textbf{Subcase}[$x=p\mtt{(}s\mtt{)}t$].

  \textbf{Prove that $x \in \RM$ in this subcase.}

\begin{solution}
Let $t' \eqdef \mtt{(}s\mtt{)}t$ and $s'$ be the empty string.
  Then $x = \mtt{(}s'\mtt{)}t'$.  But we know $s',t' \in \RM$, which
  implies that $x \in \RM$ because it is the result the $\RM$ constructor
  step applied to $s',t'$.
\end{solution}

\end{itemize}

The proofs of the remaining subcases are just like this last one.
\textbf{List these remaining subcases.}

\begin{solution}
\begin{itemize}

\item \textbf{case} [$x=\mtt{(}ps\mtt{)}t$],
\item \textbf{case} [$x=\mtt{(}sp\mtt{)}t$],
\item \textbf{case} [$x=\mtt{(}s\mtt{)}pt$],
\item \textbf{case} [$x=\mtt{(}s\mtt{)}tp$].
\end{itemize}

\end{solution}

This completes the proof by induction on $n$, so we conclude that $P(n)$
holds for all $n \in \naturals$.  Therefore $x \in \RM$ for every string
$x \in \ES$.  That is,
\[
\ES \subseteq \RM \text{  and hence  } \ES = \RM.
\]
\end{proof}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp1t}
%  \pcomment{}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  faulty_logic
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem} It's a fact that the Arithmetic Mean is at least as
large the Geometric Mean, namely,
\[
\frac{a + b}{2} \geq \sqrt{a b}
\]
for all nonnegative real numbers $a$ and $b$.  But there's something
objectionable about the following proof of this fact.  What's the
objection, and how would you fix it?

\begin{bogusproof}
\begin{align*}
\frac{a + b}{2} & \stackrel{?}{\geq} \sqrt{a b}, & \text{ so} \\
a + b  & \stackrel{?}{\geq} 2 \sqrt{a b}, & \text{ so} \\
a^2 + 2 a b + b^2  & \stackrel{?}{\geq} 4 a b, & \text{ so}\\
a^2 - 2 a b + b^2  & \stackrel{?}{\geq} 0, & \text{ so}\\
(a - b)^2  & \geq 0 & \text{ which we know is true.}
\end{align*}

The last statement is true because $a - b$ is a real number, and the
square of a real number is never negative.  This proves the claim.
\end{bogusproof}

\begin{solution}
In this argument, we started with what we wanted to prove and
then reasoned until we reached a statement that is surely true.  The
little question marks presumably are supposed to indicate that we're not
quite certain that the inequalities are valid until we get down to the
last step.  At that step, the inequality checks out, \emph{but that
doesn't prove the claim}.  All we have proved is that \textbf{if} $(a + b)/2
\geq \sqrt{a b}$, \textbf{then} $(a - b)^2 \geq 0$, which is not very
interesting, since we already knew that the square of any nonnegative
number is nonnegative.

To be fair, this bogus proof is pretty good: if it was written in reverse
order -- or if ``is implied by'' was simply inserted after each line -- it
would actually prove the Arithmetic-Geometric Mean Inequality:

\begin{proof}

\begin{align*}
\frac{a + b}{2} & \geq \sqrt{a b} & \text{ is implied by}\\
a + b  & \geq 2 \sqrt{a b},  & \text{ which is implied by}\\
a^2 + 2 a b + b^2  & \geq 4 a b, & \text{ which is implied by}\\
a^2 - 2 a b + b^2  & \geq 0, & \text{ which is implied by}\\
(a - b)^2  & \geq 0.
\end{align*}

The last statement is true because $a - b$ is a real number, and the
square of a real number is never negative.  This proves the claim.
\end{proof}

But the problem with the bogus proof as written is that it reasons
backward, beginning with the proposition in question and reasoning to a
true conclusion.  This kind of backward reasoning can easily ``prove''
false statements.  Here's an example:

\textbf{Bogus Claim}: $0 = 1$.
\begin{bogusproof}
\begin{align*}
0 & \stackrel{?}{=} 1, & \text{ so} \\
1 & \stackrel{?}{=} 0, & \text{ so} \\
0+1 & \stackrel{?}{=} 1+0, & \text{ so} \\
1 & = 1 & \text{ which is trivially true,}
\end{align*}
which proves $0=1$.
\end{bogusproof}

We can also come up with very easy ``proofs'' of true theorems, for
example, here's an easy ``proof'' of the Arithmetic-Geometric Mean
Inequality:

\begin{bogusproof}
\begin{align*}
\frac{a + b}{2} & \stackrel{?}{\geq} \sqrt{a b}, & \text{ so}\\
0 \cdot \frac{a + b}{2} & \stackrel{?}{\geq} 0 \cdot \sqrt{a b}, & \text{ so}\\
0 & \geq 0 & \text{ which is trivially true.}\quad \qedhere
\end{align*}
\end{bogusproof}

So watch out for backward proofs!

\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp9t}
\end{pcomments}

\pkeywords{
  asymptotics
  induction
  false_proof
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem} 
\begin{falseclm*}
\begin{equation}\label{2n1}
2^n = O(1).
\end{equation}
\end{falseclm*}

Explain why the claim is false.  Then identify and explain the mistake in
the following bogus proof.

\begin{bogusproof} The proof by induction on $n$ where the induction 
hypothesis, $P(n)$, is the assertion~\eqref{2n1}.

{\bf base case:}  $P(0)$ holds trivially.

{\bf inductive step:} We may assume $P(n)$, so there is a constant $c >0$
such that $2^n \leq c \cdot 1$.  Therefore,
\[
2^{n+1} = 2 \cdot 2^n \leq (2c) \cdot 1,
\]
which implies that $2^{n+1} = O(1)$.  That is, $P(n+1)$ holds, which
completes the proof of the inductive step.

We conclude by induction that $2^n = O(1)$ for all $n$.  That is, the
exponential function is bounded by a constant.

\end{bogusproof}

\begin{solution}
A function is $O(1)$ iff it is bounded by a constant, and since
the function $2^n$ grows unboundedly with $n$, it is not $O(1)$.

The mistake in the bogus proof is in its misinterpretation of the
expression $2^n$ in assertion~\eqref{2n1}.  The intended interpration
of~\eqref{2n1} is
\begin{equation}\label{f=exp}
\text{Let $f$ be the function defined by the rule $f(n) \eqdef 2^n$.  Then
$f = O(1)$.}
\end{equation}
But the bogus proof treats~\eqref{2n1} as an assertion, $P(n)$, about $n$.
Namely, it misinterprets~\eqref{2n1} as meaning:
\begin{quote}
  Let $f_n$ be the constant function equal to $2^n$.  That is, $f_n(k)
  \eqdef 2^n$ for all $k \in \naturals$.  Then
\begin{equation}\label{fn=c}
f_n = O(1).
\end{equation}
\end{quote}
Now~\eqref{fn=c} is true since every constant function is $O(1)$, and the
bogus proof is an unnecessarily complicated, but \emph{correct}, proof that
that for each $n$, the constant function $f_n$ is $O(1)$.  But in the
last line, the bogus proof switches from the misinterpretation~\eqref{fn=c}
and claims to have proved~\eqref{f=exp}.

So you could say that the exact place where the proof goes wrong is in its
first line, where it defines $P(n)$ based on
misinterpretation~\eqref{fn=c}.  Alternatively, you could say that the
proof was a correct proof (of the misinterpretation), and its first mistake
was in its last line, when it switches from the misinterpretation to the
proper interpretation~\eqref{f=exp}.
\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp4r}
  \pcomment{remove hard link to week 4 notes}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  false_proof
  induction
  ordinary_induction
  series
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
We've proved in two different ways that
\[
1 + 2 + 3 + \cdots + n = \frac{n(n+1)}{2}
\]
%
But now we're going to prove a \textit{contradictory} theorem!

\begin{falsethm*}
For all $n \geq 0$,
%
\[
2 + 3 + 4 + \cdots + n = \frac{n(n+1)}{2}
\]
\end{falsethm*}

\begin{proof}
We use induction.  Let $P(n)$ be the proposition that $2 + 3 + 4 +
\cdots + n = n(n+1)/2$.

\noindent \textit{Base case:} $P(0)$ is true, since both sides of the
equation are equal to zero.  (Recall that a sum with no terms is
zero.)

\noindent \textit{Inductive step:} Now we must show that $P(n)$
implies $P(n+1)$ for all $n \geq 0$.  So suppose that $P(n)$ is true;
that is, $2 + 3 + 4 + \cdots + n = n(n+1)/2$.  Then we can reason as
follows:
%
\begin{align*}
2 + 3 + 4 + \cdots + n + (n+1)
    & = \bigl[2 + 3 + 4 + \cdots + n\bigr] + (n+1) \\
    & = \frac{n(n+1)}{2} + (n+1) \\
    & = \frac{(n+1)(n+2)}{2}
\end{align*}
%
Above, we group some terms, use the assumption $P(n)$, and then
simplify.  This shows that $P(n)$ implies $P(n+1)$.  By the principle
of induction, $P(n)$ is true for all $n \in \mathbb{N}$.
\end{proof}

Where exactly is the error in this proof?

% \noindent \textit{Discuss your explanation with your recitation
% instructor.  We don't want you to conclude that there is something
% wrong with induction proofs in general!}

\begin{solution}
The short answer is that we failed to prove $P(0) \implies
P(1)$, just as in the colored horses problem in lecture.  In fact,
once again, the error is rooted in the misleading nature of the
``$\cdots$'' notation.

More precisely, in the inductive step we are required to prove that
$P(n)$ implies $P(n+1)$ for all $n \geq 0$.  However, the argument
given above breaks down when $n = 0$.  Let's look more closely at the
first equation in the indutive step to see why:
%
\[
2 + 3 + 4 + \cdots + n + (n+1)
     = \bigl[2 + 3 + 4 + \cdots + n\bigr] + (n+1)
\]
%
This seems completely innocuous; after all, we've only grouped terms!
However, the left side contains \textit{no terms} when $n = 0$.  The
``$\cdots$'' is completely misleading in this case; 2, 3, 4, and
$n+1$ are actually \textit{not} in the sum.  This misimpression
becomes an error when we ``pull out'' the $(n+1)$ term on the right
side, disregarding the fact that no such term actually existed on the
left.  Thus, for $n = 0$, the equation we've just written down says:
%
\[
\underbrace{2 + 3 + 4 + \cdots + n + (n+1)}_{= 0}
     = \bigl[\underbrace{2 + 3 + 4 + \cdots + n}_{= 0}\bigr] +
       \underbrace{(n+1)}_{= 1}
\]
%
The assertion $0 = 0 + 1$ is false, and so we have not shown that
$P(0)$ implies $P(1)$.  There is no way to fix this problem and
correctly prove that $P(0)$ implies $P(1)$, because actually $P(0)$ is
true and $P(1)$ is false.

Thus, we've only established $P(0)$, $P(1) \implies P(2)$, $P(2)
\implies P(3)$, and so forth.  The induction argument falls apart
because of the missing link $P(0) \not\implies P(1)$.
\end{solution}
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp5t}
\end{pcomments}

\pkeywords{
  state_machines
  termination
  partial_correctness
  invariant
  exponentiation
  algorithm
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
The most straightforward way to compute the $b$th power of a number, $a$,
is to multiply $a$ by itself $b$ times.  This of course requires $b-1$
multiplications.  There is another way to do it using considerably fewer
multiplications.  This algorithm is called \emph{Fast Exponentiation}:

Given inputs $a \in \reals, b \in \naturals$,
initialize registers $x,y,z$ to $a,1,b$ respectively,
and repeat the following sequence of steps until termination:
\begin{itemize}
\item if $z=0$ \textbf{return} $y$ and terminate
\item $r := \text{remainder}(z,2)$
\item $z := \text{quotient}(z,2)$
\item if $r = 1$, then $y := xy$
\item $x := x^2$
\end{itemize}
We claim this algorithm always terminates and leaves $y = a^b$.

\bparts

\ppart  Model this algorithm with a state
machine, carefully defining the states and transitions.

\begin{solution}
\begin{enumerate}
\item The set of states is $\reals \cross \reals \cross \naturals$,
\item The start state is $(a,1,b)$,
\item the transitions are defined by the rule
\begin{equation*}
(x,y,z) \rightarrow
\begin{cases}
(x^2, y, \text{quotient}(z,2)) & \text{if $z$ is positive and even},\\
(x^2, xy, \text{quotient}(z,2)) & \text{if $z$ is positive and odd}.
\end{cases}
\end{equation*}
\end{enumerate}

\end{solution}

\ppart Let $d \eqdef a^b$.  Verify that the following predicate, $P$, is
a preserved invariant:
\[
P((x,y,z)) \eqdef\ \ [yx^z = d].
\]

\begin{solution}
We show that $P$ is preserved, namely, assuming $P((x,y,z))$, that is,
\begin{equation}\label{yxzd}
yx^z = d
\end{equation}
holds and $(x,y,z) \rightarrow (x_t,y_t,z_t)$ is a transition, then
$P((x_t,y_t,z_t))$, that is,
\[
y_tx_t^{z_t} = d
\]
holds.

We consider two cases:

If $z > 0$ and is even, then we have that $x_t = x^2, y_t = y, z_t =
\quotient(z,2)$.  Therefore,
\begin{align*}
y_tx_t^{z_t} &  = yx^{2 \cdot \quotient(z,2)}\\
           & = yx^{2 \cdot \frac{z}{2}}\\
           & = yx^z\\
          & = d & \mbox{(by~\eqref{yxzd})}
\end{align*}

If $z > 0$ and is odd, then we have that $x_t = x^2, y_t = xy, z_t =
\quotient(z,2)$. Therefore,
\begin{align*}
y_tx_t^{z_t} & = xyx^{2 \cdot \quotient(z,2)}\\
& = yx^{1+2 \cdot \frac{z-1}{2}}\\
& = yx^{1+(z-1)}\\
& = yx^z\\
& = d & \mbox{(by~\eqref{yxzd})}
\end{align*}

So in both cases, $P((x_t,y_t,z_t))$ holds, proving that $P$ is a
preserved invariant.
\end{solution}

\ppart Prove that the algorithm is partially correct: if it halts, it does
so with $y=d$.

\begin{solution}
$P$ holds for the start state $(a,1,b)$ since $1\cdot a^b = a^b
  =d$ by definition.  So by the Invariant Theorem, $P$ holds for all
  reachable states.  But a terminal state must have $z = 0$, so if any
  terminal state $(x,y,0)$ is reachable, then $y = yx^0 = d$ as required.
\end{solution}

\ppart Prove that the algorithm terminates.

\begin{solution}
Just notice that $z$ is a natural-number-valued variable that
gets smaller at every transition.  So by the Well-Ordering Principle, when
this variable reaches its minimum value, the algorithm terminates.
\end{solution}

\ppart In fact, prove that it requires at most $2 \log_2 b$
multiplications for the Fast Exponentiation algorithm to compute $a^b$ for
$b>1$.

\begin{solution}
The value of $z$ is initially $b$ and gets halved at least at
every step.  So it can't be halved more than $\log_2 b$ times before
hitting zero.
\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp5t}
\end{pcomments}

\pkeywords{
  state_machines
  unreachable_states
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem} 
  By now you are very familiar with the
  \href{http://courses.csail.mit.edu/6.042/spring09}{6.042 icon} that
  appears on the course webpage and lecture slides.  This icon is a
  picture of a game called the \textbf{Fifteen Puzzle}.  In this problem
  you will establish a basic property of the Fifteen Puzzle using the
  method of invariants, which may help you appreciate why this icon was
  chosen as the course logo.

The Fifteen Puzzle consists of sliding square tiles numbered $1,\dots,15$
held in a $4\times4$ frame with one empty square.  Any tile adjacent to
the empty square can slide into it.

The standard initial position is
\[\begin{array}{|c|c|c|c|}
\hline 1 & 2 & 3 & 4\\
\hline 5 & 6 & 7 & 8\\
\hline 9 & 10 & 11 & 12\\
\hline 13 & 14  & 15 &  \\
\hline
\end{array}\]
We would like to reach the target position (known in my youth as ``the
impossible'' --- ARM):
\[\begin{array}{|c|c|c|c|}
\hline 15 & 14 & 13 & 12\\
\hline 11 & 10 & 9 & 8\\
\hline7 & 6 & 5 & 4\\
\hline3 & 2 & 1 & \\
\hline
\end{array}\]

A state machine model of the puzzle has states consisting of a $4\times 4$
matrix with 16 entries consisting of the integers $1,\dots,15$ as well as
one ``empty'' entry---like each of the two arrays above.

The state transitions correspond to exchanging the empty square and an
adjacent numbered tile.  For example, an empty at position $(2,2)$ can
exchange position with tile above it, namely, at position $(1,2)$:
\[\begin{array}{|c|c|c|c|}
\hline n_1 & n_2 & n_3 & n_4\\
\hline n_5 &  & n_6 & n_7\\
\hline n_8  & n_9 & n_{10} & n_{11}\\
\hline n_{12} & n_{13} & n_{14}  & n_{15}\\
\hline
\end{array} \longrightarrow
\begin{array}{|c|c|c|c|}
\hline n_1 &   & n_3 & n_4\\
\hline n_5 & n_2 & n_6 & n_7\\
\hline n_8  & n_9 & n_{10} & n_{11}\\
\hline n_{12} & n_{13} & n_{14}  & n_{15}\\
\hline
\end{array} 
\]

We will use the invariant method to prove that there is no way to reach
the target state starting from the initial state.

We begin by noting that a state can also be represented as a pair
consisting of two things:
\begin{enumerate}
\item a list of the numbers $1,\dots,15$ in the order in which they
appear---reading rows left-to-right from the top row down, ignoring the
empty square, and
\item the coordinates of the empty square---where the upper left
square has coordinates $(1,1)$, the lower right $(4,4)$.
\end{enumerate}

\bparts
\ppart Write out the ``list'' representation of the start state and the
``impossible'' state.

\begin{solution}
start: $((1\ 2\ \dots\ 15), (4,4))$,

impossible: $((15\ 14\ \dots\ 1), (4,4))$. 

\end{solution}
\eparts

Let $L$ be a list of the numbers $1,\dots,15$ in some order.  A pair of
integers is an \emph{out-of-order pair} in $L$ when the first element of
the pair both comes \emph{earlier} in the list and \emph{is larger}, than
the second element of the pair.  For example, the list $1,2,4,5,3$ has two
out-of-order pairs: (4,3) and (5,3).  The increasing list $1,2\dots n$ has
no out-of-order pairs.

Let a state, $S$, be a pair $(L, (i,j))$ described above.  We define the
\emph{parity} of $S$ to be the mod 2 sum of the number, $p(L)$, of
out-of-order pairs in $L$ and the row-number of the empty square, that is
the parity of $S$ is $p(L) + i \pmod 2$.

\begin{problemparts}

\problempart Verify that the parity of the start state and the target
state are different.

\begin{solution}
The parity of the start state is
\[
(0+4) \bmod 2 = 0.
\]
The parity of the target is 
\[
((15 \cdot 14/ 2) + 4) \bmod 2 = 1.
\]

\end{solution}

\problempart Show that the parity of a state is preserved under
transitions.  Conclude that ``the impossible'' is impossible to reach.

\begin{solution}
To show that the parity is constant, consider how moves may
affect the parity.  There are only 4 types of moves: a move to the
left, a move to the right, a move to the row above, or a move to the row
below.

Note that horizontal moves change nothing, and vertical moves both change
$i$ by 1, and move a tile three places forward or back in the list, $L$.
To consider how the parity is changed in this case, we need to consider
only the 3 pairs in $L$ that are between the tile's old and new position.
(The other pairs are not effected by the tile's move).  This reverses the
order of three pairs in $L$, changing the number of inversions by 3 or 1,
but always by an odd amount.

To confirm this last remark, note that if the 3 pairs were all out of
order or all in order before, the amount is changed by 3.  If two pairs
were out of order and 1 pair was in order or if one pair was out of order
and two were in order, this will change the amount by 1.  So the sum of
$i$ and the number of out-of-order pairs changes by an even amount (either
1+3 or 1+1), which implies that its parity remains the same.  Since the
initial state has parity 0 (even), all states reachable from the initial
state must have parity 0, so the target state with parity 1 can't be
reachable.
\end{solution}

\end{problemparts}

By the way, if two states have the same parity, then in fact there
\emph{is} a way to get from one to the other.  If you like puzzles, this
is a good one to think about on your own after class.

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp2m, Rosen}
%  \pcomment{}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  translating_english_statements
  logic
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem} 
This problem\footnote{From Rosen, 5th edition, Exercise 1.1.36} examines
whether the following specifications are satisfiable:

\begin{enumerate}

\item If the file system is not locked, then

   \begin{enumerate}

   \item new messages will be queued.

   \item new messages will be sent to the messages buffer.

   \item the system is functioning normally, and conversely, if the system
         is functioning normally, then the file system is not locked.

   \end{enumerate}

\item  If new messages are not queued, then they will be sent to
the messages buffer.

\item  New messages will not be sent to the message buffer.

\end{enumerate}

\bparts

\ppart Begin by translating the five specifications into
propositional formulas using four propositional variables:
\begin{eqnarray*}
L   & \eqdef &   \text{file system locked}, \\
Q   & \eqdef &   \text{new messages are queued}, \\
B   & \eqdef &   \text{new messages are sent to the message buffer}, \\
N   & \eqdef &   \text{system functioning normally}.
\end{eqnarray*}

\begin{solution}
The translations of the specifications are:
\begin{align}
\QNOT L  \QIMPLIES & Q & \tag{Spec.\ 1.(a)}\\
\QNOT L  \QIMPLIES & B & \tag{Spec.\ 1.(b)}\\
\QNOT L  \QIFF  & N & \tag{Spec.\ 1.(c)}\\
\QNOT Q  \QIMPLIES & B & \tag{Spec.\ 2.}\\
\QNOT B           &   & \tag{Spec.\ 3.}
\end{align}
\end{solution}

\ppart\label{assign} Demonstrate that this set of specifications is
satisfiable by describing a single truth assignment for the variables
$L,Q,B,N$ and verifying that under this assignment, all the specifications
are true.

\begin{solution}
An assignment that works is
\begin{eqnarray*}
L       & = &   \text{True} \\
N       & = &   \text{False} \\
Q       & = &   \text{True} \\
B       & = &   \text{False}.
\end{eqnarray*}

To find this assignment, we could have started constructing the sixteen
line truth table ---one line for each way of assigning truth values to the
four variables $L$, $N$, $Q$, and $B$ ---and calculated the truth value of
the AND of all the five specifications under that assignment, continuing
until we got one that made the AND-formula true.

If for every one of the sixteen possible truth assignments, the AND-formula
was false, then the system is not satisfiable.
\end{solution}

\ppart Argue that the assignment determined in
part~\eqref{assign} is the only one that does the job.

\begin{solution}
We can avoid calculating all 16 rows of the full truthtable
  calculation suggested in the previous solution to part~\eqref{assign} by
  reasoning as follows.  In any truth assignment that makes all five
  specifications true,
\begin{itemize}

\item $B$ must be false, or the last specification, (Spec.\ 3.), would be
false.

\item Given that $B$ is false, (Spec.\ 2.) and (Spec.\ 1.(b)) can be
true only if $Q$ and $L$ are true.

\item Given that $L$ is true, (Spec.\ 1.(c)) can
be true only if $N$ is false.

\end{itemize}
Thus, in order for all five specifications to be true, the assignment must be:
\begin{eqnarray*}
L       & = &   \text{True} \\
N       & = &   \text{False} \\
Q       & = &   \text{True} \\
B       & = &   \text{False}.
\end{eqnarray*}

\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: F09.ps3}
  \pcomment{from: S02.ps2}
\end{pcomments}

\pkeywords{
  induction
  false_proof
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
  Find the flaw in the following "proof" that $a^n = 1$ for all
  nonnegative integers $n$, whenever $a$ is a nonzero real number.

\begin{proof}
(by induction)

\textbf{Base Case:} $a^0 =1$ is true by definition of $a^0$.

\textbf{Inductive Step:} Assume that $a^k = 1$ for all nonnegative
integers $k$ with $k \leq n$. Then note that
\[
a^{n+1} = \frac{a^n \cdot a^n}{a^{n-1}} = \frac{1 \cdot 1}{1} = 1.
\]
\end{proof}

\begin{solution}
The flaw comes in the inductive step, where we implicitly assume
$n\geq 1$ in order to talk about $a^{n-1}$ in the denominator
(otherwise the exponent is not a nonnegative integer, so we cannot
apply the inductive hypothesis).  We checked the base case only for
$n=0$, so we are not justified in assuming that $n\geq 1$ when we try
to prove the statement for $n+1$ in the inductive step.  Indeed, the
proposition first breaks precisely at $n=1$.
\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp8t, S06.cp7m}
%  \pcomment{}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  number_theory
  gcd
  lcm
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}

\bparts

\ppart Let $m = 2^9 5^{24} 11^{7} 17^{12}$ and $n = 2^3 7^{22} 11^{211}
13^1 17^{9} 19^2$.  What is the $\gcd(m,n)$?  What is the \emph{least
common multiple}, $\lcm(m,n)$, of $m$ and $n$?  Verify that
\begin{equation}\label{gl}
\gcd(m,n) \cdot \lcm(m,n) = mn.
\end{equation}

\begin{solution}
\begin{align*}
g & = 2^3 11^7 17^9,\\
l & = 2^9 5^{24} 7^{22} 11^{211} 13^1 17^{12} 19^2\\
gl & = 2^{12} 5^{24} 7^{22} 11^{218} 13^1 17^{21} 19^2 = mn
\end{align*}

\end{solution}

\ppart Describe in general how to find the $\gcd(m,n)$ and $\lcm(m,n)$
from the prime factorizations of $m$ and $n$.  Conclude that
equation~\eqref{gl} holds for all positive integers $m,n$.

\iffalse \hint You may find it helpful to consider Lemma~\ref{mn}
below.
\fi

\begin{solution}
\iffalse By Lemma~\ref{mn}, \fi The divisors of $m$ correspond
to subsequences of the weakly increasing sequence of primes in the
factorization of $m$, and likewise for $n$.  So the factorization
$\gcd(m,n)$ is the largest common subsequence of the two factorizations.
This can be calculated by taking all the primes that appear in both
factorizations raised to the \emph{minimum} of the powers of that prime in
each factorization.

Likewise, the factorization of $\lcm(m,n)$ is the shortest sequence that
has the factorizations of $m$ and $n$ as subsequences.  So the
factorization of $\lcm(m,n)$ can be calculated by taking all the primes that
appear in either factorization raised to the \emph{maximum} of the powers
of that prime in each factorization.

So in the factorization of $\gcd(m,n) \cdot \lcm(m,n)$ each prime appears raised
to a power equal to the sum of its powers in the factorizations of $m$ and
$n$, which is precisely its power in the factorization of $mn$.
\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp1r}
  \pcomment{Remove inline proof in favor of link to notes version in
            preceding text.}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  root_2
  irrational
  rational
  contradiction
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}\label{generprob}
  Generalize the proof from lecture (reproduced below) that $\sqrt{2}$ is
  irrational, for example, how about $\sqrt[3]{2}$?  Remember that an
  irrational number is a number that cannot be expressed as a ratio of two
  integers.

\begin{quote}

\begin{theorem*}
$\sqrt{2}$ is an irrational number.
\end{theorem*}

\begin{proof}
  The proof is by contradiction: assume that $\sqrt{2}$ is rational, that
  is,
  \begin{equation}\label{2nd}
    \sqrt{2} = \frac{n}{d},
  \end{equation}
  where $n$ and $d$ are integers.  Now consider the smallest such positive
  integer denominator, $d$.  We will prove in a moment that the numerator,
  $n$, and the denominator, $d$, are both even.  This implies that
         \[
        \frac{n/2}{d/2}
        \]
  is a fraction equal to $\sqrt{2}$ with a smaller positive integer
  denominator, a contradiction.

\begin{quote}
\emph{Since the assumption that $\sqrt{2}$ is rational leads to this
  contradiction, the assumption must be false.  That is, $\sqrt{2}$ is
  indeed irrational.}  This italicized comment on the implication of the
contradiction normally goes without saying, but since this is the first
6.042 exercise about proof by contradiction, we've said it.
\end{quote}

  To prove that $n$ and $d$ have 2 as a common factor, we start by
  squaring both sides of~\eqref{2nd} and get $2 = n^2 / d^2$, so
\begin{equation}\label{2d2}
2 d^2 = n^2.
\end{equation}
So 2 is a factor of $n^2$, which is only possible if 2 is in fact a
factor of $n$.

This means that $n=2k$ for some integer, $k$, so
\begin{equation}\label{n24}
  n^2 = (2k)^2 = 4 k^2.
\end{equation}
Combining~\eqref{2d2} and~\eqref{n24} gives $2 d^2 = 4 k^2$, so
\begin{equation}\label{n22}
d^2 = 2k^2.
\end{equation}
So 2 is a factor of $d^2$, which again is only possible if 2 is in fact
also a factor of $d$, as claimed.
\end{proof}
\end{quote}

\begin{solution}
\begin{proof}
We prove that for any $n>1$, $\sqrt[n]{2}$ is irrational by
contradiction.

Assume that $\sqrt[n]{2}$ is rational.  Under this assumption, there exist
integers $a$ and $b$ with $\sqrt[n]{2} = a/b$, where $b$ is the smallest
such positive integer denominator.  Now we prove that $a$ and $b$ are both
even, so that
         \[
        \frac{a/2}{b/2}
        \]
  is a fraction equal to $\sqrt[n]{2}$ with a smaller positive integer
  denominator, a contradiction.

\begin{eqnarray*}
\sqrt[n]{2} & = & \frac{a}{b}\\
2 & = & \frac{a^{n}}{b^{n}}\\
2b^{n} & = & a^{n}.
\end{eqnarray*}
The lefthand side of the last equation is even, so $a^{n}$ is even.  This
implies that $a$ is even as well (see below for justification).

In particular, $a = 2c$ for some integer $c$.  Thus, 
\begin{eqnarray*}
2b^{n} & = & (2c)^n = 2^{n}c^{n},\\
b^{n} & = & 2^{n-1}c^{n}.
\end{eqnarray*}
Since $n-1>0$, the righthand side of the last equation is an even number,
so $b^{n}$ is even.  But this implies that $b$ must be even as well,
contradicting the fact that $a/b$ is in lowest terms.
\end{proof}

Now we justify the claim that if $a^n$ is even, so is $a$.

There is a simple proof by contradiction: suppose to the contrary that $a$
is odd.  It's a familiar (and easily verified\footnote{Two odd integers
  can be written as $2x+1$ and $2y+1$ for some integers $x$ and $y$.  Then
  their product is also odd because it equals $2z +1$ where $z=
  2(2xy+x+y)+1$.}) fact that the product of two odd numbers is odd, from
which it follows that the product of \emph{any} finite number of odd
numbers is odd, so $a^n$ would also be odd, contradicting the fact that
$a^n$ is even.

More generally for \emph{any} integers $m,k >0$, if $m^k$ is divisible
by a prime number, $p$, then $m$ must be divisible by $p$.  This follows
from the factorization of an integer into primes (which we'll discuss
further in a coming lecture): the primes in the factorization of $m^k$ are
precisely the primes in the factorization of $m$ repeated $k$ times, so if
there is a $p$ in the factorization of $m^k$ it must be one of $k$ copies
of a $p$ in the factorization of $m$.
\end{solution}
\end{problem}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp9m}
  \pcomment{from: S07.cp9m}
\end{pcomments}

\pkeywords{
  harmonic_numbers
  integral_method
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
There is a number $a$ such that $\sum_{i=1}^\infty i^p$ converges iff $p <
a$.  What is the value of $a$?  Prove it.

\begin{solution}
$a= -1$.

For $p=-1$, the sum is the harmonic series which we know does not
converge.  Since the term $i^p$ is increasing in $p$ for $i>1$, the sum
will be larger, and hence also diverge for $p>-1$.

For $p<-1$ there exists an $\epsilon > 0$ such that $p =
-(1+\epsilon)$. By the integral method,

\begin{align*}
 \sum_{i=1}^\infty i^{-(1+\epsilon)}
    & \leq 1 + \int_{1}^{\infty} x^{-(1+\epsilon)}\, dx\\
    & = 1 + \epsilon^{-1} - \epsilon^{-1}
                \lim_{\alpha \to \infty} \alpha^{-\epsilon}\\
    & = 1 + \epsilon^{-1}\\
    & < \infty 
\end{align*}
Hence the sum is bounded above, and since it is increasing, it has a
finite limit, that is, it converges.
\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp9m}
  \pcomment{has a commented out part}
\end{pcomments}

\pkeywords{
  harmonic_numbers
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
An explorer is trying to reach the Holy Grail, which she believes is
located in a desert shrine $d$ days walk from the nearest oasis.  In the
desert heat, the explorer must drink continuously.  She can carry at most
1 gallon of water, which is enough for 1 day.  However, she is free to
create water caches out in the desert.

For example, if the shrine were $2/3$ of a day's walk into the desert,
then she could recover the Holy Grail with the following strategy.
She leaves the oasis with 1 gallon of water, travels $1/3$ day into
the desert, caches $1/3$ gallon, and then walks back to the oasis---
arriving just as her water supply runs out.  Then she picks up another
gallon of water at the oasis, walks $1/3$ day into the desert, tops
off her water supply by taking the $1/3$ gallon in her cache, walks
the remaining $1/3$ day to the shine, grabs the Holy Grail, and then
walks for $2/3$ of a day back to the oasis--- again arriving with no
water to spare.

But what if the shrine were located farther away?

\bparts

\ppart What is the most distant point that the explorer can reach and then
return to the oasis if she takes only 1 gallon from the oasis?

\begin{solution}
At best she can walk $1/2$ day into the desert and then walk
  back.
\end{solution}

\ppart What is the most distant point the explorer can reach and still
return to the oasis if she takes only 2 gallons from the oasis?  No proof
is required; just do the best you can.

\begin{solution}
The explorer walks $1/4$ day into the desert, drops $1/2$
  gallon, then walks home.  Next, she walks $1/4$ day into the desert,
  picks up $1/4$ gallon from her cache, walks an additional $1/2$ day out
  and back, then picks up another $1/4$ gallon from her cache and walks
  home.  Thus, her maximum distance from the oasis is $3/4$ of a day's
  walk.
\end{solution}


\iffalse
\ppart What about 3 gallons?  \hint First, try to establish a cache of 2
gallons \textit{plus} enough water for the walk home as far into the
desert as possible.  Then use this cache as a springboard for your
solution to the previous part.

\begin{solution}
Suppose the explorer makes three
trips $1/6$ day into the desert, dropping $2/3$ gallon off units each
time.  On the third trip, the cache has 2 gallons of water, and the
explorer still has $1/6$ gallon for the trip back home.  So, instead of
returning immediately, she uses the solution described above to
advance another $3/4$ of a day into the desert and then returns home.
Thus, she reaches 
%
\[
\frac{1}{6} + \frac{1}{4} + \frac{1}{2} = \frac{11}{12}
\]
%
of a days' walk into the desert.
\end{solution}
\fi

\ppart The explorer will travel using a recursive strategy to go far into
the desert and back drawing a total of $n$ gallons of water from the
oasis.  Her strategy is to build up a cache of $n-1$ gallons, plus enough
to get home, a certain fraction of a day's distance into the desert.  On
the last delivery to the cache, instead of returning home, she proceeds
recursively with her $n-1$ gallon strategy to go farther into the desert
and return to the cache.  At this point, the cache has just enough water
left to get her home.

Prove that with $n$ gallons of water, this strategy will get her $H_n / 2$
days into the desert and back, where $H_n$ is the $n$th Harmonic number:
\[
H_n \eqdef \frac{1}{1} + \frac{1}{2} + \frac{1}{3} + \cdots + \frac{1}{n}.
\]
Conclude that she can reach the shrine, however far it is from the oasis.

\begin{solution}
To build up the first cache of $n-1$ gallons, she should make
  $n$ trips $1/(2n)$ days into the desert, dropping off $(n-1)/n$ gallons
  each time.  Before she leaves the cache for the last time, she has $n-1$
  gallons plus enough for the walk home.  Then she applies her $(n-1)$-day
  strategy.  So letting $D_n$ be her maximum distance into the desert and
  back, we have
%
\[
D_n = \frac{1}{2n} + D_{n-1}.
\]
So
\begin{align*}
D_n & = \frac{1}{2n} + \frac{1}{2(n-1)} + \frac{1}{2(n-2)}+ \cdots +
\frac{1}{2\cdot 2} +\frac{1}{2 \cdot 1}\\
  & = \frac{1}{2} \paren{ \frac{1}{n} + \frac{1}{(n-1)} + \frac{1}{(n-2)}+ \cdots +
\frac{1}{\cdot 2} +\frac{1}{ \cdot 1}}\\
  & = \frac{H_n}{2}.
\end{align*}

\end{solution}

\ppart Suppose that the shrine is $d = 10$ days walk into the desert.  Use
the asymptotic approximation $H_n \sim \ln n$ to show that it will take
more than a million years for the explorer to recover the Holy Grail.

\begin{solution}
She obtains the Grail when:
%
\[
\frac{H_n}{2} \approx \frac{\ln n}{2} \geq 10.
\]
%
This requires $n \geq e^{20} = 4.8 \cdot 10^8\text{ days } > 1.329M\text{ years}$.

\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%CP_images_and-propositional_formulas

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: Megumi Ando, 9/19/09, reworked by ARM}
\end{pcomments}

\pkeywords{
  propositional formula
  implies
  valid
  relation
  codomain
  image
  inverse
  graph_of_relation
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
  Let $A$ be the following set of four propositional formulas shown below
  on the left, and let $C$ be the set of five propositional formulas on
  the right.  A binary relation, $I$, from $A$ to $C$ is defined by the
  rule
\[
H \mrel{I} G \qiff [\text{the formula } (H	 \QIMPLIES G) \text{ is valid}].
\]
For example, $(P \QAND Q) \mrel{I} P$, because the formula $(P \QAND Q)$
does imply $P$.  Also, it is not true that $(P \QOR Q) \mrel{I} P$
since $(P \QOR Q) \QIMPLIES P$ is not valid.

  \bparts
  \ppart[6] Fill in the arrows so the following figure describes the graph of
  the relation, $I$:

\[\begin{array}{lcr}
A & \hspace{1in} \text{arrows} \hspace{1in} & C\\
\hline
&\\
                                  && P\\
&\\
(P \QAND Q)\\
&\\
                                  && Q\\
&\\
(P \QOR Q)\\
&\\
                                  && (\bar{P} \QOR \bar{Q})\\
&\\
\QNOT(P \QAND Q)\\
&\\
                                  && (R \QOR \bar{R})\\
&\\                             
(P \QXOR Q)\\
&\\
                                  && (R \QAND \bar{R})
\end{array}\]

 \begin{solution}

($P$ \QAND  $Q$) ->  $P$,  $Q$,  ($R$  \QOR  \bar{R})

($P$ \QOR  $Q$) -> ($R$  \QOR  \bar{R})

\QNOT ($P$  \QAND  $Q$) -> (\bar{P} \QOR \bar{Q}), ($R$  \QOR  \bar{R})

($P$ \QXOR  $Q$) -> (\bar{P} \QOR \bar{Q}), ($R$  \QOR  \bar{R})


 \end{solution}

 \ppart[3]\label{Iprops} Circle the properties below possessed by the
 relation $I$:
  \[
  \begin{array}{ccccc}
  \mbox{FUNCTION~~} & 
  \mbox{~~TOTAL~~} &
  \mbox{~~INJECTIVE~~} &
  \mbox{~~SURJECTIVE~~} &
  \mbox{~~BIJECTIVE} 
  \end{array}
  \]

\begin{solution}
  \mbox{~~TOTAL~~}
\end{solution}  

  \ppart[3]  Circle the properties below possessed by the relation $\inv{I}$:
  \[
  \begin{array}{ccccc}
  \mbox{FUNCTION~~} & 
  \mbox{~~TOTAL~~} &
  \mbox{~~INJECTIVE~~} &
  \mbox{~~SURJECTIVE~~} &
  \mbox{~~BIJECTIVE~}
  \end{array}
  \]

\begin{solution}
  \mbox{~~SURJECTIVE~~}
\end{solution}

\iffalse
%THERE is a good problem idea here, but what's written is garbled
%and needs work.

Here are two groups of expressions involving images and inverse
images under the relation $I$:
\begin{enumerate}
\item
${P,Q}I$

\begin{solution}
$\set{(R \QOR \bar{R})}$.

${P,Q}I$ is by definition equal to the expressions in $C$ that are either
implied by $P$ or implied by $Q$.  The only expression in $C$ implied by
$P$ is the valid expression $(R \QOR \bar{R})$; this is also the only
expression in $C$ implied by $Q$.
\end{solution}

\item $\set{(P \QOR Q)}I \intersect \set{\QNOT(P\ \QAND\ Q)}I$

\begin{solution}
\[\begin{array}{l}
(P \XOR Q)I\\
\set{(\bar{P} \QOR \bar{Q}), (R \QOR \bar{R})}
\end{array}\]

These are the expressions in $C$ implied by both $(P \QOR Q)$ and also by
$\QNOT(P\ \QAND\ Q)$, which is the same as being implied by $P \XOR Q$.

\end{solution}

\item \set{(P \QAND Q),\QNOT(P\ \QAND\ Q)}I

\begin{solution}
These are the expressions in $C$ implied by the formula $(P \QAND Q)$ or by
$\QNOT(P \QAND Q)$

\end{solution}
\end{enumerate}
\fi

\iffalse

\ppart If we change the codomain $C$ to include $\bar{P}$, does your
answer to part~eqref{Iprops} change?  Explain your answer.

\fi

  \eparts

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
%CP_images_and-propositional_formulas

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: Megumi Ando, 9/19/09, reworked by ARM}
\end{pcomments}

\pkeywords{
  propositional formula
  implies
  valid
  relation
  codomain
  image
  inverse
  graph_of_relation
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
  Let $A$ be the following set of five propositional formulas shown below
  on the left, and let $C$ be the set of three propositional formulas on
  the right.  The ``is implied by'' binary relation, $J$, from $A$ to $C$
  is defined by the rule
\[
F \mrel{J} G \qiff [\text{the formula } (G \QIMPLIES F) \text{ is valid}].
\]
For example, $P \mrel{J} (P \QAND Q)$, because $P$ is implied by $(P \QAND
Q)$.  Also, it is not true that $P \mrel{J} (P \QOR Q)$ since $P$ is not
implied by $(P \QOR Q)$.

  \bparts
  \ppart Fill in the arrows so the following figure describes the graph of
  the relation, $J$:

\[\begin{array}{lcr}
A & \hspace{1in} \text{arrows} \hspace{1in} & C\\
\hline
&\\
M\\
&\\
                                  && M \QAND (P \QIMPLIES M)\\
&\\
P \QAND Q\\
&\\
                                  && Q\\
&\\
P \QOR Q\\
&\\
                                  && \bar{P} \QOR \bar{Q}\\
&\\
\QNOT(P \QAND Q)\\
&\\
&\\
P \QXOR Q\\
&\\
\end{array}\]

 \begin{solution}
Three arrows for the ``is implied by'' relation, $J$, 
\begin{align*}
M & \qiff & M \QAND (P \QIMPLIES M)\\
\QNOT(P \QAND Q) & \qiff & \bar{P} \QOR \bar{Q}\\
P \QOR Q & \text{is implied by} & Q
\end{align*}
So the ``is implied by'' relation, $J$, is a surjective, injective function.
This implies that its inverse, $\inv{J}$ is a total, injective
function.

 \end{solution}

 \ppart\label{Iprops} Circle the properties below possessed by the
 relation $J$:
  \[
  \begin{array}{ccccc}
  \mbox{FUNCTION~~} & 
  \mbox{~~TOTAL~~} &
  \mbox{~~INJECTIVE~~} &
  \mbox{~~SURJECTIVE~~} &
  \mbox{~~BIJECTIVE} 
  \end{array}
  \]

  \ppart  Circle the properties below possessed by the relation $\inv{J}$:
  \[
  \begin{array}{ccccc}
  \mbox{FUNCTION~~} & 
  \mbox{~~TOTAL~~} &
  \mbox{~~INJECTIVE~~} &
  \mbox{~~SURJECTIVE~~} &
  \mbox{~~BIJECTIVE~}
  \end{array}
  \]

\iffalse
%THERE is a good problem idea here, but what's written is garbled
%and needs work.

Here are some two groups of expressions involving images and inverse
images under the relation $I$:
\begin{enumerate}
\item
${P,Q}I$

\begin{solution}
$\set{(R \QOR \bar{R})}$.

${P,Q}I$ is by definition equal to the expressions in $C$ that are either
implied by $P$ or implied by $Q$.  The only expression in $C$ implied by
$P$ is the valid expression $(R \QOR \bar{R})$; this is also the only
expression in $C$ implied by $Q$.
\end{solution}

\item $\set{(P \QOR Q)}I \intersect \set{\QNOT(P\ \QAND\ Q)}I$

\begin{solution}
\[\begin{array}{l}
(P \XOR Q)I\\
\set{(\bar{P} \QOR \bar{Q}), (R \QOR \bar{R})}
\end{array}\]

These are the expressions in $C$ implied by both $(P \QOR Q)$ and also by
$\QNOT(P\ \QAND\ Q)$, which is the same as being implied by $P \XOR Q$.

\end{solution}

\item \set{(P \QAND Q),\QNOT(P\ \QAND\ Q)}I

\begin{solution}
These are the expressions in $C$ implied by the formula $(P \QAND Q)$ or by
$\QNOT(P \QAND Q)$

\end{solution}
\end{enumerate}
\fi

\iffalse

\ppart If we change the codomain $C$ to include $\bar{P}$, does your
answer to part~eqref{Iprops} change?  Explain your answer.

\fi

  \eparts

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
%CP_images_and-propositional_formulas

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: Megumi Ando, 9/19/09, reworked by ARM}
\end{pcomments}

\pkeywords{
  propositional formula
  implies
  valid
  relation
  codomain
  image
  inverse
  graph_of_relation
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
  Let $A$ be the following set of five propositional formulas shown below
  on the left, and let $C$ be the set of three propositional formulas on
  the right.  The ``implies'' binary relation, $I$, from $A$ to $C$
  is defined by the rule
\[
F \mrel{I} G \qiff [\text{the formula } (F \QIMPLIES G) \text{ is valid}].
\]
For example, $(P \QAND Q) \mrel{I} P$, because the formula $(P \QAND Q)$
does imply $P$.  Also, it is not true that $(P \QOR Q) \mrel{I} P$
since $(P \QOR Q) \QIMPLIES P$ is not valid.

  \bparts
  \ppart Fill in the arrows so the following figure describes the graph of
  the relation, $I$:

\[\begin{array}{lcr}
A & \hspace{1in} \text{arrows} \hspace{1in} & C\\
\hline
&\\
M\\
&\\
                                  && M \QAND (P \QIMPLIES M)\\
&\\
P \QAND Q\\
&\\
                                  && Q\\
&\\
P \QOR Q\\
&\\
                                  && \bar{P} \QOR \bar{Q}\\
&\\
\QNOT(P \QAND Q)\\
&\\
&\\
P \QXOR Q\\
&\\
\end{array}\]

 \begin{solution}
Four arrows for $I$:
\begin{align*}
M & \qiff & M \QAND (P \QIMPLIES M)\\
P \QAND Q & \qimplies & Q\\
\QNOT(P \QAND Q) & \qiff & \bar{P} \QOR \bar{Q}\\
P \QXOR Q & \qimplies & \bar{P} \QOR \bar{Q}
\end{align*}
So the ``implies'' relation, $I$, is a surjective function.  That means
its inverse, $\inv{I}$, is a total injection.
\end{solution}

\ppart Circle the properties below possessed by the
 relation $I$:
  \[
  \begin{array}{ccccc}
  \mbox{FUNCTION~~} & 
  \mbox{~~TOTAL~~} &
  \mbox{~~INJECTIVE~~} &
  \mbox{~~SURJECTIVE~~} &
  \mbox{~~BIJECTIVE} 
  \end{array}
  \]

  \ppart  Circle the properties below possessed by the relation $\inv{I}$:
  \[
  \begin{array}{ccccc}
  \mbox{FUNCTION~~} & 
  \mbox{~~TOTAL~~} &
  \mbox{~~INJECTIVE~~} &
  \mbox{~~SURJECTIVE~~} &
  \mbox{~~BIJECTIVE~}
  \end{array}
  \]

\iffalse
%THERE is a good problem idea here, but what's written is garbled
%and needs work.

Here are some two groups of expressions involving images and inverse
images under the relation $I$:
\begin{enumerate}
\item
${P,Q}I$

\begin{solution}
$\set{(R \QOR \bar{R})}$.

${P,Q}I$ is by definition equal to the expressions in $C$ that are either
implied by $P$ or implied by $Q$.  The only expression in $C$ implied by
$P$ is the valid expression $(R \QOR \bar{R})$; this is also the only
expression in $C$ implied by $Q$.
\end{solution}

\item $\set{(P \QOR Q)}I \intersect \set{\QNOT(P\ \QAND\ Q)}I$

\begin{solution}
\[\begin{array}{l}
(P \XOR Q)I\\
\set{(\bar{P} \QOR \bar{Q}), (R \QOR \bar{R})}
\end{array}\]

These are the expressions in $C$ implied by both $(P \QOR Q)$ and also by
$\QNOT(P\ \QAND\ Q)$, which is the same as being implied by $P \XOR Q$.

\end{solution}

\item \set{(P \QAND Q),\QNOT(P\ \QAND\ Q)}I

\begin{solution}
These are the expressions in $C$ implied by the formula $(P \QAND Q)$ or by
$\QNOT(P \QAND Q)$

\end{solution}
\end{enumerate}
\fi

\iffalse

\ppart If we change the codomain $C$ to include $\bar{P}$, does your
answer to part~eqref{Iprops} change?  Explain your answer.

\fi

  \eparts

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
%CP_inverse_partial_order

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{9/25/09 from partial order notes problem, edited by ARM}
\end{pcomments}

\pkeywords{
 partial_order
 inverse
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problems start here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Prove that if $R$ is a partial order, then so is $\inv{R}$

\begin{solution}
\TBA{TBA}
\end{solution}
\end{problem}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problems end here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp1r}
%  \pcomment{}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  root_2
  irrational
  rational
  proof_by_cases
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
If we raise an irrational number to an irrational power, can the result be
rational?  Show that it can by considering $\sqrt{2}^{\sqrt{2}}$ and
arguing by cases.

\begin{solution}
We want to find irrational numbers $a,b$ such that $a^b$ is rational.
We argue by cases.

Case 1: [$\sqrt{2}^{\sqrt{2}}$ is rational].  Let $a = b = \sqrt{2}$.  $a$
and $b$ are irrational since $\sqrt{2}$ is irrational as we know.  Also,
$a^b$ is rational by case hypothesis.  So we have found the required $a$
and $b$ in this case.

Case 2: [$\sqrt{2}^{\sqrt{2}}$ is irrational].  Let $a =\sqrt{2}^{\sqrt{2}}$
and $b = \sqrt{2}$.  Then $a$ is irrational by case hypothesis, we know
$b$ is irrational, and
\[
a^b = \paren{\sqrt{2}^{\sqrt{2}}}^{\sqrt{2}} =
      \sqrt{2}^{\sqrt{2} \cdot \sqrt{2}} = \sqrt{2}^2 = 2,
\]
which is rational.  So we have found the required $a$
and $b$ in this case also.

So in any case, there will be irrational $a,b$ such that $a^b$ is
rational.  Note that we have no clue about which case is true, but that
didn't matter.

\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
%CP_irrational_raised_to_sqrt3
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{by ARM 9/20/0-9}
  \pcomment{formatted for quiz}
%  \pcomment{}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  root_3
  irrational
  rational
  proof_by_cases
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Prove that there is an irrational number, $a$, such that $a^{\sqrt{3}}$ is rational.

\hint Consider $\sqrt[3]{2}^{\sqrt{3}}$ and argue by cases.

\inhandout{\instatements{\newpage}}
\begin{solution}
Case 1: [$\sqrt[3]{2}^{\sqrt{3}}$ is rational].  Let $a = \sqrt[3]{2}$.
We know that $a$ is irrational from a Class Problem of Week 1, Friday.

Case 2: [$\sqrt[3]{2}^{\sqrt{3}}$ is irrational].  Let $a =
\sqrt[3]{2}^{\sqrt{3}}$.  Then $a$ is irrational by case hypothesis, and
\[
a^{\sqrt{3}} = \paren{\sqrt[3]{2}^{\sqrt{3}}}^{\sqrt{3}} =
      \sqrt[3]{2}^{\sqrt{3} \cdot \sqrt{3}} = \sqrt[3]{2}^3 = 2,
\]
which is rational.  So we have found the required $a$
nin this case also.

So in any case, there will be irrational $a$ such that $a^{\sqrt{3}}$ is
rational.
\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
%CP_irreflexive_product

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{quickie from partial order notes}
\end{pcomments}

\pkeywords{
  product_relation
  irreflexive
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%Quick Exercise:
\begin{problem}
Verify that if \emph{either} of $R_1$ or $R_2$ is irreflexive, then so is $R_1 \cross R_2$.

\begin{solution}
\TBA{TBA}
\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp6m}
  \pcomment{from: S06.cp5w}
\end{pcomments}

\pkeywords{
  isomorphisms
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
For each of the following pairs of graphs, either define an isomorphism
between them, or prove that there is none.  (We write $ab$ as shorthand
for $\edge{a}{b}$.)

\bparts

\ppart
\begin{align*}
G_1\text{ with }& V_1 = \set{1,2,3,4,5,6},\ E_1= \set{12,23,34,14,15,35,45}\\
G_2\text{ with }& V_2 = \set{1,2,3,4,5,6},\ E_2= \set{12,23,34,45,51,24,25}
\end{align*}

\begin{solution}
Not isomorphic: $G_2$ has a node, 2, of degree 4, but the maximum degree
in $G_1$ is 3.
\end{solution}

\ppart
\begin{align*}
G_3\text{ with } &V_3 = \set{1,2,3,4,5,6},\ E_3= \set{12,23,34,14,45,56,26}\\
G_4\text{ with } &V_4 = \set{a,b,c,d,e,f},\ E_4= \set{ab,bc,cd,de,ae,ef,cf}
\end{align*}

\begin{solution}
Isomorphic (two isomorphisms) with the vertex correspondences: \\
$1f, 2c, 3d, 4e, 5a, 6b$ \\
or $1f, 2e, 3d, 4c, 5b, 6a$

\end{solution}

\ppart
\begin{align*}
G_5\text{ with } & V_5 = \set{a,b,c,d,e,f,g,h},\ E_5= \set{ab,bc,cd,ad,ef,fg,gh,he,dh,bf}\\
G_6\text{ with } & V_6 = \set{s,t,u,v,w,x,y,z},\ E_6=\set{st,tu,uv,sv,wx,xy,yz,wz,sw,vz}
\end{align*}

\begin{solution}
Not isomorphic: they have the same number of vertices, edges, and set of
vertex degrees.  But the degree 2 vertices of $G_1$ are all adjacent to
two degree 3 vertices, while the degree 2 vertices of $G_2$ are all
adjacent to one degree 2 vertex and one degree 3 vertex.

\end{solution}

\eparts

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp6r}
  \pcomment{from: S04.cp5f (edited ARM in S08)}
  \pcomment{This problem has a lot of commented out material that should be cleaned up.}
\end{pcomments}

\pkeywords{
  bipartite_matching
  degree-constrained
  graph_coloring
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}

A \term{Latin square} is $n \times n$ array whose entries are the number
$1,\dots,n$.  These entries satisfy two constraints: every row contains
all $n$ integers in some order, and also every column contains all $n$
integers in some order.  Latin squares come up frequently in the design of
scientific experiments for reasons illustrated by a little story in a
footnote\footnote{At Guiness brewery in the eary 1900's, W. S. Gosset (a 
chemist) and E.  S. Beaven (a ``maltster'') were trying to improve the 
barley used to make the brew.  The brewery used different varieties of 
barley according to price and availability, and their agricultural 
consultants suggested a different fertilizer mix and best planting month 
for each variety.

Somewhat sceptical about paying high prices for customized fertilizer,
Gosset and Beavan planned a season long test of the influence of
fertilizer and planting month on barley yields.  For as many months as
there were varieties of barley, they would plant one sample of each
variety using a different one of the fertilizers.  So every month, they
would have all the barley varieties planted and all the fertilizers
used, which would give them a way to judge the overall quality of that
planting month.  But they also wanted to judge the fertilizers, so they
wanted each fertilizer to be used on each variety during the course of
the season.  Now they had a little mathematical problem, which we can
abstract as follows.

Suppose there are $n$ barley varieties and an equal number of
recommended fertilizers.  Form an $n \times n$ array with a column for
each fertilizer and a row for each planting month.  We want to fill in
the entries of this array with the integers 1,\dots,$n$ numbering the
barley varieties, so that every row contains all $n$ integers in some
order (so every month each variety is planted and each fertilizer is
used), and also every column contains all $n$ integers (so each
fertilizer is used on all the varieties over the course of the growing
season).}  

For example, here is a $4 \times 4$ Latin square:
{\Large
\[
\begin{array}{|c|c|c|c|}
\hline
1 & 2 & 3 & 4 \\ 
\hline
3 & 4 & 2 & 1 \\ 
\hline
2 & 1 & 4 & 3 \\ 
\hline
4 & 3 & 1 & 2 \\ 
\hline
\end{array}
\]
}

\bparts

\ppart

\iffalse
Before deciding to chuck it all and relax drinking a barrel of their
own product, the brewers has worked out the following \fi

Here are three rows of what could be part of a $5 \times 5$ Latin square:

{\Large
\[
\begin{array}{|c|c|c|c|c|}
\hline
2 & 4 & 5 & 3 & 1 \\ 
\hline
4 & 1 & 3 & 2 & 5 \\ 
\hline
3 & 2 & 1 & 5 & 4 \\ 
\hline
  &   &   &   &   \\ 
\hline
  &   &   &   &   \\
\hline
\end{array}
\]
}
Fill in the last two rows to extend this ``Latin rectangle'' to a complete
Latin square.

\begin{solution}
Here is one possible solution:

{\Large
\[
\begin{array}{|c|c|c|c|c|}
\hline
2 & 4 & 5 & 3 & 1 \\ 
\hline
4 & 1 & 3 & 2 & 5 \\ 
\hline
3 & 2 & 1 & 5 & 4 \\ 
\hline
1 & 5 & 2 & 4 & 3 \\ 
\hline
5 & 3 & 4 & 1 & 2 \\ 
\hline
\end{array}
\]
}
\end{solution}

%There are some nice connections between Latin squares and graph theory.
\iffalse 

\ppart
Construct a graph $G_n$ with $n^2$ vertices such that there is a
one-to-one correspondence between $n \times n$ Latin squares and valid
$n$-colorings of $G_n$.

\begin{solution}
Create a vertex in $G$ for each entry in the Latin Square.
Then connect each vertex to every other vertex in the same row and to
every other vertex in the same column.  Now color the graph with $n$
colors, each corresponding to a number between 1 and $n$.
Notice that every pair of vertices in the same row are connected, so
no two vertices in the same row can get the same color.  Similarly,
since every pair of vertices in the same column are connected, no two
vertices in the same column can get same color either.  These coloring
constraint match the constraints on Latin squares, so there is a
one-to-one correspondence between colorings of $G$ and $n \times n$
Latin squares.
\end{solution}

\eparts

Of course coloring problems can be difficult, so formulating Latin square
construction as a coloring problem is no direct help in finding them.  But
there's another approach to constructing Quadra\footnote{Get it? That's  
Latin for ``squares''.  Latin -- squares :-) Okay, we'll stop making bad 
puns and let you get on with the problem.} based on bipartite matching.

\bparts
\fi

\ppart Show that filling in the next row of an $n \times n$ Latin
rectangle is equivalent to finding a matching in some $2n$-vertex
bipartite graph.

\begin{solution}
Construct a bipartite graph as follows. One set of vertices 
are  the columns of the Latin rectangle, and the other set is the 
numbers $1$  to $n$. Put an edge between a column and a number if the 
number has \emph{not yet appeared} in the column. Thus, a matching in
this graph would associate each column with a distinct number that has 
not yet appeared in that column. These numbers would form the next row 
of the Latin rectangle.
\end{solution}

\ppart Prove that a matching must exist in this bipartite graph and,
consequently, a Latin rectangle can always be extended to a Latin square.

\begin{solution}
Suppose the Latin rectangle has $k$ rows of width $n$. Then
each column-vertex has degree $n-k$ because its edges go to the $n - k$ 
numbers missing from the column.  Also, each number-vertex also has
degree $n - k$.  That's because each number appears exactly once in each
of the $k$ rows and at most once in each column, so each number must be
missing from exactly $n-k$ columns.

So the graph is degree-constrained and therefore has a matching.
This  implies that we can add rows to the Latin rectangle by the procedure
described above as long as $k < n$.  At that point, we have a Latin
square.
\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{new by ARM, trivial variant of PS_log2_of_3_irrational}
\end{pcomments}

\pkeywords{
  irrational
  power 
  contradiction
  log
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem} Prove that $\log_9 12$ is irrational.

\begin{solution}
\begin{proof}
  Suppose to the contrary that $\log_9 12 =m/n$ for some integers $m$ and
  $n$.  Since $\log_9 12$ is positive, we may assume that $m$ and $n$ are
  also positive.  So we have
\begin{align}
\log_9 12 & = m/n \notag\\
9^{\log_9 12} & = 9^{m/n}  \notag\\
12 &= \paren{9^m}^{1/n} \notag\\
12^n & = 9^m \label{12n9m}
\end{align}
But this is impossible, since left hand side of~\eqref{12n9m} is even,
but, because $m$ is positive, the right hand side is odd.

This contradiction implies that $\log_9 12$ must be irrational.
\end{proof}
\end{solution}
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: F09.ps2}
  \pcomment{from: S09.cp2t, F02.cp2w}
%  \pcomment{}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  quantifiers
  domain_of_discourse
  predicate_calculus
  translating_english_statements  
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
A media tycoon has an idea for an all-news television network called
LNN: The Logic News Network.  Each segment will begin with a
definition of the domain of discourse and a few predicates.  The day's
happenings can then be communicated concisely in logic notation.  For
example, a broadcast might begin as follows:

\begin{quotation}\noindent
``THIS IS LNN.  The domain of discourse is $\{
\mbox{Albert}, \mbox{Ben}, \mbox{Claire}, \mbox{David}, \mbox{Emily}
\}$.  Let $D(x)$ be a predicate that is true if $x$ is deceitful.  Let
$L(x, y)$ be a predicate that is true if $x$ likes $y$.  Let $G(x, y)$
be a predicate that is true if $x$ gave gifts to $y$.''
\end{quotation}

Translate the following broadcasted logic notation into (English) statements.

\bparts

\ppart
\[
(\neg (D(\mbox{Ben}) \vee D(\mbox{David}))) \implies
(L(\mbox{Albert}, \mbox{Ben}) \wedge L(\mbox{Ben}, \mbox{Albert}))
\]

\begin{solution}
If neither Ben nor David is deceitful, then Albert and Ben like each other.
\end{solution}

\ppart
\begin{eqnarray*}
\forall x\ (x  =   \mbox{Claire} \wedge \neg L(x, \mbox{Emily})) \vee
           (x \neq \mbox{Claire} \wedge      L(x, \mbox{Emily})) \wedge \\
\quad \quad
\forall x\ (x  =   \mbox{David} \wedge      L(x, \mbox{Claire})) \vee
           (x \neq \mbox{David} \wedge \neg L(x, \mbox{Claire}))
\end{eqnarray*}

\begin{solution}
Everyone except for Claire likes Emily, and no one except David likes Claire.
\end{solution}

\ppart
\[
\neg D(\mbox{Claire}) \implies
        (G(\mbox{Albert}, \mbox{Ben}) \wedge
        \exists\ x G(\mbox{Ben}, x))
\]

\begin{solution}
If Claire is not deceitful, then Albert gave gifts to
Ben, and Ben gave gifts to someone.
\end{solution}

\ppart
\[
\forall x \exists y \exists z\ (y \neq z) \wedge L(x, y) \wedge \neg L(x, z)
\]

\begin{solution}
Everyone likes someone and dislikes someone else.
\end{solution}

\ppart
How could you express ``Everyone except for Claire likes
Emily'' using just propositional connectives \emph{without} using any
quantifiers ($\forall, \exists$)?  Can you generalize to explain how
\emph{any} logical formula over this domain of discourse can be expressed
without quantifiers?  How big would the formula in the previous part be if
it was expressed this way?

\begin{solution}
\[
L(\mbox{Albert},\mbox{Emily}) \land L(\mbox{Ben},\mbox{Emily}) \land
L(\mbox{David},\mbox{Emily}) \land L(\mbox{Emily},\mbox{Emily}) \land
\neg L(\mbox{Claire},\mbox{Emily})
\]

In general, quantifiers can be eliminated by treating $\forall x\ P(x)$ as an
abbreviation for
\[
P(\mbox{Albert}) \land P(\mbox{Ben}) \land P(\mbox{Claire}) \land P(\mbox{David}) \land
P(\mbox{Emily}),
\]
and $\exists x\ P(x)$ as an abbreviation for
\[
P(\mbox{Albert}) \lor P(\mbox{Ben}) \lor P(\mbox{Claire}) \lor
P(\mbox{David}) \lor P(\mbox{Emily}).
\]

Expanded this way, the three-quantifier formula of the previous part would
expand by a factor of $5 \times 5 \times 5 = 125$.  So using quantifiers
can pay off even when they are not strictly necessary.
\end{solution}

\eparts

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
%CP_mapping_rule

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{written by ARM 9/20/09}
  \pcomment{problems need Appendix below or NOTES access}
\end{pcomments}

\pkeywords{
 mapping rule
 images
 relations
 functions
 injections
 surjections
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
  Let $R: A \to B$ be a binary relation.  Use an arrow counting argument
  to prove the following generalization of the Mapping Rule:
\begin{lemma*}
  If $R$ is a function, and $X \subseteq A$, then
\[
\card{X} \geq \card{XR}.
\]
\end{lemma*}

\begin{solution}
\begin{proof}
The proof is virtually a repeat of the proof in the Appendix for the first
Mapping Rule.

Since $R$ is a function, the number of arrows whose starting point is an
element of $X$ is at most the number of elements in $X$,  That is,
\[
\card{X} \geq \#\text{arrows from $X$}.
\]
Also, each element of $XR$ is, by definition, the endpoint of at least one
arrow starting from $X$, so there must be at least as many arrows starting
from $X$ as the number of elements of $XR$.  That is,
\[
\#\text{arrows from $X$} \geq \card{XR}.
\]
Combining these inequalities immediately implies that $\card{X} \geq \card{XR}$.
\end{proof}

An alternative proof appeals to the original Mapping Rule:

\begin{proof}
  Consider the relation $R'$ whose domain is $X$, whose codomain is $XR$,
  and whose arrows are just the arrows of $R$ that start from $X$. (These
  arrows necessarily end in $XR$ by definition of $XR$.)  Since $R$ is a
  function, $R'$ will be one too, and by definition of $XR$, the relation
  $R'$ is a surjection.  Hence the first Mapping Rule implies that
  $\card{X} \geq \card{XR}$.
\end{proof}

\end{solution}

\end{problem}

\iffalse

\Section{Appendix}

Let $R: A \to B$ be a binary relation.

For any subset $X \subseteq A$
\[
XR \eqdef \set{b \in B \suchthat \exist x \in X.\, x\mrel{R}b}
\]
In other words, $XR$ is the set of endpoints of arrows that start in $X$.

\begin{lemma}[Mapping Rule] \mbox{}
\begin{enumerate}

\item If $R$ is a surjective function, then
\[
\card{A} \geq \card{B}.
\]

\begin{proof}
  Since $R$ is a function, every arrow in the diagram for $R$ comes from
  exactly one element of $A$, so the number of arrows is at most the
  number of elements in $A$.  That is, since $R$ is a function,
\[
\card{A} \geq \#\text{arrows}.
\]
Similarly, since $R$ is surjective, every element of $B$ has at least one
arrow into it, so there must be at least as many arrows as the number of
elements of $B$.  That is, since $R$ is surjective,
\[
\#\text{arrows} \geq \card{B}.
\]
Combining these inequalities immediately implies that $\card{A} \geq \card{B}.$

\end{proof}

\item If $R$ is total and injective, then $\card{A} \leq \card{B}$.

\item If $R$ is a bijection, then $\card{A} = \card{B}$.

\end{enumerate}

\end{lemma}
\fi

\endinput

%CP_minimal_maximal_elements

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp4m}
%  \pcomment{}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  partial_orders
  chains_and_antichains
  primes
  relations
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}

 \iffalse 
\begin{definition*}
  Let $\preceq$ be a partial order on a set, $A$. An element $a
  \in A$ is \term{maximum} iff every other element of $A$ is $\preceq a$.
  The element $a$ is \term{maximal} iff $a$ is not $\preceq$ to any other
  element.
\end{definition*}
\fi

\bparts

\ppart What are the maxim\emph{al} and minim\emph{al} elements, if any, of
the \emph{empty} \iffalse \idx\fi relation on the power set
$\power(\set{{1,\dots,n}})$, where $n$ is a positive integer?

\begin{solution}
The power set is a red herring.  With an empty relation on any set, every
element is maximal and minimal.
\end{solution}

\ppart What are the maxim\emph{al} and minim\emph{al} elements, if
any, of the set, $\naturals$, of all nonnegative integers under
divisibility?  Is there a minim\emph{um} or maxim\emph{um} element?

\begin{solution}
The minimum (and therefore unique minimal) element is 1 since 1
divides all natural numbers. The maximum (and therefore unique maximal)
element is 0 since all numbers divide 0.
\end{solution}

\ppart What are the minimal and maximal elements, if any, of the set
of integers greater than 1 under divisibility?

\begin{solution}
All prime numbers are minimal elements, since no numbers divide
them.

There is no maximal element, because for any $n > 1$, there is  a
``larger'' number under the divisibility partial order, for example,
$2n$.
\end{solution}

\iffalse
\ppart
What is the size of the longest chain that is guaranteed to exist in any
partially ordered set of $n>0$ elements?  What about the largest antichain?

\begin{solution}
Chain size is 1 in the empty relation on a set of any size, since no two
elements are comparable.  Antichain size is 1 if the whole partial
order is a chain.

\end{solution}

\ppart Describe a partially ordered set that has no minimal or maximal
elements.

\begin{solution}
$\integers$, $\reals$, etc.
\end{solution}
\fi

\ppart Describe a partially ordered set that has a \emph{unique minimal}
element, but no minimum element. \hint It will have to be infinite.

\begin{solution}
  $\integers \union \set{i}$ where $i$ is a root of $-1$, under the usual
  order $\integers$.  So $i$ is incomparable to everything but itself, and
  is therefore minimal ---and maximal too.  The remaining elements are the
  integers, and none of them is minimal since $n-1 < n$, which makes $i$
  unique.
\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp8t, S06.cp7m, S04.ps7}
%  \pcomment{}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  series
  number_theory
  divides
  remainders
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
\bparts

\ppart Why is a number written in decimal evenly divisible by 9 if and
only if the sum of its digits is a multiple of 9?  \hint $10 \equiv 1
\pmod{9}$.

\begin{solution}
Since $10 \equiv 1 \pmod{9}$, so is
\begin{equation}\label{10k}
10^k \equiv 1^k \equiv 1 \pmod{9}.
\end{equation}
Now a number in decimal has the form:
\[
d_k \cdot 10^k + d_{k-1} \cdot 10^{k-1} + \ldots + d_1 \cdot 10 + d_0.
\]

From~\eqref{10k}, we have
\begin{eqnarray*}
d_k \cdot 10^k + d_{k-1} \cdot 10^{k-1} + \ldots + d_1 \cdot 10 + d_0
    & \equiv & d_k + d_{k-1} + \ldots + d_1 + d_0 \pmod{9} \\
\end{eqnarray*}

This shows something stronger than what we were asked to show, namely, it
shows that the remainder when the original number is divided by 9 is equal
to the remainder when the sum of the digits is divided by 9.  In
particular, if one is zero, then so is the other.
\end{solution}

%S04 ps7

\ppart Take a big number, such as 37273761261.  Sum the digits, where
every other one is negated:
\[
3 + (-7) + 2 + (-7) + 3 + (-7) + 6 + (-1) + 2 + (-6) + 1  =  -11
\]
Explain why the original number is a multiple of 11 if and only
if this sum is a multiple of 11.
\hint $10 \equiv -1 \pmod{11}$.

\begin{solution}
A number in decimal has the form:
\[
d_k \cdot 10^k + d_{k-1} \cdot 10^{k-1} + \ldots + d_1 \cdot 10 + d_0
\]

From the observation above, we know:
\begin{align*}
\lefteqn{d_k \cdot 10^k + d_{k-1} \cdot 10^{k-1} + \ldots + d_1 \cdot 10 + d_0} \\
    & \equiv d_k \cdot (-1)^k + d_{k-1} \cdot (-1)^{k-1} + \ldots \cdot + d_1 \cdot (-1)^1 + d_0 \cdot (-1)^0 \pmod{11} \\
& \equiv d_k - d_{k-1} + \ldots \cdot - d_1 + d_0  \pmod{11}
\end{align*}
assuming $k$ is even.  The case where $k$ is odd is the same with signs
reversed.  

The procedure given in the problem computes $\pm$ this alternating sum of
digits, and hence yields a number divisible by 11 ($\equiv 0 \pmod {11}$)
iff the original number was divisible by 11.
\end{solution}

\eparts

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp7t}
  \pcomment{from: S07.cp6f}
  \pcomment{There is a lot of commented out material regarding 2k-cycle networks.  We had a final exam problem on them that might be nice to include along with the 2k-cycleproblem as a challenge problem.}
\end{pcomments}

\pkeywords{
  networks
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
A \emph{5-path} communication network is shown below.  From this, it's
easy to see what an $n$-path network would be.  Fill in the table of
properties below, and be prepared to justify your answers.

\begin{center}
\begin{tabular}{ccc}
\includegraphics[height=1.5in]{figures/line-nw}\\
% & & \includegraphics[height=2in]{figures/cycle4} \\
\textbf{5-Path}% & \qquad & \textbf{4-Cycle}
\end{tabular}
\end{center}

{\large
\[
\begin{array}{c|c|c|c|c}
\text{network} &
\text{\# switches} &
\text{switch size} &
\text{diameter} &
\text{max congestion} \\ \hline
\text{5-path} &
\insolutions{5} &
\insolutions{3 \times 3} &
\insolutions{6} &
\insolutions{5} \\ \hline
\text{$n$-path} &
\insolutions{n} &
\insolutions{3 \times 3} &
\insolutions{n+1} &
\insolutions{n}
\end{array}
\]
}

\begin{solution}
The congestion of the $n$-path is at least $n$, because every
path must contain the central switch when $\pi(i) = n- 1 - i$.  The congestion
is at most $n$, because there are only $n$ simple paths in total.  The longest
path is from input 0 to output $n-1$ of length $n+1$, so this is the
diameter.
\end{solution}

\iffalse
The congestion of the 4-cycle is at least 3.  Consider the permutation
routing problem in which each input sends a packet to the diagonally
opposite output: $\pi(0) = 2$, $\pi(1) = 3$, $\pi(2) = 0$, $\pi(3) =
1$.  Packets 0 and 2 must pass through the switches on the upper left
and lower right in order to access the appropriate input and output
terminals.  Packets 1 must pass through one of these switches as well,
so at least three packets pass through either the upper-left switch or
the lower-left switch.

The congestion of the 4-cycle is at most 3.  Suppose we route each
packet by the shortest path and break ties by routing clockwise around
the cycle.  Now consider any particular switch, say the one in the
upper right.  At worst, this switch sees three packets: the one from
input 1, the one destined for output 1, and one passing through from
input 0 to output 2.  By symmetry, every switch sees at most 3 packets.}
\fi

\iffalse

\ppart Now consider the $n$-path and $2k$-cycle networks, and again fill in the
table below. (The $2k$-cycle is a $k \times k$ rectangular arrangement
with $k$ inputs on the top and bottom sides of the rectangle, and $k$
outputs on the left and right sides.)


{\large
\[
\begin{array}{c|c|c|c|c}
\text{network} &
\text{\# switches} &
\text{switch size} &
\text{diameter} &
\text{max congestion} \\ \hline
\text{$n$-path} &
\insolutions{n} &
\insolutions{3 \times 3} &
\insolutions{n+1} &
\insolutions{n} \\ \hline
\text{$2k$-cycle} &
\insolutions{4(k-1)} &
\insolutions{ 3 \times 3, 2\times 3, 3 \times 2 } &
\insolutions{2(k-1)+2 = 2k} &
\insolutions{k+1}
\end{array}
\]
}

\begin{solution}
\TBA{TBA}

\mfigure{!}{3in}{figures/2kCycle}

\end{solution}

\eparts
\fi

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp6t}
\end{pcomments}

\pkeywords{
  connectivity
  graphs
  binary
  strings
  spanning_trees
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}

  The $n$-dimensional hypercube, $H_n$, is a graph with whose vertices are
  the binary strings of length $n$.  Two vertices are adjacent if and only
  if they differ in exactly $1$ bit.  For example, in $H_3$, vertices
  \texttt{111} and \texttt{011} are adjacent because they differ only in
  the first bit, while vertices \texttt{101} and \texttt{011} are not
  adjacent because they differ at both the first and second bits.

\iffalse
The \term{$n$-dimensional hypercube} is a graph, $H_n$, whose vertices are
the length-$n$ binary strings, with an edge between two vertices iff they
differ in only one position.  For $n=4$, for example, vertex \texttt{0000}
is adjacent to the length-4 binary strings with exactly one \texttt{1},
namely, the four strings \texttt{1000}, \texttt{0100}, \texttt{0010},
\texttt{0001}.
\fi

\bparts

\ppart Prove that it is impossible to find two spanning trees of $H_3$
that do not share some edge.

\begin{solution}
$H_3$ has 8 vertices so every spanning tree has 7 edges.  But $H_3$ has
only 12 edges, so any two sets of 7 edges must overlap.

\end{solution}

\ppart Verify that for any two vertices $x \neq y$ of $H_3$, there are $3$
paths from $x$ to $y$ in $H_3$, such that, besides $x$ and $y$, no two of
those paths have a vertex in common.

\begin{solution}
Define the distance between two binary strings of length $n$ to be the
number of positions at which they differ (this is known as the
\term{Hamming distance} between the strings).

To show that there are 3 paths between any two distance 1 strings, we can,
by symmetry, just consider paths between the vertices \texttt{000} and
\texttt{001}.

Paths from \texttt{000} to \texttt{001}:
\begin{align*}
\mtt{000, 001}\\
\mtt{000, 010, 011, 001}\\
\mtt{000, 100, 101, 001}
\end{align*}

Likewise for distance 2, it is enough to find paths between
\texttt{000} and \texttt{011}:

\begin{align*}
\mtt{000, 010, 011}\\
\mtt{000, 001, 011}\\
\mtt{000, 100, 110, 111, 011}
\end{align*}

Finally, for distance 3 from \texttt{000} to \texttt{111}:
\begin{align*}
\mtt{000, 001, 011, 111}\\
\mtt{000, 010, 110, 111}\\
\mtt{000, 100, 101, 111}
\end{align*}
\end{solution}

\ppart Explain why this implies that $H_3$ is $3$-connected.

\begin{solution}
Since there are three paths from $x$ to $y$ in $H_3$ that share
  no edges with one another, removing any two edges will leave one of
  these paths intact, so $x$ and $y$ remain connected.  So removing two
  edges from $H_3$ does not disconnect it.
\end{solution}

\ppart What is the connectivity of $H_3$ (the minimum number of edges that
must be deleted to disconnect it)?

\begin{solution}
Removing all $3$ edges incident to any vertex, disconnects
  $H_3$.  Thus the minimum number of edges necessary to disconnect $H_3$
  is $3$.
\end{solution}

\ppart What about $H_4$?  (In fact, the connectivity of $H_n$ is $n$ for
all $n \geq 1$.  A proof will appear in the solution to this problem.)

\begin{solution}
Two paths in a graph \emph{cross} when they have a vertex in common other
than their endpoints.  A set of paths in a graph \emph{don't cross} when no
two paths in the set cross.  A graph is \emph{$k$-routed} if between every
pair of distinct vertices in the graph there is a set of $k$ paths that
don't cross.

We'll show that
\hyperdef{H}{n}{
\begin{equation}\label{hn}
H_n \text{ is $n$-routed for all } n \geq 1.
\end{equation}
}

Since $H_n$ can be disconnected by deleting the $n$ edges incident to any
vertex, this implies that $H_n$ has connectivity $n$.

\begin{proof}
The proof is by induction on $n$ with induction hypothesis,
  $P(n)$, given by~\eqref{hn}.

\textbf{base case} [$n=1$]: Since $H_1$ consists of two
vertices connected by an edge, so $P(1)$ is immediate.

\textbf{base case} [$n=2$]: $H_2$ is a square.  Vertices on opposite
corners are obviously connected by two length 2 paths that don't cross, and
adjacent vertices are connected by a length 1 path and a length 3 path.

\textbf{inductive step:} We prove $P(n+1)$ for $n \geq 2$ by letting $v$
and $w$ be two vertices of $H_{n+1}$ and describing $n+1$ paths between them
that don't cross.

Let $R$ by any positive length path in $H_n$, say
\[
R = r_0,r_1,\dots, r_k.
\]
For $b \in \set{\mtt{0,1}}$ define the $H_{n+1}$ path
\[
bR \eqdef br_0, br_1,  \dots, br_k.
\]

\textbf{case 1:} The distance from $v$ to $w$ is $d \leq n$.  In this
case, the $(n+1)$-bit strings $v$ and $w$ agree in one or more positions.
By symmetry, we can assume without loss of generality that $v$ and $w$
both start with \texttt{0}.  That is $v=\mtt{0}v'$ and $w=\mtt{0}w'$ for
some $n$-bit strings $v', w'$.  Now by induction, there are paths, $Q_i$
for $1 \leq i \leq n$, that don't cross going between $v'$ and $w'$ in
$H_n$.

Define the first $n$ paths in $H_{n+1}$ between $v$ and $w$ to be
\[
\pi_i \eqdef \mtt{0}Q_i
\]
for $1 \leq i \leq n$.  These paths don't cross since the $Q_i$'s don't
cross.

Then define the $n+1$st path
\[
\pi_{n+1} \eqdef v,\ \mtt{1}\pi_{v',w'},\ w
\]
where $\pi_{v',w'}$ is any simple path from $v'$ to $w'$ in $H_n$.
Then $\pi_{n+1}$ obviously does not cross any of the other paths since
$\mtt{1}\pi_{v',w'}$ is vertex disjoint from $\mtt{0}Q_i$ for $1 \leq i \leq n$.

This proves that $P(n+1)$ hold in this case.

\textbf{case 2:} The distance from $v$ to $w$ is $n+1$.  By symmetry, we
can assume without loss of generality that $v=\mtt{0}^{n+1}$ and
$w=\mtt{1}^{n+1}$.

Now by induction, there are $n$ paths from $\mtt{0}^n$ to $\mtt{1}^n$ in
$H_n$ that don't cross in $H_n$.  It is clearly safe to assume that each
of these paths is simple.

Removing the shared first vertex, $\mtt{0}^n$, of these paths yields paths
$R_1,R_2,\dots,R_n$.  Now the $R_i$'s are vertex disjoint except for their
common endpoint, $1^n$.  Let $s_i$ be the start vertex of the $R_i$ for $1
\leq i \leq n$.

We now define $n+1$ paths in $H_{n+1}$ from $\mtt{0}^{n+1}$ to
$\mtt{1}^{n+1}$ that don't cross.

The first of these paths will be
\[
\pi_1 \eqdef \mtt{0}^{n+1}, \mtt{1}\mtt{0}^{n}, 1R_1.
\]

For $2 \leq i \leq n$, the $i$th of these paths will be
\[
\pi_i \eqdef \mtt{0}^{n+1}, \mtt{0}s_i, 1R_i.
\]
These paths don't cross because

\begin{itemize}

\item the paths $1R_i$ for $1 \leq i \leq n$ are vertex disjoint except
  for their common endpoint, $\mtt{1}^{n+1}$, because the $R_i$'s are
  vertex disjoint except for their common endpoint, $\mtt{1}^n$,

\item a vertex $0s_i$ does not appear on $\pi_j$ for any for $j \neq i$
  because the $s_i \neq s_j$ for $j \neq i$, and the other vertices on
  the $\pi_j$'s start with \texttt{1},

\item the vertex $\mtt{1}\mtt{0}^{n}$ appears only on $\pi_1$.  This follows
  because if it appeared on $\pi_i$ for $i \neq 1$ it must appear on $1R_i$.
  That would imply that $\mtt{0}^{n}$ appears on $R_i$, contradicting the
  fact that $H_i$ is simple.

\end{itemize}      

Finally, the $n+1$st path will be
\[
\pi_{n+1} \eqdef 0R_1, \mtt{1}^{n+1}.
\]
Note that, since all but the final vertex on $\pi_{n+1}$ start with
\texttt{0}, the only vertices besides the endpoints that $\pi_{n+1}$ could
share with another path would be $\mtt{0}s_i$ for $2 \leq i \leq n$.  But
none of these appear on $\pi_{n+1}$ because, except for their shared
endpoint, $R_1$ is vertex disjoint from all the other $R_i$'s.

This proves that $P(n+1)$ holds in case~2, and therefore holds in all
cases, which completes the proof by induction.
\end{proof}

Note that this proof implicitly defines a recursive procedure that, for
any two vertices in $H_n$, finds between the two vertices $n$ simple paths
of length at most $n+1$ that don't cross.
\end{solution} 

\eparts

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp9m}
  \pcomment{from: S05.rec10}
\end{pcomments}

\pkeywords{
  series
  closed_form
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
You've seen this neat trick for evaluating a geometric sum:
%
\begin{align*}
S & = 1 + z + z^2 + \ldots + z^n \\
zS & = z + z^2 + \ldots + z^n + z^{n+1} \\
S - z S & = 1 - z^{n+1} \\
S & = \frac{1-z^{n+1}}{1 - z}
\end{align*}

Use the same approach to find a closed-form expression for this sum:
%
\begin{align*}
T & = 1 z + 2 z^2 + 3 z^3 + \ldots + n z^n
\end{align*}

\begin{solution}
\begin{align*}
z T & = 1 z^2 + 2 z^3 + 3 z^4 + \ldots + n z^{n+1} \\
T - zT & = z + z^2 + z^3 + \ldots + z^n - n z^{n+1} \\
       & = \frac{1 - z^{n+1}}{1 - z} - 1 - n z^{n+1} \\
T & = \frac{1 - z^{n+1}}{(1 - z)^2} - \frac{1 + n z^{n+1}}{1 - z}
\end{align*}

\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp6m}
\end{pcomments}

\pkeywords{
  isomorphisms
  degree
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
\bparts

\ppart\label{fhat} For any vertex, $v$, in a graph, let $N(v)$ be
the set of \term{neighbors} of $v$, namely, the vertices adjacent to $v$:
\[
N(v) \eqdef \set{u \suchthat \edge{u}{v}\text{ is an edge of the
graph}}.
\]

Suppose $f$ is an isomorphism from graph $G$ to graph $H$.
Prove that $f(N(v)) = N(f(v))$.

Your proof should follow by simple reasoning using the definitions of
isomorphism and neighbors ---no pictures or handwaving.

\hint Prove by a chain of iff's that
\[
h \in N(f(v)) \qiff h \in f(N(v))
\]
for every $h \in V_H$.  Use the fact that $h=f(u)$ for some $u \in V_G$.

\begin{solution}
\begin{proof}
Suppose $h \in V_H$.  By definition of isomorphism, there is a
  unique $u \in V_G$ such that $f(u)=h$.  Then
\begin{align*}
h \in N(f(v))
    & \qiff \edge{h}{f(v)} \in E_H          & \text{(def of $N$)}\\
    & \qiff \edge{f(u)}{f(v)} \in E_H       & \text{(def of $u$)}\\
    & \qiff \edge{u}{v} \in E_V             & \text{(since $f$ is an isomorphism)}\\
    & \qiff u \in N(v)                      & \text{(def of $N$)}\\
    & \qiff f(u) \in f(N(v))                & \text{(def of $f$-image)}\\
    & \qiff h \in f(N(v))                   & \text{(def of $u$)}
\end{align*}
So $N(f(v))$ and $f(N(v))$ have the same members and therefore are equal.

\end{proof}
\end{solution}

\ppart Conclude that if $G$ and $H$ are isomorphic graphs, then for each
$k \in \naturals$, they have the same number of degree $k$ vertices.

\begin{solution}
By definition, $\degr{v}= \card{N(v)}$.  Since an isomorphism is
  a bijection, any set of vertices and its image under an isomorphism will
  be the same size (by the Mapping Rule from Week 2 Notes), so the Lemma
  of part~\eqref{fhat} implies that an isomorphism, $f$, maps degree $k$
  vertices to degree $k$ vertices.  This means that the image under $f$ of
  the set of degree $k$ vertices of $G$ is precisely the set of degree $k$
  vertices of $H$.  So by the Mapping Rule again, there are the same
  number of degree $k$ vertices in $G$ and $H$.
\end{solution}

\eparts

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp9r}
  \pcomment{parts (a) and (b) are unrelated and could be split into 2 independent problems}
\end{pcomments}

\pkeywords{
  counting
  counting_rules
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}           
  
\bparts

\ppart How many of the billion numbers in the range from 1 to $10^9$
contain the digit~$1$?  (\hint How many don't?)
  
\begin{solution}
We can count up how many \emph{do not} contain the digit 1 and
subtract.  So (total number) - (number without 1's) $= 10^9 - (9^9 - 1) =
612,579,512$ (the $-1$ is for 0 which is not in our range).
\end{solution}
  
\ppart There are 20 books arranged in a row on a shelf.  Describe a
bijection between ways of choosing 6 of these books so that no two
adjacent books are selected and $15$-bit strings with exactly 6 ones.

\begin{solution}
A selection of six among twenty books on a shelf corresponds in
  an obvious way to a 20-bit string with exactly six \texttt{1}'s.  For
  example, the 20-bit string with \texttt{1}'s in exactly the 3rd, 4th,
  5th, 10th, 19th and 20th positions corresponds to selecting 3rd, 4th,
  5th, 10th, 19th and 20th books on the shelf.

  So the problem reduces to finding a bijection between 20-bit strings
  with six \emph{nonadjacent} \texttt{1}'s and 15-bit strings with six
  \texttt{1}'s.
 
  But in a string, $s$, with six nonadjacent \texttt{1}'s, all but the
  last \texttt{1} must have a \texttt{0} to its right.  So we can map $s$
  to a string with six \texttt{1}'s and five fewer \texttt{0}'s by erasing
  the \texttt{0}'s immediately to the right of each of the first five
  \texttt{1}'s.  For example, erasing the underlined \texttt{0}'s in the
  20-bit string $\mathtt{0001 \underline{0} 1\underline{0} 01
    \underline{0}1 \underline{0}00001 \underline{0}10}$ yields the 15-bit
  string $\mathtt{000110110000110}$.

  This map is a bijection because given any 15-bit string with six
  \texttt{1}'s, there is a unique 20-bit string with nonadjacent
  \texttt{1}'s that maps to it, namely, the string obtained by replacing
  each of the first five \texttt{1}'s in the 15-bit string by a
  \texttt{10}.
\end{solution}

\iffalse
There is a bijection from
  15-bit sequences with exactly six 1's to valid book selections: given
  such a sequence, map each zero to a non-chosen book, each of the first
  five 1's to a chosen book followed by a non-chosen book, and the last 1
  to a chosen book.  For example, here is a configuration of books and the
  corresponding binary sequence:
%
\fboxsep=0pt
\fboxrule=1pt
\definecolor{lightgray}{gray}{0.8}
\newsavebox{\selected}
\newsavebox{\unselected}
\savebox{\selected}
    {\fcolorbox{black}{lightgray}{\rule{15pt}{0pt}\rule{0pt}{40pt}}}
\savebox{\unselected}
    {\fcolorbox{black}{white}{\rule{15pt}{0pt}\rule{0pt}{40pt}}}
\newcommand{\sbk}{\usebox{\selected}}
\newcommand{\ubk}{\usebox{\unselected}}
%
\[
\overbrace{\sbk\ubk}^{1}\overbrace{\ubk}^{0}\overbrace{\ubk}^{0}\overbrace{\sbk\ubk}^{1}\overbrace{\sbk\ubk}^{1}\overbrace{\ubk}^{0}\overbrace{\ubk}^{0}\overbra%
%
Selected books are darkened.  Notice that the first fives ones are
mapped to a chosen book \textit{and} a non-chosen book in order to
ensure that the binary sequence maps to a valid selection of books.

\fi

\eparts

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp8t}
%  \pcomment{}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  modular_arithmetic
  number_theory
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Two nonparallel lines in the real plane intersect at a point.
Algebraically, this means that the equations
\begin{align*}
y & =  m_1 x + b_1 \\
y & =  m_2 x + b_2
\end{align*}
have a unique solution $(x, y)$, provided $m_1 \neq m_2$.  This statement
would be false if we restricted $x$ and $y$ to the integers, since the two
lines could cross at a noninteger point:

\centerline{\resizebox{!}{1in}{\includegraphics{figures/integerlines}}}

However, an analogous statement holds if we work over the integers
\emph{modulo a prime}, $p$.  Find a solution to the congruences
\begin{align*}
y & \equiv  m_1 x + b_1 \pmod{p} \\
y & \equiv  m_2 x + b_2 \pmod{p}
\end{align*}
when $m_1 \not\equiv m_2 \pmod{p}$.  Express your solution in the form $x
\equiv ? \pmod{p}$ and $y \equiv ? \pmod{p}$ where the ?'s denote
expressions involving $m_1$, $m_2$, $b_1$, and $b_2$.  You may find it
helpful to solve the original equations over the reals first.

\begin{solution}
Subtracting the second congruence from the first, we have:
\begin{eqnarray*}
0 & \equiv & m_1 x+b_1 - (m_2 x + b_2)  \pmod{p} \\
(m_1 - m_2)x & \equiv & b_2 - b_1 \pmod{p} \\
x & \equiv & (m_1 - m_2)^{-1} \cdot (b_2 - b_1) \pmod{p}
\end{eqnarray*}
Substituting this value of $x$ into the first congruence, we have
\[
y  \equiv  m_1 \cdot (m_1 - m_2)^{-1} \cdot (b_2 - b_1) + b_1 \pmod{p}
\]
Here $(m_1 - m_2)^{-1} \pmod p$ exists because $m_1 \not\equiv m_2
\pmod{p}$ and hence $p$ does not divide $(m_1 - m_2)$.

\textbf{Further exercise:} Show that $(x,y)$ are unique modulo $p$.

\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp9r}
  \pcomment{has a pset problem associated with it}
\end{pcomments}

\pkeywords{
  counting
  bijections
  trees
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\hyperdef{numbered}{trees}{\begin{problem}}
A \emph{numbered tree} is a tree whose vertex set is
$\set{1,2,\dots,n}$ for some $n \geq 2$.  We define the \emph{code} of
the numbered tree to be a sequence of $n-2$ integers from 1 to $n$
obtained by the following recursive process:
\begin{quotation}
If $n=2$, stop---the code is the empty sequence.  Otherwise, write down
the \emph{father} of the largest leaf\footnote{The necessarily unique node
adjacent to a leaf is called its \emph{father}.}, delete this \emph{leaf},
and continue the process on the resulting smaller tree.
\end{quotation}

For example, the codes of a couple of numbered trees are shown in 
the Figure~\ref{codetrees}.

\begin{figure}[htb]
\begin{center}
\includegraphics[width=4in]{figures/n-2}
\end{center}
\caption{}
\label{codetrees}
\end{figure}

\bparts

\ppart Describe a procedure for reconstructing a numbered tree from
its code.

\begin{solution}
The key observation is that, given a code of length $n-2$, the numbers
between 1 and $n$ which \emph{do not appear} in the code must be leaves of
the tree.  Hence, the largest missing number is a leaf attached to the
first number of the code.  The rest of the tree can now be reconstructed
by deleting the first number in the code, henceforth ignoring the largest
leaf, and proceeding recursively on the rest of the code.  (We're using
the obvious fact that what's left after deleting a leaf from a tree is
another tree.)

More precisely, the reconstruction procedure applies to any finite tree
whose vertex set is totally ordered.  The procedure takes \emph{two}
parameters: the vertex set, $V$, and a length $\card{V}-2$ ``code''
sequence, $S$, of elements in $V$.  If $l$ is the largest element in $V$
which does not appear in $S$, and $f$ is the first element of $S$, then
the reconstructed tree is obtained by adding edge $(l,f)$ to the tree
reconstructed by calling the procedure recursively with first argument
$V-\set{l}$ and second argument equal to the code obtained by erasing the
initial $f$ from $S$.  The procedure terminates when $\card{V}=2$,
returning the edge between the two numbers in $V$.

%This paragraph is correct, but would benefit from a rewrite:

To justify the key observation, note that any vertex that gets deleted by
the process and was not a leaf to begin with, must have been the father of
a previously deleted leaf, which means it would appear in the code.  So
the missing integers must have been leaves to begin with or must be one of
the two undeleted vertices left when the coding process terminates.  But
by the end of the process the two remaining vertices are leaves, and if
they weren't leaves to begin with, they must have become leaves by having
their sons deleted, which means they would not have been missing from the
code.  So the two vertices remaining at the end must also have been leaves
of the original tree.

\end{solution}

\ppart How many numbered trees with $n$ vertices are there?  Justify
your answer assuming the result of the previous problem part.

\begin{solution}
There are exactly as many $n$-vertex numbered trees as the
number of possible code words, that is, the number of length $n-2$
sequences of integers between 1 and $n$.  So there are $n^{n-2}$ numbered
trees.
  
The reason is that the map from trees to codes is a bijection.  To see
this, note that the tree reconstruction procedure finds \emph{the only
possible tree} with that code.  So there can't be two trees with the same
code, i.e., the map from a tree to its code is an injection.  But since
the reconstruction procedure finds a tree for every possible codeword, the
map from trees to codes is also a surjection.
\end{solution}

\eparts
\end{problem} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%CP_partial_order_on_power_set

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: F07.ps2}
\end{pcomments}

\pkeywords{
  partial_order
  power_set
  antichain
  maximal_and_minimal_elements
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Consider the proper subset partial order, $\subset$, on the power set
$\power{\set{1,2,\dots,6}}$.


\begin{problemparts}
\problempart 
What is the size of a maximal chain in this partial order?
Describe one.

\begin{solution}
Size 7, for example,
\[
\set{\emptyset, \set{1}, \set{1,2},
  \set{1,2,3},\set{1,2,3,4},\set{1,2,3,4,5}, \set{1,2,3,4,5,6}}.
\]
\end{solution}


\problempart An \emph{antichain}
\iffalse \idx{} \fi
in a partial order is a set of
elements such that any two elements in the set are incomparable.  Describe
the largest antichain you can find in this partial order.

\begin{solution}
All the size 3 subsets of $\set{1,2,\dots, 6}$ form an antichain
of size 20.  These are actually the largest, though proving this can be
a challenge, especially trying to generalize to the power set of an $n$
element set.
\end{solution}


\problempart
What are the maximal and minimal elements?  Are they maximum and
minimum?

\begin{solution}
$\emptyset$ is minimum and $\set{1,2,\dots,6}$ is maximum.
\end{solution}


\problempart 
Answer the previous part for the $\subset$ partial order on the set
$\power{\set{1,2,\dots, 6}} - \emptyset$.

\begin{solution}
Now the six size 1 subsets are minimal and there is no minimum.
$\set{1,2,\dots,6}$ is still maximum.
\end{solution}

\end{problemparts}
\end{problem}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
%CP_partially_ordered_by_divisibility

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: F03.ps2}
\end{pcomments}

\pkeywords{
  partial_ordered_by_divisibility
  unique_minimal_and_maximal_elements
  infinite_chain
  infinite_antichain
  antichain
  chain
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Consider the nonnegative numbers partially ordered by divisibility.

\begin{problemparts}

\problempart 
Show that this partial order has a unique minimal element.

\begin{solution}
1 is minimal as there is no other natural number that divides 1.
It is unique because all other numbers are divisible by 1 and therefore
are not minimal.
\end{solution}


\problempart 
Show that this partial order has a unique maximal element.

\begin{solution}
0 is maximal: all natural numbers divide zero.  It is the only
maximal element, because for every positive natural number, $n$, we have
that $n$ is strictly ``smaller'' than $2n$ under divisibility.
\end{solution}


\problempart  
Prove that this partial order has an infinite chain.

\begin{solution}
1 2 4 8 16 \dots is a chain with infinite length.
\end{solution}

\problempart An \term{antichain} in a partial order is a set of elements
such that any two elements in the set are incomparable.  Prove that this
partial order has an infinite antichain. \hint The primes.

\begin{solution}
The set of prime numbers is infinite.  Since no prime divides
another, any two primes are incomparable.  So the set of prime numbers is
an antichain.
\end{solution}

\ppart  What are the minimal elements of divisibility on the integers
greater than 1?  What are the maximal elements?
\begin{solution}

The primes are the minimal elements.  There are no maximal elements.

\end{solution}
\end{problemparts}

\end{problem}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp8m, S06.cp6w}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  series
  divides
  number_theory
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% S09, S06

\begin{problem}
A number is \term{perfect} if it is equal to the sum of its
positive divisors, other than itself.  For example, 6 is perfect,
because $6 = 1 + 2 + 3$.  Similarly, 28 is perfect, because $28 = 1 +
2 + 4 + 7 + 14$.  Explain why $2^{k-1} (2^k - 1)$ is perfect if $2^k -
1$ is prime.

\begin{solution}
If $2^k - 1$ is prime, then the only divisors of
$2^{k-1} (2^k - 1)$ are:
\[
1,\quad 2,\quad 4,\quad \ldots,\quad 2^{k-1}
\]
which sum to $2^k-1$ (using the formula for a geometric series; in this
case there's a direct ``Computer Science'' proof: think about the binary
representations of $2^j$ and $2^k - 1$), and also
\[
1 \cdot (2^k - 1),\quad 2 \cdot (2^k - 1),\quad 4 \cdot (2^k - 1),\quad
   \ldots,\quad 2^{k-2} \cdot (2^k - 1)
\]
which sum to $(2^{k-1} - 1) \cdot (2^k - 1)$.  Adding these two sums
gives $2^{k-1} (2^k - 1)$, so the number is perfect.

Euclid knew this, and also was able to show that all \emph{even} perfect numbers
are of exactly this form.  To this day, no one knows if there are any
odd perfect numbers!
\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp7m}
\end{pcomments}

\pkeywords{
  structural_induction
  recursive_data
  planar_graphs
  planar_embeddings
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}\label{structind}
Prove the following assertions by structural induction on the definition
of planar embedding.

\bparts

\ppart\label{structind-twice}
In a planar embedding of a graph, each edge is traversed a total of two
times by the faces of the embedding.

\begin{solution}
In the bridge case, the only change is that some face now makes
two traversals of a new edge.  In the face-splitting case, the only change
is that one face splits into two new faces, each traversing the same new
edge once.
\end{solution}

\ppart\label{structind-face-length} In a planar embedding of a graph with
at least three vertices, each face is of length at least three.

\begin{solution}
\textbf{Base case:} Check all possible embeddings of 3 vertex graphs.

\textbf{Constructor case:} (bridge) Two faces are replaced by a longer
face.

\textbf{Constructor case:} (face-splitting) The new faces are of the from
$ab...a$ where the three dots indicate at least one vertex since $a$ and
$b$ are not adjacent, so both new faces are of length at least 3; no other
faces change.
\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp6m}
  \pcomment{from: S06.cp5f}
\end{pcomments}

\pkeywords{
  false_proof
  buildup_error
  graphs
  induction
  connectivity
  degree
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}

A graph is \term{connected} iff there is a path between every pair of its
vertices.

\begin{falseclm*}
If every vertex in a graph has positive degree, then the graph is
connected.
\end{falseclm*}

\bparts

\ppart Prove that this Claim is indeed false by providing a
counterexample.

\begin{solution}
There are many counterexamples; here is one:

\mfigure{!}{0.75in}{figures/false-connect-cx.pdf}

\end{solution}

\ppart Since the claim is false, there must be an logical mistake in the
following ``proof.''  Pinpoint the \emph{first} logical mistake
(unjustified step) in the proof.

%\instatements{\newpage}

\begin{falseproof}

We use induction.  Let $P(n)$ be the proposition that if every vertex in
an $n$-vertex graph has positive degree, then the graph is connected.

\textbf{Base cases}: ($n \leq 2$).  In a graph with 1 vertex, that vertex
cannot have positive degree, so $P(1)$ holds vacuously.

$P(2)$ holds because there is only one graph with two vertices of positive
degree, namely, the graph with an edge between the vertices, and this
graph is connected.

\textbf{Inductive step}: We must show that $P(n)$ implies
$P(n+1)$ for all $n \geq 2$.  Consider an $n$-vertex graph in which every
vertex has positive degree.  By the assumption $P(n)$, this graph is
connected; that is, there is a path between every pair of vertices.  Now
we add one more vertex $x$ to obtain an $(n+1)$-vertex graph:

\mfigure{!}{1.75in}{figures/false-connect-pic.pdf}

All that remains is to check that there is a path from $x$ to every other
vertex $z$.  Since $x$ has positive degree, there is an edge from $x$ to
some other vertex, $y$.  Thus, we can obtain a path from $x$ to $z$
by going from $x$ to $y$ and then following the path from $y$ to $z$.  This
proves $P(n+1)$.

By the principle of induction $P(n)$ is true for all $n \geq 0$, which
proves the theorem.

\end{falseproof}

\begin{solution}
This one is tricky: the proof is actually a good proof of
something else.  The first error in the proof is only in the final
statement of the inductive step: ``This proves $P(n+1)$''.

The issue is that to prove $P(n+1)$, \emph{every} $(n+1)$-vertex
positive-degree graph must be shown to be connected.  But the proof
doesn't show this.  Instead, it shows that every $(n+1)$-vertex
positive-degree graph \emph{that can be built up by adding a vertex of
positive degree to an $n$-vertex connected graph}, is connected.

The problem is that \emph{not every} $(n+1)$-vertex positive-degree graph
can be built up in this way.  The counterexample above illustrates this:
there is no way to build that 4-vertex positive-degree graph from a
3-vertex positive-degree graph.

More generally, this is an example of ``buildup error''.  This error
arises from a faulty assumption that every size $n+1$ graph with some
property can be ``built up'' in some particular way from a size $n$ graph
with the same property.  (This assumption is correct for some properties,
but incorrect for others--- such as the one in the argument above.)

One way to avoid an accidental build-up error is to use a ``shrink
down, grow back'' process in the inductive step: start with a size
$n+1$ graph, remove a vertex (or edge), apply the inductive hypothesis
$P(n)$ to the smaller graph, and then add back the vertex (or edge)
and argue that $P(n+1)$ holds.  Let's see what would have happened if
we'd tried to prove the claim above by this method:

\noindent \textit{Inductive step:} We must show that $P(n)$ implies
$P(n+1)$ for all $n \geq 1$.  Consider an $(n+1)$-vertex graph $G$ in
which every vertex has degree at least 1.  Remove an arbitrary vertex
$v$, leaving an $n$-vertex graph $G'$ in which every vertex has
degree... uh-oh!

The reduced graph $G'$ might contain a vertex of degree 0, making the
inductive hypothesis $P(n)$ inapplicable!  We are stuck--- and
properly so, since the claim is false!
\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%CP_power_set-tower

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{9/23/09 by ARM, from logic notesproblem}
\end{pcomments}

\pkeywords{
 powerset
 cardinality
 Strictly bigger
 infinite
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem} 
There are lots of different sizes of infinite sets.  For example, starting
with the infinite set, $\naturals$, of nonnegative integers, we can build
the infinite sequence of sets
\[
\naturals,\ \power(\naturals),\ \power(\power(\naturals)),\
\power(\power(\power(\naturals))),\ \dots.
\]
By Theorem~\ref{powbig} from the Notes, each of these sets is
\emph{strictly bigger}\footnote{Reminder: set $A$ is \term{strictly bigger than}
  set $B$ just means that $A \surj B$, but $\QNOT(B \surj A)$.}
than all the preceding ones.  But that's not all:
if we let $U$ be the union of the sequence of sets above, then $U$ is
strictly bigger than every set in the sequence!  Prove this:
\begin{lemma*}
  Let $\power^n(\naturals)$ be the $n$th set in the sequence,
  and
  \[
  U \eqdef \lgunion_{n=0}^\infty \power^n(\naturals).
  \]
  Then
\begin{enumerate}
\item\label{Usp} $U \surj \power^n(\naturals)$ for every $n \in \naturals$, but

\item\label{nopsU} there is no $n \in \naturals$ for which
  $\power^n(\naturals) \surj U$.
\end{enumerate}
\end{lemma*}

Now of course, we could take $U, \power(U), \power(\power(U)), \dots$ and can
keep on indefinitely building still bigger infinities.

\begin{solution}
Everything follows from a trivial observation: if $A \supseteq B$, then $A
\surj B$.  (Why is this trivial?)

So since $U \supseteq \power^n(\naturals)$, we have $U \surj
\power^n(\naturals)$, which proves~\ref{Usp}.

To prove~\ref{nopsU}, assume to the contrary that $\power^m(\naturals)
\surj U$.  Now we know from~\ref{Usp} that $U \surj
\power^{m+1}(\naturals)$.  But this implies that
\[
\power^m(\naturals)
\surj \power^{m+1}(\naturals) = \power(\power^m(\naturals)),
\]
contradicting the fact that, by Theorem~\ref{powbig}, a power set of
$\power^m(\naturals))$ is ``strictly bigger'' than $\power^m(\naturals))$.
\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
%CP_prerequisite_relation

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp3r}
  \pcomment{There is some pdf error that needs to be addressed}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  relations
  scheduling
  partial_orders
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem} \mbox{}  %LaTeX artifact to position the table

\begin{center}
\begin{tabular}{|l|l|}
\hline
Direct Prerequisites & Subject\\ \hline
 18.01 & 6.042\\ \hline
 18.01 & 18.02\\ \hline
 18.01 & 18.03\\ \hline
 8.01  & 8.02\\ \hline
 8.01  & 6.01\\ \hline
 6.042 & 6.046\\ \hline
 18.02, 18.03, 8.02, 6.01 & 6.02\\ \hline
 6.01, 6.042 & 6.006\\ \hline
 6.01 & 6.034\\ \hline
 6.02 & 6.004\\ \hline
\end{tabular}
\end{center}

\bparts

\ppart\label{prereqtable} For the above table of MIT subject
prerequisites, draw a diagram showing the subject numbers with a line
going down from each subject to each of its (direct) prerequisites.

\begin{solution}
%\TBA{pdf bug in figure}
\textbf{TBA}

\iffalse
\begin{center}%causes latex error
\includegraphics[height=2.5in]{prereq-poset}%.pdf}
\end{center}
\fi

\end{solution}

\eparts

For each of the following binary relations, describe an isomorphic (``same
shape'') collection of sets partially ordered by the proper subset
relation, $\subset$.

\bparts

\ppart The prerequisite relation among MIT subjects from part\eqref{prereqtable}.
Explain what would go wrong if the set corresponding to a subject consisted only
of its indirect prerequisites (that is, the subject itself was not
included in the corresponding set)?  \hint Consider 18.01 and 6.042.

\begin{solution}
  For each subject, let the corresponding set be the subject itself along
  with all the subjects that are indirect prerequisites of that subject.
  (Remember that a direct prerequisite is considered to be a special case
  of an indirect one.)  For example, the set corresponding to 6.006 would
  be $\set{\text{6.006, 6.01, 6.042, 18.01}}$.

If the subject itself was not included in its corresponding set, then
subjects like 18.01 and 6.042 that have the same prerequisites would both
correspond to the same set, so the correspondence between subjects and
sets would not be a bijection.
\end{solution}

\ppart  The ``empty'' relation on 5 elements.  That is, the relation
under which no element is related to anything.

\begin{solution}
  Letting the five elements be $1,2,3,4,5$, the recipe of mapping an
  element to its preimages under the relation, with the element itself
  thrown in, gives the five sets $\set{1},\set{2},\set{3},\set{4},\set{5}$.

Of course any 5 sets none of which is contained in any of the others will
also work, for example, all the size 4 subsets of $\set{1,2,3,4,5}$

\textbf{Quick Question}: The empty binary relation on a set is defined to
be the relation whose graph is empty, that is, it has no arrows.  Why is
the empty relation a strict partial order?  Why isn't it a weak partial
order?

\iffalse
It's vacuously asymmetric and transitive.  It's not reflexive because
element don't have self-looping arrows.
\fi

\end{solution}

\ppart The "properly contains'' relation, $\supset$, on
$\power{\set{1, 2, 3,4}}$.

\begin{solution}
  The standard inverse image solution involves sets of subsets.  A more
  elegant correspondence is to let each set $A \subseteq \set{1, 2, 3,4}$
  correspond to its complement.  That is,
\[
f(A) = \bar{A} \eqdef \set{1, 2, 3,4} - A.
\]
This works because $A \supset B$ iff $\bar{A} \subset \bar{B}$
\end{solution}

\eparts

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
%CP_product_relation_properties

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{quickie and remarked in partial order notes}
\end{pcomments}

\pkeywords{
  product_relation
  irreflexive
  transitivity
  reflexivity
  antisymmetry
  preserved
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
  Let $R_1$, $R_2$ be binary relations on the same set, $A$.  A relational
  property is preserved under product, if $R_1 \times R_2$ has the
  property whenever both $R_1$ and $R_2$ have the property.

\bparts

\ppart Verify that each of the following properties are preserved under
product.
\begin{enumerate}

\item reflexivity,

\item asymmetry,

\item transitivity.             %

\end{enumerate}

\ppart
Verify that if \emph{either} of $R_1$ or $R_2$ is irreflexive, then so is $R_1 \cross R_2$.
\eparts

\begin{solution}
\TBA{TBA}
\end{solution}

\end{problem}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp8t, S06.cp7m}
%  \pcomment{}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  modular_arithmetic
  number_theory
  divides
  congruence
  remainders
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}

\bparts

The following properties of equivalence mod $n$ follow directly from its
definition and simple properties of divisibility.  See if you can prove
them without looking up the proofs in the notes.

\ppart\label{multc} If $a \equiv b \pmod{n}$, then $a c \equiv b c
\pmod{n}$.

\begin{solution}
The condition $a \equiv b \pmod{n}$ is equivalent to the
assertion $n \divides (a - b)$.  This implies that $n \divides (a - b)c$,
and so $n \divides (ac - bc)$.  This is equivalent to $ac \equiv bc
\pmod{n}$.
\end{solution}

\ppart\label{transitive} If $a \equiv b \pmod{n}$ and $b \equiv c
\pmod{n}$, then $a \equiv c \pmod{n}$.

\begin{solution}
Assume $a \equiv b \pmod{n}$ and $b \equiv c \pmod{n}$, that is,
$n \divides (a - b)$ and $n \divides (b - c)$.  Then $n \divides (a - b) +
(b - c) = (a-c)$, so $a \equiv c \pmod{n}$.
\end{solution}

\ppart If $a \equiv b \pmod{n}$ and $c \equiv d \pmod{n}$, then $a c
\equiv b d \pmod{n}$.

\begin{solution}
$a \equiv b \pmod{n}$ implies $ac \equiv bc \pmod{n}$ by
part~\eqref{multc}; likewise, $c \equiv d \pmod{n}$ implies $bc \equiv bd
\pmod{n}$.  So $a c \equiv b d \pmod{n}$ by part~\eqref{transitive}.
\end{solution}

\ppart $\rem{a}{n} \equiv a \pmod{n}$.

\begin{solution}
The remainder $\rem{a}{n}$ is equal to $a - qn$ for some integer
$q$.  However, for every integer $q$:
\begin{align*}
n \divides qn &  \iff  n \divides ((a - qn) - a) \\
              &  \implies  n \divides (\rem{a}{n} - a)\\
              & \iff  \rem{a}{n} \equiv a \pmod{n}.
\end{align*}
\end{solution}
\eparts

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp8m, S06.cp6w}
  \pcomment{has some commented out parts that should be proofread and 
            added or removed}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  gcd
  linear_combinations
  divides
  number_theory
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
  Use the fact that $\gcd(a, b)$ is an integer linear combination of $a$
  and $b$ to prove the following properties of divisibility and gcd's.
  (You may not appeal to uniqueness of prime factorization ---aka the
  Fundamental Theorem of Arithmetic ---because these properties are needed
  to \emph{prove} the Fundamental Theorem.)

\bparts

\ppart\label{ecd} Every common divisor of $a$ and $b$ divides $\gcd(a, b)$.

\begin{solution}
For some $s$ and $t$, $\gcd(a, b) = s a + tb$.  Let $c$ be a
common divisor of $a$ and $b$.  Since $c \divides a$ and $c \divides b$,
we have $a =kc, b=k'c$ so
\[
s a + t b = skc + tk'c = c(sk+tk')
\]
so $c \divides s a + t b$.
\end{solution}


\iffalse

\ppart $\gcd(k a, k b) = k \cdot \gcd(a, b)$ for all $k > 0$.

\begin{solution}
We prove that each divides the other, which implies that one is $\pm$ the
other.  Since both are nonnegative, this implies they are equal.

Since $k\gcd(a,b) =k(sa+tb) = s(ka)+t(kb)$ for some $s,t$, any common
divisor of of $ka$ and $kb$ will divide $k\gcd(a,b)$, so in particular,
\[
\gcd(ka,kb) \divides k\gcd(a,b)
\]

Conversely, $\gcd(k a, k b) = s'(ka)+t'(kb) = (s'k)a+(t'k)b$ for some
$s',t'$, so is a linear combination of $a$ and $b$ and therefore,
\[
\gcd(a,b) \divides \gcd(k a, k b)
\]

\end{solution}
\fi


\ppart\label{adb} If $a \divides b c$ and $\gcd(a, b) = 1$, then $a \divides c$.

\begin{solution}
Since $\gcd(a, b) = 1$, we have $sa+tb=1$ for some $s,t$.  Multiplying by
$c$, we have
\[
sac+tbc=c
\]
but $a$ divides the second term of the sum since $a \divides b c$, and it
obviously divides the first term, and therefore it divides the sum, which
equals $c$.

\end{solution}

\ppart If $p \divides ab$ for some prime, $p$, the $p \divides a$ or $p
\divides b$.

\begin{solution}
If $p$ does not divide $a$, then since $p$ is prime, $\gcd(p,a)
  =1$.  By part~\eqref{adb}, we conclude that $p \divides b$.  
\end{solution}

\ppart $\gcd(a, b) = \gcd(b, \rem{a}{b})$

\begin{solution}
Let $r = \rem{a}{b}$.

Since $r=a-qb$ for some $q$, we have that $r$ is a linear combination of
$a$ and $b$ and is therefore divisible by $\gcd(a,b)$.  So any linear
combination of $r$ and $b$ is divisible by $\gcd(a,b)$.  Hence,
\[
\gcd(a,b) \divides \gcd(b,r)
\]

Conversely, $a = qb+r$ is a linear combination of $b$ and $r$ and is
therefore divisible by $\gcd(b,r)$.  Since $\gcd(b,r)$ divides both $a$
and $b$, we conclude from part~\eqref{ecd} that
\[
\gcd(b,r) \divides \gcd(a,b).
\]

\end{solution}

\eparts

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp2r}
%  \pcomment{}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  logic
  set_theory
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
\emph{Set Formulas and Propositional Formulas.}
\bparts

\ppart\label{verprop}

Verify that the propositional formula $(P\ \QAND\ \,
\QNOT(Q))\ \QOR\ (P\ \QAND\ Q)$ is equivalent to $P$.

\begin{solution}
There is a simple verification by truth table with 4 rows which we omit.

There is also a simple cases argument: if $Q$ is \true, then the formula
simplifies to $(P\ \QAND\ \false)\ \QOR\ (P\ \QAND\ \true)$ which further
simplifies to $(\false\ \QOR\ P)$ which is equivalent to $P$.

Otherwise, if $Q$ is \textcolor{red}{F}, then the formula simplifies to
$(P\ \QAND\ \true)\ \QOR\ (P\ \QAND\ \false)$ which
is likewise equivalent to $P$.
\end{solution}

\ppart Use part~\eqref{verprop} to prove that
\[
A = (A-B) \union (A \intersect B)
\]
for any sets, $A,B$, where
\[
A-B \eqdef \set{a \in A \suchthat a \notin B}.
\]

\begin{solution}
We need only show that the two sets have the same elements, that is $x$ is
in one set iff $x$ is in the other set, for any $x$.

Let $P$ be $x \in A$ and $Q$ be $x \in B$.  Then
\begin{align*}
\lefteqn{x \in (A-B) \union (A \intersect B)}\\
 & \qiff x \in (A-B)\ \QOR\ x \in (A
\intersect B) & \text{(by def of $\union$)}\\
& \qiff (x \in A\ \QAND\  \QNOT(x \in B))\ \QOR\ (x \in A\ \QAND\  x \in B) 
  & \text{(by def of $\intersect$ and $-$)}\\
& \qiff (P\ \QAND\  \QNOT(Q))\ \QOR\ (P\ \QAND\ Q) & \text{(by def of
  $P$ and $Q$)}\\
&\qiff P & \text{(by part~\eqref{verprop})}\\
& \qiff x \in A & \text{(by def of $P$)}.
\end{align*}

\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp3t}
%  \pcomment{}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  bijections
  mapping_lemma
  rational
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
  \bparts \ppart Describe a bijection between the integers, $\integers$,
  and the positive integers, $\integers^+$.

  \begin{solution}
One such bijection is defined by lining up all the integers and
    the positive integers as follows:
\[\begin{array}{ccccccccl}
0 & 1 & -1 & 2 & -2 & 3 & -3 & 4 & \dots\\
1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & \dots
\end{array}\]
We can also define this bijection, $f:\integers \to \integers^+$, by a specification rule
\[
f(n) = \begin{cases}
       2n & \text{for } n>0,\\
       2\abs{n} +1  & \text{for } n\leq 0.
       \end{cases}
\]

\end{solution}

\ppart Define a bijection between the positive integers, $\integers^+$,
and the set, $\integers^+ \times \integers^+$, of all the ordered pairs of
positive integers:
\[\begin{array}{l}
(1,1),(1,2),(1,3),(1,4),\dots\\
(2,1),(2,2),(2,3),(2,4),\dots\\
(3,1),(3,2),(3,3),(3,4),\dots\\
(4,1),(4,2),(4,3),(4,4),\dots\\
\qquad \vdots
\end{array}\]

\begin{solution}
Line up all the pairs by following successive upper-right to
  lower-left diagonals along the top row.

That is, start with (1,1) which counts as an initial diagonal of length 1.
Then follow the length 2 second diagonal (1,2), (2,1), then the length 3
third diagonal (1,3), (2,2), (3,1), then the length 4 fourth diagonal
(1,4) (2,3) (3,2) (4,1) \dots.  So the line up would be
\[\begin{array}{ccccccccccccl}
(1,1) & (1,2) & (2,1) & (1,3) & (2,2) & (3,1) & (1,4) & (2,3) & (3,2) &
(4,1) & \dots\\ 
   1  & 2     & 3     & 4     & 5     & 6     & 7     & 8     & 9     & 10 &\dots
\end{array}\]

It's interesting that this bijection from $\integers^+ \times \integers^+$
to $\integers^+$ has a simple formula: the pair $(k,m)$ is the $k$th
element on the diagonal consisting of the pairs whose sum is $k+m$.  The
total number of elements in all the preceding diagonals is
\[
1 + 2 + 3 + \cdots + (k+m-2) = (k+m - 1)(k+m-2 )/2
\]
so the pair $(k,m)$ appears as the $(k+m -1)(k+m-2)/2 + k$th element in
the line up.
\end{solution}

\ppart Conclude that $\integers^+$ is the same size as the set,
$\rationals^+$, of all positive rational numbers.

\begin{solution}
One way to line up the positive rationals is to take the list
  of all pairs, $(k,m)$, of integers above and replace each remaining pair
  by the rational number $k/m$,
\begin{quote}
1/1\ \ \ 1/2\ \ \ 2/1\ \ \ 1/2\ \ \ 2/2\ \ \ 3/1\ \ \ 1/3\ \ \ 2/3\ \ \ 3/2\ \ \ 4/1\ \ \ \dots
\end{quote}
and, going from left to right, delete all the occurrences of numbers
that are already in the list:
\begin{quote}
1\ \ \ 1/2\ \ \ 2\ \ \ 3\ \ \ 1/3\ \ \ 2/3\ \ \ 3/2\ \ \ 4 \dots.
\end{quote}

\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
%CP_recognizable_sets

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S06.cp2f; revised by ARM 9/20/09}
  \pcomment{needs handy copy of Russell paradox or Theorem~ref{powbig}}
\end{pcomments}

\pkeywords{
  diagonal argument
  Russell paradox
  recognizable
  halting problem
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Let's refer to a programming procedure (written in your favorite
programming language ---C++, or Java, or Python, \dots) as a \term{string
  procedure} when it is applicable to data of type \texttt{string} and
only returns values of type \texttt{boolean}.  When a string procedure,
$P$, applied to a \texttt{string}, $s$, returns \True, we'll say that $P$
\term{recognizes} $s$.  If $\mathcal{R}$ is the set of strings that $P$
recognizes, we'll call $P$ a \term{recognizer} for $\mathcal{R}$.

\bparts

\ppart\label{odd_numeral} Describe how a recognizer for the set of strings
that are the arabic (decimal) numeral for an odd number would work.  (Even
better, actually write a recognizer procedure in your favorite programming
language).

\begin{solution}
  Of course if your programming language has a commonly built-in
  \texttt{string->number} procedure, this is trivial: when applied to an
  input \texttt{string}, $s$, your procedure applies
  \texttt{string->number} to $s$ and checks that the resulting number is
  odd.  (Better watch out though, how does your built-in procedure handle
  strings with leading zeros? ---the arabic numeral for 170 is
  ``\texttt{170},'' not ``\texttt{00017}.'')

  There's also a simpler approach than writing a general
  \texttt{string->number} procedure.  All the standard programming
  languages have built-in operations for scanning the characters in a
  string.  So simply write a procedure that starts by checking that the
  first character of input $s$ is a decimal digit other than \texttt{0}.
  Then let it scan the remaining characters, checking that each is a
  decimal digit, and that the last digit is odd.

\end{solution}

\eparts

A set of \texttt{string}s is called \emph{recognizable} if
there is a recognizer procedure for it.

When you actually program a procedure, you have to type the program text
into a computer system.  This means that every procedure is described by
some \texttt{string} of typed characters.  If a \texttt{string}, $s$, is
actually the typed description of some string procedure, let's refer to
that procedure as $P_s$.  You can think of $P_s$ as the result of
compiling $s$.\footnote{The string, $s$, and the procedure, $P_s$, have to
  be distinguished to avoid a type error: you can't apply a string to
  string.  For example, let $s$ be the string that you wrote as your
  program to answer part~\eqref{odd_numeral}.  Applying $s$ to a string
  argument, say \texttt{27309}, should throw a type exception; what you
  need to do is apply the procedure $P_s$ to \texttt{27309}.  This should
  result in a returned value \True, since \texttt{27309} is the numeral for
  an odd number.}

In fact, it will be helpful to associate every string, $s$, with a
procedure, $P_s$; we can do this by defining $P_s$ to be some fixed string
procedure ---it doesn't matter which one ---whenever $s$ is not the typed
description of an actual procedure that can be applied to
\texttt{string}s.  The result of this is that we have now defined a total
function, $f$, mapping every \texttt{string}, $s$, to the set, $f(s)$, of
\texttt{string}s recognized by $P_s$.  That is we have a total function,
\begin{equation}\label{f:s-to-Ps}
f: \mtt{string} \to \power(\mtt{string}).
\end{equation}

\bparts

\ppart
Explain why the actual range of $f$ is the set of all recognizable sets of
strings.

\begin{solution}
Since $f(s)$ is the set of strings recogized by $P_s$, everything in
$\range{f}$ is a recogizable set.  Conversely,  every recogizable set is
in $\range{f}$: if $\mathcal{R}$ is a recognizable
set, then by definition, there is a procedure, $P$, that recognizes $R$.  So
if $r$ is the input program from which $P$ was compiled, then
$\mathcal{R} = f(r)$.
\end{solution}

\eparts

This is exactly the set up we need to apply the reasoning behind Russell's
Paradox to define a set that is not in the range of $f$, that is, a set of
strings, $\mathcal{N}$, that is \emph{not} recognizable.

\bparts

\ppart\label{Ps-to-s}
Let
\[
\mathcal{N} \eqdef \set{s \in \mtt{string} \suchthat P_s \text{ applied to
$s$ does not return \True}}.
\]
So for every \texttt{string}, $s$, we have by definition
\begin{equation}\label{Ps}
s \in \mathcal{N} \qiff P_s\text{ applied to $s$ does not return \True}.
\end{equation}

Prove that $\mathcal{N}$ is not recognizable.

\hint Russell's paradox.

\begin{solution}
Assume to the contrary that $\mathcal{N}$ was recognizable by some string
procedure.  This procedure must have a string, $w$, that describes it,
so we have
\begin{equation}\label{Pr}
s \in \mathcal{N} \qiff  P_w\text{ applied to $s$ returns \True},
\end{equation}
for all \texttt{string}'s $s$.

Combining~\eqref{Ps} and ~\eqref{Pr}, we have that for every string, $s$,
\begin{equation}\label{PP}
  P_s\text{ applied to $s$ does not return \True}
  \qiff P_w\text{ applied to $s$ returns \True}.
\end{equation}
Now letting $s$ be $w$ in~\eqref{PP}, we reach the contradiction
\[
P_w\text{ applied to $w$ does not return \True}
\qiff P_w\text{ applied to $w$ returns \True}.
\]

This contradiction implies that the assumption that $\mathcal{N}$ was
recognizable must be false.

Notice that $\mathcal{N}$ could have been described as $\set{s \in
  \texttt{string} \suchthat s \not f(s)}$ for $f$ defined
in~\eqref{f:s-to-Ps}.  Using this description of $\mathcal{N}$, the proof
above would be exactly the same as the proof in the Notes of
Theorem~\ref{powbig} that the powerset of $A$ is strictly bigger than $A$.
\end{solution} 

\ppart Discuss what the conclusion of part~\eqref{Ps-to-s} implies about
the possibility of writing ``program analyzers'' that take programs
as inputs and analyze their behavior.

\begin{solution}
  Lets call a programming procedure ``self-unconscious'' if it does not
  return \True\ when applied to its own textual definition.

  Rephrased informally, the conclusion of part~\eqref{Ps-to-s} says that
  it is logically impossible to design a \emph{general} program analyzer,
  which takes as input the (textual definition) of an arbitrary program,
  and recognizes when the program is self-unconscious.  This implies that
  it is impossible to write a program which does the more general analysis
  of how an arbitrary procedure behaves when applied to some given
  arguments.

  BTW, it \emph{is} feasible to write a general procedure that recognizes
  when an arbitrary input procedure \emph{does} return a value ---the
  general procedure just carries out the computation specified by its
  input and returns \True\ exactly when the procedure it is simulating
  returns a value.  In other words, this general procedure just acts like
  a virtual machine simulator or ``interpreter'' for the programming
  language of its input programs.

  It's also important to recognize that there's no hope of getting around
  this by switching programming languages.  For example, by
  part~\eqref{Ps-to-s}, no C++ program can analyze arbitrary C++ programs,
  and no Java program can analyze Java programs, but you might wonder if a
  language like C++, which allows more intimate manipulation of computer
  memory than Java, might therefore allow a C++ program to analyze general
  Java programs.  But there is no loophole here: since it's possible to
  write a Java program that is a simulator/interpreter for C++ programs,
  if a C++ program could analyze Java programs, so could the Java program
  that simulated the C++ program, contradicting~\eqref{Ps-to-s}.
  
  It's a different story if we think about the \emph{practical}
  possibility of writing programming analyzers.  The fact that it's
  logically impossible to write analyzers for completely general programs
  does not mean that you can't do a very good job analyzing interesting
  programs that come up in practice.  In fact these ``interesting''
  programs are commonly \emph{intended} to be analyzable in order to
  confirm that they do what they're supposed to do.

  So it's not clear how much of a hurdle this theoretical limitation
  implies in practice.  What the theory does provide is some perspective
  on claims about general analysis methods for programs.  The theory tells
  us that people who make such claims either

\begin{itemize}
\item are exaggerating the power (if any) of their methods ---say to get a
  grant or make a sale, or

\item are trying to keep things simple by not going into technical
  limitations they're aware of, or

\item perhaps most commonly, are so excited about some useful practical
    successes of their methods, that they haven't bothered to think about
    their limitations.
\end{itemize}  

So from now on, if you hear people making claims about completely general
program analysis/verification/optimization methods, you'll know they can't
be telling the whole story.
\end{solution}

\eparts

\end{problem}

\endinput
\begin{problem}
Here is a simple recursive definition of the set, $E$, of even integers:
\begin{definition*}
\textbf{Base case}: $ 0 \in E$.

\textbf{Constructor cases}:
    If $n \in E$, then so are $n+2$ and $-n$.
\end{definition*}
Provide similar simple recursive definitions of the following sets:

\begin{problemparts}

\item The set $S \eqdef \set{ 2^k 3^m 5^n \suchthat k,m,n \in
\naturals}$.

\begin{solution}
We can define the set $S$ recursively as follows:

\begin{itemize}
\item $1 \in S$
\item If $n \in S$, then $2n$, $3n$, and $5n$ are in $S$.
\end{itemize}

\end{solution}

\item  The set $T \eqdef \set{2^k 3^{2k+m} 5^{m+n} \suchthat k,m,n \in
\naturals}$.

\begin{solution}
We can define the set $T$ recursively as follows:

\begin{itemize}
\item $1 \in T$
\item If $n \in S$, then $18n$, $15n$, and $5n$ are in $T$.
\end{itemize}

\end{solution}

\item The set $L \eqdef \set{ (a, b) \in \integers^2 \suchthat 3
  \divides (a-b)}$.

\begin{solution}
We can define a set $L' = L$ recursively as follows:

\begin{itemize}
\item $(0, 0), (1,1), (2,2) \in L'$
\item If $(a, b) \in L'$, then $(a + 3, b)$, $(a - 3, b)$, $(a, b +3)$, and
$(a, b -3)$ are in $L'$.
\end{itemize}

Lots of other definitions are also possible.
\end{solution}
\eparts

Let $L'$ be the set defined by the recursive definition you gave for $L$
in the previous part.  Now if you did it right, then $L'=L$, but maybe you
made a mistake.  So let's check that you got the definition right.

\bparts
\ppart Prove by structural induction on your definition of $L'$ that
\[
L' \subseteq L.
\]

\begin{solution}
For the $L'$ defined above, a straightforward structural induction shows
that if $(c,d) \in L'$, then $(c,d) \in L$.  Namely, each of the base
cases in the definition of $L'$ are in $L$ since $3 \divides 0$.  For the
constructor cases, we may assume $(a,b) \in L$, that is $3 \divides
(a-b)$, and must prove that $(a\pm 3,b) \in L$ and $(a,b \pm 3) \in L$.
In the first the case, we must show that $3 \divides ((a\pm 3)-b)$.  But
this follows immediately because $((a\pm 3)-b) = (a-b)\pm 3$ and 3 divides
both $(a-b)$ and 3.  The other constructor case $(a,b\pm 3)$ follows in
exactly the same way.  So we conclude by structural induction on the
definition of $L'$ that $L' \subseteq L$.
\end{solution}

\ppart \emph{Optional: come back to this part only if you finish all the
  remaining problems.}  Confirm that you got the definition right by
proving that
\[
L \subseteq L'.
\]

\begin{solution}
Conversely, we must show that $L \subseteq L'$.  So suppose
  $(c,d) \in L$, that is, $3 \divides (c-d)$.  This means that $c = r+3k$
  and $d=r +3j$ for some $r \in \set{0,1,2}$ and $j,k \in \integers$.
  Then starting from base case $(r,r) \in L'$, we can apply the $(a \pm
  3,b)$ constructor rule $\abs{k}$ times to conclude that $(c,r) \in L'$,
  and then apply the $(a ,b \pm 3)$ rule $\abs{j}$ times to conclude that
  $(c,d) \in L'$.  This implies that $L \subseteq L'$, which completes the
  proof that $L = L'$.
\end{solution} 

\ppart \emph{Optional: come back to this part only if you finish all the
  remaining problems.}  Give an \emph{unambiguous} recursive definition of
$L$.

\begin{solution}
This is tricky.  Here is an attempt:

  \textbf{base cases}: $(0, 0), (1,1), (2,2), (-1,-1), (-2,-2), (-3,-3)
  (1, -2), (2, -1), (-1, 2), (-2, 1) \in L$

Now the idea is to constrain the constructors so the two coordinates have
absolute values that increase differing by at most 1, then one coordinate only
can continue to grow in absolute value.  Let
\[
\sg(x) \eqdef \begin{cases}
              1 \text{ if } x \geq 0,\\
             -1 \text{ if } x < 0.
              \end{cases}
\]

\textbf{constructors}: if $(a,b) \in L'$, then

\begin{itemize}

\item if $\abs{\abs{a} - \abs{b}} \leq 1 $, then $(a+3\sg(a),b+3\sg(b)),
  (a+3\sg(a),b), (a,b+3\sg(b)) \in L'$,

\item if $\abs{a} > \abs{b}+1$, then $(a+3\sg(a),b) \in L'$,

\item if $\abs{b} > \abs{a} + 1$, then $(a,b+3\sg(b)) \in L'$.

\end{itemize}

\end{solution}

\end{problemparts}
\end{problem}

%CP_recursively_defined_sets

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp5m}
%  \pcomment{}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  set_theory
  recursive_data
  structural_induction  
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
%
Here is a simple recursive definition of the set, $E$, of even integers:
\begin{definition*}
\textbf{Base case}: $ 0 \in E$.

\textbf{Constructor cases}:
    If $n \in E$, then so are $n+2$ and $-n$.
\end{definition*}
Provide similar simple recursive definitions of the following sets:

\bparts

\item The set $S \eqdef \set{ 2^k 3^m 5^n \suchthat k,m,n \in
\naturals}$.

\begin{solution}
We can define the set $S$ recursively as follows:

\begin{itemize}
\item $1 \in S$
\item If $n \in S$, then $2n$, $3n$, and $5n$ are in $S$.
\end{itemize}

\end{solution}

\item  The set $T \eqdef \set{2^k 3^{2k+m} 5^{m+n} \suchthat k,m,n \in
\naturals}$.

\begin{solution}
We can define the set $T$ recursively as follows:

\begin{itemize}
\item $1 \in T$
\item If $n \in S$, then $18n$, $15n$, and $5n$ are in $T$.
\end{itemize}

\end{solution}

\item The set $L \eqdef \set{ (a, b) \in \integers^2 \suchthat 3
  \divides (a-b)}$.

\begin{solution}
We can define a set $L' = L$ recursively as follows:

\begin{itemize}
\item $(0, 0), (1,1), (2,2) \in L'$
\item If $(a, b) \in L'$, then $(a + 3, b)$, $(a - 3, b)$, $(a, b +3)$, and
$(a, b -3)$ are in $L'$.
\end{itemize}

Lots of other definitions are also possible.
\end{solution}
\eparts

Let $L'$ be the set defined by the recursive definition you gave for $L$
in the previous part.  Now if you did it right, then $L'=L$, but maybe you
made a mistake.  So let's check that you got the definition right.

\bparts
\ppart Prove by structural induction on your definition of $L'$ that
\[
L' \subseteq L.
\]

\begin{solution}
For the $L'$ defined above, a straightforward structural induction shows
that if $(c,d) \in L'$, then $(c,d) \in L$.  Namely, each of the base
cases in the definition of $L'$ are in $L$ since $3 \divides 0$.  For the
constructor cases, we may assume $(a,b) \in L$, that is $3 \divides
(a-b)$, and must prove that $(a\pm 3,b) \in L$ and $(a,b \pm 3) \in L$.
In the first the case, we must show that $3 \divides ((a\pm 3)-b)$.  But
this follows immediately because $((a\pm 3)-b) = (a-b)\pm 3$ and 3 divides
both $(a-b)$ and 3.  The other constructor case $(a,b\pm 3)$ follows in
exactly the same way.  So we conclude by structural induction on the
definition of $L'$ that $L' \subseteq L$.
\end{solution}

\ppart  Confirm that you got the definition right by
proving that
\[
L \subseteq L'.
\]

\begin{solution}
Conversely, we must show that $L \subseteq L'$.  So suppose
  $(c,d) \in L$, that is, $3 \divides (c-d)$.  This means that $c = r+3k$
  and $d=r +3j$ for some $r \in \set{0,1,2}$ and $j,k \in \integers$.
  Then starting from base case $(r,r) \in L'$, we can apply the $(a \pm
  3,b)$ constructor rule $\abs{k}$ times to conclude that $(c,r) \in L'$,
  and then apply the $(a ,b \pm 3)$ rule $\abs{j}$ times to conclude that
  $(c,d) \in L'$.  This implies that $L \subseteq L'$, which completes the
  proof that $L = L'$.
\end{solution} 

\ppart See if you can give an \emph{unambiguous} recursive definition of
$L$.

\begin{solution}
This is tricky.  Here is an attempt:

  \textbf{base cases}: $(0, 0), (1,1), (2,2), (-1,-1), (-2,-2), (-3,-3)
  (1, -2), (2, -1), (-1, 2), (-2, 1) \in L$

Now the idea is to constrain the constructors so the two coordinates have
absolute values that increase differing by at most 1, then one coordinate only
can continue to grow in absolute value.  Let
\[
\sg(x) \eqdef \begin{cases}
              1 \text{ if } x \geq 0,\\
             -1 \text{ if } x < 0.
              \end{cases}
\]

\textbf{constructors}: if $(a,b) \in L'$, then

\begin{itemize}

\item if $\abs{\abs{a} - \abs{b}} \leq 1 $, then $(a+3\sg(a),b+3\sg(b)),
  (a+3\sg(a),b), (a,b+3\sg(b)) \in L'$,

\item if $\abs{a} > \abs{b}+1$, then $(a+3\sg(a),b) \in L'$,

\item if $\abs{b} > \abs{a} + 1$, then $(a,b+3\sg(b)) \in L'$.

\end{itemize}

\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp6r}
  \pcomment{from: S07.cp6m}
\end{pcomments}

\pkeywords{
  graph_coloring
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
A portion of a computer program consists of a sequence of calculations
where the results are stored in variables, like this:
\[
\begin{array}{rrrcl}
&& \text{Inputs:} &  & a, b \\
\text{Step } 1. & \hspace{0.5in} & c & = & a + b \\
2. && d & = & a * c \\
3. && e & = & c + 3 \\
4. && f & = & c - e \\
5. && g & = & a + f \\
6. && h & = & f + 1 \\
&& \text{Outputs:} & & d, g, h
\end{array}
\]
A computer can perform such calculations most quickly if the value of
each variable is stored in a {\em register}, a chunk of very fast
memory inside the microprocessor.  Computers usually have few
registers, however, so they must be used wisely and reused often.  The
problem of assigning each variable in a program to a register is
called {\em register allocation}.

In the example above, variables $a$ and $b$ must be assigned different
registers, because they hold distinct input values.  Furthermore, $c$
and $d$ must be assigned different registers; if they used the same
one, then the value of $c$ would be overwritten in the second step and
we'd get the wrong answer in the third step.  On the other hand,
variables $b$ and $d$ may use the same register; after the first step,
we no longer need $b$ and can overwrite the register that holds its
value.  Also, $f$ and $h$ may use the same register; once $f + 1$ is
evaluated in the last step, the register holding the value of $f$ can
be overwritten.(Assume that the computer carries out each step in the 
order listed and that each step is completed before the next is begun.)

\bparts

\ppart Recast the register allocation problem as a question
about graph coloring.  What do the vertices correspond to?  Under what
conditions should there be an edge between two vertices?  Construct
the graph corresponding to the example above.

\begin{solution}
There is one vertex for each variable.  An edge
between two vertices indicates that the values of the variables must
be stored in different registers.

We can classify each appearance of a variable in the program as either
an {\em assignment} or a {\em use}.  In particular, an appearance is
an assignment if the variable is on the left side of an equation or on
the ``Inputs'' line.  An appearance of a variable is a use if the
variable is on the right side of an equation or on the ``Outputs'' line.
The {\em lifetime} of a variable is the segment of code extending from
the initial assignment of the variable until the last use.  There is
an edge between two variables if their lifetimes overlap.  This rule
generates the following graph:

\mfigure{5in}{!}{figures/register1}
\end{solution}

\ppart Color your graph using as few colors as you can.  Call
the computer's registers $R1$, $R2$, etc.  Describe the assignment of
variables to registers implied by your coloring.  How many registers
do you need?

\begin{solution}
Four registers are needed.

One possible assignment of variables to registers is indicated in 
the figure above. In general, coloring a graph using the minimum 
number of colors is quite difficult; no efficient procedure is known.  
However, the register allocation problem always leads to an {\em 
interval graph}.For interval graphs, there are efficient coloring 
procedures, which can be incorporated into a compiler.
\end{solution}

\ppart Suppose that a variable is assigned a value more than
once, as in the code snippet below:
\begin{eqnarray*} 
  & \ldots & \\
t & = & r + s \\
u & = & t * 3 \\
t & = & m - k \\
v & = & t + u \\  
& \ldots &
\end{eqnarray*}

How might you cope with this complication?

\begin{solution}
Each time a variable is reassigned, we could
regard it as a completely new variable.  Then we would regard the
example as equivalent to the following:
\begin{eqnarray*}
  & \ldots & \\
t & = & r + s \\
u & = & t * 3 \\
t' & = & m - k \\
v & = & t' + u \\
  & \ldots &
\end{eqnarray*}

We can now proceed with graph construction and coloring as before.
\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%CP_relation_images

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps2}
\end{pcomments}

\pkeywords{
  relations
  set_theory
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem} 

\bparts

\ppart Give an example of a binary relation $R$ from $A$ to $B$ such
that $RB \neq A$.

\begin{solution}
Any relation that has an element in $A$ that does not relate
to any element in $B$, and is therefore not total, will work.

For example, consider the less-than relation $R$ from $A=\set{0,1}$ to 
$B=\set{0,1}$. $RB$ consists of the elements in $A$ that relate to some
element in $B$ and since $1 \in A$ is not less than either 0 or 1, 
$RB = \set{0} \neq A$.
\end{solution}

\ppart Prove that $R(AR) = RB$ for any binary relation $R$ from $A$ to 
$B$.

\begin{solution}
We proceed by showing $x \in R(AR) \iff x \in RB$ using a
chain of if and only if statements.

\begin{align*}
x \in R(AR) & \qiff \exists\, b \in AR \;.\; x\,R\,b\\ 
            & \qiff \exists\, b \in B, a \in A \;.\; a\,R\,b \ \QAND\  x\,R\,b\\
            & \qiff \exists\, b \in B \;.\; x\,R\,b\\
            & \qiff x \in RB
\end{align*}

The first and second iff's are simply applications of the definitions 
of the inverse image and image (respectively).  The third follows 
directly from the fact that $x \in A$: if $x\,R\,b$ then there must exist 
an $a \in A$, namely $a=x$, such that $a\,R\,b$.
\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\endinput
\documentclass[problem]{mcs}

%CP_relational_properties_table.tex

\begin{pcomments}
  \pcomment{from: S09.cp3t}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  relations
  relational_properties
  mapping_lemma
  functions
  injections
  surjections
  bijections
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
  The \term{inverse}, $\inv{R}$, of a binary relation, $R$, from $A$ to
  $B$, is the relation from $B$ to $A$ defined by:
\[
b \mrel{\inv{R}} a \qiff a \mrel{R} b.
\]
In other words, you get the diagram for $\inv{R}$ from $R$ by ``reversing
the arrows'' in the diagram describing $R$.  Now many of the relational
properties of $R$ correspond to different properties of $\inv{R}$.  For
example, $R$ is an \emph{total} iff $\inv{R}$ is a \emph{surjection}.

\bparts

% This part would be a good tutor problem

\ppart\label{invprops} Fill in the remaining entries is this table:
\begin{center}
\begin{tabular}{l|cl}
$R$ is  & iff & $\inv{R}$ is \\ \hline
total                    && a surjection\\
a function\\
a surjection\\
an injection\\
a bijection
\end{tabular}
\end{center}

\hint Explain what's going on in terms of ``arrows'' from $A$ to $B$ in
the diagram for $R$.

\begin{solution}
\begin{center}
\begin{tabular}{l|cl}
$R$ is  & iff & $\inv{R}$ is \\ \hline
total                    && a surjection\\
a function               && \insolutions{an injection}\\
a surjection             && \insolutions{total}\\
an injection             && \insolutions{a function}\\
a bijection              && \insolutions{a bijection}
\end{tabular}
\end{center}

\end{solution}

\ppart Let $A,B$ be sets.  We say $A$ is \emph{as small as} $B$ iff there
is a total injective relation\footnote{The problem used in class used
  ``function'' instead of ``relation'' here.  Both are correct, but
  relation follows more easily from part~\eqref{invprops}} from $A$ to $B$.
  Prove that $A$ is \emph{as small as} $B$ iff $B$ is \emph{as big as}
  $A$.

\hint Use part~\eqref{invprops}.

\begin{solution}
\begin{proof}
(left to right): $A$ is \emph{as small as} $B$ means there is a total injective
function, $R:A \to B$.  By part\eqref{invprops}, this means $\inv{R}$ is a
surjective function from $B$ to $A$, so by definition, $B$ is as big as $A$.

(right to left): $B$ is \emph{as big as} $A$ means there is a surjective
function, $S:B \to A$.  So by part\eqref{invprops}, $\inv{S}$ is a total
injection from $A$ to $B$, so by definition, $A$ is as small as $B$.
\end{proof}

\end{solution}

\ppart Prove that if $A$ is as big as $B$, and $B$ is as big as $C$, then
$A$ is as big as $C$.  \textcolor{red}{Warning}: The ``as big as''
relation has a precise technical meaning.  You should not assume it has
any properties suggested by its name until they're proved.

\begin{solution}
Since $A$ is as big as $B$, there is a surjective function, $f:A \to B$.
Likewise, there is a surjective function, $g:B \to C$.  Let $h \eqdef g
\compose f$ be the function equal to the composition of $g$ and $f$, that
is
\[
h(a) \eqdef g(f(a)).
\]
Then $h$ will be a surjection from $A$ to $C$, proving that $A$ is as big as $C$.

To see why $h$ is a surjection, suppose $c \in C$.  Then since $g$ is a
surjection, $c = g(b)$ for some $b \in B$.  Likewise, $b = f(a)$ for some
$a \in A$.  Hence $c = g(f(a)) = h(a)$, proving that $c$ is in the range
of $h$, as required.
\end{solution}

\eparts
\end{problem}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
%CP__robot_invariant

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: F09.state machines notes problem}
  \pcomment{similar to PS_robot_on_2D_grid}
\end{pcomments}

\pkeywords{
  state_machines
  unreachable_states
  invariant
  integer_grid
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{problem}
A robot moves on the two-dimensional integer grid.  It starts out at
$(0,0)$, and is allowed to move in any of these four ways:
\begin{enumerate}
\item (+2,-1)   Right 2, down 1
\item (-2,+1)   Left 2, up 1 
\item (+1,+3) 
\item (-1,-3) 
\end{enumerate}

Prove that this robot can never reach (1,1).
\begin{solution}

A simple preserved invariant that does the job is defined on
  states $(i,j)$ by the predicate: $i + 2j$ is an integer multiple of $7$.
\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp1r, S08.cp2m(?), S99 Tutorial 1 Notes}
  \pcomment{Has a reference to another problem that should be resolved.}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  irrational
  primes
  polynomials
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
  Here is a generalization of Problem~\ref{generprob} that you may not have
  thought of:

\begin{lemma}\label{poly}
Let the coefficients of the polynomial
$a_0+a_1x+a_2x^2+\cdots + a_{n-1}x^{n-1} + x^n$ be
integers.  Then any real root of the polynomial is either integral or
irrational.
\end{lemma}

\bparts

\ppart Explain why Lemma~\eqref{poly} immediately implies that
$\sqrt[n]{k}$ is irrational whenever $k$ is not an $n$th power of some integer.

\begin{solution}
Saying that an integer, $k$, is not the $n$th power of an
  integer, is equivalent to saying that the equation $x^n = k$ has no
  integer solutions.  Another way to say this is that the polynomial $x^n
  - k$ has no integer root.  Lemma~\eqref{poly} therefore implies that any
  root of $x^n-k$ is irrational.  But $\sqrt[n]{k}$ is, by definition, a
  root of this polynomial, so it is irrational.
\end{solution}

\ppart Collaborate with your tablemates to write a clear, textbook quality
proof of Lemma~\ref{poly} on your whiteboard.  (Besides clarity and
correctness, textbook quality requires good English with proper
punctuation.  When a real textbook writer does this, it usually takes
multiple revisions; if you're satisfied with your first draft, you're
probably misjudging.)  You may find it helpful to appeal to the following:
\begin{lemma}\label{ppow}
  If a prime, $p$, is a factor some power of an integer, then it is a
  factor of that integer.
\end{lemma}
You may assume Lemma~\ref{ppow} without writing down its proof, but see if
you can explain why it is true.

\begin{solution}
%From S08 class problem 2M(?) and S99 Tutorial 1 Notes:

\begin{proof}

Let $r$ be a real root of the polynomial, so that
\[
a_0+a_1r+a_2r^2+\cdots+  a_{n-1}r^{n-1}+ r^n = 0.
\]
There are three cases: either $r$ is an integer, or $r$ is irrational, or
$r = s/t$ for integers $s$ and $t$ which have no common factors and such
that $t >1$.  We want to eliminate the last case, so assume for the sake
of contradiction that it held for some $r$.

Substituting $s/t$ for $r$ and multiplying both sides of the above
equation by $t^n$ yields:
\begin{eqnarray}
a_0t^n+a_1st^{n-1}+a_2s^2t^{n-2}+ \cdots + a_{n-1}s^{n-1}t+s^n & = & 0,\\
a_0t^n+a_1st^{n-1}+a_2s^2t^{n-2}+ \cdots + s^{n-1}t & = & -s^n.\label{e2}
\end{eqnarray}

Now since $t>1$, it must have a prime factor, $p$.  The prime, $p$,
therefore divides each term of the lefthand side of equation~\eqref{e2},
so $p$ also divides the righthand side, $-s^n$.  This means that $p$
divides $s^n$, so by Lemma~\ref{ppow}, $p$ is also a factor of
$s$.  So $p$ is a common factor of $s$ and $t$, contradicting the
fact that $s$ and $t$ have no common factors.
\end{proof}

Lemma~\ref{ppow} is a simple consequence of the \emph{Fundamental Theorem
  of Arithmetic} which says that every integer $> 1$ factors into a
product of primes that is \emph{unique} except for the order in which the
primes are multiplied.

For example, here are some ways to express 140 as a product of primes:
\[
140 = 2\cdot 2 \cdot 5 \cdot 7 = 2\cdot 5 \cdot 7 \cdot 2 = 7 \cdot 5 \cdot
2\cdot 2 = \cdots.
\]
By the Fundamental Theorem, every such product will have exactly two
occurrences of 2 and one each of 5 and 7.  Next, we can obviously get a
product of primes equal to, say, the third power of 140 by taking a
product that equals $140$ and repeating it three times.  For example,
\[
(140)^3 = 2\cdot 2 \cdot 5 \cdot 7 \ \ \cdot \ \  2\cdot 2 \cdot 7 \cdot 5
\ \ \cdot \ \ 2\cdot 2 \cdot 7 \cdot 5.
\]
The Fundamental Theorem now says that \emph{every} prime product equal to
the third power of 60 must have the same primes as this repeated product,
namely, six occurrences of 2 and three occurrences each of 5 and 7.  In
particular, the \emph{only} primes that are factors of $(140)^3$ are the
primes 2, 5 and 7 that are factors of 140.  This reasoning applies equally
well with any other integer greater than 1 in place of 140 and any power
greater than 0 in place of 3, proving that if $p$ is a prime factor of
$s^n$, then $p$ must have been a factor of $s$.

The Fundamental Theorem of Arithmetic is also know as the \emph{Unique
  Prime Factorization Theorem}.  It one of those familiar Mathematical
facts that is not exactly obvious.  We'll work out a proof of the
Fundamental Theorem later in the term.
\end{solution}

\eparts

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
%CP_set_product_bijection

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{written by ARM 9/20/09}
\end{pcomments}

\pkeywords{
 set product
 Cartesian product
 bijection
 finite set
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}
Let $A = \set{a_0,a_1,\dots,a_{n-1}}$ be a set of size $n$, and $B =
\set{b_0,b_1,\dots,b_{m-1}}$ a set of size $m$.  Prove that
$\card{A \times B} = mn$ by defining a simple bijection from $A \times B$ to
the nonnegative integers from $0$ to $mn-1$.

\begin{solution}
A bijection $f:A \times B \to \set{0,1,\dots,mn-1}$ can be defined by the rule
\[
f(a_k,b_j) \eqdef jn + k.
\]
\end{solution}

\end{problem}

\endinput

%CP_smallest_infinite_set

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: Ch. ``sets'', notes problem, adapted by ARM 9/20/09}
%  \pcomment{needs def of \surj in Appendix}
\end{pcomments}

\pkeywords{
  surjection
  as big as
  axiom of choice}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}\mbox{}

\begin{center}

\begin{quote}
\textbox{
\begin{lemma}\label{AUb}
  Let $A$ be a set and $b \notin A$.  If $A$ is infinite, then there is a
  bijection from $A \union \set{b}$ to $A$.
\end{lemma}

\begin{proof}
Here's how to define the bijection: since $A$ is infinite, it certainly has
at least one element; call it $a_0$.  But since $A$ is infinite, it has at
least two elements, and one of them must not be equal to $a_0$; call this
new element $a_1$.  But since $A$ is infinite, it has at least three
elements, one of which must not equal $a_0$ or $a_1$; call this new
element $a_2$.  Continuing in the way, we conclude that there is an
infinite sequence $a_0,a_1,a_2,\dots,a_n,\dots$ of different elements of
$A$.  Now we can define a bijection $f: A \union \set{b} \to A$:
\begin{align*}
f(b) & \eqdef a_0,\\
f(a_n) & \eqdef a_{n+1}  &\text{ for } n \in \naturals,\\
f(a) & \eqdef a & \text{ for } a \in A - \set{b,a_0,a_1,\dots}.
\end{align*}
\end{proof}
}

\end{quote}
\end{center}


\bparts

\ppart
Several students felt the proof of Lemma~\ref{AUb} was worrisome, if not
circular.  What do you think?

\begin{solution}
There is no ``solution'' for this discussion problem, since it depends on
what seems bothersome.

It may be bothersome that the proof asserts that $f$ is bijection without
spelling out a proof.  But the bijection property really does follow
directly from definition of $f$, so it shouldn't be much burden for a
bothered reader to fill in such a proof.

Another possibly bothersome point is that the proof assumes that if a set
is infinite, it must have more than $n$ elements, for every nonnegative
integer $n$.  But really that's the definition of infinity: a set is
finite iff it has $n$ elements for some nonnegative integer, $n$, and a
set is infinite iff it is \emph{not} finite.

A possibly worrisome point is how you find an element $a_{n+1} \in A$
given $a_0,a_1,\dots,a_n$.  But you don't have to \emph{find} a specific
one: there must be an element in $A -\set{a_0,a_1,\dots,a_n}$ ---so just
pick any one.  Actually, the justification for this step is the
set-theoretic Axiom of Choice described in the Notes chapter first-order
logic, and some logicians do consider it worrisome.
\end{solution}


\ppart Use the proof of Lemma~\ref{AUb} to show that if $A$ is an infinite
set, then there is surjective function from $A$ to $\naturals$, that is,
every infinite set is ``as big as'' the set of nonnegative integers.

\begin{solution}

  By the proof of Lemma~\ref{AUb}, there is an infinite sequence
  $a_0,a_1,a_2,\dots,a_n,\dots$ of different elements of $A$.  Then we can
  define a surjective function $f:A \to \naturals$ by defining
\[
f(a) \eqdef \begin{cases}
               n, & \text{if } a= a_n,\\
               \text{undefined}, & \text{otherwise}.
              \end{cases}
\]

---A total surjective function is not required, but if you want one define
$f':A \to \naturals$, by
\[
f'(a) \eqdef \begin{cases}
               n, & \text{if } a= a_n,\\
               0, & \text{otherwise}.
              \end{cases}
\]
\end{solution}

\eparts

\end{problem}

\endinput
%from fall95 pset2
\begin{problem}
Explain where the following proof goes wrong.

{\em Theorem:} Every positive integer can be described in fewer than
fourteen words.

\begin{proof}
  Let $S$ be the set of all numbers that cannot be so described. It
  contains a least element.  This element is ``the smallest number that
  cannot be described in less than fourteen English words.''  But this is
  a thirteen-word description, a contradiction.  Thus $S$ must be empty,
  implying the theorem.
\end{proof}

\begin{solution}
\TBA{TBA}
\end{solution}
\end{problem}

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp6t}
\end{pcomments}

\pkeywords{
  graphs
  spanning_trees
  state_machines
  increasing_decreasing_variables
  termination
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}

Given a simple graph $G$, we apply the following operation to the
graph: pick two vertices $u \neq v$ such that either
\begin{enumerate}
\item there is an edge of $G$ between $u$ and $v$ and there is
also a path from $u$ to $v$ which does \emph{not} include this edge;
in this case, delete the edge $\edge{u}{v}$.

\item or, there is no path from $u$ to $v$; in which case, add the edge
  $\edge{u}{v}$.
\end{enumerate}

We keep repeating these operations until it is no longer possible to
find two vertices $u \neq v$ to which an operation applies.

Assume the vertices of $G$ are the integers $1,2,\dots,n$ for some $n \geq
2$.  This procedure can be modeled as a state machine whose states are
all possible simple graphs with vertices $1,2,\dots,n$.  The start state
is $G$, and the final states are the graphs on which no operation is
possible.

\bparts

\ppart Let $G$ be the graph with vertices $\set{1,2,3,4}$ and edges
\[
\set{\edge{1}{2},\edge{3}{4}}
\]
What are the possible final states reachable from start state $G$?  Draw
them.

\begin{solution}
It's not possible to delete any edge.  The procedure can only
add an edge connecting exactly one of vertices 1 or 2 to exactly one of
vertices 3 or 4, and then terminate.  So there are four possible final
states.
\end{solution}

\ppart \label{derived} For any state, $G'$, let $e$ be the number of edges
in $G'$, $c$ be the number of connected components it has, and $s$ be the
number of simple cycles.  For each of the derived variables below, indicate
the \emph{strongest} of the properties that it is guaranteed to satisfy, no
matter what the starting graph $G$ is and be prepared to briefly explain
your answer.

The choices for properties are: \emph{constant}, \emph{strictly
increasing}, \emph{strictly decreasing}, \emph{weakly increasing},
\emph{weakly decreasing}, \emph{none of these}.  The derived variables are
 
\begin{enumerate}

\item[(i)] $e$ \begin{solution}
none of these
\end{solution}

\item[(ii)] $c$ \begin{solution}
weakly decreasing
\end{solution}

\item[(iii)] $s$ \begin{solution}
weakly decreasing
\end{solution}

\item[(iv)] $e-s$  \begin{solution}
weakly increasing
\end{solution}

\item[(v)] $c+e$  \begin{solution}
weakly decreasing
\end{solution}

\item[(vi)] $3c + 2e$  \begin{solution}
strictly decreasing
\end{solution}

\item[(vii)] $c+s$ \begin{solution}
strictly decreasing
\end{solution}

\item[(viii)] $(c,e)$, partially ordered coordinatewise (the \emph{product}
partial order). \begin{solution}
none of these
\end{solution}

\item[(ix)] $(c,e)$, ordered lexicographically  \begin{solution}
strictly decreasing
\end{solution}

\end{enumerate}

\ppart Conclude that the procedure terminates by proving that one of the
derived variables above is strictly decreasing under some well founded
partial order.

\begin{solution}
To show that the variable (vi) strictly decreases, note that
  the rule for deleting an edge ensures that the connectedness relation
  does not change, so neither does the number of connected components $c$.
  Meanwhile the number of edges $e$ decreases by one when an edge is
  deleted.  Therefore the variable $3c+2e$ decreases by $2$.  The rule for
  adding an edge ensures that the number of connected components $c$
  decreases by one and the number of edges $e$ increases by one.
  Therefore the variable $3c+2e$ decreases by $1$.

  To show that the variable (vii) strictly decreases, note that the rule
  for deleting an edge ensures that the number of connected components $c$
  does not change and the number of simple cycles $s$ decreases by $n$,
  where $n \geq 1$. Therefore the variable $c+s$ decreases by $n$.  The
  rule for adding an edge ensures that the number of connected components
  $c$ decreases by one and the number of simple cycles $s$ does not
  change.  Therefore the variable $c+s$ decreases by one.

To show that the lexicographically ordered $(c,e)$ strictly decreases,
note that the rule for deleting an edge ensures that the number of
connected components $c$ does not change and the number of edges $e$
decreases by one.  The rule for adding an edge ensures that the number of
connected components $c$ decreases by one.
\end{solution}

\ppart Prove that any final state must be a tree on the vertices.

\begin{solution}
We use the characterization of a tree as an acyclic connected
graph.

A final state must be connected, because otherwise there would be two
vertices with no path between them, and then a transition adding the edge
between them would be possible, contradicting finality of the state.

A final state can't have a simple cycle, because deleting any edge on the
cycle would be a possible transition.
\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp6r}
  \pcomment{from: S07.cp6w (slightly edited/shortened)}
\end{pcomments}

\pkeywords{
  bipartite_matching
  degree-constrained
  Halls_Theorem
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
MIT has a lot of student clubs loosely overseen by the MIT Student
Association.  Each eligible club would like to delegate one of its members
to appeal to the Dean for funding, but the Dean will not allow a student to
be the delegate of more than one club.  Fortunately, the Association VP
took 6.042 and recognizes a matching problem when she sees one.

\bparts

\ppart  Explain how to model the delegate selection problem as a bipartite
matching problem.

\begin{solution}
Define a bipartite graph with the student clubs as one set of
vertices and everybody who belongs to some club as the other set of
vertices.  Let a club and a student be adjacent exactly when the student
belongs to the club.  Now a matching of clubs to students will give a
proper selection of delegates: every club will have a delegate, and every
delegate will represent exactly one club.
\end{solution}

\ppart The VP's records show that no student is a member of more than 9
clubs.  The VP also knows that to be eligible for support from the Dean's
office, a club must have at least 13 members.  That's enough for her to
guarantee there is a proper delegate selection.  (If only the VP had taken
6.046, \emph{Algorithms}, she could even have found a delegate selection
without much effort.)

\begin{solution}
The degree of every club is at least 13, and the degree of every
student is at most 9, so the graph is \emph{degree-constrained} (see the
Appendix) which implies there will be no bottlenecks to prevent a
matching.  Hall's Theorem then guarantees a matching.
\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp2r}
%  \pcomment{}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  set_theory
  fun_game
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
%
Subset take-away\footnote{From Christenson \& Tilford, \emph{David Gale's
Subset Takeaway Game, American Mathematical Monthly, Oct. 1997}} is a two
player game involving a fixed finite set, $A$.  Players alternately choose
nonempty subsets of $A$ with the conditions that a player may not choose
\begin{itemize}
\item the whole set $A$, or
\item any set containing a set that was named earlier.
\end{itemize}
The first player who is unable to move loses the game.

For example, if $A$ is $\set{1}$, then there are no legal moves and the
cond player wins.  If $A$ is $\set{1,2}$, then the only legal moves are
$\set{1}$ and $\set{2}$.  Each is a good reply to the other, and so once
again the second player wins.

The first interesting case is when $A$ has three elements.  This time, if
the first player picks a subset with one element, the second player picks
the subset with the other two elements.  If the first player picks a
subset with two elements, the second player picks the subset whose sole
member is the third element.  \iffalse In short, in response to any first
move, the second player may choose the complementary set.\fi Both cases
produce positions equivalent to the starting position when $A$ has two
elements, and thus leads to a win for the second player.

Verify that when $A$ has four elements, the second player still has a
winning strategy.\footnote{David Gale worked out some of the properties of
this game and conjectured that the second player wins the game for
any set $A$.  This remains an open problem.}

\begin{solution}
There are way too many cases to work out by hand if we tried to
list all possible games.  But the elements of $A$ all behave the same, so
we can cut to a small number of cases using the fact that permuting around
the elements of $A$ in any game yields another possible game.  We can do
this by not mentioning specific elements of $A$, but instead using the
\emph{variables} $a,b,c,d$ whose values will be the four elements of $A$.

We consider two cases for the move of the Player 1 when the game starts:

\begin{enumerate}
\item Player 1 chooses a one element or a three element subset.  Then
Player 2 should choose the complement of Player one's choice.  The game
then becomes the same as playing the $n=3$ game on the three element set
chosen in this first round, where we know Player 2 has a winning
strategy.

\item Player 1 chooses a subset of 2 elements.  Let $a,b$ be these
elements, that is, the first move is $\set{a,b}$.  Player 2 should choose
the complement, $\set{c,d}$, of Player 1's choice.  We then have the
following subcases:
\begin{enumerate}

\item Player 1's second move is a one element subset, $\set{a}$.  Player 2
should choose $\set{b}$.  The game is then reduced to the two element game
on $\set{c,d}$ where Player 2 has a winning strategy.

\item
Player 1's second move is a two element subset, $\set{a,c}$.  Player 2
should choose its complement, $\set{b,d}$.  This leads to two subsubcases:
\begin{enumerate}

\item Player 1's third move is one of the remaining sets of size two,
$\set{a,d}$.  Player 2 should choose its complement, $\set{b,c}$.  The
remaining possible moves are the four sets of size 1, where the Player 2
clearly wins after two more rounds.

\item Player 1's third move is a one element set, $\set{a}$.  Player 2
should choose $\set{b}$.  The game is then reduced to the case two element
game on $\set{c,d}$ where Player 2 has a winning strategy.
\end{enumerate}
\end{enumerate}
\end{enumerate}
So in all cases, Player 2 has a winning strategy in the Gale game for
$n=4$.
\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
%CP_sum_of_inverse_squares_induction

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S02.ps2}
\end{pcomments}

\pkeywords{
  induction
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem} Prove by induction:
\begin{equation}\label{1n2}
\forall\ n>1,\quad 1+\frac{1}{4}+\frac{1}{9}+\cdots+\frac{1}{n^2}  <  2-\frac{1}{n}
\end{equation}

\begin{solution}
\begin{proof}
(by Induction).  The induction hypothesis is $P(n) \eqdef\text{ the
inequality~(\ref{1n2})}$.

\textbf{Base Case}: ($n = 2$).  The LHS of~(\ref{1n2}) in this case is
$1 + 1/4$ and the RHS is $2 - 1/2$.  Since LHS $= 5/4 < 6/4 = 3/2 =$ RHS, 
inequality~(\ref{1n2}) holds, and $P(2)$ is proved.

\textbf{Inductive Step}: Let $n$ be any natural number greater than $1$, and
assume $P(n)$ in order to prove $P(n+1)$.

So by assumption, we have
\[
1+\frac{1}{4}+\cdots+\frac{1}{n^2}  <  2-\frac{1}{n}.
\]
Adding $1/(n+1)^2$ to both sides of this inequality yields
\begin{eqnarray*}
1+\frac{1}{4}+\cdots+\frac{1}{n^2}+\frac{1}{(n+1)^2}& < & 2-\frac{1}{n}
             +\frac{1}{(n+1)^2}\\
& = & 2 - \left(\frac{1}{n} - \frac{1}{(n+1)^2}\right)\\
& = & 2 - \left(\frac{n^2 + 2n + 1-n}{n(n+1)^2}\right)\\
& = & 2 - \frac{n^2 + n}{n(n+1)^2}-\frac{1}{n(n+1)^2}\\
& = & 2 - \frac{1}{n+1} - \frac{1}{n(n+1)^2}\\
& < & 2 - \frac{1}{n+1}.
\end{eqnarray*}
So we have proved $P(n+1)$.
\end{proof}

\end{solution}
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: ???}
\end{pcomments}

\pkeywords{
  well-ordering
  WOP
  series
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Use the Well Ordering Principle to prove that
\begin{equation}\label{sum-of-sq}
\sum_{k=0}^n k^2 = \frac{n(n+1)(2n+1)}{6}.
\end{equation}
for all nonnegative integers, $n$.


\begin{solution}
The proof is by contradiction.

Suppose to the contrary that equation~\eqref{sum-of-sq} failed for some $n
\geq 0$.  Then by the WOP, there is a \emph{smallest} nonnegative integer,
$m$, such that~\eqref{sum-of-sq} does not hold when $n = m$.

But~\eqref{sum-of-sq} clearly holds when $n = 0$, which means that $m \geq
1$.  So $m-1$ is nonegative, and since it is smaller than $m$,
equation~\eqref{sum-of-sq} must be true for $n = m-1$.  That is,
\begin{equation}\label{sum-to-m-1}
\sum_{k=0}^{m-1} k^2 = \frac{(m-1)((m-1) + 1)(2(m-1)+1)}{6}.
\end{equation}
Now add $m^2$ to both sides of equation~\eqref{sum-to-m-1}.
Then the left hand side equals
\[
\sum_{k=0}^{m} k^2
\]
and the right hand side equals
\[
\frac{(m-1)((m-1) + 1)(2(m-1)+1)}{6} + m^2 
\]
Now a little algebra (given below) shows that the right hand side equals
\[
\frac{m(m+1)(2m+1)}{6}.
\]
That is,
\[
\sum_{k=0}^{m} k^2 = \frac{m(m+1)(2m+1)}{6},
\]
contradicting the fact that equation~\eqref{sum-of-sq} does not hold for
$m$.

It follows that there is no smallest nonnegative integer for which
equation~\eqref{sum-of-sq} fails.  Hence~\eqref{sum-of-sq} must hold for
all nonnegative integers.

Here's the algebra:
\textbox{
\begin{align*}
\frac{(m-1)((m-1) + 1)(2(m-1)+1)}{6} + m^2 
&= \frac{(m-1)m(2m-1)}{6} + m^2\\
 &  = \frac{(m^2-m)(2m-1)}{6} + m^2\\
 & = \frac{(2m^3-3m^2 +m)}{6} + \frac{6m^2}{6}\\
 &  = \frac{(2m^3 +3m^2 +m)}{6}\\
 &  = \frac{m(m+1)(2m+1)}{6}
\end{align*}}

\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%CP_surj_relation-n-soln

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: excerpted from CP_relational_properties_table
            do not use with that problem}
  \pcomment{this version has solns copmmented out for reuse as PS}
\end{pcomments}

\pkeywords{
  relations
  functions
  injections
  surjections
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
The following problem has been carried over to Pset 2; the solution will
appear there.

Define a \term{surjection relation}, $\surj$\footnote{This is the same as the
  ``\emph{as big as}'' relation defined in the Notes, but we're giving it
  a less suggestive name to avoid assumptions about properties it may have
  because of it name.}, on sets by the rule
\begin{definition*}
  $A \surj B$ iff there is a surjective function from $A$ to $B$.
\end{definition*}
Define the \term{injection relation}, $\inj$, on sets by the rule
\begin{definition*}
  $A \inj B$ iff there is a total injective relation from $A$ to $B$.
\end{definition*}

\bparts

\ppart\label{surjinj} Explain why $A \surj B \qiff B \inj A$.

\iffalse

\begin{solution}
\begin{proof}

(right to left): By definition of $\inj$, there is a total injective
  relation, $R:B \to A$.  By problem~\ref{TP_inverse_relation_table}, this
  implies that $\inv{R}$ is a surjective function from $A$ to $B$.

(left to right): By definition of $\surj$, there is a surjective function,
$F:A \to B$.
By problem~\ref{TP_inverse_relation_table}, this
 implies that $\inv{F}$ is a total injective relation from $A$ to $B$.
\end{proof}
\end{solution}
\fi

\ppart\label{surjsurj} Prove that if $A \surj B$ and $B \surj C$, then $A \surj C$.
\iffalse

\begin{solution}
By definition of $\surj$, there area surjective functions,
$F:A \to B$ and $G:B \to C$.

Let $H \eqdef G \compose F$ be the function equal to the composition of
$G$ and $F$, that is
\[
H(a) \eqdef G(F(a)).
\]
We show that $H$ is surjective, which will complete the proof.  So suppose
$c \in C$.  Then since $G$ is a surjection, $c = G(b)$ for some $b \in B$.
Likewise, $b = F(a)$ for some $a \in A$.  Hence $c = G(F(a)) = H(a)$,
proving that $c$ is in the range of $H$, as required.
\end{solution}
\fi

\ppart Conclude from~\eqref{surjinj} and~\eqref{surjsurj} that if $A \inj
B$ and $B \inj C$, then $A \inj C$.
\iffalse

\begin{solution}
From~\eqref{surjinj} and~\eqref{surjsurj} we have that if $C \inj B$ and
$B \inj A$, then $C \inj A$, so just switch the names $A$ and $C$.
\end{solution}
\fi

\eparts
\end{problem}

\documentclass[problem]{mcs}

%CP_surj_relation.tex

\begin{pcomments}
  \pcomment{from: excerpted from CP_relational_properties_table
            do not use with that problem}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  relations
  functions
  injections
  surjections
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Define a \term{surjection relation}\footnote{This is the same as the
  ``\emph{as big as}'' relation defined in the Notes, but we're giving it
  a less suggestive name to avoid assumptions about properties it may have
  because of its name.}, $\surj$, on sets by the rule
\begin{definition*}
  $A \surj B$ iff there is a surjective \textbf{function} from $A$ to $B$.
\end{definition*}
Define the \term{injection relation}, $\inj$, on sets by the rule
\begin{definition*}
  $A \inj B$ iff there is a total injective \textbf{relation} from $A$ to $B$.
\end{definition*}

\bparts

\ppart\label{surjinj} Explain why $A \surj B$ iff $B \inj A$.

\begin{solution}
\begin{proof}

(right to left): By definition of $\inj$, there is a total injective
  relation, $R:B \to A$.  But
\iffalse by  problem~\ref{TP_inverse_relation_table}, \fi
this implies that $\inv{R}$ is a surjective function from $A$ to $B$.

(left to right): By definition of $\surj$, there is a surjective function,
$F:A \to B$.
But
\iffalse By problem~\ref{TP_inverse_relation_table}, \fi
this implies that $\inv{F}$ is a total injective relation from $A$ to $B$.
\end{proof}
\end{solution}

\ppart\label{surjsurj} Prove that if $A \surj B$ and $B \surj C$, then $A \surj C$.

\begin{solution}
By definition of $\surj$, there area surjective functions,
$F:A \to B$ and $G:B \to C$.

Let $H \eqdef G \compose F$ be the function equal to the composition of
$G$ and $F$, that is
\[
H(a) \eqdef G(F(a)).
\]
We show that $H$ is surjective, which will complete the proof.  So suppose
$c \in C$.  Then since $G$ is a surjection, $c = G(b)$ for some $b \in B$.
Likewise, $b = F(a)$ for some $a \in A$.  Hence $c = G(F(a)) = H(a)$,
proving that $c$ is in the range of $H$, as required.
\end{solution}

\ppart Conclude from~\eqref{surjinj} and~\eqref{surjsurj} that if $A \inj
B$ and $B \inj C$, then $A \inj C$.

\begin{solution}
From~\eqref{surjinj} and~\eqref{surjsurj} we have that if $C \inj B$ and
$B \inj A$, then $C \inj A$, so just switch the names $A$ and $C$.
\end{solution}

\eparts
\end{problem}

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp1t}
%  \pcomment{}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  faulty_reasoning
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem} Albert announces that he plans a surprise 6.042
quiz next week.  His students wonder if the quiz could be next Friday.
The students realize that it obviously cannot, because if it hadn't been
given before Friday, everyone would know that there was only Friday left
on which to give it, so it wouldn't be a surprise any more.

So the students ask whether Albert could give the surprise quiz Thursday?
They observe that if the quiz wasn't given \emph{before} Thursday, it
would have to be given \emph{on} the Thursday, since they already know it
can't be given on Friday.  But having figured that out, it wouldn't be a
surprise if the quiz was on Thursday either.  Similarly, the students
reason that the quiz can't be on Wednesday, Tuesday, or Monday.  Namely,
it's impossible for Albert to give a surprise quiz next week.  All the
students now relax, having concluded that Albert must have been bluffing.

And since no one expects the quiz, that's why, when Albert gives it on
Tuesday next week, it really is a surprise!

What do you think is wrong with the students' reasoning?

\begin{solution}
The basic problem is that ``surprise'' is not a mathematical
concept, nor is there any generally accepted way to give it a mathematical
definition.  The ``proof'' above assumes some plausible axioms about
surprise, without defining it.  The paradox is that these axioms are
inconsistent.  But that's no surprise \texttt{:-)}, since ---mathematically
speaking ---we don't know what we're talking about.

Mathematicians and philosophers have had a lot more to say about what might
be wrong with the students' reasoning, (see Chow, Timothy Y.
\href{http://courses.csail.mit.edu/6.042/fall09/surprise-paradox.pdf}
{\emph{The surprise examination or unexpected hanging paradox}}, American
Mathematical Monthly (January 1998), pp.41--51.)
\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{new problem}
  \pcomment{swapping quantifiers}
\end{pcomments}

\pkeywords{
  induction
  strong_induction
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem} \mbox{}

Circle the invalid implication, and provide a counter model for your answer.  
\begin{enumerate}
\item $\forall x, \exists y. P(x, y) \implies \exists y, \forall x. P(x, y)$
\item $\exists y, \forall x. P(x, y) \implies \forall x, \exists y. P(x, y)$
\end{enumerate}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp7r}
  \pcomment{Could use some revision (one of the parts was redundant in the version used in class).}
\end{pcomments}

\pkeywords{
  digraphs
  relations
  relational_properties
  partial_orders
  cycles
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem} {\bf Tournament Graphs}

  \newcommand{\beats}{\!\rightarrow\!}

  Consider a $n$-player round-robin tournament where every pair of 
  distinct players compete in a single game that doesn't allow for a tie. 
  We can model the results of such a tournament using either a ``beats'' 
  relation or a digraph (called a \emph{tournament graph}).  The players 
  are represented by vertices and there is an edge $x \beats y$ if $x$ 
  beat $y$.

  \bparts

  \ppart Explain why there can be no cycles of length 2 or less.

  \begin{solution}
There are no self-loops in a tournament graph since no player 
  plays himself. Since every pair competes exactly once and there are no 
  ties, there are no cycles\footnote{Since there are no self-loops, 
  any cycle of length 2 or 3 must necessarily be simple.} of length 2 
  (it cannot be that $x$ beats $y$ and $y$ beats $x$).
\end{solution}

  \ppart Explain whether the ``beats'' relation for a tournament 
  graph is always/sometimes/never
  \begin{itemize}
  \item symmetric,
  \item asymmetric,
  \item reflexive,
  \item irreflexive,
  \item transitive.
  \end{itemize}

  \begin{solution}
No self-loops implies the relation is irreflexive.  It 
  is also asymmetric since it is irreflexive and for every pair of 
  distinct players, exactly one game is played and results in a win
  for one of the players.  Some tournament graphs represent 
  transitive relations and others don't.
\end{solution}

  \ppart Show that a tournament graph represents a total order iff
  there are no cycles of length 3.

  \begin{solution}
As observed in the previous part, the ``beats'' relation 
  whose graph is a tournament is asymmetric and irreflexive. Since 
  every pair of players is comparable, the relation is a total order 
  iff it is transitive.

  ``Beats'' is transitive iff for any players $x$, $y$ and $z$, 
  $x \beats y$ and $y \beats z$ implies that $x \beats z$ 
  (and consequently that there is no edge $z \beats x$).  Therefore, 
  ``beats'' is transitive iff there are no cycles of length 3.
\end{solution}

  \eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%/CP_transitive_irreflexive_implies_SPO

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp3r}
%  \pcomment{}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  relational_properties
  partial_orders
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
  A relation, $R$, on a set, $A$, is \emph{irreflexive} iff $\QNOT(a
  \mrel{R} a)$ for all $a \in A$.

  Prove that if $R$ is transitive and irreflexive, then it is a strict
  partial order.

\begin{solution}
  Suppose $R$ is transitive and irreflexive.  To show that $R$ is a strict
  partial order, we need to show that it is transitive and asymmetric.  That
  $R$ is transitive we know already. To prove that it is asymmetric, suppose
  $a\mrel{R}b$ holds for some $a,b\in A$.  We need to prove 
  $\QNOT(b \mrel{R} a)$.

  So assume to the contrary that $b\mrel{R}a$ holds.  Now $a\mrel{R}b$ and
  $b\mrel{R}a$, imply $a\mrel{R}a$ since $R$ is transitive. This
  contradicts the fact that $R$ is irreflexive.  So $b\mrel{R}a$ cannot
  hold, that is, $\QNOT(b\mrel{R}a)$ holds.
\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp6t}
  \pcomment{remove hard ref to thm in notes}
  \pcomment{was commented out in S09}
\end{pcomments}

\pkeywords{
  trees
  graphs
  connectivity
  cycles
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Prove that a graph is a tree iff it has a unique simple path between any
two vertices.

\begin{solution}
The proof in Week 6 Notes of Theorem 4.1.2 shows that in a tree
there are unique simple paths between any two vertices:

\begin{quote}
There is at least one path, and hence one simple path, between every pair
of vertices, because the tree is connected.  Suppose that there are two
different simple paths between vertices $u$ and $v$.  Beginning at $u$,
let $x$ be the first vertex where the paths diverge, and let $y$ be the
next vertex they share, illustrated in the figure below.  Then there are
two simple paths from $x$ to $y$ with no common edges, and this defines a
simple cycle.  This is a contradiction, since trees are acyclic.
Therefore, there is exactly one simple path between every pair of
vertices.

\mfigure{!}{1in}{figures/unique-path}
\end{quote}

Conversely, suppose we have a graph, $G$, with unique paths.  Now $G$ is
connected since there is a path between any two vertices.  So we need only
show that $G$ has no simple cycles.  But if there was a simple cycle in
$G$, there are two paths between any two vertices on the cycle (going one
way around the cycle or the other way around), a violation of uniqueness.
So $G$ must cannot have any simple cycles.
\end{solution}
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp2m}
%  \pcomment{}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  truth_table
  logic  
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Prove by truth table that $\QOR$ distributes over $\QAND$:
\begin{equation}\label{dist}
\brac{P \; \QOR\ (Q\ \QAND\ R)} \quad\text{is equivalent to}\quad
\brac{(P\ \QOR\ Q)\ \QAND\ (P\ \QOR\ R)}
\end{equation}

\begin{solution}

\[
\begin{array}{|c|c|ccc|}
\hline
\text{[}P      & \underline{\QOR}  & \text{(}Q    & \QAND & R\text{)]}   \\ \hline
\true  &\true       & \true  & \true      & \true \\ \hline
\true  &\true       & \true  & \false     & \false\\ \hline
\true  &\true       & \false & \false     & \true \\ \hline
\true  &\true       & \false & \false     & \false\\ \hline
\false &\true       & \true  & \true      & \true \\ \hline
\false &\false      & \true  & \false     & \false\\ \hline
\false &\false      & \false & \false     & \true \\ \hline
\false &\false      & \false & \false     & \false\\ \hline
\end{array}
\]

\[
\begin{array}{|ccc|c|ccc|}
\hline
\text{[(}P  & \QOR      & Q\text{)} & \underline{\QAND}       & \text{(}P & \QOR      & R\text{)]} \\  \hline
     \true  & \true     & \true     & \true      &   \true   & \true     & \true \\  \hline
     \true  & \true     & \true     & \true      &   \true   & \true     & \false\\  \hline
     \true  & \true     & \false    & \true      &   \true   & \true     & \true \\  \hline
     \true  & \true     & \false    & \true      &   \true   & \true     & \false\\  \hline
     \false & \true     & \true     & \true      &   \false  & \true     & \true \\  \hline
     \false & \true     & \true     & \false     &   \false  & \false    & \false\\  \hline
     \false & \false    & \false    & \false     &   \false  & \true     & \true \\  \hline
     \false & \false    & \false    & \false     &   \false  & \false    & \false\\  \hline
\end{array}
\]

The two columns for the principle operator (underlined) are the same, and
therefore the corresponding propositional formulas are equivalent.
\end{solution}


\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp2r}

  \pcomment{Can only be used AFTER pred calculus and the referenced class
    problem
      Needs handy copy of Russell Paradox}

  \pcomment{The students had some trouble with this one and sent 
            suggestions via email in S09 (maybe Noah Caplan?) about 
            their difficulties and how to fix this problem. It seems
            like some of their suggestions were discussed at the end (?)
            but it could probably still use a good revision.}
\end{pcomments}

\pkeywords{
  Russells_paradox
  strings
  binary
  logic
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
%  \newcommand{\nns}{\mop{bins}}
  \newcommand{\desc}{\text{ok-strings}}
  \def\all0s{\textbf{all-0s}}

  Though it was a serious challenge for set theorists to overcome
  Russells' Paradox, the idea behind the paradox led to some important
  (and correct \texttt{:-)} ) results in Logic and Computer Science.

  To show how the idea applies, let's recall the formulas from 
  Problem~\ref{CP_assertions_about_binary_strings}
  that made assertions about binary strings.  For
  example, one of the formulas in that problem was
  \begin{equation}\tag{\all0s} %\label{no1}
  \QNOT[\exists y\, \exists z. s = y1z]
  \end{equation}
  This formula defines a property of a binary string, $s$, namely that $s$
  has no occurrence of a 1.  In other words, $s$ is a string of (zero or
  more) 0's.  So we can say that this formula \emph{describes} the set of
  strings of 0's.

  More generally, when $G$ is any formula that defines a string property,
  let $\desc(G)$ be the set of all the strings that have this property.  A
  set of binary strings that equals $\desc(G)$ for some $G$ is called a
  \term{describable} set of strings.  So, for example, the set of all
  strings of 0's is describable because it equals $\desc(\all0s)$.

\iffalse
\[
\desc(G) \eqdef \set{s} \suchthat G(s)\ \text{is true}}.
\]
\fi

Now let's shift gears for a moment and think about the fact that
formula~$\all0s$ appears above.  This happens because instructions for
formatting the formula were generated by a computer text processor (in
6.042, we use the \LaTeX\ text processing system), and then an image
suitable for printing or display was constructed according to these
instructions.  Since everybody knows that data is stored in computer
memory as binary strings, this means there must have been some binary
string in computer memory ---call it $t_{\all0s}$ ---that enabled a
computer to display formula~$\all0s$ once $t_{\all0s}$ was retrieved from
memory.

In fact, it's not hard to find ways to represent \emph{any} formula, $G$,
by a corresponding binary word, $t_G$, that would allow a computer to
reconstruct $G$ from $t_G$.  We needn't be concerned with how this
reconstruction process works; all that matters for our purposes is that
every formula, $G$, has a representation as binary string, $t_G$.

Now let
\[
V \eqdef \set{t_G \suchthat\ \text{$G$ defines a property of strings and
    $t_G \notin \desc(G)$}}.
\] 
Use reasoning similar to Russell's paradox to show that $V$ is not
describable.

\begin{solution}
\hint  By definition of $V$,
\begin{equation}\label{nV}
t_G \in V \qiff t_G \notin \desc(G),
\end{equation}    
for every formula, $G$, that defines a property of strings.

\hint Suppose to the contrary that $V = \desc(H)$ for some formula, $H$.

So from~\eqref{nV}, we have
\begin{equation}\label{tGH}
t_G \in \desc(H) \qiff t_G \notin \desc(G).
\end{equation}
for all formulas, $G$, that define a property of strings.  Substituting
$H$ for $G$ in~\eqref{tGH} now yields the immediate contradiction
\[
t_H \in \desc(H) \qiff t_H \notin \desc(H).
\]
So there cannot be any formula, $H$ that describes $V$.
\end{solution}
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp8m, S06.cp6w}
  \pcomment{references pulverizer in appendix which should be in notes instead}
%  \pcomment{}
\end{pcomments}

\pkeywords{
  gcd
  linear_combinations
  Pulverizer
  number_theory
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
\bparts

\ppart Use the Pulverizer (see the Appendix) to find integers $x,y$ such
that
\[
x50 + y21 = \gcd(50,21).
\]

\begin{solution}
Here is the table produced by the Pulverizer:
\[
\begin{array}{ccccrcl}
x & \quad & y & \quad & \rem{x}{y} & = & x - q \cdot y \\ \hline
 50 &&  21 &&  8 & = &    50 - 2 \cdot  21 \\
 21 &&   8 &&  5 & = &    21 - 2 \cdot  8 \\
&&&&             & = &    21 - 2 \cdot (50 - 2 \cdot  21) \\
&&&&             & = &   -2 \cdot 50 + 5 \cdot 21 \\
  8 &&   5 &&  3 & = &    8 - 1 \cdot 5  \\
&&&&             & = &   (50 - 2 \cdot  21) 
                         -1 \cdot (-2 \cdot 50 + 5 \cdot 21) \\
&&&&             & = &   3\cdot 50 -7 \cdot 21 \\
  5 &&   3 &&  2 & = &    5 - 1\cdot 3 \\
&&&&             & = &   (-2 \cdot 50 + 5 \cdot 21) 
                         -1 \cdot (3\cdot 50 -7 \cdot 21) \\
&&&&             & = &   -5\cdot 50 + 12 \cdot 21 \\
  3 &&   2 &&  1 & = &    3 - 1\cdot 2 \\
&&&&             & = &   (3\cdot 50 -7 \cdot 21) 
                         -1\cdot (-5\cdot 50 + 12 \cdot 21) \\
&&&&             & = &   \fbox{$8\cdot 50 - 19 \cdot 21$} \\
  2 &&   1 &&  0 &   & 
\end{array}
\]
\end{solution}

\ppart Now find integer $x',y'$ with $y'>0$ such that
\[
x'50 + y'21 = \gcd(50,21)
\]
\begin{solution}
since $(x,y) = (8,-19)$ works, so does $(8 - 21n,-19+50n)$ for any $n \in
\integers$, so letting $n=1$, we have
\[
-13 \cdot 50 + 31 \cdot 21 = 1
\]
\end{solution}

\eparts
\end{problem}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
%CP_valid_vs_satisfiable

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp2m}
  \pcomment{commented out in S09}
\end{pcomments}

\pkeywords{
  logic
  environment
  valid
  satisfiable
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
\bparts

\ppart A propositional formula is \term{valid} iff it is equivalent to
\true.  Verify by truth table that
\[
(P\ \QIMP\ Q)\ \QOR\ (Q \ \QIMP\ P)
\]
is valid.

\begin{solution}
\[
\begin{array}{cc|c|c|c}
P & Q & P\ \QIMP\ Q & Q\ \QIMP\ P  & (P\ \QIMP\ Q)\ \QOR\ (Q \ \QIMP\ P)\\ \hline
\true & \true & \true & \true & \true\\
\true & \false & \false & \true & \true\\
\false & \true & \true & \false & \true\\
\false & \false & \true & \true & \true
\end{array}
\]
\end{solution}

\ppart Let $P$ and $Q$ be propositional formulas.  Describe a single
propositional formula, $R$, involving $P$ and $Q$ such that $R$ is valid
iff $P$ and $Q$ are equivalent.

\begin{solution}
\[
R \eqdef (P \ \QIFF\ Q)
\]
or
\[
R \eqdef (P \ \QIMP\ Q)\ \QAND\ (Q \ \QIMP\ P)
\]
or
\[
R \eqdef (P\ \QAND\  Q)\ \QOR\ [\QNOT(P)\ \QAND \QNOT(Q)]
\]
are all possible solutions.

\end{solution}

\ppart\label{sat} A propositional formula is \emph{satisfiable} iff there
is an assignment of truth values to its variables ---an \emph{environment}
---which makes it true.  Explain why
\begin{quote}
$P$ is valid iff $\QNOT(P)$ is \emph{not} satisfiable.
\end{quote}

\begin{solution}
To prove the iff, we prove first, that the left hand statement implies the
right hand one, and second, vice-versa.

\textbf{(left-to-right case)}: If $P$ is valid, then $\QNOT(P)$ is \emph{not}
satisfiable.

\begin{proof}
Now $P$ is true in an environment iff $\QNOT(P)$ is false in that
environment.  Since $P$ is valid, it is true in every environment, which
means that $\QNOT(P)$ is false in every environment.  So no environment makes
$\QNOT(P)$ true, which means that $\QNOT(P)$ is \emph{not} satisfiable.
\end{proof}

\textbf{(right-to-left case)}: If $\QNOT(P)$ is \emph{not}
satisfiable, the $P$ is valid.

\begin{proof}
  Since $\QNOT(P)$ is not satisfiable, every truth assignment makes it
  false.  This implies that every truth assignment makes $P$ true, that
  is, $P$ is valid.
\end{proof}

\end{solution}

\ppart A set of propositional formulas $P_1,\dots,P_k$ is
\emph{consistent} iff there is an environment in which they are all
true.  Write a formula, $S$, so that the set $P_1,\dots,P_k$ is \emph{not}
consistent iff $S$ is valid.

\begin{solution}
Note that the set $P_1,\dots,P_k$ is consistent iff
\[
(P_1\ \QAND\ P_2\ \QAND\ \dots\ \QAND\ P_k)
\]
is satisfiable.  So by part~\eqref{sat}
\[
S \eqdef \QNOT(P_1\ \QAND\ P_2\ \QAND\ \dots\ \QAND\ P_k)
\]
is the desired formula.  In more concise notation this would written
\[
\QNOT\paren{\Land_{i=1}^k P_i}
\]
or, using DeMorgan's Law:
\[
\Lor_{i=1}^k \bar{P_i}.
\]
\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
include ../Makefile.com

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{adapted by ARM from first part of PS_sums_and_products_of_integers}
\end{pcomments}

\pkeywords{
 Well ordering principle
 inequality
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Use the Well Ordering Principle to prove that
\begin{equation}\label{n3n3}
n \leq 3^{n/3}
\end{equation}
for every nonnegative integer, $n$.

\hint Verify~\eqref{n3n3} for $n \leq 4$ by explicit calculation.

\begin{solution}
  Suppose to the contrary that~\eqref{n3n3} failed for some
  nonnegative integer.  Then by the WOP, there is a least such
  nonnegative integer, $m$.

  But $0 \leq 3^{0/3}$, so $m \neq 0$.  Also, $1^3 \leq 3^1$, so
  taking cube roots, $1 \leq 3^{1/3}$, which implies $m \neq 1$.
  Likewise, $2^3 \leq 3^2$, so taking cube roots, $2 \leq 3^{2/3}$,
  which implies $m \neq 2$.  Similar simple calculations show that $m
  \neq 3,4$.  That is, $m \geq 5$.

  Now since $m > m-3 \geq 0$ and $m$ is the least nonnegative integer
  for which the inequality~\eqref{n3n3} fails, the inequality must
  hold when $n = m-3$. So
\begin{align}
3^{m/3} & = 3 \cdot 3^{(m-3)/3} \notag\\
    & \geq 3 \cdot (m-3)  & \text{(by~\eqref{n3n3} for $n = m-3$)}\label{g3m3}
\end{align}
But
\begin{align}
3 \cdot (m-3) & = 3m - 9\notag\\
              & > 3m - 2m & \text{since $m > 9/2$}\notag\\
              & = m.\label{3m3gm}
\end{align}

Combining~\eqref{g3m3} and~\eqref{3m3gm}, we get
\[
m \leq 3^{m/3},
\]
contradicting the assumption that~\eqref{n3n3} fails for $n = m$.

This contradiction implies that there cannot be a nonnegative integer for
which~\eqref{n3n3} fails.  That is,~\eqref{n3n3} must hold for all
nonnegative integers.

\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps4}
  \pcomment{based on problem 6 of F07.ps3}
\end{pcomments}

\pkeywords{
  structural_induction
  games
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\fiftypg}{\text{50-PG}}

\begin{problem}
 Define \emph{2-person 50-point games of perfect information}%\term{}
 $\fiftypg$'s, recursively as follows:

\textbf{Base case}: An integer, $k$, is a $\fiftypg$ for $-50\leq k \leq
50$.  This $\fiftypg$ called the \emph{terminated game with payoff} $k$. %emph
A \emph{play} of this $\fiftypg$ is the length one integer sequence, $k$.

\textbf{Constructor case}: If $G_0,\dots, G_n$ is a finite sequence of
$\fiftypg$'s for some $n \in \naturals$, then the following game, $G$, is a
$\fiftypg$: the possible first moves in $G$ are the choice of an integer $i$
between 0 and $n$, the possible second moves in $G$ are the possible first
moves in $G_i$, and the rest of the game $G$ proceeds as in $G_i$.

A \emph{play} of the $\fiftypg$, $G$, is a sequence of nonnegative integers
starting with a possible move, $i$, of $G$, followed by a play of $G_i$.
If the play ends at the game terminated game, $k$, then $k$ is called the
\emph{payoff} of the play.

There are two players in a $\fiftypg$ who make moves alternately.  The
objective of one player (call him the \emph{max}-player) is to have the
play end with as high a payoff as possible, and the other player (called
the \emph{min}-player) aims to have play end with as low a payoff as
possible.

Given which of the players moves first in a game, a strategy for the
max-player is said to \emph{ensure} the payoff, $k$, if play ends with a
payoff of at least $k$, no matter what moves the min-player makes.
Likewise, a strategy for the min-player is said to \emph{hold down} the
payoff to $k$, if play ends with a payoff of at most $k$, no matter what
moves the max-player makes.

A $\fiftypg$ is said to have \emph{max value}, $k$, if the max-player has a
strategy that ensures payoff $k$, and the min-player has a strategy that
holds down the payoff to $k$, when the \emph{max-player moves first}.
Likewise, the $\fiftypg$ has \emph{min value}, $k$, if the max-player has a
strategy that ensures $k$, and the min-player has a strategy that holds
down the payoff to $k$, when the \emph{min-player moves first}.

The \emph{Fundamental Theorem} for 2-person 50-point games of perfect
information is that is that every game has both a max value and a min
value.  (Note: the two values are usually different.)

What this means is that there's no point in playing a game: if the max
player gets the first move, the min-player should just pay the max-player
the max value of the game without bothering to play (a negative payment
means the max-player is paying the min-player).  Likewise, if the
min-player gets the first move, the min-player should just pay the
max-player the min value of the game.

\bparts

\ppart\label{finpg} Prove this Fundamental Theorem for 50-valued
$\fiftypg$'s by structural induction.

\begin{solution}
The proof is by structural induction on the definition of a
  $\fiftypg$, $G$.  The induction hypothesis is that there is that
\begin{quote}
  $G$ has a max value and a min value.
\end{quote}

\textbf{Base case}: [$G$ is the terminated game with payoff $k$].  The only
possible play is $k$.  So the max value and the min value are both $k$.

\textbf{Constructor case}: [$G = (G_0,\dots, G_n)$].  By structural
induction we may assume that each of the games $G_i$ have both max values
and min values.

We first show that $G$ has max value, $k$, where $k$ is the largest min
value among the games $G_0,\dots,G_n$.

To prove the max value of $G$ is $k$, we must show how the max-player,
moving first in $G$, can ensure $k$, and how the min-player, moving second
in $G$, can hold down the payoff to $k$.

To ensure $k$, the max-player simply chooses $i$ as her first move where
game $G_i$ has this largest min value, $k$.  The min-player then has the
first move in $G_i$, so by definition of min value, the max-player has a
strategy in $G_i$ that ensures $k$, which she can now follow.  So this
first move, combined with the ensuring strategy in $G_i$, defines a
strategy for the max-player in $G$ that ensures $k$.

Likewise, there is a simple strategy for the min-player, moving second in
$G$, to hold down the payoff to $k$.  Namely, suppose the max-player's
first move is $i$.  Then $G_i$ has a min value of $m \leq k$, since $k$ is
the largest min value.  So by definition of min value, there is a strategy
in $G_i$ for the min-player to hold down the payoff to $m$, which he can
now follow, thereby holding down the payoff of play on $G$ to $m \leq k$.

The existence of these ensuring and holding down strategies for $G$
implies that the max value of $G$ is $k$.

Second, to show that $G$ has a min value, we can repeat the previous
argument with min and max exchanged.

Therefore, by structural induction, we can conclude that all $\fiftypg$'s have
min and max values.
\end{solution}

\ppart A meta-$\fiftypg$ game has as possible first moves the choice of
\emph{any} $\fiftypg$ to play.  Meta-$\fiftypg$ games aren't any harder to
understand than $\fiftypg$'s, but there is one notable difference, they
have an infinite number of possible first moves.  We could also define
meta-meta-$\fiftypg$'s in which the first move was a choice of any
$\fiftypg$ \emph{or} the meta-$\fiftypg$ game to play.  In
meta-meta-$\fiftypg$'s there are an infinite number of possible first
\emph{and} second moves.  And then there's $\text{meta}^3-\fiftypg$ \dots.

\iffalse
The 2D-origin game in a Week 4 class problem is a game in which there are
an infinite number of possible first moves, an infinite number of possible
second moves, \dots.  \iffalse (with two values, ``win'' or ``lose''
instead of values from -50 to 50)\fi
\fi

To model such infinite games, we could have modified the recursive
definition of $\fiftypg$'s to allow first moves that choose any one of an
infinite sequence $G_0,G_1,\dots,G_n,G_{n+1}, \dots$ of $\fiftypg$'s.  Now
a $\fiftypg$ can be a mind-bendingly infinite datum instead of a finite
one.

Do these infinite $\fiftypg$'s still have max and min values?  In
particular, do you think it would be correct to use structural induction
as in part~\eqref{finpg} to prove a Fundamental Theorem for such infinite
$\fiftypg$'s?  Offer an answer to this question, and briefly indicate why
you believe in it.

\begin{solution}
It may not be obvious, but structural induction is a perfectly
  sound proof technique even for infinite recursively defined data, and
  the proof of the Fundamental Theorem for $\fiftypg$'s applies without
  change to infinite ones.
\end{solution}

\eparts

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps1}
  \pcomment{revision made by professor meyer}
\end{pcomments}

\pkeywords{
  logic
  translating_english_statements
  predicate_calculus
  domain_of_discourse
  quantifiers
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\Eric}{\text{Justin }}
\newcommand{\Tom}{\text{Megumi }}
\newcommand{\Albert}{\text{Tom }}
\newcommand{\Claire}{\text{Steven }}
\newcommand{\Edmond}{\text{Richard }}
\newcommand{\Florent}{\text{Jodyann }}
\newcommand{\Nick}{\text{Rajeev }}

\begin{problem}
  A cabal consisting of some of the 6.042 TA's is plotting to make the
  final exam \textit{ridiculously hard}.  (``Problem 1.  Prove the
  Goldbach Conjecture starting from the axioms of ZFC.  Express your
  answer in khipu -- the knot language of the Incas.'')  The only way to
  stop their evil plan is to determine exactly who is in the cabal.  The
  course TA's consists of seven people:
%
\[
\set{\Eric, \Tom, \Albert, \Claire, \Edmond, \Florent, \Nick }
\]
%
The cabal is a subset of these seven.
A membership roster has been found and appears below, but it is deviously
encrypted in logic notation.  The predicate $C$ indicates who is in the
cabal; that is, $C(x)$ is true if and only if $x$ is a member.  Translate
each statement below into English and deduce who is in the cabal.

\begin{enumerate}%[\upshape (i)]

\item\label{eee} $\exists x \ \exists y \ \exists z \
    (x \neq y \wedge
     x \neq z \wedge
     y \neq z \wedge
     C(x) \wedge C(y) \wedge C(z))$

\begin{solution}
A direct English paraphrase would be ``There
exist people we'll call $x,y$, and $z$, who are all different, such that
$x,y$ and $z$ are each in the cabal.''  A better version would use the
fact that there's no need in this case to give names to the people.
Namely, a better paraphrase is ``There are 3 different people in the
cabal.''  Perhaps a simpler way to say this is: ``The cabal is of size at
least 3.''
\end{solution}

\item\label{nNC} $\neg (C(\text{\Nick}) \wedge C(\text{\Claire}))$

\begin{solution}
\Nick and \Claire are not both in the cabal.
Equivalently: at least one of \Nick and \Claire is not in the cabal.
\end{solution}

\item\label{Fall} $C(\text{\Florent}) \rightarrow \forall x \ C(x)$

\begin{solution}
If \Florent is in the cabal, then everyone is.
\end{solution}

\item\label{CN} $C(\text{\Claire}) \rightarrow C(\text{\Nick})$

\begin{solution}
If \Claire is in the cabal, then \Nick is also.
\end{solution}

\item\label{EAnT}
$(C(\text{\Edmond}) \vee C(\text{\Albert})) \rightarrow \neg C(\text{\Tom})$

\begin{solution}
If either of \Edmond or \Albert is in the cabal,
then \Tom is not.  Equivalently, if \Tom \emph{is} in the cabal, the neither
\Albert nor \Edmond is.
\end{solution}

\item\label{ENnE}
$(C(\text{\Edmond}) \vee C(\text{\Nick})) \rightarrow \neg C(\text{\Eric})$

\begin{solution}
If either of \Edmond or \Nick is in the cabal,
then \Eric is not.  Equivalently, if \Eric \emph{is} in the cabal, the
neither \Edmond nor \Nick is.
\end{solution}

\end{enumerate}

\insolutions{So much for the translations.  We now argue that the only
cabal satisfying all six propositions above is one whose members are
exactly \Nick, \Edmond, and \Albert.

We first observe that by~\eqref{nNC}, there must be someone -- either \Nick
or \Claire -- who is not in the cabal.  But if Flo were in the cabal, then
by~\eqref{Fall}, everyone would be.  So we conclude by contradiction
that:

\begin{equation}\label{nF}
\text{\Florent is not in the cabal.}
\end{equation}

Next observe that if \Claire was in the cabal, then by~\eqref{CN}, \Nick would
be too, contradicting~\eqref{nNC}.  So by again contradiction, we conclude:
\begin{equation}\label{nC}
\text{\Claire is not in the cabal.}
\end{equation}

Now suppose \Tom is in the cabal.  Then by~\eqref{EAnT}, \Edmond and \Albert
are not, and we already know \Florent and \Claire are not, so only three remain
who could be in the cabal, namely, \Tom, \Nick, and \Eric.  But
by~\eqref{eee} the cabal must have at least three members, so it follows
that the cabal must consist of exactly these three.  This proves:
\begin{lemma}\label{TNE}
\text{If \Tom is in the cabal, then \Nick and \Eric are in the cabal.}
\end{lemma}

But by~\eqref{ENnE}, if \Nick is the cabal, then \Eric is not.  That is, 
\begin{lemma}\label{NnE}
\text{\Nick and \Eric cannot both be in the cabal.}
\end{lemma}
Now from Lemma~\ref{NnE} we conclude that the conclusion of
Lemma~\ref{TNE} is false.  So by contrapositive, the hypothesis of
Lemma~\ref{TNE} must also be false, namely,
\begin{equation}\label{nT}
\text{\Tom is not in the cabal.}
\end{equation}

Finally, suppose \Eric is in the cabal.  Then by~\eqref{ENnE}, \Edmond
and \Nick are not, and we already know \Florent, \Claire and \Tom are not. So
the cabel must consist of at most two people (\Albert and \Eric). This
contradicts~\eqref{eee}, and we conclude by contradiction that
\begin{equation}\label{nE}
\text{\Eric is not in the cabal.}
\end{equation}
So the only remaining people who could be in the cabal are \Albert, \Edmond,
and \Nick.  Since the cabal must have at least three members, we conclude
that
\begin{lemma}
The only possible cabal consists of \Albert, \Edmond, and \Nick.
\end{lemma}

But we're not done yet: we haven't shown that a cabal consisting of
\Albert, \Edmond, and \Nick actually does satisfy all six conditions.  So let
$\mathcal{A} =\set{\text{\Albert}, \text{\Edmond}, \text{\Nick}}$, and let's quickly
check that $\mathcal{A}$ satisfies~\eqref{eee}--\eqref{ENnE}:

\begin{itemize}

\item $\card{A} = 3$, so $A$ satisfies~\eqref{eee}.
\item \Claire is not in $A$, so $A$ satisfies~\eqref{nNC} and~\eqref{CN}.
\item \Florent is not in $A$, so the hypothesis of~\eqref{Fall} is false, which
means that $A$ satisfies~\eqref{Fall}.
\item Finally, \Tom and \Eric are not in $A$, so the conclusions of
both~\eqref{EAnT} and~\eqref{ENnE} are true, and so $A$
satisfies~\eqref{EAnT} and ~\eqref{ENnE}.

\end{itemize}

So now we have proved
\begin{proposition*}
$\set{\text{\Albert}, \text{\Edmond}, \text{\Nick}}$ is the \emph{unique} cabal
satisfying conditions~\eqref{eee}--\eqref{ENnE}.
\end{proposition*}}
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps1}
  \pcomment{commented out in S09}
  \pcomment{Might be better to use fixed names to avoid newcommand's.}
\end{pcomments}

\pkeywords{
  logic
  translating_english_statements
  predicate_calculus
  domain_of_discourse
  quantifiers
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
A certain cabal within the 6.042 course staff is plotting to make the
final exam \textit{ridiculously hard}.  (``Problem 1.  Prove the Poincare
Conjecture starting from the axioms of ZFC.  Express your answer in khipu
-- the knot language of the Incas.'')  The only way to stop their evil
plan is to determine exactly who is in the cabal.  The course staff
consists of seven people:
%
\[
\set{\Eric, \Tom, \Albert, \Claire, \Edmond, \Florent, \Nick }
\]
%
(\Florent is the course secretary.)  The cabal is a subset of these seven.
A membership roster has been found and appears below, but it is deviously
encrypted in logic notation.  The predicate $\C$ indicates who is in the
cabal; that is, $\C(x)$ is true if and only if $x$ is a member.  Translate
each statement below into English and deduce who is in the cabal.

\begin{enumerate}%[\upshape (i)]

\item\label{eee} $\exists x \ \exists y \ \exists z \
    (x \neq y \wedge
     x \neq z \wedge
     y \neq z \wedge
     \C(x) \wedge \C(y) \wedge \C(z))$

\begin{solution}
A direct English paraphrase would be ``There
exist people we'll call $x,y$, and $z$, who are all different, such that
$x,y$ and $z$ are each in the cabal.''  A better version would use the
fact that there's no need in this case to give names to the people.
Namely, a better paraphrase is ``There are 3 different people in the
cabal.''  Perhaps a simpler way to say this is: ``The cabal is of size at
least 3.''
\end{solution}

\item\label{nNC} $\neg (\C(\text{\Nick}) \wedge \C(\text{\Claire}))$

\begin{solution}
\Nick and \Claire are not both in the cabal.
Equivalently: at least one of \Nick and \Claire is not in the cabal.
\end{solution}

\item\label{Fall} $\C(\text{\Florent}) \rightarrow \forall x \ \C(x)$

\begin{solution}
If \Florent is in the cabal, then everyone is.
\end{solution}

\item\label{CN} $\C(\text{\Claire}) \rightarrow \C(\text{\Nick})$

\begin{solution}
If \Claire is in the cabal, then \Nick is also.
\end{solution}

\item\label{EAnT}
$(\C(\text{\Edmond}) \vee \C(\text{\Albert})) \rightarrow \neg \C(\text{\Tom})$

\begin{solution}
If either of \Edmond or \Albert is in the cabal,
then \Tom is not.  Equivalently, if \Tom \emph{is} in the cabal, the neither
\Albert nor \Edmond is.
\end{solution}

\item\label{ENnE}
$(\C(\text{\Edmond}) \vee \C(\text{\Nick})) \rightarrow \neg \C(\text{\Eric})$

\begin{solution}
If either of \Edmond or \Nick is in the cabal,
then \Eric is not.  Equivalently, if \Eric \emph{is} in the cabal, the
neither \Edmond nor \Nick is.  
\end{solution}
\end{enumerate}

\insolutions{So much for the translations.  We now argue that the only
cabal satisfying all six propositions above is one whose members are
exactly \Nick, \Edmond, and \Albert.

We first observe that by~\eqref{nNC}, there must be someone -- either \Nick
or \Claire -- who is not in the cabal.  But if Flo were in the cabal, then
by~\eqref{Fall}, everyone would be.  So we conclude by contradiction
that:

\begin{equation}\label{nF}
\text{\Florent is not in the cabal.}
\end{equation}

Next observe that if \Claire was in the cabal, then by~\eqref{CN}, \Nick would
be too, contradicting~\eqref{nNC}.  So by again contradiction, we conclude:
\begin{equation}\label{nC}
\text{\Claire is not in the cabal.}
\end{equation}

Now suppose \Tom is in the cabal.  Then by~\eqref{EAnT}, \Edmond and \Albert
are not, and we already know \Florent and \Claire are not, so only three remain
who could be in the cabal, namely, \Tom, \Nick, and \Eric.  But
by~\eqref{eee} the cabal must have at least three members, so it follows
that the cabal must consist of exactly these three.  This proves:
\begin{lemma}\label{TNE}
\text{If \Tom is in the cabal, then \Nick and \Eric are in the cabal.}
\end{lemma}

But by~\eqref{ENnE}, if \Nick is the cabal, then \Eric is not.  That is, 
\begin{lemma}\label{NnE}
\text{\Nick and \Eric cannot both be in the cabal.}
\end{lemma}
Now from Lemma~\ref{NnE} we conclude that the conclusion of
Lemma~\ref{TNE} is false.  So by contrapositive, the hypothesis of
Lemma~\ref{TNE} must also be false, namely,
\begin{equation}\label{nT}
\text{\Tom is not in the cabal.}
\end{equation}

Finally, suppose \Eric is in the cabal.  Then by~\eqref{ENnE}, \Edmond
and \Nick are not, and we already know \Florent, \Claire and \Tom are not. So
the cabel must consist of at most two people (\Albert and \Eric). This
contradicts~\eqref{eee}, and we conclude by contradiction that
\begin{equation}\label{nE}
\text{\Eric is not in the cabal.}
\end{equation}
So the only remaining people who could be in the cabal are \Albert, \Edmond,
and \Nick.  Since the cabal must have at least three members, we conclude
that
\begin{lemma}
The only possible cabal consists of \Albert, \Edmond, and \Nick.
\end{lemma}

But we're not done yet: we haven't shown that a cabal consisting of
\Albert, \Edmond, and \Nick actually does satisfy all six conditions.  So let
$\mathcal{A} =\set{\text{\Albert}, \text{\Edmond}, \text{\Nick}}$, and let's quickly
check that $\mathcal{A}$ satisfies~\eqref{eee}--\eqref{ENnE}:

\begin{itemize}

\item $\size{A} = 3$, so $A$ satisfies~\eqref{eee}.
\item \Claire is not in $A$, so $A$ satisfies~\eqref{nNC} and~\eqref{CN}.
\item \Florent is not in $A$, so the hypothesis of~\eqref{Fall} is false, which
means that $A$ satisfies~\eqref{Fall}.
\item Finally, \Tom and \Eric are not in $A$, so the conclusions of
both~\eqref{EAnT} and~\eqref{ENnE} are true, and so $A$
satisfies~\eqref{EAnT} and ~\eqref{ENnE}.

\end{itemize}

So now we have proved
\begin{proposition*}
$\set{\text{\Albert}, \text{\Edmond}, \text{\Nick}}$ is the \emph{unique} cabal
satisfying conditions~\eqref{eee}--\eqref{ENnE}.
\end{proposition*}}
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%PS_brents_theorem

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: F06 pset5Back.tex, maybe same as F04 pset5}
  \pcomment{major revision by ARM 10/3/09}
\end{pcomments}

\pkeywords{
  partial_orders
  chains
  antichain
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
  We consider a finite strict partial order where each element in the
  domain represents a task to be completed.

\bparts

\ppart Give a small example of a strict partial order with more than one
minimum time schedule.

\begin{solution}
\TBA{revise to p.o. instead of DAG}

$V= \set{1,2,3}, E= \set{\diredge{1}{2}}$.  There are two minimum time
schedules: $\set{\set{1,3}\set{2}}$ and $\set{\set{1}\set{2,3}}$.

\end{solution}

\ppart Explain why any schedule that requires only $p$ processors to
complete $n$ tasks must take time at least $\ceil{n/p}$.

\begin{solution}
 If there are $k < \ceil{n/p}$, then the integer $k$ is less
than $n/p$.  
\end{solution}

\ppart\label{timeD} Let $D_{n,t}$ be the strict partial order with $n$
elements that consists of a chain of $t-1$ elements, with the largest
element in the chain being a prerequisite of all the remaining elements as
in the following figure:

\mfigure{!}{2.5in}{pset5-hasse}

What is the minimum time schedule for $D_{n,t}$?  Explain why it is
unique.  How many processors does it require?

\begin{solution}
There's no choice but to schedule each of the $t-1$ vertices on
the path one at a time in order.  A minimum time schedule then does all
the remaining $n-(t-1)$ vertices at the $t$th time interval.  The number
of processors required is therefore $n-t+1$.  
\end{solution}

\ppart Write a simple formula, $M(n,t,p)$, for the minimum time of a
$p$-processor schedule to complete $D_{n,t}$.

\begin{solution}
As in part~\eqref{timeD}, there's no choice but to schedule each
of the $t-1$ vertices on the path one at a time in order.  A minimum time
schedule then does all the remaining $n-(t-1)$ vertices $p$ at a time, for
a total time of
\begin{equation}\label{tnp}
M(n,t,p) \eqdef (t-1) + \ceil{\frac{n-(t-1)}{p}}.
\end{equation}

\end{solution}

\ppart Show that \emph{every} DAG with $n$ vertices and maximum chain
size, $t$, has a $p$-processor schedule that runs in time $M(n,t,p)$.

\begin{solution}

\begin{proof}
Define the \term*{height} of a task to be the length of the longest chain
among its prerequisites.  Start off by scheduling as many tasks as
possible at time 1, namely, the smaller of $p$ and the number of height
zero tasks.  At each successive time $i$ for $1 < i <t$, schedule the
smaller of $p$ and the number of unscheduled tasks of height less than
$i$, with lower height tasks scheduled before higher height tasks.

Since at least one task will be scheduled at each time from 1 to $t-1$,
\TBA{there are ...}

\iffalse  %Ugly, cumbersome propf from F06 was cut by ARM 10/3/09 \fi
\end{proof}

\end{solution}

\eparts

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput


\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S02.ps5}
\end{pcomments}

\pkeywords{
  state_machines
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{problem} \textbf{Provide recursive definitions of the following sets and functions:}

\bparts

\ppart The set $S = \{ 2^a 3^b 5^c \mid a, b, c \in \mathbb{N}
\}$.

\begin{solution}
 We can define the set $S$ recursively as follows:

\begin{enumerate}
\item $1 \in S$
\item If $n \in S$, then $2n$, $3n$, and $5n$ are in $S$.
\end{enumerate}
\end{solution}

\ppart The set $L = \{ (a, b) \in \mathbb{Z} \times \mathbb{Z}
\mid \text{$a + 2b = 3k$ for some $k \in \mathbb{Z}$} \}$.

\begin{solution}
\begin{enumerate}
\item $(0, 0) \in L$
\item If $(a, b) \in L$, then $(a + 3, b)$, $(a - 3, b)$, $(a + 2, b -
1)$, and $(a - 2, b + 1)$ are in $L$.
\end{enumerate}
\end{solution}

\ppart The set $\Sigma^*$, which consists of all finite strings
of symbols drawn from the set $\{ p, n, d, q \}$.  (We'll use this set
$\Sigma^*$ in the next three problem parts as well.)

\begin{solution}
\begin{enumerate}
\item The empty string $\lambda$ is in $\Sigma^*$.
\item If $\alpha \in \Sigma^*$, then $p\alpha$, $n\alpha$, $d\alpha$,
$q\alpha$ are in $\Sigma^*$.
\end{enumerate}
\end{solution}


\ppart Recursively define a function $l : \Sigma^* \to
\mathbb{N}$ that maps each string in $\Sigma^*$ to its length.

\begin{solution}
\begin{enumerate}
\item $l(\lambda) = 0$.
\item If $\alpha \in \Sigma^*$, and $\beta \in \{p, n, d, q\}$, then
$l(\beta \alpha) = 1 + l(\alpha)$.
\end{enumerate}
\end{solution}

\ppart Suppose that $p$ stands for penny, $n$ stands for nickel,
$d$ stands for dime, and $q$ stands for quarter.  Recursively define a
function $m : \Sigma^* \to \mathbb{N}$ that maps each string in
$\Sigma^*$ to the monetary value of the corresponding pile of change.

\begin{solution}
\begin{enumerate}
\item $m(\lambda) = 0$.
\item If $\alpha \in \Sigma^*$, then $m(p \alpha) = 1 + m(\alpha)$.
\item If $\alpha \in \Sigma^*$, then $m(n \alpha) = 5 + m(\alpha)$.
\item If $\alpha \in \Sigma^*$, then $m(d \alpha) = 10 + m(\alpha)$.
\item If $\alpha \in \Sigma^*$, then $m(q \alpha) = 25 + m(\alpha)$.
\end{enumerate}
\end{solution}

\ppart Recursively define a function $r : \Sigma^* \to \Sigma^*$
that maps each string $\sigma_1 \sigma_2 \ldots \sigma_{n}$ in
$\Sigma^*$ to its reverse:

\[
\sigma_n \sigma_{n-1} \ldots \sigma_1
\]

\begin{solution}
\begin{enumerate}
\item $r(\lambda) = \lambda$.
\item If $\alpha \in \Sigma^*$ and $\beta \in \{p, n, d, q\}$, then
$r(\beta \alpha) = r(\alpha) \beta$.
\end{enumerate}
\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps5}
  \pcomment{from: F06.rec6 (revised by ARM)}
\end{pcomments}

\pkeywords{
  Euler_circuits
  cycles
  degree
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
  In this problem we'll consider some special cycles in graphs called {\em
    Euler circuits}, named after the famous mathematician Leonhard Euler.
  (Same Euler as for the constant $e\approx 2.718$ ---he did a lot of
  stuff.)

\begin{definition}
  An Euler circuit of a graph is a cycle which traverses every edge
  exactly once.
\end{definition}

Does the graph in the following figure contain an Euler circuit?

\begin{center}
\includegraphics[height=1.75in]{example}
\end{center}

Well, if it did, the edge $(E, F)$ would need to be included.  If the path
does not start at $F$ then at some point it traverses edge $(E,F)$, and
now it is stuck at $F$ since $F$ has no other edges incident to it and an
Euler circuit can't traverse $(E,F)$ twice.  But then the path could not
be a circuit.  On the other hand, if the path starts at $F$, it must then
go to $E$ along $(E,F)$, but now it cannot return to $F$.  It again cannot
be a circuit. This argument generalizes to show that if a graph has a
vertex of degree $1$, it cannot contain an Euler circuit.

\iffalse
On the other hand, it is easy to see that any cycle contains an Euler
circuit. You can just start at any vertex and walk around back to it.
\fi

So how do you tell in general whether a graph has an Euler circuit?  At
first glance this may seem like a daunting problem (the similar sounding
problem of finding a cycle that touches every vertex exactly once is one
of those million dollar NP-complete problems known as the \term{Traveling
  Salesman Problem}) ---but it turns out to be easy.

\bparts

\ppart Show that if a graph has an Euler circuit, then the degree of each
of its vertices is even.

  \begin{solution}
Let circuit $C \eqdef v_1, v_2, \dots, v_r, v_1$ be an Euler
    circuit.  Consider any vertex $v$.  Then every time $v$ occurs in
    $C$, there is a vertex $a$ which comes immediately before $v$ and a
    vertex $b$ which comes immediately after $v$.  Note that this holds for
    $v = v_1$ as well since $C$ is a circuit. Moreover, $(a,v)$ and
    $(v,b)$ must be distinct edges of $G$ since $C$ is an Euler circuit.
    It follows that if $v$ occurs $s$ times in $C$, then it has degree
    $2s$ since every edge incident to $v$ occurs in $C$ exactly once.
    Thus, $v$ has even degree.
\end{solution}
\eparts

In the remaining parts, we'll work out the converse: if the degree of
every vertex of a connected finite graph is even, then it has an Euler
circuit.  To do this, let's define an Euler \term{path} to be a path that
traverses each edge \emph{at most} once.

\bparts

\ppart\label{conn} Suppose that an Euler path in a connected graph does
not traverse every edge.  Explain why there must be an untraversed edge
that is incident to a vertex on the path.

\begin{solution}
If either end of the untraversed edge is on the Euler path, that
  already is the desired edge.  So suppose there's an untraversed edge,
  $e$, both of whose endpoints are not on the Euler path.  Since the graph
  is connected, there must be a shortest path, $P$, from an endpoint of
  $e$ to a vertex on the Euler path.  Then all the edges on $P$ must be
  untraversed (or $P$ could be shortened), so the last edge traversed by
  $P$ will be the desired edge.
\end{solution}

\eparts

In the remaining parts, let $W$ be the \emph{longest} Euler path in some
finite, connected graph.

\bparts

\ppart\label{cycle-circuit} Show that if $W$ is a cycle, then it must be
an Euler circuit.

\hint part~\eqref{conn}

\begin{solution}
Suppose an edge was not traversed by $W$.  By part~\eqref{conn},
  there must be a vertex on $W$ incident to an edge not traversed by $W$.
  Starting at this vertex, go around $W$ back to that vertex, and then the
  follow the edge.  This makes a longer Euler path, contradicting the
  maximality of $W$.  So no edge can be missing from $W$.
\end{solution}

\ppart\label{already} Explain why all the edges incident to the end of $W$
must already have been traversed by $W$.

\begin{solution}
Otherwise we could extend $W$ to a longer Euler path with any
  edge from the end not already traversed by $W$.  
\end{solution}

\ppart\label{odd} Show that if the end of $W$ was not equal to the start
of $W$, then the degree of the end would be odd.

\hint part~\eqref{already}

\begin{solution}
Let $v$ be the end vertex of $W$.  Given that $v$ is not the
  start of $W$, it follows that at any occurrence of $v$ in $W$ other than
  at the end, $W$ would enter and leave that occurrence of $v$ traversing
  a pair of edges.  Since $W$ is an Euler path, all the edges in all these
  pairs are distinct.  In addition, the final edge traversed by $W$ as it
  ends at $v$ is distinct from all the paired edges.  Altogether, this
  imples that there are an odd number of edges traversed by $W$ and
  incident to $v$.  But by part~\eqref{already}, these are all the edges
  incident to $v$, proving that $v$ has odd degree.
\end{solution}

\ppart Conclude that if every vertex of a finite, connected graph has even
degree, then it has an Euler circuit.

\begin{solution}
If all vertices in $G$ have even degree, then by
  part~\eqref{odd}, the only possibility is that the end of $W$ equals the
  start, that is, $W$ is a cycle.  So by part~\eqref{cycle-circuit}, $W$ is
  an Euler circuit.
\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S02.ps5}
\end{pcomments}

\pkeywords{
  state_machines
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem} 

The \textbf{Fifteen Puzzle} consists of sliding square tiles numbered
$1,\dots,15$ held in a $4\times4$ frame with one empty square.  Any tile
adjacent to the empty square can slide into it.  The
\href{http://theory.lcs.mit.edu/classes/6.042/spring02/}{6.042 Icon} is
based on this puzzle.

The standard initial position is
\[\begin{array}{|c|c|c|c|}
\hline 1 & 2 & 3 & 4\\
\hline 5 & 6 & 7 & 8\\
\hline 9 & 10 & 11 & 12\\
\hline 13 & 14  & 15 &  \\
\hline
\end{array}\]
We would like to reach the target position (known in my youth as ``the
impossible'' --- ARM):
\[\begin{array}{|c|c|c|c|}
\hline 15 & 14 & 13 & 12\\
\hline 11 & 10 & 9 & 8\\
\hline7 & 6 & 5 & 4\\
\hline3 & 2 & 1 & \\
\hline
\end{array}\]

A state machine model of the puzzle has states consisting of a $4\times 4$
matrix with 16 entries consisting of the integers $1,\dots,15$ as well as
one ``empty'' entry---like each of the two arrays above.

The state transitions correspond to exchanging the empty square and an
adjacent numbered tile.  For example, a empty at position $(2,2)$ can
exchange position with tile above it, namely, at position $(1,2)$:
\[\begin{array}{|c|c|c|c|}
\hline n_1 & n_2 & n_3 & n_4\\
\hline n_5 &  & n_6 & n_7\\
\hline n_8  & n_9 & n_{10} & n_{11}\\
\hline n_{12} & n_{13} & n_{14}  & n_{15}\\
\hline
\end{array} \longrightarrow
\begin{array}{|c|c|c|c|}
\hline n_1 &   & n_3 & n_4\\
\hline n_5 & n_2 & n_6 & n_7\\
\hline n_8  & n_9 & n_{10} & n_{11}\\
\hline n_{12} & n_{13} & n_{14}  & n_{15}\\
\hline
\end{array} 
\]

In this problem you will use the invariant method prove that starting
from the initial state, there is no way to reach the target state.

We begin by noting that a state can also be represented as a pair
consisting of two things:
\begin{enumerate}

\item a list of the numbers $1,\dots,15$ in the order in which they
appear---reading rows left-to-right from the top row down, ignoring the
empty square, and

\item the coordinates of the empty square---where the upper left
square has coordinates $(1,1)$, the lower right $(4,4)$.

\end{enumerate}

Let $L$ be such an ordered list of the numbers $1,\dots,15$.  A pair of
integers is an \emph{out-of-order pair} in $L$ when the first element of
the pair both comes \emph{earlier} in the list \emph{and is larger}, than
the second element of the pair.  For example, the list $1,2,4,5,3$ has two
out-of-order pairs: 4,3 and 5,3.  The increasing list $1,2\dots n$ has no
out-of-order pairs.

Representing a state, $S$, as the pair $(L, (i,j))$ described above,
define the \emph{parity} of $S$ to be the mod 2 sum of the number of
out-of-order pairs in $L$ and the row-number, $i$, of the empty
square.


\bparts
\ppart  Verify that the parity of the initial state and the parity of the
target state are different.

\begin{solution}
The parity of the initial state is $(0+4) \bmod 2 = 0$.
Parity of target is $((15 \cdot 14/ 2) + 4) \bmod 2 = 1$.
\end{solution}

\ppart Show that the parity of a state is invariant under transitions.
Conclude that ``the impossible'' is impossible to reach.

\begin{solution}
To show that the parity is constant, let us consider what
types of moves may affect the parity.  The only 4 moves we need to worry
about are the following:  a move to the left, a move to the right, a move
to the row above, or a move to the row below.  

Note that horizontal moves change nothing, and vertical moves both change
$i$ by 1, and move a tile three places forward or back in the list, $L$.
To consider how the parity is changed in this case, we need to consider
only the 3 pairs in $L$ that are between the tile's old and new position.
(The other pairs are not effected by the tile's move).  This reverses the
order of three pairs in $L$, changing the number of inversions by 3 or 1,
but always by an odd amount.

To confirm this last remark, note that if the 3 pairs were all out of
order or all in order before, the amount is changed by 3.  If two pairs
were out of order and 1 pair was in order or if one pair was out of order
and two were in order, this will change the amount by 1.  So the sum of
$i$ and the number of out-of-order pairs changes by an even amount (either
1+3 or 1+1), which implies that its parity remains the same.  Since the
initial state has parity 0 (even), all states reachable from the initial
state must have parity 0, so the target state with parity 1 can't be
reachable.
\end{solution}

\ppart (optional, extra credit) Show that if two states have the same
aprity, then there is a way to get from one to the other.

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps1}
  \pcomment{from: S04 (Eric Lehman)}
  \pcomment{minor edits by ARM in S09}
  \pcomment{Fix hard reference to Week 1 notes.}
\end{pcomments}

\pkeywords{
  well-ordering
  WOP
  contradiction
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
  \href{http://en.wikipedia.org/wiki/Euler's_sum_of_powers_conjecture}{\emph{Euler's
      Conjecture}} in 1769 was that there are no positive integer
  solutions to the equation
\[
a^4 + b^4 + c^4 =  d^4.
\]
Integer values for $a,b,c,d$ that do satisfy this equation, were first
discovered in 1986.  So Euler guessed wrong, but it took more two hundred
years to prove it.

Now let's consider Lehman's\footnote{Suggested by Eric Lehman, a former
  6.042 Lecturer.} equation, similar to Euler's but with some
coefficients:
\begin{eqnarray}\label{lehman-eqn}
8 a^4 + 4 b^4 + 2 c^4 & = & d^4
\end{eqnarray}

Prove that Lehman's equation~\eqref{lehman-eqn} really does not have any positive
integer solutions.

\hint Consider the minimum value of $a$ among all possible solutions
to~\eqref{lehman-eqn}.

\begin{solution}
Suppose that there exists a solution.  Then there must be a
  solution in which $a$ has the smallest possible value.  We will show
  that, in this solution, $a$, $b$, $c$, and $d$ must all be even.
  However, we can then obtain another solution over the positive integers
  with a smaller $a$ by dividing $a$, $b$, $c$, and $d$ in half.  This is
  a contradiction, and so no solution exists.

All that remains is to show that $a$, $b$, $c$, and $d$ must all be even.
The left side of Lehman's equation is even, so $d^4$ is even, so $d$ must
be even.  Substituting $d = 2 d'$ into Lehman's equation gives:

\begin{eqnarray}
8 a^4 + 4 b^4 + 2 c^4 & = & 16 d'^4
\end{eqnarray}

Now $2 c^4$ must be a multiple of 4, since every other term is a
multiple of 4.  This implies that $c^4$ is even and so $c$ is also
even.  Substituting $c = 2 c'$ into the previous equation gives:

\begin{eqnarray}
8 a^4 + 4 b^4 + 32 c'^4 & = & 16 d'^4
\end{eqnarray}

Arguing in the same way, $4 b^4$ must be a mutliple of 8, since every
other term is.  Therefore, $b^4$ is even and so $b$ is even.
Substituting $b = 2 b'$ gives:

\begin{eqnarray}
8 a^4 + 64 b'^4 + 32 c'^4 & = & 16 d'^4
\end{eqnarray}

Finally, $8 a^4$ must be a multiple of 16, $a^4$ must be even, and so
$a$ must also be even.  Therefore, $a$, $b$, $c$, and $d$ must all be
even, as claimed.
\end{solution}
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps7}
  \pcomment{slightly muddled solution from latency ambiguity (do we include input edges?)}
\end{pcomments}

\pkeywords{
  networks
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Louis Reasoner figures that, wonderful as the Bene\u{s} network may be, the
butterfly network has a few advantages, namely: fewer switches, smaller
diameter, and an easy way to route packets through it.  So Louis designs an
$N$-input/output network he modestly calls a \textit{Reasoner-net} with the
aim of combining the best features of both the butterfly and Bene\u{s} nets:
\begin{quote}
The $i$th input switch in a Reasoner-net connects to two switches, $a_i$
and $b_i$, and likewise, the $j$th output switch has two switches, $y_j$
and $z_j$, connected to it.  Then the Reasoner-net has an $N$-input
Bene\u{s} network connected using the $a_i$ switches as input switches and
the $y_j$ switches as its output switches.  The Reasoner-net also has an
$N$-input butterfly net connected using the $b_i$ switches as inputs and<
the $z_j$ switches as outputs.
\end{quote}

In the Reasoner-net a minimum latency routing does not have minimum
congestion.  The \textit{latency for min-congestion} (LMC) of a net is the
best bound on latency achievable using routings that minimize congestion.
Likewise, the \textit{congestion for min-latency} (CML) is the best bound
on congestion achievable using routings that minimize latency.

Fill in the following chart for the Reasoner-net and briefly explain your
answers.

\[
\begin{array}{|c|c|c|c|c|c|}
\textbf{diameter} &
\textbf{switch size(s)} &
\textbf{\# switches} &
\textbf{congestion} &
\textbf{LMC} &
\textbf{CML}\\
\hline
&&&&&\\
\hline
\end{array}
\]

\begin{solution}
\[
\begin{array}{|c|c|c|c|c|c|}
\textbf{diameter} &
\textbf{switch size(s)} &
\textbf{\# switches} &
\textbf{congestion} &
\textbf{LMC}&
\textbf{CML}\\
\hline \log N + 4 & 2 \times 2 & 3N (\log N + 1) & 1 & 2 \log N +
3 &
\sqrt{N}\\
\hline
\end{array}
\]

or

\[
\begin{array}{|c|c|c|c|c|c|}
\textbf{diameter} & \textbf{switch size(s)} & \textbf{\# switches}
& \textbf{congestion} & \textbf{LMC}&
\textbf{CML}\\
\hline \log N + 2 & 2 \times 2 & 3N (\log N + 1) & 1 & 2 \log N +1
&
\sqrt{N}\\
\hline
\end{array}
\]

%REVISE wrt to current notes --ARM

There are two possible answers for the diameter, because in lecture the
special ``square'' input/output switches were not used (they mess up the
recursive definitions).  To match the Notes, these switches have to be
added after the recursion, increasing the diameter by 2.  So the first
answer corresponds to the lecture notes, and the second one corresponds to
the slides.

The diameter of a Reasoner-net is 2 plus the smaller of the
diameters of its Bene\u{s} component, $2 \log N + 1$ or $2\log
N-1$, and its butterfly component, $\log N +2$ or $\log N$.

The number of switches is the number of input and output switches in the
Reasoner-net, namely, $2N$, plus the number of switches in its butterfly
component, $N (\log N + 1)$, and its Bene\u{s} component, $2N \log N$.

The congestion is the congestion of the better of the two component nets.

The LMC for the butterfly net equals its diameter, and likewise for the LMC
of the Bene\u{s} net.  So the LMC of the Reasoner-net is 2 plus the LMC of
the routing through the component with minimum congestion, namely, 2 plus
the diameter of the Bene\u{s} net.

The CML equals the congestion of the routing through the component
with minimum latency, namely, the congestion of butterfly net.
\end{solution}
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps8}
  \pcomment{from: S07.ps7}
  \pcomment{commented out in S09}
\end{pcomments}

\pkeywords{
  series
  closed_form
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}           
  Is a Harvard degree really worth more than an MIT degree?!  Let us say
  that a person with a Harvard degree starts with \$40,000 and gets a
  \$20,000 raise every year after graduation, whereas a person with an MIT
  degree starts with \$30,000, but gets a 20\% raise every year.  Assume
  inflation is a fixed $8\%$ every year.  That is, \$1.08 a year from now
  is worth \$1.00 today.


\begin{problemparts}


\problempart How much is a Harvard degree worth today if the holder will work
for $n$ years following graduation? 

\problempart How much is an MIT degree worth in this case?

\problempart If you plan to retire after twenty years, which degree would
be worth more?

\begin{solution}
One dollar after year $i$ is worth $r^i$ in today's currency, where
\[
r= \frac{1}{1.08} = 0.925\, 925\, 925 \dots
\]
So 
\begin{eqnarray*}
\mbox{Hvd}_n & = & \sum_{i=0}^{n} (40000+ 20000i)r^i\\
        & = & 40000\sum_{i=0}^{n} r^i + 20000\sum_{i=0}^{n} i r^i,\\
\mbox{MIT}_n & = & 30000\sum_{i=0}^{n} {1.2}^i r^i\\
        & = & 30000\sum_{i=0}^{n} (1.2r)^i
\end{eqnarray*}

But
\[
\sum_{i=0}^{n} ir^i = \frac{{r - (n+1) r^{n+1} + n r^{n+2}}}{(1-r)^2},
\]
so 
\begin{eqnarray*}
\mbox{Hvd}_n & = & 40000 \frac{(1- r^{n+1})}{1- r}  + 
                   20000 \frac{(r - (n+1) r^{n+1} + n r^{n+2})}{(1-r)^2}\\
  & = &  \frac{20000(2(1- r^{n+1} -r +r^{n+2}) + r - (n+1) r^{n+1} + n r^{n+2})}{(1-r)^2}\\
  & = &  \frac{{20000(2 - r - (n+3)r^{n+1} + (n + 2)r^{n+2})}}{(1-r)^2}\\
\mbox{MIT}_n & = &  \frac{{30000(1 - (1.2r)^{n+1})}}{1 - 1.2r}
\end{eqnarray*}
and for $n=20$,
\begin{eqnarray*}
\mbox{Hvd}_{20} & = &  \frac{{20000(2 - r - 23r^{21} + 22r^{22})}}{(1-r)^2} = 2,010,885\\
\mbox{MIT}_{20} & = &  \frac{{30000(1 - (1.2r)^{21})}}{1 - 1.2r} = 2,197,579.
\end{eqnarray*}

so the MIT degree is more valuable! (But we knew that already.)
\end{solution}

\end{problemparts}
\end{problem} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps8}
  \pcomment{from: S05.ps4}
  \pcomment{commented out in S09 - compare this problem to the CP version and also to the version adapted for use in a pset in F08}
\end{pcomments}

\pkeywords{
  number_theory
  RSA
  modular_arithmetic
  primes
  prime_factorization
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Reviewing the analysis of RSA may help you solve the following
problems.  You may assume results proved in class.

\bparts

\ppart Let $n$ be a nonnegative integer.  Prove that $n$ and $n^5$
have the same last digit.  For example:
%
\[
\underline{2}^5 = 3\underline{2}
\hspace{1in}
7\underline{9}^5 = 307705639\underline{9}
\]

\begin{solution}
The correctness of RSA relies on the following fact: if $p$
and $q$ are distinct primes, then
%
\[
m^{1 + k (p - 1)(q - 1)} \equiv m \pmod{pq}
\]
%
for all $m$ and $k$.  Setting $k = 1$, $p = 5$, and $q = 2$ proves the
claim.
\end{solution}

\ppart Suppose that $p_1, \ldots, p_k$ are distinct primes.  Prove
that
%
\[
m^{1 + (p_1 - 1)(p_2 - 1) \cdots (p_k - 1)} \equiv m \pmod{p_1 p_2
\cdots p_k}
\]
%
for all $m$ and all $k \geq 1$.

\begin{solution}
If $m$ is a multiple of a prime $p_j$, then
%
\begin{equation}
m^{1 + (p_1 - 1)(p_2 - 1) \cdots (p_k - 1)} \equiv m \pmod{p_j} \tag{*} \label{e
q:star}
\end{equation}
%
holds, because both sides are congruent to 0.  If $m$ is not a
multiple of $p_j$, then congruence~\eqref{eq:star} still holds
because:
%
\begin{align*}
m^{1 + (p_1 - 1)(p_2 - 1) \cdots (p_k - 1)}
    & \equiv m \cdot (m^{p_j - 1})^{(p_1 - 1)(p_2 - 1) \cdots (p_k - 1) / (p_j -
 1)} \pmod{p_j} \\
    & \equiv m \cdot 1^{(p_1 - 1)(p_2 - 1) \cdots (p_k - 1) / (p_j - 1)} \pmod{p
_j} \\
    & \equiv m \pmod{p_j}
\end{align*}
%
The second step uses Fermat's Theorem.  Now the
congruence~\eqref{eq:star} means that:
%
\[
p_j \mid m^{1 + (p_1 - 1)(p_2 - 1) \cdots (p_k - 1)} - m
\]
%
Thus, $p_j$ appears in the prime factorization of right side.  Since
this argument is valid for every prime $p_j$ where $1 \leq j \leq k$,
all of the primes $p_1, \ldots, p_k$ appear in the prime factorization
of:
%
\[
m^{1 + (p_1 - 1)(p_2 - 1) \cdots (p_k - 1)} - m
\]
%
Therefore:
%
\[
p_1 p_2 \cdots p_k \mid m^{1 + (p_1 - 1)(p_2 - 1) \cdots (p_k - 1)} - m
\]
%
Rewriting this as a congruence gives:
%
\[
m^{1 + (p_1 - 1)(p_2 - 1) \cdots (p_k - 1)} \equiv m \pmod{p_1 p_2
\cdots p_k}
\]

\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps8}
  \pcomment{from: F06.ps6}
  \pcomment{commented out in S09 - has typos and probably needs substantial revision}
\end{pcomments}

\pkeywords{
  RSA
  number_theory
  modular_arithmetic
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
You've seen how the RSA encryption scheme works, but why is it hard to
break?  In this problem, you will see that finding secret keys is as hard
as finding the prime factorizations of integers.  Since there is a general
consensus in the crypto community (enough to persuade many large financial
institutions, for example) that factoring numbers with a few hundred
digits requires astronomical computing resources, we can therefore be sure
it will take the same kind of overwhelming effort to find RSA secret keys
of a few hundred digits.  This means we can be confident the private RSA
keys are not somehow revealed by the public keys
\footnote{This is a very weak kind of ``security'' property, because it
doesn't even rule out the possibility of deciphering RSA encoded messages
by some method that did not require knowing the secret key.  Nevertheless,
over twenty years experience supports the security of RSA in practice.}


% It would calm a lot of people down if we could show that the ability to
% compute any nontrivial piece of information about a message sent via RSA
% implies the ability to factor, but no one has been able to do that.  (To
% put this in perspective, some people would not even be calmed by such a
% statement, since we are not sure that factoring is computationally
% difficult.  Still, if someone figures out how to factoring efficiently,
% then there would be much bigger problems in the world than whether or not
% you can send your message securely.)  Instead, what .


For this problem, assume that $n = p \cdot q$ where $p,q$ are both
\emph{odd} primes \iffalse (this only rules out the prime 2, which would
not be a very secure prime to choose)\fi and that $e$ is the public key
and $d$ the secret key of the RSA protocol as described in Week 6 Notes.
Let $x \eqdef e \cdot d - 1$.

\bparts

\ppart  Show that $\phi(n)$ divides $x$.

\begin{solution}
$ed \equiv 1 \pmod \phi(n)$ by definition of $d$, so $\phi(n)$ divides $x$
by definition of $\equiv$ mod $\phi(n)$.

\end{solution}

\ppart Conclude that 4 divides $x$.

\begin{solution}
Since $p,q$ are odd, both $p-1$ and $q-1$ are even.  Thus $4$
divides $(p-1)(q-1) = \phi(n)$, so by part~(a), 4 also divides $x$.
\end{solution}

\ppart
\label{squareequals1modn}
Show that if $\gcd(r,n)=1$, then $r^x \equiv 1 \pmod{n}.$

\begin{solution}
By Euler's Theorem, $r^{\phi(n)} \equiv 1 \pmod{n}$.  By part~(a), $x =
k\phi(n)$ for some integer, $k$, so
\[
r^x = r^{k\phi(n)} = \paren{r^{\phi(n)}}^k \equiv 1^k \equiv 1 \pmod n.
\]

\end{solution}


% \ppart\label{k} Show that if you are lucky and find a positive integer $k<n$ such
% that $\gcd(k,n) \neq 1$, then you can factor $n$.

% \begin{solution}
%Since $0< k<n$, we know $0 < \gcd(k,n) < n$.  Also $\gcd(k,n)$
% divides $n$.  So if $\gcd(k,n) \neq 1$, it must be $p$ or $q$.
%\end{solution}

\eparts

A \emph{square root} of $m$ modulo $n$ is a nonnegative integer $s
< n$ such that $s^2 \equiv m \pmod n$.  Here is a nice fact to know: when
$n$ is a product of two odd primes, then every number $m$ such that
$\gcd(m,n)=1$ has 4 square roots modulo $n$.

In particular, the number 1 has four square roots modulo $n$.  The two
trivial ones are 1 and $n-1$ (which is $\equiv - 1 \pmod n$).  The other
two are called the \emph{nontrivial} square roots of 1.

\bparts
\ppart\label{y2=1}
Since you know $x$, then for any integer, $r$, you can also compute the
remainder, $y$, of $r^{x/2}$ divided by $n$.  So $y^2 \equiv r^x \pmod n$.
Now if $r$ is relatively prime to $n$, then $y$ will be a square root of 1
modulo $n$ by part~\eqref{squareequals1modn}.

Show that if $y$ turns out to be a \emph{nontrivial} root of 1 modulo $n$,
then you can factor $n$.  \hint From the fact that $y^2 - 1 = (y+1)(y-1)$,
show that $y+1$ must be divisible by exactly one of $q$ and $p$.

\begin{solution}
Since $y$ is a square root of 1 modulo $n$, we know that $n$
divides $y^2 -1 = (y+1)(y-1)$.  So $p$ must divide either $y+1$ or $y-1$,
and likewise $q$ must divide either $y+1$ or $y-1$.

But if $y$ is nontrivial, then $y+1$ and $y-1$ are positive and smaller
than $n$, so if $y+1$ is divisible by $p$ it can't also be divisible by
$q$, and likewise, if it is divisible by $q$ it can't also be divisible by
$p$.  So $y+1$ must be divisible by exactly one of $p$ and $q$.  So
$\gcd(y+1,n)$ must equal $p$ or $q$.
\end{solution}

\ppart It turns out that at least half the positive integers $r< n$ that
are relatively prime to $n$ will yield $y$'s in part~\eqref{y2=1} that are
nontrivial roots of 1.  Conclude that if, in addition to $n$ and the
public key, $e$, you also knew the secret key $d$, then you can be sure of
being able to factor $n$.

\begin{solution}
Keep choosing $r$'s at random.  Most $r$'s wil be relatively
prime to $n$ and at least half of these will yield nontrivial $y$'s in
part~\eqref{y2=1}, so you can be sure to turn up the needed nontrivial $y$
in not very many tries.  
\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S02.ps5}
\end{pcomments}

\pkeywords{
  state_machines
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{problem}
A robot named ``Spike'' wanders around a two-dimensional
grid.  He starts out at $(0,0)$ and is allowed to take four different
types of step:

\begin{enumerate}
\item $(+2,-1)$
\item $(+1,-2)$
\item $(+1,+1)$ 
\item $(-3,0)$ 
\end{enumerate}

Thus, for example, Spike might walk as follows.  The types of his
steps are listed above the arrows.

\[
(0,0) \stackrel{1}{\rightarrow}
(2,-1) \stackrel{3}{\rightarrow}
(3,0) \stackrel{2}{\rightarrow}
(4,-2) \stackrel{4}{\rightarrow}
(1,-2) \rightarrow \ldots
\]

Spike's true love, a perky toaster named ``Daisy'', awaits at $(0,2)$.

\bparts

\ppart Describe a state machine model of this problem.

\begin{solution}
Let the set of states $Q$ be $\mathbb{Z} \times \mathbb{Z}$.
Let the set of start states $Q_0$ consist of the single state $(0,
0)$.  For each $(x, y) \in Q$, there are four transitions in $\delta$:

\beqn
(x, y) & \rightarrow & (x + 2, y - 1) \\
(x, y) & \rightarrow & (x + 1, y - 2) \\
(x, y) & \rightarrow & (x + 1, y + 1) \\
(x, y) & \rightarrow & (x - 3, y) \\
\eeqn
\end{solution}

\ppart State the most restrictive invariant you can find that
holds for all the states that Spike can reach.

\begin{solution}
Let $P$ be the property that $x + 2y$ is a multiple of 3 for
every reachable position $(x, y)$.  We show that the property is
preserved under each transition in $\delta$.  Suppose that $x + 2y =
3k$ for some $k \in \mathbb{Z}$.  Then we can show that the property
still holds after one transition as follows:

\beqn
(x + 2) + 2 (y - 1)
	& = &	x + 2 y \\
	& = &	3k \\
(x + 1) + 2 (y - 2)
	& = &	x + 2 y - 3\\
	& = &	3 (k - 1) \\
(x + 1) + 2 (y + 1)
	& = &	x + 2 y + 3\\
	& = &	3 (k + 1) \\
(x - 3) + 2 y
	& = &	x + 2 y - 3 \\
	& = &	3 (k - 1)
\eeqn

Therefore, $P$ is an invariant.
\end{solution}

\ppart Will Spike ever find his true love?  Either find a path
from Spike to Daisy or use the Invariant Theorem to prove that no such
path exists.

\begin{solution}
The invariant $P$ holds in the start state, since $0 + 2
\cdot 0 = 0$, which is a multiple of 3.  However, the invariant does
not hold for Daisy's position, $(0, 2)$, since $0 + 2 \cdot 2 = 4$ is
not a multiple of 3.  Therefore, by the Invariant Theorem, this is not
a reachable state.

Later, though, as it turns out, Spike takes one ``illegal'' step,
sweeps up Daisy, and carries her off to the third quadrant of
$\mathbb{C}^2$, where they live happily every after.
\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S02.ps5}
\end{pcomments}

\pkeywords{
  recursive_data
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem} \textbf{Structural Induction}

Suppose we start with a sequence of fully parenthesized arithmetic or
Scheme expressions, and then erase all the alphanumeric characters other
than parentheses.  The result is a string of parentheses which ``match
up''.

For example, erasing non-parenthesis characters from the expression
\texttt{(if (or x y) u v)} leaves the string \texttt{(())}.  Similarly,
erasing non-parentheses from the sequence of three arithmetic expressions
\[
\texttt{(x * x), (y + (3 * (z - 9))), ((x + y) * (u + w))}
\]
leaves the string
\[
\texttt{()((()))(()())}.
\]
On the other hand, even though the string \texttt{())(()} has an equal
number of left and right parentheses, it cannot be obtained by erasing in
this way---because the two middle parentheses don't match up.  Also, no
string of parentheses which begins with a right parenthesis or ends with a
left parenthesis can match up.

We can give an inductive definition of the set, SMU, of ``Strings which
Match Up'', as follows:

\begin{itemize}
\item The empty string (consisting of no parentheses) is an SMU.

\item If $s$ and $t$ are SMU's, then the string $\texttt{(}s\texttt{)}t$
is an SMU.  That is, the new string starts with a left parenthesis which
is followed by the parenthesis characters in the string $s$, followed by a
right parenthesis, followed by the parenthesis characters in the string
$t$.

\end{itemize}


There is a simple test to determine whether a string of parentheses is an
SMU: starting with zero, read the string from left to right adding one for
each left parenthesis and -1 for each right parenthesis.  A string
\emph{counts well} when the count never goes negative and is back to zero
by the end of the string.  Let CW be the set of strings of parentheses
which Count Well.

\bparts
\ppart Prove that CW contains SMU by structural induction on the
definition of SMU.

\begin{solution}
We prove by induction on the definition of SMU (that is,
structural induction) that every element of SMU counts well, so SMU is
contained in CW.  The induction hypothesis is
\[
P(s) ::\equiv s \in \mbox{CW}.
\]
\begin{proof}

{\bf Base Case}: $P(\mbox{empty string})$ holds since the count of the
empty string ends when it starts at zero.

{\bf Inductive Step:} Assume $P(s)$ and $P(t)$ are true.  We need to show
that $P(\texttt{(}s\texttt{)}t)$ is true.

The count values for $\texttt{(}s\texttt{)}t$ start with 0.  Reading the
initial left parenthesis yields 1 as the next count value.  This 1 serves
as the start of a series of count values exactly equal to the count values
of $s$, with each value incremented by one.  Since $s \in \mbox{CW}$ by
hypothesis, these incremented count values begin with 1, always stay
positive, and end with 1.  The right parenthesis immediately after $s$
reduces the ending count to 0.  This 0 serves as the start of the
remaining count values which are exactly the count values of $t$.  Since
$t \in \mbox{CW}$, these remaining values never go negative and end at 0.
Hence the entire sequence of count values for $\texttt{(}s\texttt{)}t$
starts with 0, never goes negative, and ends with 0, which proves that
$\texttt{(}s\texttt{)}t \in \mbox{CW}$.
\end{proof}
\end{solution}

\ppart Conversely, prove that SMU contains CW.

\begin{solution}
We show that every string $r\in \mbox{CW}$ is an SMU by
strong induction on the length of $r$.  The induction hypothesis is
\[Q(n) ::\equiv \forall r \in \mbox{CW}(\mbox{if $r$ is length $n$, then
$r \in \mbox{SMU}$}).\]
\begin{proof}

{\bf Base Case} $n = 0$: In this case there is only one string of length
$n$, namely the empty string, which is in SMU by definition, proving
$Q(0)$.

{\bf Inductive Step:} Assume that $Q(k)$ is true for all $k\leq n$, we
need to prove that $Q(n+1)$ is also true.

So suppose $r$ is a length $n+1$ string that counts well.  We must prove
that $r \in \mbox{SMU}$.

Now since $r$ counts well, it must start with a left parenthesis (or else
the count would immediately go negative).  Likewise, since the count for
$r$ returns to the value 0 by the end, $r$ must end with right
parenthesis.  So there must be a \emph{first} right parenthesis in $r$
after which the count returns to 0.  Let $s$ be the substring of $r$
between the initial left parenthesis and this right parenthesis.  So
\[
r = \texttt{(}s\texttt{)}t
\]
for some string $t$.

Since counts only change by one as each parenthesis character is read, and
the count for $r$ \emph{first} returns to 0 after the right parenthesis
following $s$, the count during $s$ must start and end with 1 and must
stay \emph{positive} in between.  But this implies that a count for $s$
alone, which would start with 0, would also end with 0 and stay
\emph{nonnegative} in between.  That is, $s$ by itself counts well.  Since
the length of $s \in \mbox{CW}$ is less than the length of $r$, we have by
strong induction that $s \in \mbox{SMU}$.

Further, we know the count for $r$ returns to 0 after the right
parenthesis following $s$, and since $r \in \mbox{CW}$, the count ends
with 0 again and stays nonnegative in between.  But this implies that $t$
counts well, and since the length of $t$ is less than the length of $r$,
we have by strong induction that $t \in \mbox{SMU}$.  Now by the second
case in the definition of SMU, we conclude $\texttt{(}s\texttt{)}t$,
namely $r$, is in SMU.
\end{proof}
\end{solution}

\eparts
\end{problem}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps4}
  \pcomment{from: F05.ps6}
\end{pcomments}

\pkeywords{
  state_machines
  increasing_decreasing_variables
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}

The Massachusetts Turnpike Authority is concerned about the integrity of
the new Zakim bridge.  Their consulting architect has warned that the
bridge may collapse if more than 1000 cars are on it at the same time.
The Authority has also been warned by their traffic consultants that the
rate of accidents from cars speeding across bridges has been increasing.

Both to lighten traffic and to discourage speeding, the Authority has
decided to make the bridge \emph{one-way} and to put tolls at \emph{both}
ends of the bridge (don't laugh, this is Massachusetts).  So cars will pay
tolls both on entering and exiting the bridge, but the tolls will be
different.  In particular, a car will pay \$3 to enter onto the bridge and
will pay \$2 to exit.  To be sure that there are never too many cars on
the bridge, the Authority will let a car onto the bridge only if the
difference between the amount of money currently at the entry toll booth
minus the amount at the exit toll booth is strictly less than a certain
threshold amount of \$$T_0$.

The consultants have decided to model this scenario with a state
machine whose states are triples of natural numbers, $(A,B,C)$, where
\begin{itemize}
\item $A$ is an amount of money at the entry booth,
\item $B$ is an amount of money at the exit booth, and
\item $C$ is a number of cars on the bridge.
\end{itemize}
Any state with $C>1000$ is called a \emph{collapsed} state, which the
Authority dearly hopes to avoid.  There will be no transition out of a
collapsed state.

Since the toll booth collectors may need to start off with some amount of
money in order to make change, and there may also be some number of
``official'' cars already on the bridge when it is opened to the public,
the consultants must be ready to analyze the system started at \emph{any}
uncollapsed state.  So let $A_0$ be the initial number of dollars at the
entrance toll booth, $B_0$ the initial number of dollars at the exit toll
booth, and $C_0 \leq 1000$ the number of official cars on the bridge when
it is opened.  You should assume that even official cars pay tolls on
exiting or entering the bridge after the bridge is opened.

\bparts

\problempart Give a mathematical model of the Authority's system for
letting cars on and off the bridge by specifying a transition relation
between states of the form $(A,B,C)$ above.  

\begin{solution}

State $(A,B,C)$ goes to state
\begin{enumerate}
\item[(i)] $(A+3,B,C+1)$, provided that $A-B<T_0$ and $C < 1000$.  This
transition models the case where a car enters the bridge.

\item[(ii)] $(A,B+2,C-1)$, provided that $0 < C \leq 1000$.  This
transition models the case where a car leaves the bridge.

\end{enumerate}

\end{solution}
 
\problempart\label{variables}
Characterize each of the following derived variables
\[
A, B, A+B, A-B, 3C-A, 2 A - 3 B, B+3C, 2A - 3B - 6C, 
2A - 2B - 3C
\]
as one of the following
\begin{center}
\begin{tabular}{|ll|} \hline
constant              & C  \\  
strictly increasing   & SI \\
strictly decreasing   & SD \\
weakly increasing but not constant & WI \\
weakly decreasing but not constant & WD \\
 none of the above     & N  \\\hline
\end{tabular}
\end{center}
and briefly explain your reasoning.

\begin{solution}

%$A$ WI,
%$B$ WI,
%$A+B$  SI,
%$A-B$ N,
%$3C-A$ WD,
%$2A - 3B$ N,
%$B+3C$ WI,
%$2A - 3B - 6C$ C,
%$2A - 2B - 3C$ N

In every transition, at least one of $A$ and $B$ increases. So
their sum is strictly increasing.  $2A-3B$ can fluctuate, going up on (i)
and down on (ii).

The difference $3C-A$ doesn't change under transitions of type~(i), but
decreases under transitions of type~(ii); so is weakly decreasing.
Likewise, $B+3C$ doesn't change under transitions of type~(ii), but
increases under transitions of type~(i); so is weakly increasing.

On the other hand, $6C$ and $2A-3B$ simultaneously increase by 6 under
transition (i) or simultaneously decrease by 6 under transition (ii),
which makes their difference constant.

Finally, under (i), $2A$ increases by 6, $B$ is unchanged, and $3C$
increases by 3, so $2A-2B-3C$ increases by $6-3 =3$.  However, under (ii),
$A$ is unchanged, $3C$ decreases by 3 and $2B$ increases by 4, so $2A-2B-3C$
decreases by $-(-4) - 3 = 1$.

The completed table follows.
\[
\renewcommand{\arraystretch}{2}
\begin{array}{|c|c|} \hline
A  		  & WI \\\hline 
B                 & WI \\\hline 
A+B 		  & SI \\\hline 
A-B 		  & N  \\\hline 
3C-A              & WD \\\hline
2A - 3B 	  & N \\\hline 
B+3C              & N \\\hline 
2A - 3B - 6C      & C  \\\hline
2A - 2B -3C       & N \\\hline
\end{array}
\]
\end{solution}

\eparts

The Authority has asked their engineering consultants to determine $T$ and
to verify that this policy will keep the number of cars from exceeding
1000.

The consultants reason that if $C_0$ is the number of official cars on the
bridge when it is opened, then an additional $1000-C_0$ cars can be allowed
on the bridge.  So as long as $A-B$ has not increased by $3(1000-C_0)$,
there shouldn't more than 1000 cars on the bridge.  So they recommend
defining
\begin{equation}\label{T0}
T_0 \eqdef 3(1000-C_0) + (A_0 - B_0),
\end{equation}
where $A_0$ is the initial number of dollars at the entrance toll booth,
$B_0$ is the initial number of dollars at the exit toll booth.

\bparts

\problempart Use the results of part~(\ref{variables}) to define a simple
predicate, $P$, on states of the transition system which is satisfied by
the start state, that is $P(A_0,B_0,C_0)$ holds, is not satisfied by any
collapsed state, and is a preserved invariant of the system.  Explain why
your $P$ has these properties.

\begin{solution}

Let $D_0 \eqdef 2A_0 - 3B_0 - 6C_0$.

\textbf{Preserved Invariant:} 
\[
P(A,B,C) \eqdef [2A - 3B - 6C =  D_0]\ \QAND\ [C \leq 1000].
\]
Note that $P(A_0,B_0,C_0)$ is true because we know that $C_0 \leq 1000$,
and it is not true in any collapsed state.  To verify that $P$ is
preserved, suppose state $(A,B,C)$ has a transition to $(A',B',C')$, and
$P(A,B,C)$ is true.  We verify that $P(A',B',C')$ is true by considering
the two kinds of transitions.

Transition (i) (a car enters the bridge): so
\[
6C' = 6(C + 1) = 6C + 6 = (2A-3B-D_0) + 6 = 2(A+3)-3B-D_0=
2A' - 3B' -D_0,
\]
which implies that
\begin{equation}\label{2A}
2A' - 3B' - 6 C' =  D_0,
\end{equation}
as required.

Also, the transition is possible only if $A-B < T_0$.
But this implies
\begin{align*}
6C' & = 2A' -  3B' - D_0 & \text{(by~(\ref{2A}))}\\
& = 2(A'- B') - B' - D_0\\
& = 2((A+3) - B) - B - D_0 & \text{(since $A'=A+3$, $B'=B$)}\\
& = 2(A-B) - B - D_0 + 6\\
& \leq 2(A - B) - B_0 -D_0 + 6 &\text{(since $B$ is WI)}\\
& \leq 2(T_0 - 1) -B_0 -D_0 + 6 & \text{(since $A-B \leq T_0 - 1$)}\\
&= 2[3(1000-C_0) + (A_0 - B_0)] -B_0 -D_0+4 \text{(by~\eqref{T0})}\\
&=6000 -6C_0 +2A_0-3B_0 -D_0+4\\
& =6004,
\end{align*}
and so $C' \leq \floor{6004/6} = 1000$, as required.

Transition (ii) (a car leaves the bridge): so
\[
6C' = 6(C - 1) = 6C - 6= 2A-3B - 6= 2A - 3(B+3) = 2A' - 3B'.
\]
In addition, $C' < C \leq 1000$ so $C' \leq 1000$.
\end{solution}


\problempart A clever MIT intern working for the Turnpike Authority agrees
that the Turnpike's bridge management policy will be \emph{safe}: the
bridge will not collapse.  But she warns her boss that the policy will
lead to \emph{deadlock}--- a situation where traffic can't move on the
bridge even though the bridge has not collapsed.

Explain more precisely in terms of system transitions what the intern
means, and briefly, but clearly, justify her claim.

\begin{solution}

The intern means that any long enough sequence of transitions will arrive
at a state in which no transition is possible, even though there are no
cars on the bridge.  This happens because every time a car enters and then
exits the bridge the value of $A-B$ increases by 1.  So after 3000 cars
have crossed the bridge, no further car can enter the bridge because
\[
A-B \geq 3000 + A_0-B_0 \geq 3(1000-C_0) + (A_0 - B_0) = T_0.
\]
After that, cars can only exit the bridge.  So after at most 3000+1000
transitions, the system deadlocks with the bridge empty but no cars
allowed onto the bridge.

\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%CP_ant_on_grid

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: F01.ps6}
%  \pcomment{}
%  \pcomment{}
\end{pcomments}

\pkeywords{
    state_machine
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}

  A hungry ant is placed on an unbounded grid.  Each square of the grid
  either contains a crumb or is empty.  The squares containing crumbs form
  a path in which, except at the ends, every crumb is adjacent to exactly
  two other crumbs.  The ant is placed at one end of the path and on a
  square containing a crumb.  For example, the figure below shows a
  situation in which the ant faces North, and there is a trail of food
  leading approximately Southeast.  The ant has already eaten the crumb
  upon which it was initially placed.

\bigskip
\begin{center}
\includegraphics[width=2in]{figures/ant}
\end{center}
%%\centerline{\resizebox{!}{2.0in}{\includegraphics{figs/ant.eps}}}
\bigskip

The ant can only smell food directly in front of it.  The ant can only
remember a small number of things, and what it remembers after any move
only depends on what it remembered and smelled immediately before the
move.  Based on smell and memory, the ant may choose to move forward one
square, or it may turn right or left.  It eats a crumb when it lands on
it.

% The ant sends a signal whenever it cannot smell food on all 
% four adjacent squares.

The above scenario can be nicely modelled as a state machine in which
each state is a pair consisting of the ``ant's memory'' and
``everything else,'' e.g., information about where things are on the
grid.  Work out the details of such a model state machine; design the
ant-memory part of the state machine so the ant will eat all the
crumbs on \emph{any} finite path at which it starts and then signal
when it is done.  Be sure to clearly describe the possible states,
transitions, and inputs and outputs (if any) in your model.  Briefly
explain why your ant will eat all the crumbs.

\begin{solution}

If all the crumbs are placed as if ``on a string'', then the ant can
pick them all up very easily: If the ant smells no crumb in front of
it, it should turn in some fixed direction (say left), and if it does
smell a crumb, it should go forward and eat it.  Hence the ant can eat
all the crumbs of bread even if it is completely memory-less.
However, we requested that the ant-machine stops and signals {\em
done} when all the bread crumbs are eaten.  If the ant had no memory
then after eating the last crumb it would rotate indefinitely.
Therefore we should embed it with a memory of how many times it
rotated in the same spot in the search of an adjacent bread crumb.  If
the number of turns reaches four, all the bread crumbs are eaten and
the ant can signal {\em done}.  Here is the state machine:
\begin{eqnarray*}
AntMemory &=& \{0,1,2,3,4\}
\\
BoardLocation &=& \naturals \times \naturals
\\
AntDirection &=& \set{N,E,W,S}
\\
Crumbs &\subseteq& BoardLocation
\\
AntLocation &=& BoardLocation
\\
Q &=& AntMemory \times (AntLocation \times AntDirection \times
\mathcal{P}(Crumbs) )
\end{eqnarray*}

The transitions correspond to the three actions \{``go straight'',
``turn left'', ``done''\}.  We will use variables $q=(m,l,d,C)$ to
represent a state $q\in{Q}$ ($m\in{AntMemory}, l\in{AntLocation},
d\in{AntDirection}, C\in{\mathcal{P}(Crumbs)}$).  Let ${\sf Loc}(l,d)$ be a
function taking a location $l\in{AntLocation}$ and
$d\in{AntDirection}$ and returning $l'\in{AntLocation}$ s.t. $l'$ is the
location adjacent to $l$ in direction $d$.  In particular, if the ant
is in location $l$ and goes in direction $d$, it will come to location
$l'={\sf Loc}(l,d)$.  Let ${\sf Next}(d)$ be a function which picks
next direction of an ant which turns left, i.e. ${\sf Next}$ maps N to
W, W to S, S to E, and E to N.

\begin{itemize}
\item
{\sf go straight:}
$(m,l,d,C)\rightarrow(0,{\sf Loc}(l,d),d,C\setminus\{{\sf Loc}(l,d)\})$ if
${\sf Loc}(l,d)\in{C}$.
\item
{\sf turn left:} $(m,l,d,C)\rightarrow(m+1,l,{\sf Next}(d),C)$ if
${\sf Loc}(l,d)\not\in{C}$ and $m\neq{4}$.
\item
{\sf done:} $(m,l,d,C)\rightarrow(m,l,d,C)$ if
${\sf Loc}(l,d)\not\in{C}$ and $m=4$. Furthermore, the ant signals ``done''.
\end{itemize}

\end{solution}

Note that the last transition is a self-loop; the ant signals done for
eternity. One could also add another end state so that the ant signals
done only once.
\end{problem}

%------------------------------------------------
% source: source: spring00 pset4-5
% Based on spring97, handout 28, pset 9 solutions
% topic: marriage problem (simple)
% last used:


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps8}
  \pcomment{from: S08.ps8}
\end{pcomments}

\pkeywords{
  asymptotics
  Stirlings_formula
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
  Indicate which of the following holds for each pair of functions $(f(n),
  g(n))$ in the table below.  Assume $k\geq 1$, $\epsilon > 0$, and $c >
  1$ are constants.  Pick the four table entries you consider to be the
  most challenging or interesting and justify your answers to these.

\begin{equation*}
\begin{array}{|cc|c|c|c|c|c|c|}
\hline
f(n) & g(n) & 
f = O(g) & f=o(g) & 
g = O(f) & g=o(f) & 
f = \Theta(g) & f\sim g 
\\\hline\hline
2^n & 2^{n/2} & & & & & & \\\hline
\sqrt{n} & n^{\sin n\pi/2} & & & & & & \\\hline
\log(n!) & \log(n^n) & & & & & & \\\hline
n^k & c^n & & & & & & \\\hline
\log^k n & n^\epsilon & & & & & & \\\hline
\end{array}
\end{equation*}

%\item $f=O(g)$
%\item $f=o(g)$
%\item $g=O(f)$
%\item $g=o(f)$
%\item $f = \Theta(g)$
%\item $f \sim g$
%\item none of the above.
%
%\begin{equation*}
%\begin{array}{|cc|}
%\hline
%f(n) & g(n) \\\hline\hline
%\log^k n & n^\epsilon \\\hline
%n^k & c^n \\\hline
%\sqrt{n} & n^{\sin n\pi/2} \\\hline
%2^n & 2^{n/2} \\\hline
%\log(n!) & \log(n^n) \\\hline
%\end{array}
%\end{equation*}

\begin{solution}
\newcommand\y{\text{yes}}
\newcommand\n{\text{no}}
\[
\begin{array}{|cc|c|c|c|c|c|c|}
\hline
f(n) & g(n) & 
f = O(g) & f=o(g) & 
g = O(f) & g=o(f) & 
f = \Theta(g) & f\sim g 
\\\hline\hline
2^n & 2^{n/2} & 
\n & \n & \y & \y & \n & \n
\\\hline
\sqrt{n} & n^{\sin n\pi/2} & 
\n & \n & \n & \n & \n & \n
\\\hline
\log(n!) & \log(n^n) & 
\y & \n & \y & \n & \y &  \y
\\\hline
n^k & c^n &             
\y & \y & \n & \n & \n & \n
\\\hline
\log^k n & n^\epsilon & 
\y & \y & \n & \n & \n & \n
\\\hline
\end{array}
\]

Following are some hints on deriving the table above:

\begin{itemize}

\item[(a)] 
$\dfrac{2^n}{2^{n/2}}=2^{n/2}$ grows without bound as $n$
grows---it is not bounded by a constant.

\item[(b)] 
When $n$ is even, then $n^{\sin n\pi/2}=1$.  So, no constant times
$n^{\sin n\pi/2}$ will be an upper bound on $\sqrt n$ as $n$ ranges
over even numbers.  When $n \equiv 1 \bmod 4$, then $n^{\sin n\pi/2}=
n^1 =n$. So, no constant times $\sqrt n$ will be an upper bound on
$n^{\sin n\pi/2}$ as $n$ ranges over numbers $\equiv 1 \bmod 4$.

\item[(c)] 
\begin{eqnarray}
\log(n!) & = & \log \sqrt{2\pi n}\left(\frac{n}{e}\right)^n \pm
c_n\label{logS}\\
& = & \log n + n(\log n - 1) \pm d_n \label{logprod}\\
& \sim & n \log n\label{sim}\\
& = & \log n^n.\notag
\end{eqnarray}
where $a \leq c_n,d_n \leq b$ for some constants $a,b \in \reals$ and all
$n$.  Here equation~(\ref{logS}) follows by taking logs of Stirling's
formula,~(\ref{logprod}) follows from the fact that the log of a product
is the sum of the logs, and~(\ref{sim}) follows because any constant,
$\log n$, and $n$ are all $o(n \log n)$ and hence so is their sum.

\iffalse

\dots follows\textbf{from Problem~\ref{o+o}, part~\ref{f+o} because any
constant, $\log n$, and $n$ are all $o(n \log n)$.}
\fi

\item[(d)] 
\emph{Polynomial} growth versus \emph{exponential} growth.

\item[(e)] 
\emph{Polylogarithmic} growth versus \emph{polynomial} growth. 

\end{itemize}


\end{solution}
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps7}
\end{pcomments}

\pkeywords{
  networks
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem} Consider the following communication network:

\begin{center}
\begin{tabular}{ccc}
\includegraphics[height=2.0in]{figures/MQ_oct31_network}\\
\end{tabular}
\end{center}

\bparts

\ppart What is the max congestion? \hfill \brule{0.5in}

\begin{solution}
The congestion of the network is at least 3,
  because every path must contain the central switches when $\pi(i) = 2 -
  i$.  The congestion is at most 3, because there are only 3 simple paths
  in total.
\end{solution}

\ppart Give an input/output permutation, $\pi_0$, that forces maximum
  congestion:

\hfill $\pi_0(0) =$ \brule{0.4in}  \qquad $\pi_0(1) =$ \brule{0.4in}
\qquad $\pi_0(2) =$ \brule{0.4in}

\begin{solution}
The permutation $\pi_0$ is the same as the one specified in
  part (a)---$\pi_0(i) = 2-i$.  All three paths contain the central
  switch. 
\end{solution}

\ppart\label{minpi} Give an input/output permutation, $\pi_1$, that
allows \emph{minimum} congestion:

\hfill $\pi_1(0) =$ \brule{0.4in}  \qquad $\pi_1(1) =$ \brule{0.4in}
\qquad $\pi_1(2) =$ \brule{0.4in}

\begin{solution}
The permutation is $\pi_1(i) = i$---each switch has only
  one path going through it, so the congestion is $1$. 
\end{solution}


\ppart What is the latency for the permutation $\pi_1$? (If you could not find $\pi_1$, just choose a permutation and find its latency.)
\hfill\brule{0.5in}

\begin{solution}
\textbf{3}.  This is the latency of
  the (unique) shortest path routing for the permutation in
  part~\eqref{minpi}.  No smaller latency is possible since the minimum
  distance from any input to any output is 3.

\end{solution}
\eparts


\iffalse

{\large
\[
\begin{array}{c|c|c}
%\text{\# switches} &
%\text{switch size} &
\text{diameter} &
\text{latency} &
\text{max congestion} \\ \hline
%\insolutions{6} &
%\insolutions{2 \times 3, 3 \times 2} &
\insolutions{7} &
\insolutions{7} &
\insolutions{3}
\end{array}
\]
}
\fi

\iffalse

  The diameter of a communication net is the largest distance from an input
  to an output.  In this example, the largest distance is from input 0 to
  output 2 of length 7, so the diameter is 7.

  Latency depends on how packets are routed.  If you choose a shortest
  path routing, then the worst I/O pattern (permutation) will be the one
  that maps the maximum distance input to output, so the latency will
  equal the diameter.

  However, a shortest-path routing may be pretty congested, so we're
  usually more interested in the worst latency among the
  minimum-congestion routings.  But in this example, the shortest path
  routing is also the minimum congestion routing, so the latency is any
  case equals the diameter, namely 7.
\fi
  
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps1}
  \pcomment{Has 2 hard references to ps1 and class problems.}
\end{pcomments}

\pkeywords{
  set_theory
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
\bparts
\ppart\label{AUBUC_equiv}
Prove that
\begin{equation}\label{AUBUC}
A \cup B \cup C = (A - B) \cup (B - C) \cup (C - A) \cup (A \cap B \cap C)
\end{equation}
for all sets $A$, $B$, and $C$.

\hint Use the valid propositional formula from
\href{http://courses.csail.mit.edu/6.042/spring09/ps1.pdf} {Pset 1},
Problem 2(b).

\begin{solution}
As illustrated in lecture and Thursday, Week 2 Class Problem n,
  a set-theoretic equality can be proved by showing that an arbitrary
  element in either of the sets must also be an element of the other set.
In particular, the aim is to prove that
\begin{equation}\label{ABC}
x \in A \cup B \cup C,
\end{equation}
iff 
\begin{equation}\label{A-B}
x \in (A - B) \cup (B - C) \cup (C - A) \cup (A \cap B \cap C).
\end{equation}

By definition
\begin{align*}
x \in A \union B & \qiff (x \in A)\ \QOR\ (x\in B)\\
x \in A \intersect B & \qiff (x \in A)\ \QAND\ (x\in B)\\
x \in A-B & \qiff (x \in A)\ \QAND\ \QNOT(x\in B).
\end{align*}
So~\eqref{A-B} is equivalent to
\begin{align}
\lefteqn{[x \in A \ \QAND\  \QNOT(x \in B)]} & \label{xAand}\\
& \QOR\ [x \in B \ \QAND\  \QNOT(x \in C)]\notag\\
& \QOR\ [x \in C \ \QAND\  \QNOT(x \in A)] \notag\\
& \QOR\ [x \in A \ \QAND\  x \in B \ \QAND\  x \in C].\notag
\end{align}
Letting $P \eqdef (x \in A)$, $Q \eqdef (x \in B)$, $R \eqdef (x \in C)$,
the hinted equivalence in Pset 1 implies that~\eqref{xAand} is equivalent
to $(x\in A)\ \QOR\ (x \in B)\ \QOR\ (x \in C)$, which is equivalent
to~\eqref{ABC} by definition.
\end{solution}

\ppart Suppose you had a powerful \emph{VAL-checker} program for
determining whether or not an arbitrary propositional formula was valid.
Explain how to modify this program into a powerful \emph{SETEQ-checker}
program for checking whether an arbitrary equality between set formulas
like~\eqref{AUBUC} ---involving only the operations of union,
intersection, and set-difference ---was correct.

\begin{solution}
Let $L$ and $R$ be the two set formulas that \emph{SETEQ-checker} is
checking for equality.  Then $L=R$ iff for all $x$, $x \in L \iff x \in R$.  
If we can find a propositional formula $P_L$ that is true iff $x \in L$ 
and another propositional formula $P_R$ that is true iff $x \in R$ then
we could use \emph{VAL-checker} to check the validity of the statement
$P_L \iff P_R$.

To find $P_R$ and $P_L$ we proceed in the same manner as in part 
\eqref{AUBUC_equiv}, using the definitions of intersection, union and 
set-difference to convert the $\union$, $\intersect$ and $-$ operations 
in the statements $x \in L$ and $x \in R$ into statements involving 
only $\QAND$, $\QOR$ and $\QNOT$.  $P_L$ and $P_R$ are then found
by replacing set membership with propositions: replace each occurrence 
of the statement $x \in A$ with a boolean variable $P_A$ for each set
$A$ that appears in $L$ and/or $R$.

\end{solution}

\eparts
\end{problem}


%% Another version...
\iffalse
\begin{problem}
Let $A$, $B$, and $C$ be sets.
Prove that:
%
\[
A \cup B \cup C = (A - B) \cup (B - C) \cup (C - A) \cup (A \cap B \cap C).
\]
%
You are welcome to use a diagram to aid your own reasoning, but your
proof must be text.

\begin{solution}
We prove that the left side is contained in the right side, and that
the right side is contained in the left side.

First, we show that the left side is contained in the right side.  Let $x$
be any element of $A \cup B \cup C$.  Then $x$ belongs to at least 
one of $A$, $B$, and $C$.  We distinguish two cases.
\begin{itemize}
\item $x$ belongs to all three sets: Then $x$ belongs to the
intersection $A\cap B\cap C$. 

\item $x$ does \emph{not} belong to all three sets: Then at least one
of $A$, $B$, $C$ does not contain $x$.  So overall, at least one set
contains $x$ and at least one set doesn't. We distinguish cases:
\begin{itemize}
\item If $A$ contains $x$, then one of $B$ and $C$ must not contain
it. 
\begin{itemize}
\item If $B$ does not contain it, then $x\in A-B$. 
\item If $B$ contains it, then $C$ does not, therefore $x\in B-C$.
\end{itemize}

\item If $A$ does \emph{not} contain $x$, then one of $B$ and $C$ must  
contain it. 

\begin{itemize}
\item If $C$ does, then $x\in C-A$. 
\item If $C$ does not contain it, then $B$ does, therefore $x\in B-C$. 
\end{itemize}
\end{itemize}
\end{itemize}
In all cases, we end up with $x$ being a member of one of 
$A - B$, $B - C$, $C - A$, or $A\cap B\cap C$.  Therefore, it belongs
to the right side. Hence, the set on the left is contained in the set
on the right.

Next, we show that the right side is contained in the left.  This is
easier. Let $x$ belong to the right side. Then it belongs to one of $A
- B$, $B - C$, $C - A$, or $A\cap B\cap C$.  In the first case, we
clearly know $x\in A$. In the second case, $x\in B$. In the third
case, $x\in C$. In the last case, $x\in A$ again. So, in all cases,
$x$ belongs to one of $A$, $B$, or $C$. So $x$ belongs to the left
side. Therefore, the set on the right is contained in the set on the
left.

Since each set is contained in the other, they are equal.
\end{solution}

\end{problem}
\fi

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: f03.ps2}
\end{pcomments}

\pkeywords{
  binary_relations
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}

List all the different binary relations on the set $\set{0,1}$.

\begin{solution}

There are altogether 16 binary relations.

\( \begin{array}{ll}
1. &  \emptyset\\
2. &  \{(0,0)\}\\
3. &  \{(0,1)\}\\
4. &  \{(1,0)\}\\
5. &  \{(1,1)\}\\
6. &  \{(0,0),(0,1)\}\\
7. &  \{(0,0),(1,0)\}\\
8. &  \{(0,0),(1,1)\}\\
9. &  \{(0,1),(1,0)\}\\
10. &  \{(0,1),(1,1)\}\\
11. &  \{(1,0),(1,1)\}\\
12. &  \{(0,0),(0,1),(1,0)\}\\
13. &  \{(0,0),(0,1),(1,1)\}\\
14. &  \{(0,0),(1,0),(1,1)\}\\
15. &  \{(0,1),(1,0),(1,1)\}\\
16. &  \{(0,0),(0,1),(1,0),(1,1)\}
\end{array} \)

\end{solution}
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps8}
  \pcomment{blah}
\end{pcomments}

\pkeywords{
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Find closed-form expressions for the following sums.

\bparts

\ppart

\[
\sum_{i=0}^n \frac{9^i - 7^i}{11^i}
\]

\begin{solution}
Split the expression into two geometric series and then
apply the formula for the sum of a geometric series.
%
\begin{align*}
\sum_{i=0}^n \frac{9^i - 7^i}{11^i}
    & = \sum_{i=0}^n \left(\frac{9}{11}\right)^i -
        \sum_{i=0}^n \left(\frac{7}{11}\right)^i \\
    & = \frac{1 - \left(\frac{9}{11}\right)^{n+1}}{1 - \frac{9}{11}}
          - \frac{1 - \left(\frac{7}{11}\right)^{n+1}}{1 - \frac{7}{11}} \\
    & = - \frac{11}{2} \cdot \left(\frac{9}{11}\right)^{n+1}
        + \frac{11}{4} \cdot \left(\frac{7}{11}\right)^{n+1}
        + \frac{11}{4}
\end{align*}

\end{solution}

\ppart

\[
\sum_{i=0}^n \sum_{j=0}^m 3^{i+j}
\]

\begin{solution}
\begin{align*}
\sum_{i=0}^n \sum_{j=0}^m 3^{i+j}
    & = \sum_{i=0}^n \left(3^i \cdot \sum_{j=0}^m 3^j\right) \\
    & = \left(\sum_{j=0}^m 3^j\right) \cdot \left(\sum_{i=0}^n 3^i\right)\\
    & = \left(\frac{3^{m+1} - 1}{2}\right) \cdot \left(\frac{3^{n+1} - 1}{2}\right)
\end{align*}

\end{solution}


\ppart
\[
\sum_{j=1}^n \sum_{i=0}^{\infty} j^{5/3} \cdot \left(1 - \frac{1}{2 j^{1/3}}\right)^i
\]

\begin{solution}
This fearsome-looking sum is a paper tiger; we just apply
the formula for the sum of a geometric series followed by the formula
for the sum of an arithmetic series.
%
\begin{align*}
\sum_{j=1}^n \sum_{i=0}^{\infty} j^{5/3} \cdot \left(1 - \frac{1}{2 j^{1/3}}\right)^i
    & = \sum_{j=1}^n j^{5/3} \cdot \frac{1}{1 - \left(1 - \frac{1}{2 j^{1/3}}\right)} \\
    & = \sum_{j=1}^n 2j^2 \\
    & = \frac{2n (n+\frac{1}{2})(n+1)}{3}
\end{align*}

\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps7}
  \pcomment{commented out in S09 - looks like it needs substantial revision}
\end{pcomments}

\pkeywords{
  networks
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Let $B_n$ denote the butterfly network with $N=2^n$ inputs and $N$
outputs, as defined in Week 5 Notes. Show that the congestion of $B_n$ is
exactly $\sqrt{N}$ when $n$ is even.

%Let $b$ be the binary number for vertex $v$. Now, let the set of
%input vertices that can reach $v$ be $S_v$ and the set of output
%vertices reachable from $v$ be $T_v$. The set $S_v$ consists of all
%input vertices whose binary numbers match $b$ in the last $n-i$
%bits, but the first $i$ bits can be arbitrary. There are $2^i$ ways
%to set these bits, so there are $2^i$ inputs in $S_v$. The set $T_v$
%consists of all output vertices whose binary numbers match $b$ in
%the first $i$ bits, but the last $n-i$ bits can be arbitrary. There
%are $2^{n-i}$ ways to set these bits, so there are $2^{n-i}$ outputs
%in $T_v$.

\emph{Hints:}
\begin{itemize}
\item For the butterfly network, there is a unique path from
each input to each output, so the congestion is the maximum number
of messages passing through a vertex for any matching of inputs to
outputs.
\item If $v$ is a vertex at level $i$ of the butterfly
network, there is a path from exactly $2^i$ input vertices to $v$
and a path from $v$ to exactly $2^{n-i}$ output vertices.\\
\item At which level of the butterfly network must the congestion be
worst? What is the congestion at the node whose binary
representation is all $0$s at that level of the network?
\end{itemize}

\begin{solution}
First we will show that the congestion is at most $\sqrt{N}$.

Let $v$ be an arbitrary vertex at some level $i$. Let $S_v$ be the
set of inputs that can reach vertex $v$. Let $T_v$ be the set of
outputs that are reachable from vertex $v$.

By the hint, we have $\card{S_v} = 2^i$ and $\card{T_v} = 2^{n-i}$.
The number of inputs in $S_v$ that are matched with outputs in $T_v$
is at most $\min \set{2^i,2^{n-i}}$.  To obtain an upper-bound on
the congestion of the network, we need to find the maximum value of
$\min \set{2^i,2^{n-i}}$, where the maximum is taken over all $i$.
The maximum value is achieved when $2^i$ and $2^{n-i}$ are as equal
as possible. Since $n$ is even, these two quantities are equal when
$i=n/2$, hence the maximum congestion is
\[
2^{n/2}=N^{1/2} = \sqrt{N}.
\]

Now we need to show that the congestion achieves $\sqrt{N}$
somewhere in the network. We concluded that the congestion of
$\sqrt{N}$ can be achieved only at a node at level $\frac{n}{2}$.
Consider the node at that level whose binary representation is all
$0$s. Any packet from the input in the form
$z\underbrace{0\ldots000}_{n/2\ bits}$ with destination
$\underbrace{000\ldots0}_{n/2\ bits}z'$, where $z$ and $z'$ are any
$\frac{n}{2}$-bit numbers, must pass through this node. But there
are $2^{n/2}=\sqrt{N}$ of them, giving the node load $\sqrt{N}$.
Therefore, we can conclude that the congestion of $B_n$ is exactly
$\sqrt{N}$ when $n$ is even.

%In fact, the set of vertices with load $\sqrt{N}$ are those vertices
%$v$ at level $\frac{n}{2}$ with the last $\frac{n}{2}$ bits being
%the reversal of its first $\frac{n}{2}$ bits.
%
%As a sanity check, there are a total of $\sqrt{N}\ n$-bit numbers in
%the form $kk^r$. So there are $\sqrt{N}$ vertices at level
%$\frac{n}{2}$ with load $\sqrt{N}$, giving us a total of $N$
%packets.


\end{solution}
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%PS_card_shuffle_state_machine.tex

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{S03.ps7}
\end{pcomments}

\pkeywords{
  state_machines
  termination
  partial_correctness
  invariant
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem} Suppose that you have a regular deck of cards arranged as
follows, from top to bottom:
\[
A \heartsuit\ 2 \heartsuit \dots K \heartsuit\ 
A \spadesuit\ 2 \spadesuit \dots K \spadesuit\ 
A \clubsuit\ 2 \clubsuit \dots K \clubsuit\ 
A \diamondsuit\ 2 \diamondsuit \dots K \diamondsuit
\]

Only two operations on the deck are allowed: \emph{inshuffling} and
\emph{outshuffling}.  In both, you begin by cutting the deck exactly in
half, taking the top half into your right hand and the bottom into
your left.  Then you shuffle the two halves together so that the cards
are perfectly interlaced; that is, the shuffled deck consists of one
card from the left, one from the right, one from the left, one from
the right, etc.  The top card in the shuffled deck comes from the
right hand in an outshuffle and from the left hand in an inshuffle.

\begin{problemparts}

\ppart Model this problem as a state machine.

\begin{solution}
Let the set of states $Q$ be all the possible orderings of
the deck of cards.  Let the set of start states $Q_0$ consist of the
single ordering listed above.  For each state $(c_1, \ldots c_{52}) \in
Q$, there are two transitions in $\delta$:

\begin{align*}
(c_1, \dots c_{52})
	& \rightarrow 
		(c_1, c_{27}, c_2, c_{28}, \dots, c_{26}, c_{52}) \\
(c_1, \dots c_{52})
	& \rightarrow 
		(c_{27}, c_1, c_{28}, c_2, \dots, c_{52}, c_{26})
\end{align*}
\end{solution}

\ppart Use the Invariant Theorem to prove that you can not make
the entire first half of the deck black through a sequence of
inshuffles and outshuffles.

\begin{solution}
The proof uses the Invariant Theorem.  Define two cards to
be {\em opposites} if the sum of their positions is 53.  For example,
the top card is opposite the bottom card, the second card from the top
is opposite the second from the bottom, etc.

Let $P$ be the property that $A \heartsuit$ is opposite $K
\diamondsuit$, $2 \heartsuit$ is opposite $Q \diamondsuit$, etc., as
in the initial configuration.  We claim that $P$ is a preserved invariant.
Suppose that $P$ holds for a given state and consider the two types of
transition out of that state.  Note that, for both types of
transition, cards in opposite positions are mapped to opposite
positions.  Therefore, the property $P$ still holds.  Thus, $P$ is preserved.

Note that $P$ holds for the start state by definition.
However, the $P$ cannot hold when all black cards are in the
top half of the deck; in that case, every black card is opposite a red
card.  Therefore, by the Invariant Theorem, that state is not
reachable.
\end{solution}

\end{problemparts}

Note: Discovering a suitable invariant can be difficult!  The standard
approach is to identify a bunch of reachable states and then look for
a pattern, some feature that they all share.\footnote{If this does not
work, consider twitching and drooling until someone takes the problem
away.}

\end{problem}

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps6}
  \pcomment{from: F07.ps6 (revised)}
\end{pcomments}

\pkeywords{
  bipartite_matching
  Halls_Theorem
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}

  Take a regular deck of $52$ cards.  Each card has a suit and a
  value. The suit is one of four possibilities: heart, diamond, club,
  spade. The value is one of $13$ possibilities, $A, 2, 3, \dots, 10,
  J, Q, K$.  There is exactly one card for each of the $4 \times
  13$ possible combinations of suit and value.

  Ask your friend to lay the cards out into a grid with 4 rows and 13
  columns.  They can fill the cards in any way they'd like.  In this 
  problem you will show that you can always pick out 13 cards, one 
  from each column of the grid, so that you wind up with cards of all 
  13 possible values.

  \bparts

  \ppart Explain how to model this trick as a bipartite matching 
  problem between the 13 column vertices and the 13 value vertices.  
  Is the graph necessarily degree constrained?

  \begin{solution}
Create a simple bipartite graph with 13 column vertices and
  13 value vertices.  Connect a column to a value by a single edge iff
  a card with that value is contained in that column.  A perfect 
  matching would then indicate the value of the card you would choose
  from each column.

  The graph may not be degree constrained if any one of the columns
  contains more than one card with the same value.  In the case where 
  the matching indicates a value that appears more than once in the 
  column it is matched to, you can arbitrarily pick any card of that 
  value in that column.
\end{solution}

  \ppart Show that any $n$ columns must contain at least $n$ different
  values and prove that a matching must exist.

  \begin{solution}
If $S$ is a set of columns, they contain $4|S|$ cards.  No
  card value repeats more than four times, so at least $|S|$ values
  must appear among those cards.  Thus $|N(S)| \geq |S|$ and Hall's
  theorem gives us a matching.
\end{solution}

\eparts

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%PS_composition-of-jections.tex

\begin{pcomments}
  \pcomment{from: S09 ln3 notesproblem;
            mostly subsumed by CP_surj_relation}
\end{pcomments}

\pkeywords{
composition
surjection
bijection
inverse}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
  Let $f:A \to B$ and $g: B \to C$ be functions and $h:A \to C$ be their
  composition, namely, $h(a) \eqdef g(f(a))$ for all $a \in A$.
\bparts
  \ppart Prove that if $f$ and $g$ are surjections, then so is $h$.

  \ppart Prove that if $f$ and $g$ are bijections, then so is $h$.

  \ppart If $f$ is a bijection, then define $f':B \to A$ so that
  \[
  f'(b) \eqdef\text{ the unique } a \in A \text{ such that } f(a)=b.
  \]
  Prove that $f'$ is a bijection.  (The function $f'$ is called the
  \emph{inverse} of $f$.  The notation $f^{-1}$ is often used for the
  inverse of $f$.)
\eparts

\begin{solution}
TBA
\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps8}
  \pcomment{from: S04.ps7}
\end{pcomments}

\pkeywords{
  Eulers_theorem
  number_theory
  modular_arithmetic
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Find an integer $k > 1$ such that $n$ and $n^k$ agree in their last three
digits whenever $n$ is divisible by neither 2 nor 5.

\begin{solution}
Two numbers agree in their last three digits iff they are congruent
  modulo 1000.  So we must find a $k > 1$ such that
\[
n \equiv n^k \pmod{1000}
\]
for all $n$ not divisible by 2 or 5 --that is, for all $n$ relatively prime to
1000.  But by Euler's theorem, we know $k = \phi(1000)+1$ will work, namely,
\[
k = \phi(1000)+1 = \phi(2^3)\phi(5^3) +1 = 4\cdot 100 + 1 = 401.
\]

\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps8}
  \pcomment{S08.ps7}
\end{pcomments}

\pkeywords{
  primes
  number_theory
  Eulers_theorem
  modular_arithmetic
  bijections
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
  Suppose $m,n$ are relatively prime.  In the problem you will prove the
  key property of Euler's function that $\phi(mn)=\phi(m)\phi(n)$.

\bparts

\ppart Prove that for any $a,b$, there is an
$x$ such that
\begin{align}
x & \equiv a \pmod{m}, \label{xa}\\
x & \equiv b \pmod{n}. \label{xb}
\end{align}

\hint Congruence~\eqref{xa} holds iff
\begin{equation}\label{xj}
x = jm + a.
\end{equation}
for some $j$.  So there is such an $x$ only if
\begin{equation}\label{jn}
j m +a \equiv b \pmod{n}.
\end{equation}
Solve~\eqref{jn} for $j$.

\begin{solution}
\begin{proof}
\footnote{Adapted from
\href{http://www.cut-the-knot.org/blue/chinese.shtml}{\texttt{http://www.cut-the
-knot.org/blue/chinese.shtml}}.}
Since $m,n$ are relatively prime, there is an inverse, $m'$, modulo $n$ of
$m$.  So $j = m'(b-a)$ satisfies~\eqref{jn}.  Now~\eqref{xj} leads to the
definition
\[
x_1 \eqdef m'(b-a)m + a.
\]
So
\[
x_1 = (m'(b-a))m + a \equiv a \pmod{m},
\]
and
\[
x_1 = m'(b-a)m + a = m'm(b-a) +a \equiv 1\cdot(b-a) + a \equiv b \pmod{n},
\]
proving that $x_1$ satisfies the congruences~\eqref{xa} and~\eqref{xb}.
\end{proof}
\end{solution}

\ppart\label{x0} Prove that there is an $x$ satisfying the
congruences~\eqref{xa} and~\eqref{xb} such that $0 \leq x < mn$.

\begin{solution}
Let
\[
x_0 \eqdef \rem{x_1}{mn},
\]
where $x_1$ satisfies~\eqref{xa} and~\eqref{xb}.

Now $0 \leq x_0 < mn$ by definition of remainder.  Further, we know $x_0
\equiv x_1 \pmod{mn}$, which immediately implies that $x_0 \equiv x_1 \pmod{m}$
and $x_0 \equiv x_1 \pmod{n}$.  So $x_0$ also satisifies~\eqref{xa}
and~\eqref{xb}, and is therefore the desired solution.

\end{solution}

\ppart\label{uniq} Prove that the $x$ satisfying part~\eqref{x0} is unique.

\begin{solution}
Assume $x_0,y$ both satisfy congruences~\eqref{xa}
and~\eqref{xb}.  Taking the differences we see that
\[
x_0 - y \equiv 0 \pmod{m} \text{  and  } x_0 - y \equiv 0 \pmod{n}.
\]
So by definition, both $m$ and $n$ divide $x_0 - y$, and since $m$ and
$n$ are relatively prime, this implies $mn \divides (x_0 - y)$.  But
if $x_0$ and $y$ are both in the range $0$ to $mn-1$, then $mn >
\card{x_0 - y}$, so it must be that $y = x_0$, as required.
\end{solution}

\ppart For an integer $k$, let $k^*$ be the integers between $1$ and
$k-1$ that are relatively prime to $k$.  Conclude from part~(c) that
the function
\[
f: (mn)^* \rightarrow m^* \times n^*
\]
defined by
\[
f(x) \eqdef (\rem{x}{m},\rem{x}{n})
\]
is a bijection.

\begin{solution}
For any positive integer, $k$, let
\[
[0,k) \eqdef \set{0,1,\dots, k-1}.
\]
By part~\eqref{uniq}, the mapping from $x$ to
$(\rem{x}{m},\rem{x}{n})$ is a bijection between $[0,mn)$ and $[0,m)
\cross [0,n)$.  Moreover, since $x$ is relatively prime to $mn$ iff
$x$ is relatively prime to $m$ and $x$ is relatively prime to $n$,
this mapping also defines a bijection between the integers in $[0,mn)$
that are relatively prime to $mn$ and the pairs of integers in $[0,m)
\cross [0,n)$ that are relatively prime to $m$ and $n$, respectively.

\end{solution}

\ppart Conclude from the preceding parts of this problem
that
\[
\phi(mn)=\phi(m)\phi(n).
\]

\begin{solution}
The mapping $f$ defines a bijection between numbers
  integers in $[0,mn)$ that are relatively prime to $mn$ and the pairs
  of integers in $[0,m) \cross [0,n)$ that are relatively prime to $m$
  and $n$, respectively.  In particular the number, $\phi(mn)$ of
  numbers in $[0,mn)$ that are relatively prime to $mn$ is the same as
  the number $\phi(m)\phi(n)$ of pairs of integers in $[0,m) \cross
  [0,n)$ whose first coordinate is relatively prime to $m$ and whose
  second coordinate is relatively prime to $n$.  
\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: F07.ps4}
\end{pcomments}

\pkeywords{
  state_machines
  termination
  partial_correctness
  invariant
  division
  algorithm
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
In the late 1960s, the military junta that ousted the government of the
small republic of Nerdia completely outlawed built-in multiplication
operations, and also forbade division by any number other than $3$.
Fortunately, a young dissident found a way to help the population multiply
any two nonnegative integers without risking persecution by the junta.  The
procedure he taught people is:

%\instatements{\newpage}
\begin{tabbing}
XXX\=XXX\=XXX\=XXX\kill
{\bf procedure} {\it multiply}$(x, y$: nonnegative integers$)$ \\
$r:=x$; \\
$s:=y$; \\
$a:=0$;\\
\textbf{while} $s \neq 0$ \textbf{do} \\
   \>{\bf if} $3 \divides s$ {\bf then} \\
   \>\>   $r := r+r+r$; \\
   \>\>   $s := s / 3$;\\
   \>{\bf else if} $3 \divides (s-1)$ {\bf then} \\
   \>\>   $a := a + r$; \\
   \>\>   $r := r+r+r$; \\
   \>\>   $s := (s - 1) / 3$; \\
   \>{\bf else} \\
   \>\>   $a := a + r+ r$; \\
   \>\>   $r := r+r+r$; \\
   \>\>   $s := (s - 2) / 3$; \\
{\bf return} $a$; \\
\end{tabbing}

We can model the algorithm as a state machine whose states are triples of
nonnegative integers $(r,s,a)$.  The initial state is $(x,y,0)$.  The
transitions are given by the rule that for $s>0$:
\[
(r,s,a)\rightarrow\begin{cases}
        (3r,s/3,a) &\text{ if } 3 \divides s\\
        (3r,(s-1)/3,a+r) &\text{ if } 3 \divides (s-1)\\
        (3r,(s-2)/3,a+2r) &\text{otherwise}.
       \end{cases}
\]

\iffalse
\begin{solution}

\medskip
\textbf{Solution:}
\begin{description}
\item $Q=\{(r,s,a,x, n) | r,s,a,x, n\in \mathbb{N}\}$
\item $Q_0=\{(x, n,0,x, n)\}$
\item $\delta: (r,s,a,x, n)\rightarrow (3r,s',a',x, n)$, where \\
If $s \equiv 0 \pmod{3}$: $s'=s/3$, and $a'=a$ \\
If $s \equiv 1 \pmod{3}$: $s'=(s-1)/3$, and $a'=a+r$\\
If $s \equiv 2 \pmod{3}$: $s'=(s-2)/3$, and $a'=a+2r$
\end{description}
\end{solution}
\fi

\bparts

\ppart
List the sequence of steps that appears in the execution of the
algorithm for inputs $x = 5$ and $y = 10$.

\begin{solution}
$(5, 10, 0) \\movesto
(15, 3, 5) \\movesto
(45 ,1, 5) \\movesto
(135, 0, 50)$
\end{solution}

\ppart Use the Invariant Method to prove that the algorithm is partially
correct ---that is, if $s = 0$, then $a = xy$.

\begin{solution}
Let
\[
P((r,s,a)) \eqdef\quad [rs+a = xy].
\]

Clearly, $P$ holds for the start state because
\[
P((x,y,0)) \qiff [xy+0 = xy].
\]

Now, we show that $P$ is indeed a preserved invariant, namely, assuming
$P((r,s,a))$,
\begin{equation}\label{inv}
rs+a = xy,
\end{equation}
holds and $(r,s,a) \to (r',s',a')$ is a transition, then $P((a',b',p'))$,
\begin{equation}\label{inv'}
r's'+a' = xy,
\end{equation}
holds.

We consider three cases:

If $3 \divides s$, then we have that $r' = 3r, s' = s/3, a'=a$.
Therefore,
\begin{align*}
  r's' + a' = & 3r \cdot \frac{s}{3} + a\\
            = & rs+a\\
            = & xy & \text{(by~\eqref{inv})}.
\end{align*}

If $3 \divides s-1$, then $r' = 3r, s' = (s-1)/3,a = a+r$.  So:
\begin{align*}
  r's' + a'  = & 3r \cdot \frac{s-1}{3} + a+r\\
   = & r\cdot(s-1) + a + r\\
   = & rs+a\\
   = & xy & \text{(by~\eqref{inv})}.
\end{align*}

Otherwise, we have $r' = 3r, s' = (s-2)/3,a = a+2r$.  So:
\begin{align*}
  r's' + a'  = & 3r \cdot \frac{s-2}{3} + a+2r\\
   = & r\cdot(s-2) + a + 2r\\
   = & rs+a\\
   = & xy & \text{(by~\eqref{inv})}.
\end{align*}

So in all three cases,~\eqref{inv'} holds, proving that $P$ is indeed a
preserved invariant.

Since the procedure's only termination condition is that $s=0$,
partial correctness will follow if we can show that if $s=0$, then $a=xy$.
But this follows immediately from~\eqref{inv}.
\end{solution}

\ppart
Prove that the algorithm terminates after at most $1+ \log_3 y$ executions
of the body of the \texttt{do} statement.

\begin{solution}
We first notice that $s \in \naturals$ is a preserved invariant.
  Also, each transition corresponds to an execution of the \texttt{do}
  statement body, and each transition reduces $s$ to at most $s/3$.
  Hence, after at most $1+ \log_3 y$ executions of the body, the value of
  $s$ is at most its initial value, $y$, times $\paren{1/3}^{1+ \log_3 y}
  = 1/3y$.  That is, the value of $s$ will at most 1/3.  Since $s \in
  \naturals$, it follows that $s$ will be 0 after this many executions of
  the body, if it wasn't 0 earlier.  But with $s=0$, the procedure
  terminates.
\end{solution}

\eparts
\end{problem}

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps1}
\end{pcomments}

\pkeywords{
  quantifiers
  predicate_calculus
  domain_of_discourse
  translating_english_statements
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Translate the following sentence into a predicate formula:
\begin{quote}
There is a student who has emailed exactly two other people in the class,
besides possibly herself.
\end{quote}

The domain of discourse should be the set of students in the class; in
addition, the only predicates that you may use are 
\begin{itemize}
\item equality, and
\item $E(x,y)$, meaning that ``$x$ has sent e-mail to $y$.''
\end{itemize}

\begin{solution}

A good way to begin tackling this problem is by working
``top-down'' to translate the successive parts of the sentence.  First of
all, our formula must be of the form
\[
\exists x. P(x)
\]
where $P(x)$ should be a formula that says that ``student $x$ has
e-mailed  exactly two other people in the class, besides possibly
herself''.

One way to write $P(x)$ is to give names, say $y$ and $z$, to the two
students whom $x$ has emailed.  So we translate $P(x)$ as ``besides $x$,
there are two students, $y$ and $z$, and \dots'':
\[
\exists y,z.\ x \neq y \land x \neq z \land y \neq z \land \dots
\]
``$x$ has emailed both $y$ and $z$, and \dots'':
\[
E(x,y) \land E(x,z) \land \dots
\]
``if $x$ has emailed somebody, it's either $x$, $y$, or $z$.'':
\[
\forall s.\ E(x,s) \implies (s=x \lor s=y \lor s=z).
\]
Putting these together, we get:
\[\begin{array}{rll}
P(x)  \eqdef &\quad \exists y,z. & x \neq y \land x \neq z \land y \neq z\ \land\\
             &   & E(x,y) \land E(x,z)\ \land\\
             &   & [\forall s. E(x,s)  \implies (s=x \lor s=y \lor s=z)]
\end{array}\]
\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps1}
  \pcomment{incomplete solution to part (b)}
\end{pcomments}

\pkeywords{
  logic
  truth_tables
  boolean
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
\bparts
\ppart Verify that $(P \xor Q)$ is equivalent to $\neg(P \iff Q)$.

\begin{solution}
\[
\begin{array}{|c|c|c|}
\hline
\text{(}P & \xor  & Q\text{)}\\ \hline
\true     &\false      & \true    \\ \hline
\true     &\true       & \false   \\ \hline
\false    &\true       & \true    \\ \hline
\false    &\false      & \false   \\ \hline
\end{array}
\]

\[
\begin{array}{|c|ccc|}
\hline
\neg   &\text{(}P & \iff  & Q\text{)}\\ \hline
\false &\true     &\true  & \true    \\ \hline
\true  &\true     &\false & \false   \\ \hline
\true  &\false    &\false & \true    \\ \hline
\false &\false    &\true  & \false   \\ \hline
\end{array}
\]
\end{solution}

\ppart Verify that $P \Or Q \Or R$ is equivalent to
\[
(P \And \bar{Q}) \Or (Q \And \bar{R}) \Or (R \And \bar{P}) \Or (P \And Q \And R).
\]

\begin{solution}
TBA

The following table from cp2m might be useful to edit from:
\[
\begin{array}{|ccc|c|ccc|}
\hline
\text{[(}A  & \text{OR} & B\text{)} & \text{AND} & \text{(}A & \text{OR} & C\text{)]} \\  \hline
     \true  & \true     & \true     & \true      &   \true   & \true     & \true \\  \hline
     \true  & \true     & \true     & \true      &   \true   & \true     & \false\\  \hline
     \true  & \true     & \false    & \true      &   \true   & \true     & \true \\  \hline
     \true  & \true     & \false    & \true      &   \true   & \true     & \false\\  \hline
     \false & \true     & \true     & \true      &   \false  & \true     & \true \\  \hline
     \false & \true     & \true     & \false     &   \false  & \false    & \false\\  \hline
     \false & \false    & \false    & \false     &   \false  & \true     & \true \\  \hline
     \false & \false    & \false    & \false     &   \false  & \false    & \false\\  \hline
\end{array}
\]
\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: F03.ps2}
\end{pcomments}

\pkeywords{
  equivalence_relations
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}

Let $R_1$ and $R_2$ be two equivalence relations on a set, $A$.  Which of
the following relations must also be equivalence relations?  Prove it.

\begin{problemparts}

\problempart
$R_1 \intersect R_2$

\begin{solution}
Let $R \eqdef R_1 \intersect R_2$.  We give two proofs that $R$ is an
equivalence relation using different characterizations of equivalence
relations.

\begin{proof}
We first prove that $R$ is an equivalence relations by showing that $R$ is
reflexive, symmetric, and transitive.

\emph{Reflexive:} $R_i$ is reflexive because it is an equivalence
relation, for $i=1,2$.  So $(a,a) \in R_i$ for $i=1,2$ and all $a \in A$.
So, $(a,a) \in (R_1 \intersect R_2) = R$ for all $a \in A$, that is, $R$
is reflexive.

\emph{Transitive:} Suppose $(a,b), (b,c) \in R$.  Since $R = R_1
\intersect R_2$, we have $(a,b), (b,c) \in R_i$ for $i=1,2$.  But $R_i$ is
an equivalence relation, and so is transitive.  Therefore, $(a,c) \in
R_i$, and so $(a,c) \in R_1\intersect R_2 = R$.  This shows that $R$ is
transitive.

\emph{Symmetric:} The proof that $R$ is symmetric follows the same format.

\end{proof}

\begin{proof}
Since $R_i$ is an equivalence relation for $i=1,2$, there is by
definition a total function, $f_i$, with domain, $A$, such that
\[
aR_i b \quad\text{ iff }\quad f_i(a) = f_i(b).
\]
Define the function, $f$, with domain, $A$, by
\[
f(a) \eqdef (f_1(a),f_2(a)).
\]
Clearly $f$ is total, since $f_i$ is total for $i=1,2$.  Now we have,
\begin{align*}
aRb \quad &  \text{ iff }\quad a(R_1 \intersect R_2)b & \text{def.\ of $R$}\\
    &  \text{ iff }\quad aR_ib\text{ for }i=1,2 & \text{def.\ of $\intersect$}\\
    &  \text{ iff }\quad f_i(a)=f_i(b) \text{ for }i=1,2 & \text{def.\ of $f_i$}\\
    &  \text{ iff }\quad (f_1(a),f_2(a)) = (f_1(b),f_2(b)) & \text{def.\ of $=$ pairs}\\
    &  \text{ iff }\quad f(a) = f(b) & \text{def.\ of $f$}.
\end{align*}
That is
\[
aRb \quad \text{ iff }\quad f(a) = f(b),
\]
which proves that $R$ is the equivalence relation $\equiv_f$.
\end{proof}
\end{solution}


\problempart
$R_1 \cup R_2$ 

\begin{solution}
We give a counterexample showing that $R_1 \cup R_2$ may not be
an equivalence relation.  Let $R_1$ and $R_2$ be the relations on
$\set{1, 2, 3}$ where
\begin{align*}
R_1 \eqdef & \set{(1,1) (2,2) (3,3) (1,2) (2,1)},\\
R_2 \eqdef & \set{(1,1) (2,2) (3,3) (2,3) (3,2)}.
\end{align*}
It's easy to check that $R_1$ and $R_2$ are both equivalence relations.
But $R_1\cup R_2$ is not transitive, because $(1,2),(2,3) \in R_1\cup R_2$
and $(1,3) \notin R_1\cup R_2$.  Therefore $R_1\cup R_2$ is not an
equivalence relation.
\end{solution}

\end{problemparts}

\end{problem}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps1}
\end{pcomments}

\pkeywords{
  logic
  predicate_calculus
  domain_of_discourse
  translating_english_statements
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Express each of the following predicates and propositions in formal
logic notation.  The domain of discourse is the nonnegative integers,
$\naturals$.  Moreover, in addition to the propositional operators,
variables and quantifiers, you may define predicates using addition,
multiplication, and equality symbols, but no \emph{constants} (like 0,
1,\dots) and no \emph{exponentiation} (like $x^y$).  For example, the
proposition ``n is an even number'' could be written
\[
\exists m.\; (m + m = n).
\]

\bparts
\ppart 
$n$ is the sum of two fourth-powers (a fourth-power is $k^4$ for some
integer $k$).

\begin{solution}
\[
\exists x \exists y.\;
(x \cdot x \cdot x \cdot x + y \cdot y \cdot y \cdot y = n)
\]
\end{solution}
\eparts

Since the constant 0 is not allowed to appear explicitly, the predicate
``$x = 0$'' can't be written directly, but note that it could be expressed
in a simple way as:
\[
x + x = x.
\]
Then the predicate $x > y$ could be expressed
\[
\exists w.\; (y + w = x) \land (w \neq 0).
\]
Note that we've used ``$w \neq 0$'' in this formula, even though it's
technically not allowed.  But since ``$w \neq 0$'' is equivalent to the
allowed formula ``$\neg(w+w= w)$,'' we can use ``$w \neq 0$'' with the
understanding that it abbreviates the real thing.  And now that we've shown
how to express ``$x>y$,'' it's ok to use it too.

\bparts
\ppart $x = 1$.

\begin{solution}
One formula is $\forall y.\; xy=y$.  Another is $(x \cdot x = x) \conj (x
\neq 0)$.
\end{solution}

\ppart $m$ is a divisor of $n$ (notation: $m \divides n$)

\begin{solution}\[
m \divides n 
\eqdef\quad 
\exists k.\; k \cdot m = n
\]
\end{solution}

\ppart 
$n$ is a prime number (hint: use the predicates from the previous parts)

\begin{solution}
\[
\CMD{IsPrime}(n)
\eqdef\quad 
(n\neq 1) 
\;\;\conj\;\;
\forall m.\; (m \divides n) \implies (m=1 \disj m=n).
\]
Note that the requirement $n\neq 1$ is necessary, or else our
predicate would be satisfied by 1, which is not considered to be a
prime number. Also note that $n\neq 1$ is given here as an
abbreviation of the formula $\neg(n=1)$; and thus of $\neg\forall y.yn=n$.

If we don't want to use the divisor predicate, we can write:
\[
\CMD{IsPrime}(n) 
\eqdef\quad 
(n > 1) 
\;\;\conj\;\;
\neg\bigl(
\exists x 
\exists y.\; 
(x > 1) \conj 
(y > 1) \conj 
(x \cdot y = n)
\bigr).
\]
Do you agree this formula is also correct?  If so, note that the formulas
$n>1$, $x>1$ and $y>1$ are not allowed.  Can you express them in terms of
allowed formulas?
\end{solution}

\ppart $n$ is a power of 3.

\begin{solution}
We can simply say that $n \neq 0$ and the only prime divisor of $n$ is 3:
\[
n \neq 0 \land \forall m.\; (\CMD{IsPrime}(m) \land m \divides n) \implies m=3.
\]
Still, $m=3$ is not allowed, so we have to express it in terms of
allowed formulas. Here is one way to do this:
\[
m=3
\eqdef\quad
\exists z.
z=1
\;\conj\;
m= z + z + z
\]
\end{solution}
\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%PS_express_predicates_in_formal_logic_notation

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S06.ps1}
\end{pcomments}

\pkeywords{
  predicates
  propositional_logic
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\isprime}{\text{\sc{is-prime}}}

\begin{problem}
Express each of the following predicates and propositions in formal
logic notation.  The domain of discourse is the nonnegative integers,
$\naturals$. Moreover, in addition to the propositional operators,
variables and quantifiers, you may define predicates using addition,
multiplication, and equality symbols, but no \emph{constants} (like 0,
1,\dots) and no \emph{exponentiation} (like $x^y$).  For example, the
proposition ``n is an even number'' could be written
\[
\exists m.\; (m + m = n).
\]

\begin{problemparts}
\problempart 
$n$ is the sum of two cubes (a cube is a number equal to $k^3$ for some
integer $k$).

\begin{solution}
\[
\exists x \exists y.\; (x \cdot x \cdot x + y \cdot y \cdot y = n)
\]

Since the constant 0 is not allowed to appear explicitly, the predicate
``$x = 0$'' can't be written directly, but note that it could be expressed
in a simple way as:
\[
x + x = x.
\]
Then the predicate $x > y$ could be expressed
\[
\exists w.\; (y + w = x) \land (w \neq 0).
\]
Note that we've used ``$w \neq 0$'' in this formula, even though it's
technically not allowed.  But since ``$w \neq 0$'' is equivalent to the
allowed formula ``$\neg(w+w= w)$,'' we can use ``$w \neq 0$'' with the
understanding that it abbreviates the real thing.  And now that we've shown
how to express ``$x>y$,'' it's ok to use it too.
\end{solution}

\problempart $x = 1$.

\begin{solution}
One formula is $\forall y.\; xy=y$.  Another is $(x \cdot x = x) \conj (x
\neq 0)$.
\end{solution}

\ppart $m$ is a divisor of $n$ (notation: $m \divides n$)

\begin{solution}
\[
m \divides n 
\eqdef\quad 
\exists k.\; k \cdot m = n
\]
\end{solution}

\problempart 
$n$ is a prime number (hint: use the predicates from the previous parts)

\begin{solution}
\[
\isprime(n)
\eqdef\quad 
(n\neq 1) 
\;\;\conj\;\;
\forall m.\; (m \divides n) \implies (m=1 \disj m=n).
\]
Note that the requirement $n\neq 1$ is necessary, or else our
predicate would be satisfied by 1, which is not considered to be a
prime number. Also note that $n\neq 1$ is given here as an
abbreviation of the formula $\neg(n=1)$; and thus of $\neg\forall y.yn=n$.

If we don't want to use the divisor predicate, we can write:
\[
\isprime(n) 
\eqdef\quad 
(n\neq 1) 
\;\;\conj\;\;
\neg\bigl(
\exists x 
\exists y.\; 
(x > 1) \conj 
(y > 1) \conj 
(x \cdot y = n)
\bigr).
\]
Do you agree this formula is also correct? If so, note that the
formulas $x>1$ and $y>1$ are not allowed. Can you express them in
terms of allowed formulas?  
\end{solution}

\problempart 
$n$ is a power of 2.

\begin{solution}
We can simply say that the only prime divisor of $n$ is 2:
\[
\forall m.\; (m \divides n \QAND \isprime(m)) \QIMPLIES 2 \divides m.
\]
Still, the constant $2$ is not allowed, so we have to express it in terms
of allowed formulas.  Here is one way to do this:
\[
m=2
\eqdef\quad
\exists z.
z=1
\;\conj\;
m= z + z
\]
\end{solution}

\end{problemparts}
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: F09.ps2}
  \pcomment{from: S09.ps1}
  \pcomment{from: F07.ps1}
  \pcomment{from: F05}
  \pcomment{commented out in S09}
\end{pcomments}

\pkeywords{
  set_theory
  false_proof
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}

\bparts
\ppart Give an example where the following result fails:

\begin{falsethm*}
For sets $A$, $B$, $C$, and $D$, let
\begin{align*}
L \eqdef (A \union B) \times (C \union D),\\
R \eqdef (A \times C) \union (B \times D).
\end{align*}
Then $L=R$.
\end{falsethm*}

\begin{solution}
If $A=D=\emptyset$ and $B$ and $C$ are both nonempty, then $L = B \times C
\neq \emptyset$, but $R = \emptyset$.
\end{solution}

\ppart Identify the mistake in the following proof of the False Theorem.

\begin{bogusproof}
Since $L$ and $R$ are both sets of pairs, it's sufficient to prove that
$(x,y) \in L \iff (x,y) \in R$ for all $x,y$.

The proof will be a chain of iff implications:
\begin{center}
\begin{tabular}{ll}
    & $(x, y) \in R$  \\
iff & $(x,y) \in (A \times C) \union (B \times D) $ \\
iff & $(x,y) \in A \times C$, or $(x,y) \in B \times D$ \\
iff & ($x \in A$ and $y \in C$) or else ($x \in B$ and $y \in D$)  \\
iff & either $x \in A$ or $x \in B$, and either $y \in C$ or $y \in D$ \\
iff & $x \in A \union B$ and $y \in C \union D$ \\
iff & $(x,y) \in L$.
\end{tabular}
\end{center}

\end{bogusproof}

\begin{solution}
The mistake is in the fourth ``iff.''  If [$x \in A$ or $x \in
B$, and either $y \in C$ or $y \in D$], it does not necessarily follow
that [($x \in A$ and $y \in C$) or else ($x \in B$ and $y \in D$)].  It might be that
$(x,y)$ is in $A \times D$ instead.  This happens, for example, if $A =
\set{1}, B = \set{2}, C = \set{3}, D = \set{4}$, and $(x,y) = (1, 4)$.
\end{solution}

\ppart Fix the proof to show that $R \subseteq L$.

\begin{solution}
Replacing the fourth ``iff'' with ``implies that'' yields a
correct proof that $(x,y) \in R$ leads to $(x,y) \in L$, which
implies that $R \subseteq L$.
\end{solution}

\eparts

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
%PS_faster_adder_logic

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp2m}
  \pcomment{skipped in S09 (maybe commented out because it doesn't appear in .pdf)}
\end{pcomments}

\pkeywords{
  binary
  logic
  circuits
  boolean
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Considerably faster adder circuits work by computing the values in later
columns for both a carry of 0 and a carry of 1, \emph{in parallel}.  Then,
when the carry from the earlier columns finally arrives, the pre-computed
answer can be quickly selected.  We'll illustrate this idea by working out
the equations for an $n+1$-bit parallel half-adder.

Parallel half-adders are built out of parallel ``add1'' modules.  An
$n+1$-bit add1 module takes as input the $n+1$-bit binary representation,
$a_n \dots a_1 a_0$, of an integer, $s$, and produces as output the binary
representation, $c\,p_n\dots p_1\,p_0$, of $s+1$.

\bparts

\ppart A 1-bit add1 module just has input $a_0$.  Write propositional
formulas for its outputs $c$ and $p_0$.

\begin{solution}
\begin{align}
p_0 & = a_0\ \QXOR\ 1 = \QNOT(a_0)\\
c & = a_0.
\end{align}
\end{solution}

\ppart Explain how to build an $n+1$-bit parallel half-adder from an
$n+1$-bit add1 module by writing a propositional formula for the
half-adder output, $o_i$, using only the variables $a_i$, $p_i$, and $b$.

\begin{solution}
\[
o_i  = (b\ \QAND\ p_i)\ \QOR\ (\QNOT(b)\ \QAND\ a_i)
\]
\end{solution}

\eparts

We can build a double-size add1 module with $2(n+1)$ inputs using two
single-size add1 modules with $n+1$ inputs.  Suppose the inputs of the
double-size module are $a_{2n+1},\dots, a_1, a_0$ and the outputs are
$c,p_{2n+1},\dots, p_1,p_0$.  The setup is illustrated in
Figure~\ref{fig:add1}.

Namely, the first single size add1 module handles the first $n+1$ inputs.
The inputs to this module are the low-order $n+1$ input bits $a_n,\dots,
a_1, a_0$, and its outputs will serve as the first $n+1$ outputs $p_n,
\dots, p_1, p_0$ of the double-size module.  Let $c_{(1)}$ be the
remaining carry output from this module.

The inputs to the second single-size module are the higher-order $n+1$
input bits $a_{2n+1}, \dots, a_{n+2}, a_{n+1}$.  Call its first $n+1$
outputs $r_n, \dots, r_1, r_0$ and let $c_{(2)}$ be its carry.

\bparts

\ppart Write a formula for the carry, $c$, in terms of $c_{(1)}$ and
$c_{(2)}$.

\begin{solution}
\[
c = c_{(1)}\ \QAND\ c_{(2)}.
\]
\end{solution}

\ppart Complete the specification of the double-size module by writing
propositional formulas for the remaining outputs, $p_i$, for $n+1 \leq i
\leq 2n+1$.  The formula for $p_i$ should only involve the variables
$a_i$, $r_{i-(n+1)}$, and $c_{(1)}$.

\begin{solution}
  The $n+1$ high-order outputs of the double-size module are the
  same as the inputs if there is no carry from the low-order $n+1$
  outputs, and otherwise is the same as the outputs of the second
  single-size add1 module.  So
\begin{equation}\label{parallel-pi}
p_i = (\QNOT(c_{(1)})\ \QAND\ a_i)\ \QOR\ (c_{(1)}\ \QAND\ r_{i-(n+1)}).
\end{equation}
for $n+1 \leq i \leq 2n+1$.
\end{solution}

\ppart Parallel half-adders are exponentially faster than ripple-carry
half-adders.  Confirm this by determining the largest number of
propositional operations required to compute any one output bit of an
$n$-bit add module.  (You may assume $n$ is a power of 2.)

\begin{solution} 
  The most operations for an output are those specified in
  formula~\eqref{parallel-pi}.  So it takes at most 4 additional
  operations to get any one double-size output bit from the single-size
  output bits that it depends on.  It takes $\log_2 n$ doublings to get to
  from 1-bit to $n$-bit modules, so the largest number of operations
  needed for any one output bit is $4 \log_2 n$.

This observation also shows that the \emph{total} number of operations
used in the parallel adder to calculate \emph{all} the output digits is
propositional to $ n \log_2 n$.  This is larger than the total for a
ripple-carry adder by a factor proportional to $\log_2 n$.
\end{solution}

\eparts

\begin{figure}[htbp]
%\centering \includegraphics[height=2.3in]{figures/loveTriangle.pdf}
%\includegraphics{figures/add1-circuit-diagram.pdf}
\includegraphics[height=7in]{figures/add1-circuit-diagram.pdf}
\caption{Structure of a Double-size Add1 Module.}
\label{fig:add1}
\end{figure}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: F02.ps5}
\end{pcomments}

\pkeywords{
	state_machines
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
You are given two buckets, $A$ and $B$, a water hose, a receptacle, and a
drain.  The buckets and receptacle are initially empty.  The buckets are
labeled with their respectively capacities, positive integers $a$ and $b$.
The receptacle can be used to store an unlimited amount of water, but has
no measurement markings.  Excess water can be dumped into the drain.
Among the possible moves are:

\begin{enumerate}

\item\label{hose-bucket} fill a bucket from the hose,

\item pour from the receptacle to a bucket until the bucket is full
or the receptacle is empty, whichever happens first,

\item empty a bucket to the drain,

\item\label{bucket-receptacle} empty a bucket to the receptacle,

\item pour from $A$ to $B$ until either $A$ is empty or $B$ is full,
whichever happens first,

\item pour from $B$ to $A$ until either $B$ is empty or $A$ is full,
whichever happens first.

\end{enumerate}

\bparts

\ppart
Model this scenario with a state machine.  (What are the states?  How does
a state change in response to a move?)

\begin{solution}
The states are triples $(x,y,z)$ which give the current amount of
water in the bucket $A$, bucket $B$, and the receptacle, respectively.
The initial state is $(0,0,0)$.

The moves make the following transitions:
\begin{enumerate}
\item fill a bucket from the hose
\[
(x,y,z) \rightarrow \left \{ \begin{array}{l}
(a,y,z) \mbox{ if filling A from the hose } \\
(x,b,z) \mbox{ if filling B from the hose }
\end{array} \right.
\]

\item pour from the receptacle to a bucket until the bucket is full
or the receptacle is empty, whichever happens first
\[
(x,y,z) \rightarrow \left \{ \begin{array}{l}
(a,y,z-(a-x)) \mbox{ if pouring to A and } z \geq (a-x) \\
(x+z,y,0) \mbox{ if pouring to A and } z < (a-x) \\
(x,b,z-(b-y)) \mbox{ if pouring to B and } z \geq (b-y) \\
(x,y+z,0) \mbox{ if pouring to B and } z < (b-y)
\end{array} \right.
\]

\item empty a bucket to the drain
\[
(x,y,z) \rightarrow \left \{ \begin{array}{l}
(0,y,z) \mbox{ if emptying A to the drain } \\
(x,0,z) \mbox{ if emptying B to the drain }
\end{array} \right.
\]

\item empty a bucket to the receptacle
\[
(x,y,z) \rightarrow \left \{ \begin{array}{l}
(0,y,z+x) \mbox{ if emptying A to the receptacle } \\
(x,0,z+y) \mbox{ if emptying B to the receptacle }
\end{array} \right.
\]

\item pour from $A$ to $B$ until either $A$ is empty or $B$ is full,
whichever happens first
\[
(x,y,z) \rightarrow \left \{ \begin{array}{l}
(0,y+x,z) \mbox{ if } x < (b-y) \\
(x-(b-y),b,z) \mbox{ if } x \geq (b-y)
\end{array} \right.
\]

\item pour from $B$ to $A$ until either $B$ is empty or $A$ is full,
whichever happens first
\[
(x,y,z) \rightarrow \left \{ \begin{array}{l}
(x+y,0,z) \mbox{ if } y < (a-x) \\
(a,y-(a-x),z) \mbox{ if } y \geq (a-x)
\end{array} \right.
\]
\end{enumerate}
\end{solution}

\ppart
\label{gcd-iff}

Prove that we can put $k\in\naturals$ gallons of water into the receptacle
using the above operations if and only if $\gcd(a,b) \mid k $.  \hint Use
the fact that if $a,b$ are positive integers then there exist integers
$s,t$ such that $\gcd(a,b)=sa+tb$ (see Notes~\bref{ExtendedGCD}).

% was (proven Week 5 Notes, \S5.4).

\begin{solution}
We need to prove two facts (the ``iff'' statement has two directions):
\begin{enumerate}
\item
If $\gcd(a,b) \mid k $ then we can put $k$ gallons of water into
the receptacle.

\begin{proof}

Since there exist integers $s,t$ s.t.  $\gcd(a,b)=sa+tb$, then
if $\gcd(a,b) \mid k $ then there exists an integer $n$ s.t. $n
 \gcd(a,b) = k$, and hence $n(sa+tb)=k$.  Assume without loss
of generality that $sa\geq{tb}$ (otherwise exchange the buckets in the
following argument).  Then we can fill the receptacle with $k$ gallons: \\
First, we repeat $ns$ times moves $1$ and $4$, filling the $A$ bucket
and pouring its content into the receptacle (note that if $sa\geq{tb}$
then $s\geq{0}$).  With this series of moves we will get from state
$(0,0,0)$ to $(0,0,nsa)$.  Then, if $t=0$, we are already done since
$k=nsa$.  If $t>0$, we repeat $nt$ times moves $1$ and $4$ but now
using the bucket $B$.  This gets us from $(0,0,nsa)$ to
$(0,0,nsa+ntb)=(0,0,k)$.  If $t<0$ we repeat $n\abs{t}$ times moves $2$
and $3$ using the bucket $B$.  At the end of this series we will be in
state $(0,0,nsa-n(-t)b)=(0,0,nsa+ntb)=(0,0,k)$
\end{proof}

\item
If we can put $k$ gallons of water into the receptacle then
$\gcd(a,b) \mid k $.

\begin{proof}
We show that it is an invariant of our state machine that $\gcd(a,b)$ divides
$x$, $y$ and $z$.  Thus, in particular $z$ is always a multiple of $\gcd(a,b)$.

Let's denote $\gcd(a,b)$ by $c$.  The invariant is true in the
initial state $(0,0,0)$.\footnote{Remember that $(x \divides
y) \qiff (\exists_{b\in\integers}.\, y=xb)$}.  Each move preserves this
invariant, because in each move the new values of $x,y$ or $z$ are
always integer linear combinations of the previous values $x,y,z$ or
$a,b$, that is, they are expressed by a formula
$n_1x+n_2y+n_3z+n_4a+n_5b$ for some
$(n_1,n_2,n_3,n_4,n_5)\in\integers^5$.  For example in move 2, case 1,
the new value of $z$ is expressed by the above formula with
$(n_1,n_2,n_3,n_4,n_5)=(1,0,1,-1,0)$.  Since $c$ divides $a$ and $b$,
if $c$ divides $x,y,z$ before the move, then it divides every such
linear formula, and hence it divides the values of $x,y$ and $z$ after
each move.
\end{proof}

\end{enumerate}

\end{solution}

% \ppart Let's restrict the valid moves to numbers~\ref{hose-bucket}
% and~\ref{bucket-receptacle} only.  Prove that there exists a number
% $n$, such that for all integer $k\geq n$, we can fill the receptacle
% with $k$ gallons of water iff $\gcd(a,b) \mid k$.

% \begin{solution}
% Again, pick $s,t$ s.t. $c=\gcd(a,b)=sa+bt$.  If both
% $s,t\geq{0}$ then $(s,t)=(0,1)$ or $(1,0)$, i.e., $a=b$ (check that in
% all other cases $c$ would be greater than either $a$ or $b$, which is
% impossible).  If $a=b$ then $c=a=b$, and for each $k\geq{c}$, $c\mid
% k$, we can fill the receptacle by repeating moves $1$ and $4$
% ${k}/{c}\in\naturals$ times (with any bucket, since $a=b$).

% Clearly it cannot be that both $s,t\leq0$ (or $c$ would be a
% non-positive integer).  So we are left with two cases: $t<0<s$ or
% $s<0<t$.  Assume without loss of generality that $t<0<s$.

% We show that if $k\geq{n}$ for $n=-t{b^2}/{c}$, and $k$ is a
% multiple of $c$, then we can fill the receptacle with $k$ gallons.
% Let's denote $k$ as a multiple of $b$ plus a ``remainder'' in the
% following way:
% %
% $$ k=k_1b+k_2c\mbox{, where
% }k_1,k_2\in\naturals\,\,\wedge\,\,0\leq{k_2}<\frac{b}{c} $$
% %
% We can represent $k$ in this way since it is divisible by $c$.  Notice
% also, that since $k\geq{-t{b^2}/{c}}$, then
% $k_1\geq{-t{b}/{c}}$.  Since $c=sa+bt$, we can rewrite $k$ as
% follows:
% \begin{eqnarray*}
% k&=&k_1b+k_2c
% \\
% &=&k_1b+k_2(sa+bt)
% \\
% &=&(k_2s)a+(k_1+k_2t)b
% \end{eqnarray*}
% Hence, as long as $k_1\geq{-t{b}/{c}}$, both $(k_2s)$ and $(k_1+k_2t)$
% are non-negative integers.  And hence, we can fill the receptacle by
% $(k_2s)$ times pouring bucket $A$ into it, and then $(k_1+k_2t)$ times
% bucket $B$, both just with moves $1$ and $4$.
% 
% \end{solution}
\eparts
\end{problem}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: F09.ps3}
  \pcomment{from: S02.ps2}
\end{pcomments}

\pkeywords{
  induction
  false_proof
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
  Find the flaw in the following "proof" that $a^n = 1$ for all
  nonnegative integers $n$, whenever $a$ is a nonzero real number.

\begin{proof}
(by induction)

\textbf{Base Case:} $a^0 =1$ is true by definition of $a^0$.

\textbf{Inductive Step:} Assume that $a^k = 1$ for all nonnegative
integers $k$ with $k \leq n$. Then note that
\[
a^{n+1} = \frac{a^n \cdot a^n}{a^{n-1}} = \frac{1 \cdot 1}{1} = 1.
\]
\end{proof}

\begin{solution}
The flaw comes in the inductive step, where we implicitly assume
$n\geq 1$ in order to talk about $a^{n-1}$ in the denominator
(otherwise the exponent is not a nonnegative integer, so we cannot
apply the inductive hypothesis).  We checked the base case only for
$n=0$, so we are not justified in assuming that $n\geq 1$ when we try
to prove the statement for $n+1$ in the inductive step.  Indeed, the
proposition first breaks precisely at $n=1$.
\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps2}
\end{pcomments}

\pkeywords{
  surjections
  injections
  functions
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Let $A$, $B$, and $C$ be nonempty sets, and let $f : B \to C$ and $g : A
\to B$ be functions.  Let $h \eqdef f \compose g$ be the composition
function of $f$ and $g$, namely, the function with domain $A$ and range
$C$ such that $h(x) = f(g(x))$.

\bparts

\ppart Prove that if $h$ is surjective and $f$ is total and injective, 
then $g$ must be surjective.

\hint contradiction.

\begin{solution}
Assume for the purposes of obtaining a contradiction that $h$ is 
  surjective and $f$ is total and injective but that $g$ was not a 
  surjection.

  Then there must exist some $b \in B$ not in the image of $A$ under
  $g$.  By the assumption that $f$ is total and injective, $f(b)$ is
  an element of $C$ and there is no $b^{\prime} \neq b$ in $B$ such that
  $f(b^{\prime}) = f(b)$. Therefore $f(b)$ is not in the range
  of $h$, contradicting the assumption that $h$ is surjective.
\end{solution}

\ppart Suppose that $h$ is injective and $f$ is total.  Prove that $g$ 
must be injective and provide a counterexample showing how this claim could 
fail if $f$ was \emph{not} total.

\begin{solution}
Suppose $g(x) = g(y)$; we need to show $x=y$.  But $f(g(x))$ is defined
  since $f$ is total, so we have
 \[
  h(x) = f(g(x)) = f(g(y)) = h(y).
  \]
  But since $h$ is injective, this implies that $x = y$, as required.
  Therefore, $g$ is injective.

  Suppose now that $f$ was not required to be total.  It is then possible
  that $g$ may not be injective, as demonstrated by the following example:

  Suppose $A = \set{1,2,3},\ B= \set{1,2}$ and $C = \set{1}$.  Let $f(1) =
  1$ and $f$ be undefined at 2.  Let $g(1) = 1$ and $g(2)=g(3) = 2$.  In
  this case $h$ is injective since $h$ is undefined at all but one element
  in $A$, but $g$ is not injective, since $g(2)=g(3)$.

\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{spring07 pset5-1}
\end{pcomments}

\pkeywords{
 graph theory
}

\begin{problem}
This problem generalizes the result proved in Week 5 Notes that any graph
with maximum degree at most $w$ is $(w+1)$-colorable.

A simple graph, $G$, is said to have \hyperdef{psfive}{width}{\term{width}},
$w$, iff its vertices can be arranged in a sequence such that each vertex
is adjacent to at most $w$ vertices that precede it in the sequence.  If
the degree of every vertex is at most $w$, then the graph obviously has
width at most $w$ ---just list the vertices in any order.

\bparts

\ppart Describe an example of a graph with 100 vertices, width 3, but
\emph{average} degree more than 5.  \hint Don't get stuck on this; if you
don't see it after five minutes, ask the staff for a hint.

\begin{solution} The hint is to line up the 100 vertices and have each vertex be
adjacent to the 3 immediately preceding vertices, if any.  By definition
of width, this graph has width 3.  All vertices other than the first three
are now adjacent to three preceding vertices, and all vertices except the
last three are also adjacent to the three following vertices.  So vertices
4 through 97 all have degree 6; this alone ensures that the average degree
is at least $6\cdot 94/100 = 5.76$.
\end{solution}

\ppart Prove that every graph with width at most $w$ is $(w +
1)$-colorable.

\begin{solution} We use induction on $n$, the number of vertices.  Let $P(n)$ be
the proposition that for all $w$, every $n$-vertex graph with width $w$ is
$(w+1)$-colorable.

\textbf{Base case:} ($n=1$) Every graph with $1$ vertex has width 0 and is
$0 + 1 = 1$ colorable.  Therefore, $P(1)$ is true.

\textbf{Inductive step:} Now we assume $P(n)$ in order to prove $P(n+1)$.
Let $G$ be an $(n+1)$-vertex graph with width at most $w$.  This means
that the $n+1$ vertices can be arranged in a sequence, $S$, such that each
vertex is connected to at most $w$ preceding vertices.  Removing the last
vertex, $v$, and all edges incident to it gives a subgraph $G'$ with $n$
vertices.  The subgraph $G'$ also has width at most $w$, since the
sequence $S$ with its last vertex removed is a sequence of all the
vertices of $G'$ with each vertex adjacent to exactly the same previous
vertices.  So by Induction Hypothesis, $G'$ is $(w+1)$-colorable.  But any
$(w+1)$-coloring of $G'$ can be extended to a $(w+1)$-coloring of $G$ by
assigning a color to $v$ that differs from the colors of its adjacent
vertices.  Since there are at most $w$ colors among the $w$ vertices
adjacent to $v$, there will always be a different one of the $w+1$ colors
to assign to $v$.  So $G$ is $(w+1)$-colorable, which proves $P(n+1)$.
This completes the proof of the Induction step.

The result now follows for all $G$ by the Principle of Induction.
\end{solution}

\ppart Prove that the average degree of a graph of width $w$ is at most
$2w$.

\begin{solution} 
If we line up the vertices, we can define the \emph{backdegree} of a
vertex to be the number of preceding vertices it is adjacent to.  The sum
of the back degrees equals the number, $e$, of edges.  Since
there is a sequence in which all the back degrees are at most $w$, the
total number of edges is at most $w$ times the number, $n$, of vertices.
But by the Handshaking Lemma, the sum of all the degrees is $2e$,
so the average degree is $2e/n \leq 2wn/n = 2w$.
\end{solution}

\eparts

\end{problem}



\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps5}
\end{pcomments}

\pkeywords{
  degree
  graphs
  trees
  paths
  handshaking
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
\bparts 

\ppart
Prove that the average degree of a tree is less than 2.

\begin{solution}
\begin{proof}
A tree $T$ with $v$ vertices has $v-1$ edges.  By the Handshaking 
Lemma,
\[
\sum_{x \in T} \degr{x} = 2(v-1) < 2v.
\]
Dividing both sides by $v$ proves the claim.
\end{proof}
\end{solution}


\ppart Suppose every vertex in a graph has degree at least $k$.  Explain
why the graph has a simple path of length $k$.

\hint Consider a longest simple path.

\begin{solution}
Let $P$ be the longest simple path in $G$.  Let $x$ be one
endpoint of the path $P$.  Now $x$ is adjacent to at least $k$ other
vertices.  All of these must lie on path $P$; otherwise, the path
could be extended.  Therefore, $P$ contains at least $k + 1$ vertices,
including $x$, and thus has length at least $k$.

\end{solution}


\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{spring07 pset4-6}
\end{pcomments}

\pkeywords{
 graph theory
}


\begin{problem}
A set, $M$, of vertices of a graph is a \emph{maximal connected} set if
every pair of vertices in the set are connected, and any set of vertices
properly containing $M$ will contain two vertices that are not connected.

\bparts

\ppart What are the maximal connected subsets of the following
(unconnected) graph?

\mfigure{!}{1.5in}{figures/3comp}
\begin{solution} 
There are three maximal subsets, each one equal to the vertices of one of
the connected components of the graph.
\end{solution}

\ppart Explain the connection between maximal connected sets and connected
components.  Prove it.

\begin{solution} 
They are the same.

We first show that a connected component is a maximal set.  A connected
component consists of \emph{all} the vertices connected to some vertex
$v$.  A larger set of vertices would, by definition, contain both $v$ and
a vertex, $w$, that is not in the connected component.  This means that
$w$ is not connected to $v$, and therefore the larger set is not
connected.  So a connected component is maximal.

Conversely, suppose we have a maximal connected set, $M$.  Since $M$ is
connected, any vertex, $v$, in $M$ is connected to all the other vertices
in $M$.  If there was any vertex, $w$, connected to $v$, that was not in
$M$, then $M \union \set{w}$ would be connected and properly contain $M$,
contradicting the maximality of $M$.  So $M$ consists of exactly the
vertices connected to $v$, proving that it is a connected component.
\end{solution}

\eparts
\end{problem}

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{fall07 pset5-5}
\end{pcomments}

\pkeywords{
 graph theory
}


\begin{problem}

  Let $G$ be the graph formed from $C_{2n}$, the simple cycle of
  length $2n$, by connecting every pair of vertices at maximum
  distance from each other in $C_{2n}$ by an edge in $G$.

\bparts

\ppart Given two vertices of $G$ find their distance in $G$.

\begin{solution} Let's call vertices that are distance $n$ apart in $C_{2n}$
  \emph{opposite} vertices.  Opposite vertices are at maximum distance in
  $C_{2n}$, so by definition, there is an edge between them in $G$.  We'll
  call the edge between opposite vertices a \emph{crossing edge}.

%That is, opposite vertices are distance 1 apart in $G$.

  Suppose a simple path, $Q$, in $G$ begins by traversing a crossing edge,
  then follows a path, $P$, in $C_{2n}$ and ends by traversing another
  crossing edge.  Replacing every vertex in $P$ by its opposite, you get
  a new path in $C_{2n}$ between the endpoints of $Q$, but the new path is
  two edges shorter than $Q$.  This implies that a \emph{shortest} path in
  $G$ uses at most one crossing edge.

  Suppose $v$ and $w$ are two points in $G$ and $v'$ and $w'$ are their
  opposites.  Let $c_{xy}$ be the distance in $C_{2n}$ between two
  vertices $x,y$.  Let $d$ be the distance in $G$ from $v$ to $w$.

  Clearly $d \leq c_{vw}$.  Also, $d \leq c_{v'w}+1$ because there is a
  path in $G$ of length $c_{v'w}+1$ from $v$ to $w$ which begins by
  crossing from $v$ to $v'$ and then takes a shortest path in $C_{2n}$
  from $v'$ to $w$.

  Can we have $d < c_{vw}$ or $d < c_{v'w}+1$?  No.  If a shortest path,
  $S$, in $G$ between $v$ and $w$ does not use any crossing edge, then $S$
  is actually a path in $C_{2n}$ and thus $d = \text{length}(S) \geq
  c_{vw}$.  On the other hand, if $S$ uses one crossing edge
  $\edge{p}{p'}$, then $S$ consists of a path, $S_1$, in $C_{2n}$ from $v$
  to $p$ followed by the crossing from $p$ to $p'$, followed by a path,
  $S_2$, in $C_{2n}$ from $p'$ to $w$.  But then $S_1$ followed by the
  path $(S_2)'$ of opposites of vertices in $S_2$, is a path in $C_{2n}$
  from $v$ to $p$ to $w'$ of length $d-1$.  Thus $d-1 \geq c_{v'w}$, that
  is, $d \geq c_{v'w}+1$.

  Thus $d = \min(c_{vw},c_{v'w}+1) = \min(c_{vw}, n-c_{vw}+1)$.
\end{solution}
 

\ppart What is the {\em diameter} of $G$, that is, the largest distance
between two vertices?

\begin{solution} If $n=2k$ the diameter is $k$.  If $n = 2k + 1$ the diameter
  is also $k$.  (Let $d$ range from $1$ to $n-1$ and find the maximum
  value of $\min(d,n-d+1)$.)
\end{solution}

\ppart Prove that the graph is not 4-connected.

\begin{solution} Every vertex of the graph has degree $3$.  Removing all $3$
  edges incident to a vertex disconnects the graph.  (If it was
  $4$ connected, no matter what $3$ edges we remove, the graph would
  have to remain connected.)
\end{solution}

\ppart Prove that the graph is 3-connected.

\begin{solution} Let $G'$ be the graph that remains after removing two edges.
  Removing any two edges that were orginally part of $C_{2n}$ splits
  $C_{2n}$ into two connected components, each paths.  Call them $P$ and
  $P'$.  Since the length of the paths and the two removed edges sum to
  $2n$, one path must have length at most $n-1$.  Call this one $P$.  Pick
  a vertex $v$ within $P$.  $v$ is distance $n$ to some other vertex, $w$.
  in $C_{2n}$.  So $w$ must be in the other path $P'$.  The paths $P$,
  $P'$, and the edge $\edge{v}{w}$ form a spanning tree in $G'$ which then
  must be connected.

  Removing at most one edge from $C_{2n}$ leaves $C_{2n}$ connected,
  hence $G'$ remains connected too.
\end{solution}

\ppart What is the chromatic number of $G$? (It may depend on $n$.)

\begin{solution} If $n=2$, $G$ is the complete graph on four vertices, and so
  has chromatic number $4$.  Assume $n > 2$ from now on.

  Since $G$ has an edge, $\chi(G) \geq 2$.

  If $n$ is odd, color the vertices $v_i$ with $i$ even, red, and the
  vertices $v_i$ with $i$ odd, blue.  In this way if $v_i$ and $v_j$
  are adjacent in $C_{2n}$ they are colored differently.  If vertices
  $v_i$ and $v_j$ are at distance $n$ from each other in $C_{2n}$ then
  they are endpoints of a path of $n+1$ vertices in $C_{2n}$.  Since
  this is an even number of vertices, they must be colored differently
  as well.  Thus no edge of $G$ is improperly colored and this is a
  $2$-coloring of $G$.  Hence $\chi(G)=2$.

  If $n$ is even, $v_1, \dots, v_{n+1}$ form a cycle of odd length in
  $G$, so $\chi(G) \geq 3$.  Color $v_1$ and $v_n$ green.  Color
  $v_{n+1}, \dots, v_{2n}$ alternately red and blue.

  For $1 \leq i \leq n-2$, color the vertices $v_i$ red if $v_{i+n}$ is
  blue and vice versa.

  Clearly this is a valid coloring for $C_{2n}$, and the edges
  $\edge{v_i}{v_{i+n}}$ of $G$ have also been colored properly, for $1
  \leq i \leq n$.  If $i = 1$ or $n$, this is true because $v_i$ is green
  whereas $v_{i+n}$ is red or blue.  On the other hand if $2 \leq i \leq
  n-1$, the colors of $v_i$ have been chosen to make the edge properly
  colored.  Thus $\chi(G) =3$.
\end{solution}


\eparts

\end{problem}
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{spring07 pset4-8}
\end{pcomments}

\pkeywords{
 graph theory
}



\begin{problem}
Let's say that a graph has ``two ends'' if it has exactly two vertices
of degree 1 and all its other vertices have degree 2.  For example,
here is one such graph:

\mfigure{!}{0.75in}{figures/ps4-path}

\bparts

\ppart A \emph{line graph} is a graph whose edges can all be traversed by
a simple path.  So the two-ended graph above is also a line graph of
length 4.

Prove that the following theorem is false by drawing a counterexample.

\begin{falsethm*}
Every two-ended graph is a line graph.
\end{falsethm*}

\begin{solution}A graph consisting of a path together with a simple cycle is a
counterexample.
\end{solution}

\ppart Point out the first erroneous statement in the following alleged
proof of the false theorem.  Describe the error as best you can.

\begin{falseproof}
We use induction.  The induction hypothesis is that every two-ended
graph with $n$ edges is a path.

\textbf{Base case ($n = 1$):} The only two-ended graph with a single edge
consists of two vertices joined by an edge:

\mfigure{1.5in}{!}{figures/ps4-oneedge}

Sure enough, this is a line graph.

\textbf{Inductive case:} We assume that the induction hypothesis holds for
some $n \geq 1$ and prove that it holds for $n + 1$.  Let $G_n$ be any
two-ended graph with $n$ edges.  By the induction assumption, $G_n$ is a
line graph.  Now suppose that we create a two-ended graph $G_{n+1}$ by
adding one more edge to $G_n$.  This can be done in only one way: the new
edge must join an endpoint of $G_n$ to a new vertex; otherwise, $G_{n+1}$
would not be two-ended.

\mfigure{!}{1in}{figures/ps4-induction}

Clearly, $G_{n+1}$ is also a line graph.  Therefore, the induction
hypothesis holds for all graphs with $n+1$ edges, which completes the
proof by induction.

\end{falseproof}

\begin{solution}Actually, this is a correct proof of something else.  That is,
the first erroneous statement is the last one claiming that the 
induction hypothesis holds for \emph{all} $(n+1)$-edge two-ended
graphs.

The proof doesn't show this; rather, it only shows that the induction
hypothesis holds for those two-ended $(n+1)$-edge graphs {\em that can be
obtained by adding one more edge to an $n$-edge two-ended graph}.  This is
not all two-ended graphs, as the counterexample demonstrates.

This is an example of ``buildup'' error, where you assume that a size
$n+1$ object is built up in some particular way from similar objects of
smaller size.  (This assumption is correct for some kinds of objects, but
incorrect for others--- such as the one in the argument above.)

One way to avoid an accidental buildup error is to use a ``shrink down,
grow back'' process in the inductive step: start with a size $n+1$ object,
say a graph, remove a vertex (or edge), apply the inductive hypothesis
$P(n)$ to the smaller graph, and then add back the vertex (or edge) and
argue that $P(n+1)$ holds.  Let's see what would have happened if we'd
tried to prove the claim above by this method:

\textit{Inductive step:} We must show that $P(n)$ implies
$P(n+1)$ for all $n \geq 1$.  Consider an $(n+1)$-vertex graph $G$ in
which every vertex has degree at least 1.  Remove an arbitrary vertex
$v$, leaving an $n$-vertex graph $G'$ in which every vertex has
degree... uh-oh!

The reduced graph $G'$ might contain a vertex of degree 0, making the
inductive hypothesis $P(n)$ inapplicable!  We are stuck--- and
properly so, since the claim is false!
\end{solution}

\eparts

\end{problem}

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps5}
  \pcomment{from: S06.ps4}
  \pcomment{from: F07.ps5}
  \pcomment{from: F06}
  \pcomment{from: S06.ps4}
  \pcomment{add citation (see commented out portion of this file)}
\end{pcomments}

\pkeywords{
  graphs
  isomorphisms
  bijections
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
\iffalse
Last used S06, ps4;
used F06: Essentially taken from the Course Notes for the
University of Waterloo class C&O 230.
\fi

A property of a graph is said to be \emph{preserved under isomorphism} if
whenever $G$ has that property, every graph isomorphic to $G$ also has
that property.  For example, the property of having five vertices is
preserved under isomorphism: if $G$ has five vertices then every graph
isomorphic to $G$ also has five vertices.

Determine which among the four graphs pictured in the Figures 
%~\ref{fig:isog}
are isomorphic.  If two of these graphs are isomorphic, describe an
isomorphism between them.  If they are not, give a property that is
preserved under isomorphism such that one graph has the property, but the
other does not.  For at least one of the properties you choose,
\emph{prove} that it is indeed preserved under isomorphism (you only need
prove one of them).

\begin{figure}[h] %[htbp]
\begin{center}
\mbox{  \subfigure[$G_1$]{\includegraphics[width=1.5in,clip]{figures/G1}}
        \hspace{17mm}
        \subfigure[$G_2$]{\includegraphics[width=1.5in,clip]{figures/G4}} }
\mbox{  \subfigure[$G_3$]{\includegraphics[width=1.5in,clip]{figures/G2}}
        \hspace{17mm}
        \subfigure[$G_4$]{\includegraphics[width=1.5in,clip]{figures/G3}}
        }
\end{center}
\caption{Which graphs are isomorphic?}
\label{fig:isog}
\end{figure}

\iffalse


\begin{figure}[h] %[htbp]
\includegraphics[width=1.5in,clip]{figures/G1}
\caption{$G_1$}
\label{fig:G1}
\end{figure}


\begin{figure}[h] %[htbp]
\includegraphics[width=1.5in,clip]{figures/G2}
\caption{$G_2$}
\label{fig:G2}
\end{figure}


\begin{figure}[h] %[htbp]
\includegraphics[width=1.5in,clip]{figures/G3}
\caption{$G_3$}
\label{fig:G3}
\end{figure}

\begin{figure}[h] %[htbp]
\includegraphics[width=1.5in,clip]{figures/G4}
\caption{$G_4$}
\label{fig:G4}
\end{figure}
\fi

\begin{solution}
$G_1$ and $G_3$ are isomorphic.  In particular, the function
$f:V_1 \to V_3$ is an isomomorphism, where
\begin{align*}
&f(1)=1 \quad&& f(2)=2 \quad&& f(3)=3 \quad&& f(4)=8 \quad&& f(5)=9 \\
&f(6)=10 \quad&& f(7)=4 \quad&& f(8)=5 \quad&& f(9)=6 \quad&& f(10)=7
\end{align*}

$G_1$ and $G_4$ are not isomorphic to $G_2$: $G_2$ has a vertex of degree
four and neither $G_1$ nor $G_4$ has one.

$G_1$ and $G_4$ are not isomorphic: $G_4$ has a simple cycle of length
four and $G_1$ does not.

\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S06.ps3}
\end{pcomments}

\pkeywords{
   %I don't know the format for these keywords, how do I look them up?
	recursion
	structural_induction
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
  Fractals are example of a mathematical object that can
  be defined recursively.  In this problem, we consider the Koch
  snowflake.  Any Koch snowflake can be constructed by the following
  recursive definition.
  \begin{itemize}
  \item Base Case: An equilateral triangle with a positive integer
    side length is a Koch snowflake.
  \item Recursive case: Let $K$ be a Koch snowflake, and let $l$ be a
    line segment on the snowflake.  Remove the middle third of $l$,
    and replace it with two line segments of the same length as is
    done below:

    \begin{center}
      \includegraphics[width=2.5in]{koch}
    \end{center}

    The resulting figure is also a Koch snowflake.
  \end{itemize}
  
  Prove by structural induction that the area inside any Koch
  snowflake is of the form $q\sqrt{3}$, where $q$ is a rational
  number.
  
\begin{solution}
	We first show that the side length of any Koch snowflake
    is rational, and prove it in the lemma below.

    \begin{lemma}
      Every side length of a Koch snowflake is rational.
    \end{lemma}

    \begin{proof}
      For the base case, every side length is the same positive
      integer.  For the inductive case, let $K$ be a Koch snowflake.
      Then $K$ was constructed by modifying a Koch snowflake $K'$ as
      in the recursive case.  By the induction hypothesis, each side
      length of $K'$ is rational.  Let $l$ be the line segment of $K'$
      modified via the recursive case.  The two new line segments are
      of length $\frac{l}{3}$, which is rational since $l$ is
      rational.
    \end{proof}

    Now, we prove the main theorem.
    \begin{proof}
      We prove the claim by structural induction.
      
      For the base case, the area of an equilateral triangle with side
      length $l$ is $q\sqrt{3}$, where $q = \frac{l}{2}$.
      
      For the inductive case, let $K$ be a Koch snowflake.  $K$ was
      constructed by modifying a Koch snowflake $K'$ as in the recursive
      case above.  By the induction hypothesis, the area of $K'$ is
      $q\sqrt{3}$ for some rational $q$.  Let $l'$ be the length of the
      line segment of $K'$ that was modified according to the recursive
      case.  The area added by the modification is $q' \sqrt{3}$, where
      $q' = \frac{l'}{6}$.  By the above lemma, $l'$ is rational, so
      $q'$ is rational.  Thus, the area of $K$ is $(q' + q) \cdot
      \sqrt{3}$, and $q' + q$ is rational, so we have proved our claim.
    \end{proof}
\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps7}
\end{pcomments}

\pkeywords{
  number_theory
  linear_combinations
  gcd
  state_machines
  fun_game
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Here is a {\em very, very fun} game.  We start with two distinct,
positive integers written on a blackboard.  Call them $a$ and $b$.
You and I now take turns.  (I'll let you decide who goes first.)  On
each player's turn, he or she must write a new positive integer on the
board that is the difference of two numbers that are already there.
If a player can not play, then he or she loses.

For example, suppose that 12 and 15 are on the board initially.  Your
first play must be 3, which is $15 - 12$.  Then I might play 9, which
is $12 - 3$.  Then you might play $6$, which is $15 - 9$.  Then I can
not play, so I lose.

\bparts

\ppart Show that every number on the board at the end of the game is a
multiple of $\gcd(a, b)$.

\begin{solution}

Thinking of the game as a state machine, we observe that the property that
$\gcd(a,b)$ divides all the numbers on the board is an invariant.
This follows because the next state (board) is the same as the previous
state, except for an additional number which is the difference of two
numbers already there.  Assuming these two numbers are divisible by
$\gcd(a,b)$, we know that their difference will be as well, which proves
that the next state satisfies the invariant.

\end{solution}

\ppart Show that every positive multiple of $\gcd(a, b)$ up to $\max(a,
b)$ is on the board at the end of the game.

\begin{solution}
 Assume without loss of generality that $a > b$.  Let $s$ be the
smallest number on the board at the end of the game.  So $a = q s + r$
where $0 \leq r < s$ by the division algorithm.  Then $a - s$ must be on
the board and thus so must $a - 2s$, $a - 3s$, \ldots, $a - (q-1)s$.
However, $r = a - q s$ cannot be on the board, since $r < s$ and $s$ is
defined to be the smallest number there.  The only explanation is that $r
= 0$, which implies that $s \mid a$.  By the same argument, $s \mid b$.
Therefore, $s$ is a common divisor of $a$ and $b$.  Since $s$ is a
multiple of the greatest common divisor of $a$ and $b$ by the preceding
problem part, $s$ must actually be the greatest common divisor.  We
already argued that $a$, $a - s$, $a - 2s$, \dots, $a - (q-1)s$ must be
on the board, and these are all the positive multiples of $\gcd(a, b)$ up
to $\max(a, b)$.

\end{solution}

\ppart Describe a strategy that lets you win this game every time.

\begin{solution}
Assume without loss of generality that $a = \max(a,b)$.  By the
previous parts, the numbers that appear on the final board are precisely
all the multiples $\leq a$ of $gcd(a,b)$.  Thus, for each game, we know
\emph{exactly} how many values will be placed on the board before the game
ends.  So if an odd number of values will appear on the final board (which
happens precisely when $a$ is an even multiple of $\gcd(a,b)$), then choose
to go first.  
\end{solution}

\eparts

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{new by ARM from Jean Gallier email 8/21/09}
  \pcomment{Fix hard reference to Week 1 notes.}
\end{pcomments}

\pkeywords{
  irrational
  power 
  contradiction
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
  A recent class problem %~\ref{CP_irrational_raised_to_an_irrational},
  proved that the were irrational numbers $a,b$ such that $a^b$ was
  rational.  Unfortunately, that proof was \emph{nonconstructive}: it
  didn't reveal a specific pair, $a,b$, with this property.  But in fact,
  it's easy to do this: let $a \eqdef \sqrt{2}$ and $b \eqdef 2\log_2 3$.
  
  We know $\sqrt{2}$ is irrational, and obviously $a^b =3$.  Finish the
  proof that this $a,b$ pair works, by showing that $2\log_2 3$ is
  irrational.

\begin{solution}
\begin{proof}
  Suppose to the contrary that $2\log_2 3$ was rational.  Then $\log_2 3$
  must also be rational, say $\log_2 3 =m/n$ for some positive integers
  $m$ and $n$.  So $m = n\log_2 3$.  Now raising 2 to each side of this
  equation gives
\begin{equation}\label{2m2n3}
2^m = 2^{n \log_2 3} =  2^n\cdot 3.
\end{equation}
But this is impossible, since right hand side of~\eqref{2m2n3} is
divisible by 3 and the left hand side is not.

So $2\log_2 3$ must be irrational.
\end{proof}
\end{solution}
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps1}
  \pcomment{commented out in S09 so proofread before using}
\end{pcomments}

\pkeywords{
  irrational
  rational
  implies
  primes
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Show that $\log_{7} n$ is either an integer or irrational, where $n$ is a
positive integer.  Use whatever familiar facts about integers and primes
you need, but explicitly state such facts.  (This problem will be graded
on the clarity and simplicity of your proof.  If you can't figure out how
to prove it, ask the staff for help and they'll tell you how.)

\begin{solution}
  The statement to be proved is equivalent to the assertion that, for all
  positive integers, $n$, if $\log_7 n$ is rational, then it is an
  integer.  This is clearly true for $n=1$, since $\log_7 1$ is the
  integer zero.

Since $\log_7 x>0$ for $x > 1$, if $log_7 n$ not irrational, we would have
\begin{equation}\label{ij}
\log_7 n = \frac{i}{j}
\end{equation}
for some positive integers, $i,j$.

Now, raising $7$ to the power $\log_7 n$, we have from~\eqref{ij}
\[
n  = 7^{\log_7 n} = 7^{i/j}.
\]
Then, taking $j$th powers,
\begin{equation}\label{nj}
n^j =(7^{i/j})^j =  7^i.
\end{equation}
Since $i,j >0$, both sides of equation~\eqref{nj} are integers.  Also,
since the only prime dividing the righthand of~\eqref{nj} is 7,
\emph{the fact that integers factor uniquely into primes} implies that the
only prime factor of $n^j$, and hence the only prime factor of $n$, is 7.
This means that $n$ can only be a nonnegative power of 7, so $\log_7 n$
must be a nonnegative integer.
\end{solution}
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps3}
  \pcomment{revise reference to notes}
\end{pcomments}

\pkeywords{
  WOP
  well-ordering
  rationals
  contradiction
  false_proof
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
There was a proof in the notes that used Well Ordering to
show that all positive rational numbers can be written in ``lowest terms,''
that is, as a ratio of positive integers with no common factor prime
factor.  Below is a different proof which also arrives at this correct
conclusion, but this proof is bogus.   Identify every step at which the
proof makes an unjustified inference.

\begin{bogusproof}
  Suppose to the contrary that there was positive rational, $q$, such that
  $q$ cannot be written in lowest terms.  Now let $C$ be the set of such
  rational numbers that cannot be written in lowest terms.  Then $q \in
  C$, so $C$ is nonempty.  So there must be a smallest rational, $q_0 \in
  C$.  So since $q_0/2 < q_0$, it must be possible to express $q_0/2$ in
  lowest terms, namely,
\begin{equation}\label{q02}
\frac{q_0}{2} = \frac{m}{n}
\end{equation}
for positive integers $m,n$ with no common prime factor.  Now we consider
two cases:

\textbf{Case 1:} [$n$ is odd].  Then $2m$ and $n$ also have no common prime
factor, and therefore
\[
q_0 = 2\cdot \paren{\frac{m}{n}} = \frac{2m}{n}
\]
expresses $q_0$ in lowest terms, a contradiction.

\textbf{Case 2:} [$n$ is even].  Any common prime factor of $m$ and $n/2$
would also be a common prime factor of $m$ and $n$.  Therefore $m$ and
$n/2$ have no common prime factor, and so
\[
q_0 = \frac{m}{n/2}
\]
expresses $q_0$ in lowest terms, a contradiction.

Since the assumption that $C$ is nonempty leads to a contradiction, it
follows that $C$ is empty ---that is, there are no counterexamples.
\end{bogusproof}

\begin{solution}
The proof applies Well Ordering to the positive rationals.
  Unfortunately, the positive rationals are not Well Ordered, that is, $<$
  is not well-founded on the positive rationals.  For example, there is no
  least positive rational.  Aside from that, the other steps in the
  argument are correctly reasoned.
\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

%PS_mathematician_set

\begin{pcomments}
  \pcomment{from: F09.ps2}
  \pcomment{from: S02.ps3}
\end{pcomments}
\pkeywords{
  set_theory
  relations
  relational_properties
  composition
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}

Let $R$ be the relation on the set of all mathematicians that 
contains the ordered pair (a,b) if and only if $a$ and $b$ have 
written a paper together.

\bparts
\ppart
Describe the relation $R^2$.

\begin{solution}
Two mathematicians are related under $R^2$ if and only if
each has written a joint paper with some mathematician $c$.
\end{solution}

\ppart
Describe the relation $R^*$.

\begin{solution}
Two mathematicians are related under $R^*$ if there is a
finite sequence of mathematicians $a=c_0, c_1, c_2,..., c_{m-1},
c_m=b$, with $m \geq 1$, such that for each $i$ from 1 to $m$,
mathematician $c_i$ has written a joint paper with mathematician
$c_{i-1}$.
\end{solution}

\ppart
The \href{http://en.wikipedia.org/wiki/Erd%C5%91s_number}{\emph{Erd\H{o}s number}}
of a mathematician is 1 if this mathematician wrote a paper with the 
prolific Hungarian mathematician Paul Erd\H{o}s, it is 2 if this mathematician 
did not write a joint paper with Erd\H{o}s but wrote a joint paper with
someone who wrote a joint paper with Erd\H{o}s, and so on (except that
the Erd\H{o}s number of Erd\H{o}s himself is 0). Give a definition of
the Erd\H{o}s number in terms of paths in $R$.

\begin{solution}
The Erd\H{o}s number of $a$ is the length of a shortest path
in $R$ from $a$ to Erd\H{o}s, if such a path exists.  (Some
mathematicians have no Erd\H{o}s number).
\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
%PS_min_edge_DAG

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{notes problem from S09 DAG notes}
\end{pcomments}

\pkeywords{
  DAG
  path relation
  covering edge
  digraph
  acyclic
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}%\label{mindag}

If $a$ and $b$ are distinct nodes of a digraph, then $a$ is said to
\emph{cover} $b$ if there is an edge from $a$ to $b$ and there is no other
path from $a$ to $b$.  If $a$ covers $b$, the edge from $a$ to $b$ is
called a covering edge.

\bparts

\ppart Show that if two DAG's have the same positive path relation, then
they have the same set of covering edges.

\ppart Describe two graphs with vertices $\set{1,2}$ which have the same
set of covering edges, but not the same positive path relation (\hint They
can't be DAG's.)

\begin{solution}
Let one graph have edges $\set{(1,2), (1,1)}$ and the other
$\set{(1,1),(2,1)}$.  They have the same set of covering edges, namely,
none.  The reason is that if a vertex is on a positive length cycle, then
no edge incident to it can be a covering edge.
\end{solution}

\ppart For any DAG, $D$, let $\widehat{D}$ be the subgraph of $D$
consisting of only the covering edges.  Show that if $D$ is finite, then
$D$ and $\widehat{D}$ have the same positive path relation, that is $D^+ =
\widehat{D}^+$.
 
\ppart Conclude that if $D$ is a finite DAG, then $\widehat{D}$ is the
unique DAG with the smallest number of edges among all digraphs with the same
positive path relation.

\ppart Show that the previous result is not true for the infinite DAG
corresponding to the total order on the rational numbers.

\begin{solution}
In the DAG for $<$ on the $\rationals$, there are no covering
edges, so $\widehat{<}$ has no edges.
\end{solution}

\eparts
\end{problem}

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps8}
\end{pcomments}

\pkeywords{
  asymptotics
  recurrences
  closed_form
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
We begin with two large glasses.  The first glass contains a pint of
water, and the second contains a pint of wine.  We pour 1/3 of a pint
from the first glass into the second, stir up the wine/water mixture in
the second glass, and then pour 1/3 of a pint of the mix back into the
first glass and repeat this pouring back-and-forth process a total of
$n$ times.
\begin{problemparts}
\problempart
Describe a closed form formula for the amount of wine in the first glass
after $n$ back-and-forth pourings.

\begin{solution}
The state of the system of glasses/wine/water at the beginning
of a round of pouring and pouring back is determined by the total amount
of wine in the first glass.  Suppose at the beginning of some round, the
first glass contains $w$ pints of wine, $0\leq w \leq 1$ and $1-w$ pints
of water.  The second glass contains the rest of the wine and water.

Pouring 1/3 pint from the first glass to the second leaves 2/3 pints of liquid and
$(2/3)w$ wine in the first glass, and 4/3 pints of liquid and 
$1 - (2/3)w$ wine 
in the second glass.  Pouring 1/3 pint back from the second into the first
transfers a proportion of (1/3)/(4/3) of the wine in the second glass into
the first.  So the round completes with both glasses containing a pint of
liquid, and the first glass containing
\[
(2/3)w + (1/4)(1- (2/3)w) = 1/4 + w/2
\]
pints of wine.  After one more round, the first glass contains
\[1/4 + (1/4 + w/2)/2 = 1/4 + 1/8 + w/2^2\]
pints of wine, and after $n$ more rounds
\[
\begin{array}{lll}
w/2^n + \Sigma_{i=1}^n (1/2)^{i+1} &=  w/2^n + (1/2)\Sigma_{i=1}^n
(1/2)^{i}\\
& = w/2^n + (1/2)(-1 + \Sigma_{i=0}^n (1/2)^{i})\\
& = w/2^n + (1/2)(-1 + (1 - (1/2)^{n+1})/(1 - 1/2))\\
& = w/2^n - 1/2 + 1 - (1/2)^{n+1}\\
& = w/2^n + 1/2 - (1/2)^{n+1}.
\end{array}
\]
Since $w=0$ initially, the pints of wine in the first glass
after $n$ rounds is
\[
1/2 - (1/2)^{n+1}.
\]

\end{solution}

\problempart What is the limit of the amount of wine in each glass as $n$
approaches infinity?

\begin{solution}
The limiting amount of wine in the first glass approaches 1/2 from below
as $n$ approaches infinity.  In fact, it approaches 1/2 no matter how the
wine was initially distributed.  This of course is what you would expect:
after a thorough mixing the glasses should contain essentially the same
amount of wine.

\end{solution}

\end{problemparts}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps6}
  \pcomment{from: S07.ps5}
  \pcomment{from: S06.ps4}
  \pcomment{from: S04.quiz1, S04.cp5w}
\end{pcomments}

\pkeywords{
  cycles
  graph_coloring
  bipartite
  trees
  spanning_trees
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}\label{evenlength}
In this problem you will prove:
\begin{theorem*}
A graph $G$ is 2-colorable iff it contains no odd length cycle.
\end{theorem*}

As usual with ``iff'' assertions, the proof splits into two proofs:
part~(a) asks you to prove that the left side of the ``iff'' implies the
right side.  The other problem parts prove that the right side implies the
left.

\bparts

\ppart Assume the left side and prove the right side.  Three to five
sentences should suffice.

\begin{solution}
Assume $G$ is 2-colorable and select a 2-coloring of $G$.
Consider an arbitrary cycle with successive vertices $v_1, v_2, \dots,
v_k, v_1$.  Then the vertices $v_i$ must be one color for all even $i$ and
the other color for all odd $i$.  (This is obvious, but could of course,
be proved by induction.)  Since $v_1$ and $v_k$ must be colored
differently, $k$ must be even.  Thus, the cycle has even length.
\end{solution}

\ppart Now assume the right side.  As a first step toward proving the
left side, explain why we can focus on a single connected component
$H$ within $G$.

\begin{solution}
If we can 2-color every connected component of $G$, then we can
2-color all of $G$.  Thus, it suffices to show that an arbitrary connected
component $H$ of $G$ is 2-colorable.
\end{solution}

\ppart As a second step, explain how to 2-color any tree.

\begin{solution}
A 2-coloring of a tree can be defined by selecting any fixed
vertex $v$, and coloring a vertex one color if the (unique) path to
it from $v$ has odd length, and coloring it with the other color if the
path has even length.

To verify that adjacent vertices in the tree get different colors, let $e
\eqdef \edge{x}{y}$ be an edge in the tree.  There is a unique path from $v$
to $x$.  If this path traverses $e$, it must consist of a path from $v$ to
$y$ followed by the $e$ traversal to $x$.  If this path does not traverse
$e$, then it can be extended to a path to $y$ by adding a final traversal
of $e$.  In either case, the paths to these vertices from $v$ differ by a
single traversal of $e$, and so the lengths of the paths differ by 1; in
particular, one is of odd length and the other is of even length, so $x$
and $y$ are differently-colored.
\end{solution}

\ppart Choose any 2-coloring of a spanning tree, $T$, of $H$.  Prove that
$H$ is 2-colorable by showing that any edge \emph{not} in $T$ must also
connect different-colored vertices.

\begin{solution}
Let $\edge{x}{y}$ be an edge not in $T$, and consider the unique
paths from $v$ to $x$ and from $v$ to $y$ in $T$.  Exactly one of these
two paths must have odd length; otherwise, these two paths together with
the edge $\edge{x}{y}$ would form an odd length cycle.  But this means $x$
and $y$ are colored differently.
\end{solution}

\eparts

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps7}
  \pcomment{from: F08}
\end{pcomments}

\pkeywords{
  number_theory
  Pulverizer
  modular_arithmetic
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}

For the following parts, a correct numerical answer will only earn
credit if accompanied by it's derivation.  Show your work.

\bparts

\ppart\label{pulverizer} Use the Pulverizer to find integers
$s$ and $t$ such that $95 s + 52 t = \gcd(95,52)$.

\begin{solution}
\[
\begin{array}{ccccrcl}
x & \quad & y & \quad & \rem(x,y) & = & x - q \cdot y \\ \hline
95 && 52 && 43  & = &   95 - 1 \cdot 52 \\
52 && 43 && 9   & = &   52 - 1 \cdot 43 \\
&&&&            & = &   52 - 1 \cdot (95 - 1 \cdot 52) \\
&&&&            & = &   -1 \cdot 95 + 2 \cdot 52 \\
43 && 9  && 7   & = &   43 - 4 \cdot 9 \\
&&&&            & = &   (95 - 1 \cdot 52) -
                               4 \cdot (-1 \cdot 95 + 2 \cdot 52) \\
&&&&            & = &   5 \cdot 95 - 9 \cdot 52 \\
9  && 7  && 2   & = &   9 - 1 \cdot 7 \\
&&&&            & = &   (-1 \cdot 95 + 2 \cdot 52) - 
				1 \cdot (5 \cdot 95 - 9 \cdot 52) \\
&&&&            & = &   -6 \cdot 95 + 11 \cdot 52 \\
7  && 2  && 1   & = &   7 - 3 \cdot 2 \\
&&&&            & = &   (5 \cdot 95 - 9 \cdot 52) -		
				3 \cdot (-6 \cdot 95 + 11 \cdot 52) \\
&&&&            & = &   \fbox{$23 \cdot 95 - 42 \cdot 52$} \\
2  && 1  && 0
\end{array}
\]

{\it {\bf Exam tip:} each time $rem(x,y)$ is calculated,
substitutions are immediately made to then express it as a
linear combination of 95 and 52 (using the remainders
calculated on previous lines). Simplifying at each step
leads to a much faster computation of $s$ and $t$.}

\end{solution}

\ppart Use the previous part to find the inverse of 52 modulo 95
in the range $\{1,\ldots,94\}$.

\begin{solution}
53

From part \eqref{pulverizer}, $1 = 23 \cdot 95 - 42 \cdot 52$
and so $1 \equiv -42 \cdot 52 \pmod{95}$. Therefore -42 is \emph{an}
inverse of 52. However, it is not \emph{the} unique inverse of
52 in the range $\{1,\ldots,94\}$, which is given by $\rem{-42}{95}=53$.

\end{solution}


\ppart Use Fermat's theorem to find the inverse of 13 modulo 23 in
the range $\{1,\ldots,22\}$.

\begin{solution}
16

Since 23 is prime, Fermat's theorem implies
$13^{23-2} \cdot 13 \equiv 1 \pmod{23}$ and so $\rem{13^{23-2}}{23}$ is
the inverse of 13 in the range $\{1,\ldots,22\}$. Using the method
of repeated squaring,

%
\[
\begin{array}{lcl}
13^{2}  & =      & 169\\
	& =      & 7  \cdot 23 + 8\\
	& \equiv & 8\\ &&\\
13^{4}  & \equiv & 8^2\\
	& =      & 64\\
	& =      & 2  \cdot 23 + 18\\
	& \equiv & 18\\ &&\\
13^{8}  & \equiv & 18^2\\
	& =      & 324\\
	& =      & 14 \cdot 23 + 2\\
	& \equiv & 2\\ &&\\
13^{16} & \equiv & 2^2\\
	& =      & 4\\ &&\\
13^{21} & =      & 13^{16} \cdot 13^{4} \cdot 13\\
	& \equiv & 4 \cdot (6 \cdot 3) \cdot 13\\
	& =      & (4 \cdot 6) \cdot (3 \cdot 13)\\
	& =      & 24 \cdot 39\\
	& \equiv & 1 \cdot 39\\
	& \equiv & \fbox{$16$}
\end{array}
\]
%
where the modulus for each of the congruences is 23.

\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.cp??}
  \pcomment{Insert link to Week 2 Class Probs}
\end{pcomments}

\pkeywords{
 half-adder
 circuit
 parallel
 ripple carry}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%unused from S09 cp2m
\begin{problem}
  You saw in a class problem on Monday, Week 2 how to design a simple
  half-adder circuit using propositional formulas.  That design was called
  ``ripple carry'' because the value of the carry from each digit combines
  directly with the following digit, and so the values of the carries
  ripple through all the successive inputs.  In particular, in an $n$-bit
  ripple carry half-adder, there is a path from the first input wire to
  the final carry out of the $n$th digit which goes through at least $n$
  gates,

Considerably faster adder circuits work by computing the values in later
columns for both a carry of 0 and a carry of 1, \emph{in parallel}.  Then
when the carry from the earlier columns finally arrives, the pre-computed
answer can be quickly selected.  We'll illustrate this idea by working out
the equations for an $n+1$-bit parallel half-adder.

Parallel half-adders are built out of parallel ``add1'' modules.  An
$n+1$-bit add1 module takes as input the $n+1$-bit binary representation,
$a_n \dots a_1 a_0$, of an integer, $s$, and produces as output the binary
representation, $c\,p_n\dots p_1\,p_0$, of $s+1$.

\bparts

\ppart A 1-bit add1 module just has input $a_0$.  Write propositional
formulas for its outputs $c$ and $p_0$.

\begin{solution}

\begin{align}
p_0 & = a_0\ \QXOR\ 1 = \QNOT(a_0)\\
c & = a_0.
\end{align}

\end{solution}

\ppart Explain how to build an $n+1$-bit parallel half-adder from an
$n+1$-bit add1 module by writing a propositional formula for the
half-adder output, $o_i$, using only the variables $a_i$, $p_i$, and $b$.

\begin{solution}

\[
o_i  = (b\ \QAND\ p_i)\ \QOR\ (\QNOT(b)\ \QAND\ a_i)
\]

\end{solution}

\eparts

We can build a double-size add1 module with $2(n+1)$ inputs using two
single-size add1 modules with $n+1$ inputs.  Suppose the inputs of the
double-size module are $a_{2n+1},\dots, a_1, a_0$ and the outputs are
$c,p_{2n+1},\dots, p_1,p_0$.  The setup is illustrated in
Figure~\ref{fig:add1}.

Namely, the first single size add1 module handles the first $n+1$ inputs.
The inputs to this module are the low-order $n+1$ input bits $a_n,\dots,
a_1, a_0$, and its outputs will serve as the first $n+1$ outputs $p_n,
\dots, p_1, p_0$ of the double-size module.  Let $c_{(1)}$ be the
remaining carry output from this module.

The inputs to the second single-size module are the higher-order $n+1$
input bits $a_{2n+1}, \dots, a_{n+2}, a_{n+1}$.  Call its first $n+1$
outputs $r_n, \dots, r_1, r_0$ and let $c_{(2)}$ be its carry.

\bparts

\ppart Write a formula for the carry, $c$, in terms of $c_{(1)}$ and
$c_{(2)}$.

\begin{solution}

\[
c = c_{(1)}\ \QAND\ c_{(2)}.
\]

\end{solution}

\ppart Complete the specification of the double-size module by writing
propositional formulas for the remaining outputs, $p_i$, for $n+1 \leq i
\leq 2n+1$.  The formula for $p_i$ should only involve the variables
$a_i$, $r_{i-(n+1)}$, and $c_{(1)}$.

\begin{solution}
 The $n+1$ high-order outputs of the double-size module are the
  same as the inputs if there is no carry from the low-order $n+1$
  outputs, and otherwise is the same as the outputs of the second
  single-size add1 module.  So
\begin{equation}\label{parallel-pi}
p_i = (\QNOT(c_{(1)})\ \QAND\ a_i)\ \QOR\ (c_{(1)}\ \QAND\ r_{i-(n+1)}).
\end{equation}
for $n+1 \leq i \leq 2n+1$.
\end{solution}

\ppart Parallel half-adders are exponentially faster than ripple-carry
half-adders.  Confirm this by determining the largest number of
propositional operations required to compute any one output bit of an
$n$-bit add module.  (You may assume $n$ is a power of 2.)

\begin{solution}
 The most operations for an output are those specified in
  formula~\eqref{parallel-pi}.  So it takes at most 4 additional
  operations to get any one double-size output bit from the single-size
  output bits that it depends on.  It takes $\log_2 n$ doublings to get to
  from 1-bit to $n$-bit modules, so the largest number of operations
  needed for any one output bit is $4 \log_2 n$.

This observation also shows that the \emph{total} number of operations
used in the parallel adder to calculate \emph{all} the output digits is
propositional to $ n \log_2 n$.  This is larger than the total for a
ripple-carry adder by a factor proportional to $\log_2 n$.
\end{solution}

\eparts

\end{problem}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%PS_parenthesis_good_count

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: F04.ps5, S02.ps5}
  \pcomment{related to PS_parenthesis_count_well}
\end{pcomments}

\pkeywords{
  induction
  matching_parentheses
  recursive_data
  strings
  structural_induction  
  count
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}
\iffalse
Suppose we start with a sequence of fully parenthesized arithmetic or
Scheme expressions, and then erase all the alphanumeric characters other
than parentheses.  The result is a string of parentheses which ``match
up''.

For example, erasing non-parenthesis characters from the expression
\texttt{(if (or x y) u v)} leaves the string \texttt{(())}.  Similarly,
erasing non-parentheses from the sequence of three arithmetic expressions
\[
\texttt{(x * x), (y + (3 * (z - 9))), ((x + y) * (u + w))}
\]
leaves the string
\[
\texttt{()((()))(()())}.
\]
On the other hand, even though the string \texttt{())(()} has an equal
number of left and right parentheses, it cannot be obtained by erasing in
this way---because the two middle parentheses don't match up.  Also, no
string of parentheses which begins with a right parenthesis or ends with a
left parenthesis can match up.
\fi

The set, $\RM$, of strings of matching parentheses, is defined recursively
as follows:

\begin{itemize}
\item The empty string, $\emptystring$, (consisting of no parentheses) is
  in $\RM$.

\item If $s$ and $t$ are in $\RM$, then the string $\texttt{(}s\texttt{)}t$
is in $\RM$.  That is, the new string starts with a left parenthesis which
is followed by the parenthesis characters in the string $s$, followed by a
right parenthesis, followed by the parenthesis characters in the string
$t$.

\end{itemize}

There is a simple test to determine whether a string of parentheses is in
$\RM$: starting with zero, read the string from left to right adding one
for each left parenthesis and -1 for each right parenthesis.  A string has
a \term{good count} when the count never goes negative and is back to
zero by the end of the string.  Let $\GC$ be the parenthesis strings with
good counts.

\begin{problemparts}
\problempart Prove that $\GC$ contains $\RM$ by structural induction on the
definition of $\RM$.

\begin{solution}
We prove by induction on the definition of $\RM$ (that is,
structural induction) that every element of $\RM$ counts well, so $\RM$ is
contained in $\GC$.  The induction hypothesis is
\[
P(s) \eqdef s \in \GC.
\]
\begin{proof}

{\bf Base Case}: $P(\emptystring)$ holds since the count of the
empty string ends when it starts at zero.

{\bf Inductive Step:} Assume $P(s)$ and $P(t)$ are true.  We need to show
that $P(\texttt{(}s\texttt{)}t)$ is true.

The count values for $\texttt{(}s\texttt{)}t$ start with 0.  Reading the
initial left parenthesis yields 1 as the next count value.  This 1 serves
as the start of a series of count values exactly equal to the count values
of $s$, with each value incremented by one.  Since $s \in \GC$ by
hypothesis, these incremented count values begin with 1, always stay
positive, and end with 1.  The right parenthesis immediately after $s$
reduces the ending count to 0.  This 0 serves as the start of the
remaining count values which are exactly the count values of $t$.  Since
$t \in \GC$, these remaining values never go negative and end at 0.
Hence the entire sequence of count values for $\texttt{(}s\texttt{)}t$
starts with 0, never goes negative, and ends with 0, which proves that
$\texttt{(}s\texttt{)}t \in \GC$.

\end{proof}

\end{solution}

\problempart Conversely, prove that $\RM$ contains $\GC$.

\begin{solution}
  We show that every string $r\in \GC$ is an $\RM$ by strong induction on
  the length of $r$.  The induction hypothesis is
\[
Q(n) \eqdef \forall r \in \GC.\, \lnth{r} \leq n \QIMPLIES r \in \RM.
\]
\begin{proof}

{\bf Base Case} $n = 0$: In this case there is only one string of length
$n$, namely the empty string, which is in $\RM$ by definition, proving
$Q(0)$.

{\bf Inductive Step:} Assume that $Q(k)$ is true for all $k\leq n$, we
need to prove that $Q(n+1)$ is also true.

So suppose $r$ is a length $n+1$ string that counts well.  We must prove
that $r \in \RM$.

Now since $r$ has a good count, it must start with a left parenthesis (or else
the count would immediately go negative).  Likewise, since the count for
$r$ returns to the value 0 by the end, $r$ must end with right
parenthesis.  So there must be a \emph{first} right parenthesis in $r$
after which the count returns to 0.  Let $s$ be the substring of $r$
between the initial left parenthesis and this right parenthesis.  So
\[
r = \texttt{(}s\texttt{)}t
\]
for some string $t$.

Since counts only change by one as each parenthesis character is read, and
the count for $r$ \emph{first} returns to 0 after the right parenthesis
following $s$, the count during $s$ must start and end with 1 and must
stay \emph{positive} in between.  But this implies that a count for $s$
alone, which would start with 0, would also end with 0 and stay
\emph{nonnegative} in between.  That is, $s$ by itself has a good count.
Since the length of $s \in \GC$ is less than the length of $r$, we
have by strong induction that $s \in \RM$.

Further, we know the count for $r$ returns to 0 after the right
parenthesis following $s$, and since $r \in \GC$, the count ends with 0
again and stays nonnegative in between.  But this implies that $t$ has a
good count, and since the length of $t$ is less than the length of $r$, we
have by strong induction that $t \in \RM$.  Now by the second case in the
definition of $\RM$, we conclude $r = \texttt{(}s\texttt{)}t \in \RM$.

\end{proof}

\end{solution}

\end{problemparts}
\end{problem}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: F09.ps3}
  \pcomment{from: S02.ps2}
\end{pcomments}

\pkeywords{
  induction
  fun_game
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}

The 6.042 mascot, Theory Hippotamus, made a startling discovery while
playing with his prized collection of unit squares over the weekend.
Here is what happened.

First, Theory Hippotamus put his favorite unit square down on the floor as in
Figure~\ref{fig:squares}~(a).  He noted that the length of the periphery
of the resulting shape was 4, an even number.  Next, he put a second unit
square down next to the first so that the two squares shared an edge as in
Figure~\ref{fig:squares}~(b).  He noticed that the length of the periphery
of the resulting shape was now 6, which is also an even number.  (The
periphery of each shape in the figure is indicated by a thicker line.)
Theory Hippotamus continued to place squares so that each new square shared an
edge with at least one previously-placed square and no squares overlapped.
Eventually, he arrived at the shape in Figure~\ref{fig:squares}~(c).  He
realized that the length of the periphery of this shape was 36, which is
again an even number.

Our plucky porcine pal is perplexed by this peculiar pattern.  Use
induction on the number of squares to prove that the length of the
periphery is always even, no matter how many squares Theory Hippotamus places or
how he arranges them.

\begin{figure}[htbp]
\centering
\includegraphics[width=4in]{figures/f98ps2}
\caption{Some shapes that Theory Hippotamus created.} \label{fig:squares}
\end{figure}

\begin{solution}

The proof is by induction.  Let $P(n)$ be the proposition that the
periphery length is even after $n$ squares are placed.  In the base
case, $P(1)$ is true because the periphery of a single square has
length 4, which is even.

In the inductive step, assume that the periphery length is even after
$n$ squares are placed to prove that the periphery length is even
after $n+1$ squares are placed.  The $(n+1)$-th square could share 1,
2, 3, or 4 edges with previously-placed squares.

\begin{itemize}

\item If the new square shares 1 edge with a previously placed square,
then this one edge is removed from the periphery, but three edges of
the new square are added to the periphery.  Overall, the periphery
length increases by two and thus remains even.

\item If the new square shares 2 edges with previously placed squares,
then these two edges are removed from the periphery, but two edges of
the new square are added.  The periphery length is unchanged and thus
remains even.

\item If the new square shares 3 edges, then these three edges are removed
from the periphery, but one edge is added.  The periphery length
decreases by two and remains even.

\item If the new square shares 4 edges, then these four edges are removed
from the periphery and none are added.  The periphery length decreases
by four and remains even.

\end{itemize}

In all cases, the length of the periphery remains even.  Therefore,
for all $n \geq 1$, $P(n)$ implies $P(n+1)$ and the claim is proved by
induction.

\end{solution}

\end{problem}
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps6}
  \pcomment{commented out in S09}
  \pcomment{solution missing}
  \pcomment{contains href to the lecture notes}
\end{pcomments}

\pkeywords{
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
  \href{http://courses.csail.mit.edu/6.042/spring09/ln6.pdf#switch.edges}
  {Lemma 7.8} in Notes 6 established a key property of planar embeddings:
  two edges that could be successively added to an embedding can be added
  in either order.  Carefully prove this property for the case that the
  two edges are both added by the split-a-face constructor.

\begin{solution}
TBA
\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps3}
\end{pcomments}

\pkeywords{
  WOP
  well-ordering
  postage_stamps
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Use the Well Ordering Principle to prove that any integer greater than or
equal to 8 can be represented as the sum of integer multiples of 3 and 5.

\begin{solution}
\begin{claim}\label{5-7}
For all $n \geq 8$, it is possible to represent $n$ as a sum of integer
multiples of 3 and 5.
\end{claim}

\begin{proof}
  The proof is by the well-ordering principle.  Let $P(n)$ be the
  predicate that it is possible to produce $n$ as a sum of integer multiples
  of 3 and 5. 

  Let $C = \set{ n \geq 8 | \neg P(n)}$ be the set of counter
  examples.  Assume for the sake of contradiction that $C$ is not
  empty.  Then by the well-ordering principle, $C$ must have some minimum
  element $m\in C$.  

  First, observe that $P(n)$ is true for the following small values of $n$.
  \begin{itemize}
  \item $n=8$: $8 = 3 + 5$.
    
  \item $n=9$: $9 = 3 + 3 + 3$.

  \item $n=10$: $10 = 5 + 5$.
  \end{itemize}

  We thus have $m \geq 11$.  For $m \geq 11$, we have $m-3 \geq 8$.  Since
  $m$ is the smallest counterexample, we can represent $m - 3$ as the sum
  of integer multiples of 3 and 5 Thus we can represent $m$ by adding 1 to
  the coefficient of 3 in our representation of $m-3$.  Therefore, $m$ is
  not a counterexample, contradicting the assumption that $C$ is nonempty.
\end{proof}
\end{solution}
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%PS_predicate_calculus_power_of_prime

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S06.ps1
           edited way down from PS_express_predicates_in_formal_logic_notation}
\end{pcomments}

\pkeywords{
  predicates
  propositional_logic
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\isprime}{\text{\sc{is-prime}}}

\begin{problem}
  Express each of the following predicates and propositions in formal
  logic notation.  The domain of discourse is the nonnegative integers,
  $\naturals$.  Moreover, in addition to the propositional operators,
  variables and quantifiers, you may define predicates using addition,
  multiplication, and equality symbols, and nonnegative integer
  \emph{constants} \texttt{0}, \texttt{1},\dots), but no
  \emph{exponentiation} (like $x^y$).  For example, the predicate ``n is
  an even number'' could be defined by either of the following formulas:
\[
\exists m.\; (2m = n), \qquad \exists m.\; (m + m = n).
\]

\bparts

\ppart $m$ is a divisor of $n$.

\begin{solution}
\[
m \divides n 
\eqdef\quad 
\exists k.\; k \cdot m = n
\]
\end{solution}

\problempart 
$n$ is a prime number.

\begin{solution}
\[
\isprime(n)
\eqdef\quad 
(n\neq 1)\ \QAND\ \forall m.\; (m \divides n) \QIMPLIES (m=1 \QOR m=n).
\]
Note that $n\neq 1$ is an abbreviation of the formula $\QNOT(n=1)$.
\end{solution}

\ppart 
$n$ is a power of a prime.

\begin{solution}
  We can say that there is a prime, $p$, such that every divisor of
  $n$ not equal 1 to is itself divisible by $p$:
\[
\exists p.\,[\isprime(p) \QAND \forall m.\; (m \divides n \QAND m \neq 1)
\QIMPLIES p \divides m].
\]

Alternatively, we could say that at most one prime that divides $n$:
\[
\forall p,q.\, (\isprime(p) \QAND \isprime(q) \QAND p \divides n \QAND q
\divides n) \QIMPLIES p = q.
\]
\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%PS_predicate_calculus_power_of_prime

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S06.ps1
           edited way down from PS_express_predicates_in_formal_logic_notation}
\end{pcomments}

\pkeywords{
  predicates
  propositional_logic
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\isprime}{\text{\sc{is-prime}}}

\begin{problem}
  Express each of the following predicates and propositions in formal
  logic notation.  The domain of discourse is the nonnegative integers,
  $\naturals$.  Moreover, in addition to the propositional operators,
  variables and quantifiers, you may define predicates using addition,
  multiplication, and equality symbols, and nonnegative integer
  \emph{constants} \mtt{0}, \mtt{1},\dots), biut no \emph{exponentiation}
  (like $x^y$).  For example, the predicate ``n is an even number''
  could be defined by either of the following formulas:
\[
\exists m.\; (2m = n), \qquad \exists m.\; (m + m = n).
\]

\begin{problemparts}
\iffalse
\problempart 
$n$ is the sum of two cubes (a cube is a number equal to $k^3$ for some
integer $k$).

\begin{solution}
\[
\exists x \exists y.\; (x \cdot x \cdot x + y \cdot y \cdot y = n)
\]

Since the constant 0 is not allowed to appear explicitly, the predicate
``$x = 0$'' can't be written directly, but note that it could be expressed
in a simple way as:
\[
x + x = x.
\]
Then the predicate $x > y$ could be expressed
\[
\exists w.\; (y + w = x) \land (w \neq 0).
\]
Note that we've used ``$w \neq 0$'' in this formula, even though it's
technically not allowed.  But since ``$w \neq 0$'' is equivalent to the
allowed formula ``$\neg(w+w= w)$,'' we can use ``$w \neq 0$'' with the
understanding that it abbreviates the real thing.  And now that we've shown
how to express ``$x>y$,'' it's ok to use it too.
\end{solution}

\problempart $x = 1$.

\begin{solution}
One formula is $\forall y.\; xy=y$.  Another is $(x \cdot x = x) \conj (x
\neq 0)$.
\end{solution}
\fi

\ppart $m$ is a divisor of $n$ (notation: $m \divides n$)

\begin{solution}
\[
m \divides n 
\eqdef\quad 
\exists k.\; k \cdot m = n
\]
\end{solution}

\problempart 
$n$ is a prime number.

\begin{solution}
\[
\isprime(n)
\eqdef\quad 
(n\neq 1)\ \QAND\ \forall m.\; (m \divides n) \QIMPLIES (m=1 \QOR m=n).
\]
Note that $n\neq 1$ is an abbreviation of the formula $\QNOT(n=1)$.
\end{solution}

\problempart 
$n$ is a power of a prime.

\begin{solution}
  We can say that there is a prime, $p$, such that every divisor of
  $n$ not equal to is itself divisible by $p$.
\[
\exist p.\,[\isprime(p) \QAND \forall m.\; (m \divides n \QAND m \neq 1)
\QIMPLIES p \divides m].
\]
\end{solution}

\end{problemparts}
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%PS_preserve_transitivity

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: F09.ps3 revised by ARM 9/26/09 from symmetry problem S02.ps3}
\end{pcomments}

\pkeywords{
  relations
  relational_properties
  composition
  transitive
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Let $R$ and $S$ be binary relations on the same set, $A$.

\begin{definition}
  The \term{composition}, $S \compose R$, of $R$ and $S$
  is the binary relation on $A$ defined by the rule:\footnote{Note
    the reversal in the order of $R$ and $S$.  This is so that relational
    composition generalizes function composition, Composing the functions
    $f$ and $g$ means that $f$ is applied first, and then $g$ is applied
    to the result.  That is, the value of the composition of $f$ and $g$
    applied to an argument, $x$, is $g(f(x))$.  To reflect this, the
    notation $g \compose f$ is commonly used for the composition of $f$
    and $g$.  Some texts do define $g \compose f$ the other way around.}
\begin{displaymath}
a \mrel{(S \compose R)} c  \qiff \exists b\, [a \mrel{R} b\ \QAND\ b \mrel{S} c].
\end{displaymath}
\end{definition}

Suppose both $R$ and $S$ are transitive.  Which of the following new
relations must also be transitive?  For each part, justify your answer
with a brief argument if the new relation is transitive and a
counterexample if it is not.

\bparts
\ppart $R^{-1}$

\begin{solution}
  $R^{-1}$: \textbf{Yes.}  Because $a \mrel{R} b \mrel{R} c$ iff $c
  \mrel{\inv{R}} b \mrel{\inv{R}} a$.
\end{solution}

\ppart $R \intersect S$

\begin{solution}
  \textbf{Yes.} $a \mrel{R\intersect S} b \mrel{R \intersect S} c$ iff [$a
  \mrel{R} b \mrel{R} c$ and $a \mrel{S} b \mrel{S} c]$ implies [$a
  \mrel{R} c$ and $a \mrel{S} c]$ iff $a \mrel{R\intersect S} b$.
\end{solution}


\ppart $R \composition R$

\begin{solution}
\textbf{Yes.}  $a R^2 c$ means $a \mrel{R} b \mrel{R} c$ for some $b$, and
since $R$ is transitive, $a \mrel{R} c$.  But then $a \mrel{R^2} b
\mrel{R^2} c$ implies $a \mrel{R} b \mrel{R} c$, which implies $a \mrel{R^2} c$.
\end{solution}

\ppart $R \composition S$

\begin{solution}
  \textbf{No.}  Suppose $A = \set{1,2,3,4,5}$, $\graph{R} = \set{(1, 2),
    (3,4)}$ , and $\graph{S} = \set{(2, 3), (4, 5)}$ .  Then $\graph{S
    \compose R} = \set{(1,3) (3,5)}$.  Now $R$ and $S$ are vacuously
  transitive, but $S \compose R$ is missing the $(1.5)$ arrow, and so is
  not transitive.
\end{solution}


\eparts

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{new by ARM 9/8/09, revised hint 9/15/09}
  \pcomment{Fix hard reference to Week 1 notes.}
\end{pcomments}

\pkeywords{
  primes
  polynomials
  proof_by_cases
}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{problem}
  In Chapter 1 of the Class Notes, %~\ref{pn41},
  it took until $n=40$ to find a nonnegative integer argument such that
  $p(n) \eqdef n^2 + n + 41$ was not prime.  But we could have predicted
  based on general principles that no nonconstant polynomial, $q(n)$,
  with integer coefficients can map each nonnegative integer into a prime
  number.  Prove it.

  \hint Let $c \eqdef q(0)$ be the constant term of $q$.  Consider two
  cases: $c$ is not prime, and $c$ is prime.  In the second case, note
  that $q(cn)$ is a multiple of $c$ for all $n \in \integers$.  You may
  assume the familiar fact that the magnitude (absolute value) of any
  nonconstant polynomial, $q(n)$, grows unboundedly as $n$ grows.
 
\begin{solution}
%from ARM email reply S07 to Timan Goshit:
\begin{proof}
The proof is by cases following the hint.  

\textbf{Case 1} ($c$ is not prime): Then $q(0)$ is not a prime, so $q$
does not map all nonnegative integers to primes.

\textbf{Case 2} ($c$ is prime): In this case, $q(cm)$ has $c$ as a factor
for all integers, $m$.  Because $q$ is not constant, $\abs{q(cm)}$
grows unboundedly as $m$ increases.  But as soon as $\abs{q(cm)}$
grows bigger than $c$, it won't be prime because it has $c$ as a factor.
\end{proof}

Note that the proof for Case 2 shows something stronger: there are
infinitely many nonprimes in $\range{q}$ as long as $c > 1$.  It's also
easy to see that there will be infinitely many nonprimes in $\range{q}$
when $c=0$.  We will bet that this is also true when $c=1$, but we haven't
found a proof.  Let us know if you find one.

\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps4}
  \pcomment{from: F08.ps4}
  \pcomment{from: F07.ps3}
\end{pcomments}

\pkeywords{
  false_proof
  primes
  induction
  divides
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
  The following Lemma is true, but the \emph{proof} given for it below is
  defective.  Pinpoint \emph{exactly} where the proof first makes an
  unjustified step and explain why it is unjustified.

\begin{lemma}
For any prime $p$ and positive integers $n, x_1, x_2,\ldots, x_n$, if
$p \divides x_1x_2\dots x_n$, then $p \divides x_i$ for some $1\leq i\leq n$.
\end{lemma}

\begin{falseproof}
Proof by strong induction on $n$.

\textbf{Base case} $n= 1$: When $n=1$, we have $p\divides x_1$, therefore
we can let $i=1$ and conclude $p\divides x_i$.

\textbf{Induction step}: Now assuming the claim holds for all $k\leq n$, we must
prove it for $n+1$.

So suppose $p\divides x_1x_2\ldots x_{n+1}$.  Let $y_n = x_n x_{n+1}$, so
$x_1x_2\ldots x_{n+1} = x_1x_2\ldots x_{n-1}y_n$.  Since the righthand
side of this equality is a product of $n$ terms, we have by induction that
$p$ divides one of them.  If $p\divides x_i$ for some $i < n$, then we have the
desired $i$.  Otherwise $p\divides y_n$.  But since $y_n$ is a product of the two
terms $x_n, x_{n+1}$, we have by strong induction that $p$ divides one of
them.  So in this case $p \divides  x_i$ for $i = n$ or $i = n+1$.
\end{falseproof}

\begin{solution}
Notice that nowhere in the proof is the fact that $p$ is prime
used.  So if this proof were correct, the Lemma would hold not just for
prime $p$, but for any positive integer $p$.  But of course, the Lemma is
false when $p$ is not prime, for example if $p=6$, $x_1=3$ and $x_2=4$, we
have $p\divides x_1x_2$ but $\QNOT(p \divides x_1)$ and $\QNOT(p \divides
x_2)$.  So there has to be something wrong somewhere.

The statement ``we have by strong induction that $p$ divides
one of them'' is the place where the proof breaks down: it appeals to
strong induction to justify applying the induction hypothesis for $2=k\leq
n$.  But the base case was $n=1$, so we can't assume $2 \leq n$.  Note
that the reasoning above is fine for every $n\geq 2$, so the whole proof
would be fine if we had an argument to prove the claim for $n+1=2$.

Now in fact, if a prime, $p$ divides $x_1x_2$, it must divide $x_1$ or
$x_2$; this follows by prime factorization of integers (and we'll show you
another proof later in the term).  But the proof here never made use of
this fact.
\end{solution}
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%PS_printout_binary_strings

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps1}
\end{pcomments}

\pkeywords{
  binary
  truth_tables
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Describe a simple recursive procedure which, given a positive integer
argument, $n$, produces a truth table whose rows are all the assignments
of truth values to $n$ propositional variables.  For example, for $n=2$,
the table might look like:

\[\begin{array}{|c|c|}
\hline \true & \true\\
\true & \false\\
\false & \true\\
\false & \false\\
\hline
\end{array}\]

Your description can be in English, or a simple program in some familiar
language (say Scheme or Java), but if you do write a program, be sure to
include some sample output.

\begin{solution}
Start with an $n=1$ table, namely a one-column table whose
first row consists of a $\true$ entry and second row an $\false$ entry.
Build the $n+1$ table recursively by taking an $n$ table and attaching a
$\true$ at the beginning of every row, then taking another $n$ table and
attaching a $\false$ at the beginning of every row, and finally placing
the first table above the second table.

Here's a Scheme program that carries out this procedure:
\texttt{
\begin{tabbing}
(de\=fine (truth-values n)\\
   \> (if \= (= n 1) '((T) (F))\\
   \>    \> (let \=((table (truth-values (- n 1))))\\
              \>\>\> (ap\=pend\\
                \>\>\>\> (map (lambda (row) (cons 'T row)) table)\\
                \>\>\>\> (map (lambda (row) (cons 'F row)) table)))))\\
(truth-values 3)\\
;Value 17: \>\>\>((t t t) (t t f) (t f t) (t f f)\\
           \>\>\>\ (f t t) (f t f) (f f t) (f f f))
\end{tabbing}}
\end{solution}
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S06.ps2}
\end{pcomments}

\pkeywords{
   %I don't know the format for these keywords, how do I look them up?
	proper_subset
	partial_order
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Consider the proper subset partial order, $\subset$, on the power set
$\power{\set{1,2,\dots 5}}$.

\bparts
\ppart What is the size of a maximal chain in this partial order?
Describe one.
\begin{solution}
Size 6, for example,
\[
\set{\emptyset, \set{1}, \set{1,2}, \set{1,2,3},\set{1,2,3,4},\set{1,2,3,4,5}}.
\]
\end{solution}

\ppart Describe the largest antichain you can find in this partial order.

\begin{solution}
All the size 3 subsets of $\set{1,2,\dots 5}$ form an antichain of size 10.
This is actually the largest, though proving this is a challenge.
\end{solution}

\ppart  What are the maximal and minimal elements?  Are they maximum and
minimum?

\begin{solution}
$\emptyset$ is minimum and $\set{1,2,\dots 5}$ is maximum.
\end{solution}

\ppart Answer the previous part for the $\subset$ partial order on the set
$\power{\set{1,2,\dots 5}} - \emptyset$.

\begin{solution}
Now the five size 1 subsets are minimal and there is no minimum.
$\set{1,2,\dots 5}$ is still maximum.
\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps6}
  \pcomment{from: S06.ps4}
  \pcomment{from: S04.ps4}
\end{pcomments}

\pkeywords{
  graph_coloring
  scheduling
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem} 6.042 is often taught using recitations.  Suppose it
happened that 8 recitations were needed, with two or three staff members
running each recitation.  The assignment of staff to recitation sections
is as follows:

\begin{itemize}
\item R1:  Eli, Rong, Eric \\
\item R2:  Eli, Megumi, Albert\\
\item R3:  Rong, Jay\\
\item R4:  Chuck, Megumi, Eric\\
\item R5:  Chuck, William, Albert\\
\item R6:  William, Jay\\
\item R7:  William, Megumi\\
\item R8:  Rong, Jay, Albert
\end{itemize}

Two recitations can not be held in the same 90-minute time slot if some
staff member is assigned to both recitations.  The problem is to determine
the minimum number of time slots required to complete all the recitations.

\bparts

\ppart Recast this problem as a question about coloring the
vertices of a particular graph.  Draw the graph and explain what the
vertices, edges, and colors represent.

\begin{solution}
Each vertex in the graph below represents a recitation
section.  An edge connects two vertices if the corresponding
recitation sections share a staff member and thus can not be scheduled
at the same time.  The color of a vertex indicates the time slot of
the corresponding recitation.

\begin{center}
\includegraphics[height=2in]{figures/ps3-schedule.pdf}
\end{center}

\end{solution}

\ppart{Show a coloring of this graph using the fewest possible
colors.  What schedule of recitations does this imply?}

\begin{solution}
Four colors are necessary and sufficient. To see why they
are \emph{sufficient}, consider the coloring:
\begin{center}
\includegraphics[height=2in]{figures/ps3-schedule-colored.pdf}
\end{center}
This corresponds to the following assignment of recitations to four
time slots:
\begin{enumerate}

\item R1, R5

\item R2, R3

\item R4, R6

\item R7, R8

\end{enumerate}
Other schedules are also possible.

To see why 4 colors are \emph{necessary}, look at the subgraph defined
by the vertices for R2, R4, R5, and R7.  This is the complete graph on 4
vertices, and it obviously needs 4 colors.
\end{solution}

\eparts

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: F09.ps2}
  \pcomment{from: S03.ps5}
\end{pcomments}

\pkeywords{
  relations
  relational_properties
  mapping_lemma
  functions
  injections
  surjections
  bijections
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}

Let $A$, $B$, and $C$ be finite sets, and let $f : B \to
C$ and $g : A \to B$ be functions.  Let $h$ be the function with
domain $A$ and range $C$ that maps $x \in A$ to $f(g(x))$.  Prove or
disprove the following claims:

\bparts
\ppart
If $h$ is surjective, then $f$ must be surjective.

\begin{solution}
True.

For all $x$ in $C$: Since $h$ is surjective, there exists $y$ in $A$ such that 
$h(y) = x$. Therefore, by definition of $h$, $f(g(y)) = x$, so $x$ is in
the image of $f$.

Therefore, all of $C$ is in the image of $f$, so $f$ is surjective.
\end{solution}

\ppart
If $h$ is surjective, then $g$ must be surjective.

\begin{solution}
False.

Suppose $A = C = \{1\}$ and $B = \{1, 2\}$. Let $f$ be such that $f(1) = f(2) = 1$, and
$g$ such that $g(1) = 1$. In this case $h$ is indeed surjective, as
$h(1) = 1$, but $g$ is not surjective as it doesn't map anything to 2.
\end{solution}

\ppart
If $h$ is injective, then $f$ must be injective.

\begin{solution}
False.

Taking the same example as in the previous case. $h$ is injective, because
only 1 maps to 1. However, $f$ is not injective as $f(1) = f(2).$
\end{solution}

\ppart
If $h$ is injective, then $g$ must be injective.

\begin{solution}
True.

For all $x$ and $y$: If $g(x) = g(y)$ then $h(x) = f(g(x)) = f(g(y)) = h(y)$ so $x = y$ because
$h$ is injective.

Therefore, $g$ is injective.
\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps3}
  \pcomment{revise ref to notes}
\end{pcomments}

\pkeywords{
  partial_orders
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem} The class notes explained how partial orders can be
  represented by a collection of sets under the subset relation.  In
  particular, if $R$ is a \emph{weak} partial order on a set, $A$, then
\begin{equation}\label{ps3_rgb}
a \mrel{R} b  \qiff  R\set{a} \subseteq R\set{b}.
\end{equation}
holds for all $a,b \in A$.  Carefully prove statement~\eqref{ps3_rgb},
starting from the definitions of weak partial order and the subset
relation.

\begin{solution}
\iffalse
  \begin{theorem}
    $a = b \qiff R\set{a} = R\set{b}$.
  \end{theorem}
  \begin{proof}
    ($\Rightarrow$) Suppose $a = b$.  Then $\set{a} = \set{b}$, and
    hence $R\set{a} = R\set{b}$. 

    ($\Leftarrow$) Suppose $R\set{a} = R\set{b}$, and let $X =
    R\set{a} = R\set{b}$.  Since $R$ is a weak partial order, it is
    reflexive (i.e., $a \mrel{R} a$ and $b \mrel{R} b$), and thus $a,b \in X$.
    Since $X = \set{ x | x \mrel{R} a}$, and $b \in X$, it follows that $b R
    a$.  Similarly, $a \mrel{R} b$ by swapping $a$ and $b$ in the previous
    sentence.  Since $R$ is a weak partial order, it must be
    antisymmetric (i.e., $a \mrel{R} b \implies \neg(b \mrel{R} a) \vee (a = b)$).
    Since $a \mrel{R} b$ and $b \mrel{R} a$, we conclude that $a = b$.
  \end{proof}
\fi

  \begin{theorem}
    $a \mrel{R} b \qiff R\set{a} \subseteq R\set{b}$.
  \end{theorem}
  \begin{proof}
    ($\Rightarrow$) Suppose $a \mrel{R} b$.  Then by transitivity of
    partial order, $x \mrel{R} a \implies x \mrel{R} b$.  Thus, $x \in R
    \set{a} \implies x \in R\set{b}$, and we conclude $R\set{a} \subseteq
    R\set{b}$.  Notice that this direction holds for all partial orders.

    ($\Leftarrow$) Suppose $R\set{a} \subseteq R\set{b}$.  Since $R$ is a
    weak partial order, $a \mrel{R} a$ is true, so we have $a \in
    R\set{a}$.  Since $R\set{a} \subseteq R\set{b}$, it follows that $a \in
    R\set{b}$.  This means $a \mrel{R} b$, By definition of $R\set{b}$.
  \end{proof}

\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: f03.ps1}
\end{pcomments}

\pkeywords{
  rewrite_assertions
  predicates
  quantifiers
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}

Rewrite the following assertions using only variables, logic symbols,
and arithmetic expressions involving constants, addition,
multiplication, exponentiation, and comparison.  In all parts, the
domain of discourse is $\mathbb{N}$.  In the first part, you are asked
to write a definition of a prime number.  Then, in the second and
subsequent parts, you may make use of $\text{Prime}(n)$, a predicate
that is true if and only if $n$ is a prime number.

\begin{problemparts}

\problempart $p$ is a prime number.

\begin{solution}
\[
(p > 1)
\wedge
\neg \left( \exists m \exists n (m > 1 \wedge n > 1 \wedge mn = p) \right)
\]
\end{solution}

\problempart There is no largest prime number.

\begin{solution}
The domain of discourse is $\mathbb{Z}$.

\[
\neg \left(\exists p (Prime(p) \wedge (\forall q (Prime(q) \implies p \geq q)))
\right)
\]
\end{solution}

\problempart (Goldbach Conjecture) Every even natural number $n \geq
4$ can be expressed as the sum of two primes.

\begin{solution}
\[
\forall n 
\left(
(n \geq 4 \wedge \exists k\ n = 2k) \implies \exists p \exists q (Prime(p) \wedge Prime(q) \wedge (n = p + q))
\right)
\]
\end{solution}

\problempart (Bertrand's Postulate) If $n > 1$, then there is always
at least one prime $p$ such that $n < p < 2n$.

\begin{solution}
The domain of discourse is $\mathbb{Z}$.

\[
\forall n
\left( (n > 1) \implies (\exists p ( Prime(p)  \wedge (n < p) \wedge (p < 2n))) 
\right)
\]
\end{solution}

\problempart (Fermat's Last Theorem) There are no solutions to the
equation:

\begin{eqnarray*}
x^n + y^n & = & z^n
\end{eqnarray*}

where $n > 2$ and $x$, $y$, and $z$ are positive.

\begin{solution}
The domain of discourse is $\mathbb{Z}$.

\[
\forall x \forall y \forall z \forall n
    \left(
    (x > 0 \wedge y > 0 \wedge z > 0 \wedge n > 2)
    \rightarrow
    \neg (x^n + y^n = z^n)
    \right)
\]
\end{solution}

\end{problemparts}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps4}
  \pcomment{from: S03.ps7}
  \pcomment{similar to CP_robot_invariant}
\end{pcomments}

\pkeywords{
  state_machines
  unreachable_states
  invariant
  integer_grid
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem} A robot named Wall-E wanders around a two-dimensional
grid.  He starts out at $(0,0)$ and is allowed to take four different
types of step:

\begin{enumerate}
\item $(+2,-1)$
\item $(+1,-2)$
\item $(+1,+1)$ 
\item $(-3,0)$ 
\end{enumerate}

Thus, for example, Wall-E might walk as follows.  The types of his
steps are listed above the arrows.

\[
(0,0) \stackrel{1}{\rightarrow}
(2,-1) \stackrel{3}{\rightarrow}
(3,0) \stackrel{2}{\rightarrow}
(4,-2) \stackrel{4}{\rightarrow}
(1,-2) \rightarrow \ldots
\]

Wall-E's true love, the fashionable and high-powered robot, Eve, awaits
at $(0,2)$.

\bparts

\ppart Describe a state machine model of this problem.

\begin{solution}
Let the set of states is $\integers \times \integers$.  Let the
start state is $(0,0)$.   The possible transitions are
\begin{equation}\label{mt}
(x,y) \movesto (x,y)+(u,v)
\end{equation}
for $(u,v) \in \set{(+2,-1), (+1,-2),(+1,+1),(-3,0)}$.

\end{solution}

\ppart Will Wall-E ever find his true love?  Either find a path from
Wall-E to Eve or use the Invariant Theorem to prove that no such
path exists.

\begin{solution}
Let $P(x,y)$ be the property that $x + 2y$ is a multiple of 3.
  we claim $P$ is a preserved invariant.  To show this, we must show that
  if $3 \divides x+2y$, and Wall-E moves to $(x,y)+(u,v)$, then $3$
  divides
\begin{equation}\label{xuyv}
(x+u)+ 2(y+v).
\end{equation}
But this value equals
\begin{equation}\label{xyuv}
(x+2y) +(u + 2v),
\end{equation}
and since
\[
3 \divides u+2v
\]
for each of the four possible moves $(u,v)$ listed above (as is easily
checked), we conclude that 3 divides both terms in the sum~\eqref{xyuv}
and therefore divides the whole sum.  This proves implies that 3
divides~\eqref{xuyv}, completing the proof that $P$ is preserved by
transitions.

  Now $P$ holds in the start state, since $3 \divides (0 + 2 \cdot 0)$.
  However, $P$ does not hold for Eve's position, $(0, 2)$, since $0 + 2
  \cdot 2 = 4$ is not a multiple of 3.  Therefore, by the Preserved
  Invariant Theorem, Eve's position is not a reachable state.

\end{solution}

\iffalse
\ppart State the most restrictive preserved invariant you can find that
holds for all the states that Wall-E can reach.

Later, though, as it turns out, Wall-E takes one ``illegal'' step,
sweeps up Eve, and carries her off to the third quadrant of
$\mathbb{C}^2$, where they live happily every after.
\fi

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps7}
  \pcomment{from: OCW 05}
\end{pcomments}

\pkeywords{
  number_theory
  modular_arithmetic
  primes
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem} Suppose that $p$ is a prime and $0<k<p$.

\bparts

\ppart $k$ is \emph{self-inverse} if $k^2 \equiv 1 \pmod {p}$.  Prove that
$k$ is self-inverse iff either $k = 1$ or $k = p - 1$.

\hint $k^2-1 = (k-1)(k+1)$

\begin{solution}
By definition of $\equiv \pmod {p}$, the integer $k$ is
self-inverse iff $p \divides k^2 - 1$.  But $k^2-1 = (k-1)(k+1)$, and
since $p$ is a prime, we conclude that either $p \divides k-1$ or $p
\divides k+1$.  But $0 < k < p$, so $p \divides k-1$ iff $k-1=0$, and $p
\divides k+1$ iff $k+1 = p$, so we must have $k = 1$ or $k = p - 1$.

Conversely, $1 \cdot 1 \equiv 1 \pmod{p}$ and $(p-1)\cdot (p-1) = p^2+2p+1
\equiv 1 \pmod{p}$.
\end{solution}

\ppart Wilson's Theorem asserts
\begin{theorem}[Wilson's Theorem]
If $p$ is a prime, then
\[
(p - 1)!\  \equiv  -1 \pmod{p}
\]
\end{theorem}

The English mathematician Edward Waring said that this theorem would
probably be very difficult to prove because there was no adequate notation
for primes.  Gauss proved it while standing (on one foot, it is rumored).
He suggested that Waring failed for lack of notions, not notations.  Prove
Wilson's Theorem.  \hint While standing on one foot, think about pairing
each term in $(p-1)!$ with its multiplicative inverse.

\begin{solution}
If $p = 2$, then the theorem holds, because $1 \equiv -1
\pmod{2}$.  If $p > 2$, then $p - 1$ and $1$ are distinct terms in the
product $1 \cdot 2 \cdot \cdots (p - 1)$, and these are the only
self-inverses.  Consequently, we can pair each of the remaining terms
with its multiplicative inverse.  Since the product of a number and
its inverse is congruent to 1, all of these remaining terms cancel.
Therefore, we have:

\begin{eqnarray*}
(p-1)!  & \equiv & 1 \cdot (p - 1) \pmod{p} \\
        & \equiv & -1 \pmod{p}
	\end{eqnarray*}
	
\end{solution}

	\eparts

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%PS_set_union

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: F09.ps2}
  \pcomment{from: S06.ps1}
\end{pcomments}

\pkeywords{
  set_theory
  proof_by_cases
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}

Let $A$, $B$, and $C$ be sets.
Prove that:
\begin{equation}\label{ABCA-B}
A \union B \union C = (A - B) \union (B - C) \union (C - A) \union (A \intersect B \intersect C).
\end{equation}
%
\iffalse
You are welcome to use a diagram to aid your own reasoning, but your
proof must be text.
\fi


\hint $P \QOR Q \QOR R$ is equivalent to
\[
(P \QAND \bar{Q}) \QOR (Q \QAND \bar{R}) \QOR (R \QAND \bar{P}) \QOR (P \QAND Q \QAND R).
\]

\begin{solution}

\begin{proof}
We prove that an element, $x$, is a member of the left hand side
of~\eqref{ABCA-B} iff it is a member of the right hand side.

\begin{align*}
\lefteqn{x \in A \union B \union C}\\
 & \qiff (x \in A) \QOR (x \in B) \QOR (x \in C)
           & \text{(by def of $\union$)}\\
& \qiff ((x \in A) \QAND \bar{(x \in B)})\ \QOR\\
& \qquad ((x \in B) \QAND \bar{(x \in C)})\ \QOR\\
& \qquad ((x \in C) \QAND \bar{(x \in A)})\ \QOR \\
& \qquad ((x \in A) \QAND (x \in B) \QAND (x \in C)) & \text{(by the equivalence in the Hint)}\\
& \qiff (x \in A - B) \QOR (x \in B - C) \QOR (x \in C - A)\ \QOR\\
& \qquad (x \in A \intersect B \intersect C) & \text{(by def of $-$, $\intersect$)}\\
& \qiff x \in (A - B) \union (B - C) \union (C - A) \union (A \intersect B \intersect C)
   & \text{(by def of $\union$)}
\end{align*}
\end{proof}

\textbf{Alternative solution by cases:}

  We prove that the left side is contained in the right side, and that the
  right side is contained in the left side.

First, we show that the left side is contained in the right side.  Let $x$
be any element of $A \union B \union C$.  Then $x$ belongs to at least 
one of $A$, $B$, and $C$.  We distinguish two cases.
\begin{itemize}
\item $x$ belongs to all three sets: Then $x$ belongs to the
intersection $A\intersect B\intersect C$. 

\item $x$ does \emph{not} belong to all three sets: Then at least one
of $A$, $B$, $C$ does not contain $x$.  So overall, at least one set
contains $x$ and at least one set doesn't. We distinguish cases:
\begin{itemize}
\item If $A$ contains $x$, then one of $B$ and $C$ must not contain
it. 
\begin{itemize}
\item If $B$ does not contain it, then $x\in A-B$. 
\item If $B$ contains it, then $C$ does not, therefore $x\in B-C$.
\end{itemize}

\item If $A$ does \emph{not} contain $x$, then one of $B$ and $C$ must  
contain it. 

\begin{itemize}
\item If $C$ does, then $x\in C-A$. 
\item If $C$ does not contain it, then $B$ does, therefore $x\in B-C$. 
\end{itemize}
\end{itemize}
\end{itemize}
In all cases, we end up with $x$ being a member of one of 
$A - B$, $B - C$, $C - A$, or $A\intersect B\intersect C$.  Therefore, it belongs
to the right side. Hence, the set on the left is contained in the set
on the right.

Next, we show that the right side is contained in the left.  This is
easier. Let $x$ belong to the right side. Then it belongs to one of $A
- B$, $B - C$, $C - A$, or $A\intersect B\intersect C$.  In the first case, we
clearly know $x\in A$. In the second case, $x\in B$. In the third
case, $x\in C$. In the last case, $x\in A$ again. So, in all cases,
$x$ belongs to one of $A$, $B$, or $C$. So $x$ belongs to the left
side. Therefore, the set on the right is contained in the set on the
left.

Since each set is contained in the other, they are equal.

\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps7}
  \pcomment{from: S08}
\end{pcomments}

\pkeywords{
  number_theory
  permutations
  modular_arithmetic
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Albert decides to entertain the class with a magic trick.  He says:
\begin{enumerate}
\item Pick any 5 digit number containing at least two different digits.
\item Shuffle the digits to obtain a different number.
\item Subtract the smaller number from the larger.
\item Now sum the digits of the result.
\item Repeat step 4 until you have only one digit, and write down your answer.
\end{enumerate}
He announces the right answer without seeing the paper, but the 6.042
students are not impressed.  This problem demonstrates why they were not
impressed with Albert's "magic."

\bparts

\ppart\label{shuffle} Show that taking \emph{any} nonnegative integer (not
necessarily a 5-digit number), rearranging its digits to form a new
number, and finding the difference between the two numbers, will always
result in a multiple of 9.

\begin{solution}
Let $n$ be the nonnegative integer, and let $m$ be the number
obtained after rearrangement of the digits of $n$.  We want to show that $n-m$
is divisible by 9.

To this end, let
\begin{align*}
n & =  10^0 \cdot a_0 + 10^1 \cdot a_1 + \ldots + 10^k \cdot a_k\\
m & = 10^{\pi(0)} \cdot a_0 + 10^{\pi(1)} \cdot a_1 + \ldots + 10^{\pi(k)} \cdot a_k
\end{align*}
where $\pi$ is a permutation mapping the $k$ digits of $n$ to $k$ digits
of $m$.  So,
\[
n-m = \sum_i a_i \paren{10^i - 10^{\pi(i)}}.
\]
Since $10^k \equiv 1^k = 1 \pmod{9}$ for any $k$, we have that $10^i -
10^{\pi(i)} \equiv 0 \pmod{9}$.  That is, each term, $a_i
\paren{10^i-10^{\pi(i)}}$, in the sum is equivalent $0 \pmod{9}$, and so
the whole sum is also $\equiv 0 \pmod{9}$.  That is,
\[
n-m \equiv 0 \pmod{9},
\]
which means that $n-m$ is divisible by 9.
\end{solution}

\ppart\label{congruent-sum} Show that summing the digits of a positive integer results in an
integer that is congruent to it modulo 9.

\begin{solution}
Let $n = 10^0 \cdot a_0 + 10^1 \cdot a_1 + \ldots + 10^k \cdot
a_k$.  We want to show that:
\[
\sum_i a_i \equiv \sum_i 10^i a_i \pmod{9}.
\]
Since $10 \equiv 1 \pmod{9}$, we have that $10^i \equiv 1^i = 1 \pmod{9}$.
Therefore, $10^i a_i \equiv a_i \pmod{9}$, and we have our desired result:
$\sum_i a_i \equiv \sum_i 10^i a_i \pmod{9}$.
\end{solution}

\ppart Show that for any 5 digit number, this procedure always terminates
with the same digit.  What would happen if the starting number had more
than 5 digits?

\begin{solution}
After completing steps 1-3, we have arrived at a number that is
divisible by 9, as shown in part~\eqref{shuffle} of this problem.
Moreover, this number will be positive, since the original and shuffled
numbers are different.  Then, by part~\eqref{congruent-sum}, summing the
digits of this number will still yield a positive number divisible by 9.
Furthermore, summing the digits of a number results in a smaller positive
number, so the procedure is guaranteed to terminate with the number 9.

All of the previous reasoning holds no matter how many digits the original
number had.
\end{solution}

\eparts

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%PS_stable_matching_hospitals

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S08.ps4}
%  \pcomment{}
%  \pcomment{}
\end{pcomments}

\pkeywords{
   stable_matching
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\begin{problem}
The most famous application of stable matching was in assigning
graduating medical students to hospital residencies.  Each hospital has a
preference ranking of students and each student has a preference order of
hospitals, but unlike the setup in the notes where there are an equal
number of boys and girls and monogamous marriages, hospitals generally have
differing numbers of available residencies, and the total number of
residencies may not equal the number of graduating students.  Modify the
definition of stable matching so it applies in this situation, and explain
how to modify the Mating Ritual so it yields stable assignments of students
to residencies.  No proof is required.

\begin{solution}
The Mating Ritual can be applied to this situation by letting the students
be the boys and each of the \emph{residencies} (not the hospitals) be the
girls.

A matching is an assignment of students to residencies (an injection, $A:
\text{students} \to \text{residencies}$) such that every student has a
residency ($A$ is total), or every residency has an assigned student ($A$
is a surjection).  A stable assignment is one with no \emph{rogue couples},
where a rogue couple is a hospital student pair $(H,S)$ such that $S$ is
not assigned to one of the residencies at $H$, and
\begin{itemize}
\item $H$ has some students assigned to some of its residencies and
prefers $S$ to at least one of its assigned students, or

\item $H$ has none of its residencies assigned,

\end{itemize}

\end{solution}

\end{problem}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
%PS_stable_matching_no_first_choice

\documentclass[problem]{mcs}

\begin{pcomments}

  \pcomment{from: S08.ps4, F05.ps6}
\end{pcomments}

\pkeywords{
 stable_matching
 first_choice
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{problem}

Give an example of a stable matching between 3 boys and 3 girls
where no person gets their first choice.  Briefly explain why your matching
is stable.

\begin{solution}

Call the boys $1, 2, 3$ and the girls $a, b, c$.  Consider
the following preference list:

\begin{center}
\begin{tabular}{llll||llll} \hline
choice& 1st& 2nd& 3rd& choice& 1st& 2nd& 3rd \\ \hline
1& a& b& c& a& 2& 3& 1 \\
2& b& c& a& b& 3& 1& 2 \\
3& c& a& b& c& 1& 2& 3 \\ \hline
\end{tabular}
\end{center}
   
The matching $(1, b), (2, c), (3, a)$ is stable even though no person
gets their first choice.  

To see the intuition behind this solution, notice first that the first
choice of any boy has that boy as her last choice and vice versa.  
Second, notice that everyone ends up with their second choice.  

Since we show a pairing where everyone has their second choice, this 
is stable because the only way to have a rogue pair is for a boy
or girl to want their first choice, but their first choice always 
likes them least so will never want to leave their current partner.  

\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
%PS_stable_matching_non-optimal

\documentclass[problem]{mcs}

\begin{pcomments}

  \pcomment{from F07.ps4}
\end{pcomments}

\pkeywords{
 stable_matching
 optimal
 non-optimal
 Mating_ritual}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
\bparts

\ppart Describe a simple procedure to determine whether or not a stable
marriage problem has a unique solution, that is, only one possible stable
marriage assignment.

\begin{solution}

See if the Mating algorithm with Boys as suitors yields the same solution
as the algorithm with Girls as suitors.  These two marriage assignments
are boy-optimal and girl-optimal, respectively, so they agree iff there is
a unique solution.

\end{solution}

\ppart Construct a set of marriage preferences in which there is a stable
marriage assignment which differs from the boy-optimal matching that the
Mating Ritual would yield and also differs from the girl-optimal matching
the Mating Ritual would yield when the roles of boys and girls are
reversed.

Describe such a non-optimal stable matching, and briefly explain why it has
these properties.

\hint Divide the boys into two groups and also the girls into two groups.
Assign preferences so the first group of boys and girls prefer each other
to anyone in the second group.  Use a boy-optimal matching between the
first group, and a girl-optimal matching between the second group.

\begin{solution}

Consider a stable marriage problem with 4 boys and 4 girls and the
following partial information about their preferences:

\begin{center}
\begin{tabular}{|ccccc|}
\hline
B1: & G1 & G2 & --  & --\\
B2: & G2 & G1 & --  & --\\
B3: & --  & --  & G4 & G3\\
B4: & --  & --  & G3 & G4\\
\hline
G1: & B2 & B1 & --  & --\\
G2: & B1 & B2 & --  & --\\
G3: & -- & -- & B3 & B4\\
G4: & -- & -- & B4 & B3\\
\hline
\end{tabular}
\end{center}

The assignment
\[
 (B1, G1), (B2, G2), (B3, G3), (B4, G4)
\]
will be a stable matching whatever the unspecified preferences may be:

\begin{itemize}

\item $B1$ and $B2$ get their 1st choice, so won't be in a rogue couple.

\item $G1$ and $G2$ get their 2nd choices, so won't be in a rogue couple
  with the other two boys, $B3$ or $B4$.  So $G1$ and $G2$ won't be in any
  rogue couple, either.

\item $G3$ and $G4$ get their best remaining choices, so will never be in
  a rogue couple.

\item This leaves no possible rogue partners for $B3$ and $B4$.

\end{itemize}
So the marriages are sure to be stable.

Notice that giving $G1$ and $G2$ their first choices, that is, marrying
$(B1, G2)$ and $(B2, G1)$ would also be stable for the same reason.  But
with this switch, $B1$ does worse.  So the stable matching above is not
boy-pessimal.

Likewise, after marrying off the first two boys and girls, giving $B3$ and
$B4$ their best remaining choices, that is, marrying $(B3, G4), (B4, G3)$,
will also be stable.  But with this switch, $B3$ does better.  So the
stable matching above is not boy-optimal.

This implies that the stable matching above would not be produced by the
Mating Ritual.  
\end{solution}

\ppart \iffalse (Optional) \fi

Describe how to define a set of marriage preferences among $n$ boys and
$n$ girls which have more than $2^{n/4}$ stable assignments.

\begin{solution}
To find a set of preferences which have many stable matchings,
  arrange the boys into a list of $n/2$ pairs, and likewise arrange the
  girls into a list of $n/2$ pairs of girls.  Choose preferences so that
  the $k$th pair of boys ranks the $k$th pair of girls just below the
  previous pairs of girls, and likewise for the $k$th pair of girls.  This
  ensures that any matching in which the corresponding pairs of boys and
  girls are matched will be stable, as long as the submatches involving
  each pair separately is stable.  But the preferences of the $k$th pairs
  for each other can be chosen so that either of the two ways of matching
  them to each other will be stable in isolation.  
\end{solution}

\eparts

\end{problem}

\endinput
%PS_stable_matching_unlucky.tex

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: F03.ps4; F00.ps5}
\end{pcomments}

\pkeywords{
  stable_matching
  state_machines
  termination
  partial_correctness
  invariant
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
  Consider an instance of the matching problem with $n$ boys and $n$
  girls.  Call a person \iffalse \term\fi \emph{unlucky} if they are
  matched up with one of their $\floor{n/2}$ last choices.  In this
  problem, we will prove the following:

\begin{theorem*}
The matching algorithm from class never produces a
matching in which every person is unlucky.
\end{theorem*}

Fix an execution of the matching algorithm.  Define the variables 
$B_i, G_i, i \in \set{ 1, 2, \ldots, n}$ as follows:
\begin{description}
\item $B_i = j$ if the $i$th boy is currently courting the $j$th girl
on his list
\item $G_i$ is the number of boys that the $i$th girl has rejected.
\end{description}

\begin{problemparts}

\ppart
Show that
\[
\sum_{i=1} ^n B_i - \sum_{i=1} ^n G_i
\]
is preserved at each step of the matching algorithm.

\begin{solution}
Let $S = \sum_{i=1} ^n B_i - \sum_{i=1} ^n G_i$.  Suppose that at step
$t$, boy $b_i$ proposes to girl $g_j$.  There are three possible outcomes:

If $g_j$ has not had any previous proposals, she must accept.  In this
case, none of the $B_i$s and none of the $G_j$s change, so $S$ is preserved.

If $g_j$ rejects, then $G_j$ increases by 1, $B_i$ increases by 1, and
the other $B$s and $G$s remain the same.  $S$ is preserved again.

If $g_j$ accepts $b_i$ because she likes him better than her current
mate $b_{i'}$, then $G_j$ increases by 1, $B_{i'}$ increases by 1, and
the other $B$s and $G$s remain the same.  $S$ is preserved in this case
as well.
\end{solution}

\ppart
Formulate a preserved invariant that you can use to prove the theorem, and 
verify that your invariant is preserved.

\begin{solution}

Let $P : S = n$. From part (a) it follows that
all transitions preserve the truth value of $P$.  Therefore $P$ is an
invariant.

\end{solution}

\ppart Use your preserved invariant to prove the theorem.

\begin{solution}
We prove the statement by contradiction.  Consider a match M in which
every person is unlucky.  Then:

\begin{description}
\item For every $i \in \{ 1, \ldots, n \}$, 
$B_i \geq \ceil{\frac{n}{2}} + 1$, and
\item For every $i \in \{ 1, \ldots, n \}$,
$G_i \leq \floor{\frac{n}{2}} - 1$.
\end{description}

It follows that $\sum_{i=1} ^n B_i - \sum_{i=1} ^n G_i \geq 2n$.  This
violates the invariant $P$.

\end{solution}

\end{problemparts}

\end{problem}

\endinput
%PS_state_machine_multiply

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{S07.miniquiz-3-07}

\end{pcomments}

\pkeywords{
  state_machines
  termination
  partial_correctness
  invariant
  algorithm
  multiply
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
%Tests state machine understanding, invariant method, termination arguments.
%IMPORTANT: If reusing this problem, the second part should be split into 2 parts:
% 1. Prove the invariant., 2. Apply invariant principle...

The following state machine describes a procedure that terminates with the
product of two nonnegative integers $x$ and $y$ in register $a$.  Its
states are triples of nonnegative integers $(r,s,a)$.  The initial state
is $(x,y,0)$.  The transitions are given by the rule that for $s>0$:
\[
(r,s,a)\rightarrow\begin{cases}
        (2r,s/2,a) &\text{if $s$ is even},\\
        (2r,(s-1)/2,a+r) &\text{otherwise}.
       \end{cases}
\]

%\iffalse
%\solution{
%\medskip
%\textbf{Solution:}
%\begin{description}
%\item $Q=\{(r,s,a,x, n) | r,s,a,x, n\in \mathbb{N}\}$
%\item $Q_0=\{(x, n,0,x, n)\}$
%\item $\delta: (r,s,a,x, n)\rightarrow (3r,s',a',x, n)$, where \\
%If $s \equiv 0 \pmod{3}$: $s'=s/3$, and $a'=a$ \\
%If $s \equiv 1 \pmod{3}$: $s'=(s-1)/3$, and $a'=a+r$\\
%If $s \equiv 2 \pmod{3}$: $s'=(s-2)/3$, and $a'=a+2r$
%\end{description}
%}
%\fi

\bparts

\ppart\label{rsa} Circle the predicates below that are invariant for
this state machine:
\begin{itemize}
\item $P((r,s,a)) \eqdef\quad [r+a = xy]$
\item $P((r,s,a)) \eqdef\quad [s+a = xy]$
\item $P((r,s,a)) \eqdef\quad [rs+a = xy]$
\item $P((r,s,a)) \eqdef \quad [r=r+1]$

\end{itemize}

\begin{solution}
$[rs+a = xy]$ and $[r=r+1]$ are invariants.  The second of these
  is vacuously invariant because it is always false.
\end{solution}

\iffalse

\ppart Prove that the predicate you picked in \emph{Part a} holds for
the base case and is invariant under all possible transitions.
\begin{solution}
Let
\[
P((r,s,a)) \eqdef\quad [rs+a = xy].
\]

Clearly, $P$ holds for the start state because
\[
P((x,y,0)) \qiff [xy+0 = xy].
\]

Now, we show that $P$ is indeed invariant, namely, assuming $P((r,s,a))$,
\begin{equation}\label{inv}
rs+a = xy,
\end{equation}
holds and $(r,s,a) \to (r',s',a')$ is a transition, then $P((a',b',p'))$,
\begin{equation}\label{inv'}
r's'+a' = xy,
\end{equation}
holds.

We consider 2 cases:

If $2 \divides s$, then we have that $r' = 2r, s' = s/2, a'=a$.
Therefore,
\begin{align*}
  r's' + a' = & 2r \cdot \frac{s}{2} + a\\
            = & rs+a\\
            = & xy & \text{(by~\eqref{inv})}.
\end{align*}

Otherwise, we have $r' = 2r, s' = (s-1)/2,a = a+r$.  So:
\begin{align*}
  r's' + a'  = & 2r \cdot \frac{s-1}{2} + a+r\\
   = & r\cdot(s-1) + a + r\\
   = & rs+a\\
   = & xy & \text{(by~\eqref{inv})}.
\end{align*}
So in both cases,~\eqref{inv'} holds, proving that $P$ is indeed an
invariant.
\end{solution}
\fi

\ppart Use an invariant from part~\eqref{rsa} to prove that the
algorithm is partially correct ---that is, if the machine terminates (that
is, reachs a state from which no transition is possible), then $a = xy$.
(You do \textbf{not} have to prove that the invariant you select from
part~\eqref{rsa} actually \emph{is} an invariant.)

\begin{solution}
Since the procedure's only termination
  condition is that $s=0$, partial correctness will follow if we can show
  that if $s=0$, then $a=xy$.  But this follows immediately from the
  invariant $[rs+a = xy]$.
\end{solution}

%\instatements{\newpage}

\ppart Briefly explain why this state machine will in fact terminate
for all $x,y \in \naturals$.


\begin{solution}
We'll actually prove something stronger, namely,
  that the algorithm terminates after at most $1+\log_2 y$ executions of
  \texttt{do} statement.  We first notice that $s \in \naturals$ is an
  invariant.  Also, each transition corresponds to an execution of the
  \texttt{do} statement body, and at each transition, $s$ is reduced by a
  factor of at most $1/2$.  Hence, after at most $1+ \log_2 y$ executions
  of the body, the final value of $s$ is at most $1/2^{1+ \log_2 y} =
  1/2y$ times its initial value, $y$.  This means the value of $s$ will be
  less than 1, and since the value is a nonnegative integer, $s$ must be 0
  at this point if it wasn't 0 earlier.  But with $s=0$, the procedure
  terminates.
\end{solution}

\eparts
\end{problem}

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: F07.ps3}
\end{pcomments}

\pkeywords{
  strong_induction
  defective_proof
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
  Lemma below is true, but the \emph{proof} given for it below is
  defective.  Pinpoint \emph{exactly} where the proof first makes an
  unjustified step.  Note: there is no mistaken assertion about properties
  of primes in this proof.  The mistake is in making a true, but
  not obvious, assertion without justifification.

\begin{lemma}
For any prime $p$ and positive integers $n, x_1, x_2,\ldots, x_n$, if
$p \divides x_1x_2\dots x_n$, then $p \divides x_i$ for some $1\leq i\leq n$.
\end{lemma}

\begin{falseproof}
Proof by strong induction on $n$.

\textbf{Base case} $n= 1$: When $n=1$, we have $p\divides x_1$, therefore
we can let $i=1$ and conclude $p\divides x_i$.

\textbf{Induction step}: Now assuming the claim holds for all $k\leq n$, we must
prove it for $n+1$.

So suppose $p\divides x_1x_2\ldots x_{n+1}$.  Let $y_n = x_n x_{n+1}$, so
$x_1x_2\ldots x_{n+1} = x_1x_2\ldots x_{n-1}y_n$.  Since the righthand
side of this equality is a product of $n$ terms, we have by induction that
$p$ divides one of them.  If $p\divides x_i$ for some $i < n$, then we have the
desired $i$.  Otherwise $p\divides y_n$.  But since $y_n$ is a product of the two
terms $x_n, x_{n+1}$, we have by strong induction that $p$ divides one of
them.  So in this case $p \divides  x_i$ for $i = n$ or $i = n+1$.
\end{falseproof}

\begin{solution}
Notice that nowhere in the proof is the fact that $p$ is prime
used.  So if this proof were correct, the Lemma would hold not just for
prime $p$, but for any positive integer $p$.  But of course, the Lemma is
false when $p$ is not prime, for example if $p=6$, $x_1=3$ and $x_2=4$, we
have $p\divides x_1x_2$ but $\QNOT(p \divides x_1)$ and $\QNOT(p \divides
x_2)$.  So there has to be something wrong somewhere.

The statement ``we have by strong induction that $p$ divides
one of them'' is the place where the proof breaks down: it appeals to
strong induction to justify applying the induction hypothesis for $2=k\leq
n$.  But the base case was $n=1$, so we can't assume $2 \leq n$.  Note
that the reasoning above is fine for every $n\geq 2$, so the whole proof
would be fine if we had an argument to prove the claim for $n+1=2$.

Now in fact, if a prime, $p$ divides $x_1x_2$, it must divide $x_1$ or
$x_2$; this follows by prime factorization of integers (and we'll show you
another proof later in the term).  But the proof here never made use of
this fact.
\end{solution}

\end{problem}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%PS_subsequences_partial_order_Dilworth_Lemma

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: F07.ps2}
\end{pcomments}

\pkeywords{
  subsequences
  maximum_length_of_subsequences
  partial_order
  maximal_and_minimal_elements
  Dilworth_Lemma
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Let $S$ be a sequence of $n$ different numbers.  A \emph{subsequence} of
$S$ is a sequence that can be obtained by deleting elements of $S$.

For example, if
\[
S = (6,4,7,9,1,2,5,3,8)
\]
Then $647$ and $7253$ are both subsequences of $S$ (for readability, we
have dropped the parentheses and commas in sequences, so $647$ abbreviates
$(6,4,7)$, for example).

An \emph{increasing subsequence} of $S$ is a subsequence of whose
successive elements get larger.  For example, $1238$ is an increasing
subsequence of $S$.  Decreasing subsequences are defined similarly; $641$
is a decreasing subsequence of $S$.


\begin{problemparts}

\problempart  
List all the maximum length increasing subsequences of $S$, and all
the maximum length decreasing subsequences.

\begin{solution}
The maximum length increasing subsequences are $1238$ and
$1258$.  The maximum length decreasing subsequences are
\[
641, 642, 643, 653, 753, 953
\]
\end{solution}

\end{problemparts}

Now let $A$ be the \emph{set} of numbers in $S$.  (So $A =
\set{1,2,3,\dots,9}$ for the example above.)  There are two
straightforward ways to totally order $A$.  The first is to order its
elements numerically, that is, to order $A$ with the $<$ relation.  The
second is to order the elements by which comes first in $S$; call this
order $<_S$.  So for the example above, we would have
\[
6 <_S 4 <_S 7 <_S 9 <_S 1 <_S 2 <_S 5 <_S 3 <_S 8
\]

\iffalse
letting $a_i$ be the $i$th element of $S$, we order $A$ with the total
order $<_S$, where
\[
a_i <_S a_j \iff i < j.
\]
\fi

Next, define the partial order $\prec$ on $A$ defined by the rule
\[
a \prec a' \quad \eqdef \quad a  < a' \text{ and } a <_S a'.
\]
(It's not hard to prove that $\prec$ is strict partial order, but you may
assume it.)


\begin{problemparts}

\problempart 
Draw a diagram of the partial order, $\prec$, on $A$.  What are the
maximal elements,\dots the minimal elements?

\begin{solution}
The maximal elements are 8 and 9; the minimal are 1, 4,and 6:
\begin{center}
\includegraphics[height=4in]{figures/sequence-poset.pdf}
\end{center}
\end{solution}


\problempart
Explain the connection between increasing and decreasing
subsequences of $S$, and chains and anti-chains under $\prec$.

\begin{solution}
A \emph{chain}, with its elements listed in numerically
increasing order, is an \emph{increasing} subsequence and an
\emph{antichain}, with its elements listed in numerically decreasing
order, is a \emph{decreasing} subsequence.
\end{solution}


\problempart 
Prove that every sequence, $S$, of length $n$ has an increasing
subsequence of length greater than $\sqrt{n}$ or a decreasing subsequence
of length at least $\sqrt{n}$.
\iffalse

\hint
\href{http://courses.csail.mit.edu/6.042/fall07/ln3.pdf#rule.Dilworth}
{Dilworth's Lemma}
\fi

\begin{solution}
By Dilworth's Lemma, either a chain or an antichain must have
size at least $\sqrt{n}$, which, by the previous problem part, means there
is either an increasing or a decreasing subsequence of this size.  
\end{solution}

\ppart (Optional, tricky) Devise an efficient procedure for finding the
longest increasing and the longest decreasing subsequence in any given
sequence of integers.  (There is a nice one.)

\begin{solution}
\TBA{reference to Floyd algorithm}
\end{solution}

\end{problemparts}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps3}
\end{pcomments}

\pkeywords{
  partial_orders
  chains_and_antichains
  minimal_vs_minimum
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
The proper subset relation, $\subset$, defines a partial order on the
power set $\power{\set{1,2,\dots,6}}$.

\bparts
\ppart What is the size of a maximal chain in this partial order?
Describe one.

\begin{solution}
Size 7, for example,
\[
\set{\emptyset, \set{1}, \set{1,2},
  \set{1,2,3},\set{1,2,3,4},\set{1,2,3,4,5}, \set{1,2,3,4,5,6}}.
\]
\end{solution}

\ppart Describe the largest antichain you can find in this partial order.

\begin{solution}
All the size 3 subsets of $\set{1,2,\dots, 6}$ form an antichain
  of size 20.  These are actually the largest, though proving this can be
  a challenge, especially trying to generalize to the power set of an $n$
  element set.
\end{solution}

\ppart  What are the maximal and minimal elements?  Are they maximum and
minimum?

\begin{solution}
$\emptyset$ is minimum and $\set{1,2,\dots,6}$ is maximum.
\end{solution}

\ppart Answer the previous part for the $\subset$ partial order on the set
$\power{\set{1,2,\dots, 6}}$ with $\emptyset$ removed.

\begin{solution}
Now the six size 1 subsets are minimal and there is no minimum.
$\set{1,2,\dots,6}$ is still maximum.
\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps4}
  \pcomment{from: F08.ps4}
  \pcomment{from: S04.ps2}
\end{pcomments}

\pkeywords{
  induction
  strong_induction
  ordinary_induction
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
\begin{claim}
If a collection of positive integers (not necessarily distinct) has
sum $n \geq 1$, then the collection has product at most $3^{n/3}$.
\end{claim}

For example, the collection 2, 2, 3, 4, 4, 7 has the sum:

\begin{eqnarray*}
2 + 2 + 3 + 4 + 4 + 7 & = & 22
\end{eqnarray*}

On the other hand, the product is:

\begin{eqnarray*}
2 \cdot 2 \cdot 3 \cdot 4 \cdot 4 \cdot 7
    & = & 1344 \\
    & \leq & 3^{22/3} \\
    & \approx & 3154.2
\end{eqnarray*}

\bparts

\ppart Use strong induction to prove that $n \leq 3^{n/3}$ for every
integer $n \geq 0$.

\begin{solution}
The proof is by strong induction.  Let $P(n)$ be the
proposition that $n \leq 3^{n/3}$.  First, we show that $P(0)$,
$P(1)$, $P(2)$, $P(3)$, and $P(4)$ are true:

\begin{eqnarray*}
0^3 \leq 3^0 & \rightarrow & 0 \leq 3^{0/3} \\
1^3 \leq 3^1 & \rightarrow & 1 \leq 3^{1/3} \\
2^3 \leq 3^2 & \rightarrow & 2 \leq 3^{2/3} \\
3^3 \leq 3^3 & \rightarrow & 3 \leq 3^{3/3} \\
4^3 \leq 3^4 & \rightarrow & 4 \leq 3^{4/3} \\
\end{eqnarray*}

Each implication follows by taking cube roots.  Next, we show that
$P(0), \ldots, P(n)$ imply $P(n + 1)$ for all $n \geq 4$.  Thus, we
assume that $P(0), \ldots, P(n)$ are all true and reason as follows:

\begin{eqnarray*}
3^{(n + 1)/3}
    & = & 3 \cdot 3^{(n-2)/3} \\
    & \geq & 3 \cdot (n - 2) \\
    & \geq & n + 1 \hspace{1in} \text{(for all $n \geq 7/2$)}
\end{eqnarray*}

The first step is algebra.  The second step uses our assumption $P(n -
2)$.  The third step is a linear inequality that holds for all $n \geq
7/2$.  (This forced us to deal individually with the cases $P(3)$ and
$P(4)$, above.) Therefore, $P(n + 1)$ is true, and so $P(n)$ is true
for all $n \geq 0$ by induction.
\end{solution}

\ppart Prove the claim using induction or strong induction.  (You may
find it easier to use induction on the {\em number of positive
integers in the collection} rather than induction on the sum $n$.)

\begin{solution}
We use induction on the size of the collection.  Let $P(k)$
be the proposition that every collection of $k$ positive integers with
sum $n$ has product at most $3^{n/3}$.  First, note that $P(1)$ is
true by the preceding problem part.

Next, we must show that $P(k)$ implies $P(k + 1)$ for all $k \geq 1$.
So assume that $P(k)$ is true, and let $x_1, \ldots, x_{k+1}$ be a
collection of positive integers with sum $n$.  Then we can reason as
follows:

\begin{eqnarray*}
x_1 \cdot x_2 \cdots x_k \cdot x_{k+1}
    & \leq & 3^{(n - x_{k+1}) / 3} \cdot x_{k+1} \\
    & \leq & 3^{(n - x_{k+1}) / 3} \cdot 3^{x_{k+1} / 3} \\
    & = & 3^{n / 3}
\end{eqnarray*}

The first step uses the assumption $P(k)$, the second uses the
preceding problem part, and the last step is algebra.  This shows that
$P(k + 1)$ is true, and so the claim holds by induction.

\end{solution}

\eparts

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: F09.ps3}
  \pcomment{from: S02.ps3}
\end{pcomments}

\pkeywords{
  set_theory
  relations
  relational_properties
  bijections
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}

Suppose $R$ and $S$ are binary relations on a set $A$, and
that both $R$ and $S$ are symmetric. Must each of the following new
relations be symmetric? For each part, justify your answer with a
brief argument if the new relation is symmetric and a counterexample
if it is not.

\bparts
\ppart $R^{-1}$

\begin{solution}
$R^{-1}$: \textbf{Yes.} Suppose $(x, y) \in R^{-1}$.  By
the definition of inverse, this means that $yRx$.  But since $R$ is
symmetric, this means that $xRy$.  By the definition of inverse again,
this means that $(y, x) \in R^{-1}$.  So $R^{-1}$ is symmetric.
\end{solution}

\ppart $R \intersect S$

\begin{solution}
\textbf{Yes.} If $(x, y) \in R \intersect S$, we must prove
that $(y, x) \in R \intersect S$.  We have that $xRy$ (in which case
$yRx$ as well) and $xSy$ (in which case $ySx$ as well).  Since $yRx
\land ySx$, we have $(y, x) \in R \intersect S$.
\end{solution}

\ppart $R \composition S$

\begin{solution}
\textbf{No.}  Suppose $A = \{a,b,c\}$,
$R = \{(b, c), (c, b)\}$ , and $S = \{(a, b), (b, a)\}$ .  Then $R
\composition S = \{(a, c)\}$, which is not symmetric.
\end{solution}

\ppart $R \composition R$

\begin{solution}
\textbf{Yes.} $R^2$ is symmetric.  For every ordered pair
$(a,b)$ that is a member of $R$, $(b,a)$ must also be in $R$.  Then in
the composition, $R^2$, $(a,a)$ is certainly symmetric.  What about
the case where $(a,b)$ is in $R$, and so is $(b,c)$?  $(a,c)$ will be
in $R^2$, but so will $(c,a)$ since $(c,b)$ and $(b,a)$ are both in
$R$ because of symmetry. In fact, $R^n$ is symmetric if $R$ is
symmetric.
\end{solution}

\eparts

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: F09.ps3}
  \pcomment{from: S03.ps4}
\end{pcomments}

\pkeywords{
  induction
  strong_induction
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}

  A group of $n \geq 1$ people can be divided into teams, each
  containing either 4 or 7 people.  What are all the possible values of
  $n$?  Use induction to prove that your answer is correct.

\begin{solution}

We begin by observing that the following numbers of people can be divided
into teams with 4 or 7 people per team:
\begin{align*}
4 & = 4 \\
7 & = 7 \\
8 & = 4 + 4 \\
11 & = 4 + 7 \\
12 & = 4 + 4 + 4 \\
14 & = 7 + 7 \\
15 & = 4 + 4 + 7 \\
16 & = 4 + 4 + 4 + 4 \\
18 & = 4 + 7 + 7 \\
19 & = 4 + 4 + 4 + 7 \\
20 & = 4 + 4 + 4 + 4 + 4 \\
21 & = 7 + 7 + 7,
\end{align*}
and these are the only numbers $\leq 21$ that can be divided into such
teams.  Now we claim that every group of $n \geq 18$ people can be divided
into teams, each containing either 4 or 7 people.

\begin{proof}
  The proof is by strong induction on $n$.  Let $P(n)$ be the proposition
  that a group of $n \geq 18$ people can be divided into teams, with each
  containing either 4 or 7 people.

  \textbf{Base cases:} As shown above $P(18)$, $P(19)$, $P(20)$, and
  $P(21)$ are true.

\textbf{Inductive step:} For all $n \geq 21$, we assume that $P(18)$,
$P(19)$, $\dots$, $P(n)$ are true in order to prove that $P(n+1)$ is true.

Since $n+1 = (n-3) + 4$, a team of 4 people can be removed from the set of
$n+1$ people, leaving $n-3 \geq 18$ people.  By induction hypothesis, the
$n-3$ people can be further divided into disjoint teams with 4 or 7
people.  Since this divides the $n+1$ people into teams with 4 or 7, we
have shown that $P(n+1)$ is true.  It follows by strong induction that
$P(n)$ holds for all $n \geq 18$.

So all the possible values of $n$ are 4, 7, 8, 11, 12, 14, 15, 16, and
$\geq 18$.
\end {proof}
\end{solution}

\end{problem}
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps8}
  \pcomment{from: S07.ps7}
\end{pcomments}

\pkeywords{
  integral_method
  series
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}[4]
Use integration to find upper and lower bounds that differ by at most
0.1 for the following sum.  (You may need to add the first few terms
explicitly and then use integrals to bound the sum of the remaining
terms.)
%
\[
\sum_{i=1}^{\infty} \frac{1}{(2i+1)^2}
\]

\begin{solution}
Let's first try standard bounds:
%
\[
\int_0^{\infty} \frac{1}{(2x+3)^2}\ dx
\quad \leq \quad
\sum_{i=1}^{\infty} \frac{1}{(2i+1)^2}
\quad \leq \quad
\int_0^{\infty} \frac{1}{(2x+1)^2}\ dx
\]
%
Evaluating the integrals gives:
%
\[
\left. -\frac{1}{2(2x+3)}\ \right|_0^{\infty}
\quad \leq \quad
\sum_{i=1}^{\infty} \frac{1}{(2i+1)^2}
\quad \leq \quad
\left. -\frac{1}{2 (2x+1)}\ \right|_0^{\infty}
\]
%
\[
\frac{1}{6}
\quad \leq \quad
\sum_{i=1}^{\infty} \frac{1}{(2i+1)^2}
\quad \leq \quad
\frac{1}{2}
\]
%
These bounds are too far apart, so let's sum the first couple terms
explicitly and bound the rest with integrals.
%
\[
\frac{1}{3^2} + \frac{1}{5^2} + \int_2^{\infty} \frac{1}{(2x+3)^2}\ dx
\quad \leq \quad
\sum_{i=1}^{\infty} \frac{1}{(2i+1)^2}
\quad \leq \quad
\frac{1}{3^2} + \frac{1}{5^2} + \int_2^{\infty} \frac{1}{(2x+1)^2}\ dx
\]
%
Integration now gives:
%
\[
\frac{1}{3^2} + \frac{1}{5^2} +
    \left(\left. - \frac{1}{2 (2x+3)}\ \right|_2^{\infty}\right)
\quad \leq \quad
\sum_{i=1}^{\infty} \frac{1}{(2i+1)^2}
\quad \leq \quad
\frac{1}{3^2} + \frac{1}{5^2} + 
    \left(\left. - \frac{1}{2 (2x+1)}\ \right|_2^{\infty}\right)
\]
\[
\frac{1}{3^2} + \frac{1}{5^2} + \frac{1}{14}
\quad \leq \quad
\sum_{i=1}^{\infty} \frac{1}{(2i+1)^2}
\quad \leq \quad
\frac{1}{3^2} + \frac{1}{5^2} + \frac{1}{10}
\]
%
Now we have bounds that differ by $1/10 - 1/14 < 1/10 = 0.1$.
\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps6}
  \pcomment{from: S08.ps6}
  \pcomment{from: S06.ps4 (adapted)}
\end{pcomments}

\pkeywords{
  digraphs
  DAGs
  topological_sort
  transitive_closure
  paths
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
  Vertices $u, v$ in a digraph are said to be \emph{connected} when there
  is a directed path (in either direction) between $u$ and $v$.

The following procedure can be applied to any digraph, $G$:

Pick any two vertices $u, v$ of $G$.
\begin{enumerate}

\item\label{del} If there is an edge $(u,v)$ of $G$ and there is also a
directed path connecting $u$ and $v$ (in either direction) which does
\emph{not} traverse this edge, then delete the edge $(u,v)$, or

\item\label{add} if $u$ and $v$ are not connected, then add the edge
$(u,v)$.
\end{enumerate}
Repeat these operations until it is no longer possible to find two
vertices $u \neq v$ to which an operation applies.

This procedure can be modeled as a state machine.  The start state is
$G$, and the states are all possible digraphs with the same vertices as
$G$.

\bparts

\ppart Let $G$ be the graph with vertices $\set{1,2,3,4}$ and edges
\[
\set{(1,2),(3,4)}
\]
What are the possible states reachable in one step from start state $G$?
What are the possible final states reachable from $G$?

\begin{solution}
It's not possible to delete any edge.  At the first step, the
procedure can only add an edge $(i,j)$ or $(j,i)$, where $i \in \set{1,2}$
and $j \in \set{3,4}$.

The possible final states are all graphs consisting of a single directed
path, where 1 precedes 2 and 3 precedes 4.  The possible such paths are
1234, 1324, 1342, 3124, 3142, 3412.
\end{solution}

\eparts

To prove termination, let's say that two vertices are \term{undirected}
iff either they are unconnected or they lie on the same directed cycle.
Otherwise they are \term{directed}.

\bparts

\ppart For any state, $G'$, let $c$ be its number of directed cycles, 
$e$ be its number of edges, and $p$ its
number of sets of two undirected vertices.  Show that $(c,p,e)$ is a
strictly decreasing derived variable under lexicographic order.  Conclude
that the procedure terminates started on any finite digraph, $G$.

\begin{solution}
Since $G$ is finite, the value of the derived variable $(c,p,e)$ is
a trio of nonnegative integers.  We will show that $(c,p,e)$ is strictly
decreasing under lexicographic order.  Termination then follows from the
fact that lexicographic order is well-founded.

There are two cases depending on the operation that was used.

\textbf{Case} \emph{Operation~\ref{del}}: Since $e$ decreases by~1, it is
enough to show that $c$ stays the same or decreases, and $p$ stays the same 
or decreases if $c$ stays the same.  This will follow if we show that .  
If our edge removes a cycle, then $c$ will decrease, so we can confine our 
remaining cases to when the edge removed does not remove a cycle.  But 
deleting an edge creates no new cycles, so there are no new pairs that are
undirected because they both lie on the same new cycle.  Also, since an
edge between $u$ and $v$ gets deleted only if a directed path between them
remains after the deletion, no new unconnected pairs are created
since there was no cycle containing the edge removed.  So any
pair that was undirected before the edge deletion remains undirected after
deletion.

\textbf{Case} \emph{Operation~\ref{add}}: Since $e$ increases by~1, we
must show that $p$ decreases while $c$ stays the same or that $c$ decreases
. In other words, $G'$ has strictly fewer undirected pairs of vertices.

Now since $u$ and $v$ are unconnected in $G$, they are an undirected pair.
Also, adding an edge $\diredge{u}{v}$ cannot create a new cycle in $G'$.
This follows because any new cycle would have to traverse the new edge,
and the rest of the cycle would be a directed path from $v$ to $u$ in $G$,
contradicting the fact that $u$ and $v$ are unconnected in $G$  This shows 
that $c$ will remain constant, so it only remains to show that $p$ decreases
.  The added edge between $u$ and $v$ makes them a directed pair in $G'$ 
since it does not create any cycles.  Moreover, since the new edge creates 
no new cycle, it creates no new undirected pairs that lie on a cycle.  
And of course adding an edge cannot create any new unconnected pairs.  Hence,
 adding the edge creates no new undirected pairs and removes at least one 
undirected pair, and so reduces the number of undirected pairs by at least one.
\end{solution}

\ppart Let an edge be called a generalized covering edge if removing that edge
leaves no path in either direction between its endpoints.  Let g be the number
of generalized coverging edges in our graph.  Give an alternative termination proof using the derived variable
$v+e-2g$.   Briefly indicate why this proof is more informative than the
previous one using lexicographic order. (\textbf{Correction: this answer relies on
 $G$ being a DAG, which we did not assume.  The fix using a different derived variable
will be available before the end of Spring Break.})

\begin{solution}
We let $G$ and $G'$ be as in the previous part and distinguish the same
cases.

\textbf{Case} \emph{Operation~\ref{del}}: We delete an edge, so $e$ decreases
by 1 and $v$ remains the same, so it suffices to show that $g$ remains the same.
By our definition of the deletion operation, we only delete an edge if another path
will remain between its endpoints after it is removed, so the deleted edge cannot
be a generalized covering edge.

\textbf{Case} \emph{Operation~\ref{add}}: We add an edge, so $e$ increases by 1 and
again $v$ remains the same, meaning we must show that $g$ also increases by 1 to show
strict decrease of $v+e-2g$.  We only add an edge if there is no connection between our
two endpoints, so by definition the added edge will be a generalized covering edge.

Hence, $v+e-2g$ is strictly decreasing, nonnegative integer valued derived
variable, which implies the procedure always terminates.

This proof is more informative because the $v$, $e$ and $g$ for a starting
graph give us the information that the procedure will terminate in at most
$v+e-2g$ steps.  The argument using well-founded of lexicographic order gave
no bound on the number of steps until termination.
\end{solution}

\eparts

A \emph{line graph} is a graph whose edges can all be traversed by a
simple path.  For example, the two-ended graph below is a line graph of
length 4.

\mfigure{!}{0.75in}{figures/ps4-path}

\bparts
\ppart\label{lineg}
Prove that for any finite, $G$, the procedure terminates with a line graph
with the same vertices as $G$.

\begin{solution}
To prove that $H$ is a line graph, it is sufficient to prove
  that (1)~$H$ is acyclic, (2)~$H$ is connected, and (3)~every vertex in
  $H$ has in-degree and out-degree at most ~1. (Why is this sufficient?)
  The proof follows from the definition of the termination condition.

  In order for the procedure to terminate, there are no two vertices $u
  \neq v$ to which an operation applies. We prove each property by
  contradiction.
\begin{enumerate}

\item Assume $H$ has a cycle at termination. Then there exist two adjacent
  vertices $u$, $v$, with an edge $(u,v)$ between them. By the definition
  of cycle, there is also another path $\pi$ from $v$ to $u$ that does not
  traverse $(u,v)$, so \emph{Operation~\ref{del}} applies. This
  contradicts the condition for termination, so $H$ is acyclic.

\item Assume $H$ is not connected at termination. Then by definition of
  connected, there exist two vertices $u, v$ that are not connected by a
  directed path, so \emph{Operation~\ref{add}} applies. This contradicts
  the condition for termination, so $H$ is connected.

\item Assume there exists a vertex in $H$ with in-degree or out-degree
  greater than 1. If the vertex $u$ has in-degree of 2 or more, then $H$
  contains at least two distinct edges $(u,v)$ and $(u',v)$, where there
  exists a path $\pi$ between $u$ and $u'$ by Claim~(2).

\begin{itemize}

\item If $\pi$ goes from $u$ to $u'$ through $v$, then there is a cycle
  $v,\ldots,u',v$, contradicting Claim~(1).

\item Otherwise, $\pi$ does not visit $v$ and there is a path
  $u,\ldots,u',v$ that does not traverse $(u,v)$, so
  \emph{Operation~\ref{del}} applies, contradicting the condition for
  termination.
\end{itemize}

A similar argument applies for out-degree of 2 or more. Therefore, every
vertex in $H$ has in-degree and out-degree of at most 1.
\end{enumerate}


\end{solution}

\ppart Prove that $G$ being a DAG is a preserved invariant of the procedure.

\begin{solution}
Deleting an edge cannot create a cycle, and neither can adding
  an edge between unconnected vertices.  So if there was no cycle in $G$,
  there wouldn't be any after one state transition.  
\end{solution}

\ppart Prove that if $G$ is a DAG, then the path relation of the final line
graph is a topological sort of $G$.

\hint Verify that the predicate
\[
P(u,v)\eqdef \text{there is a directed path from $u$ to $v$}
\]
is a preserved invariant of the procedure, for any two vertices $u,v$ of a DAG.

\begin{solution}
\begin{proof}
  To prove $P(u,v)$ is an invariant, suppose $P(u,v)$ holds in $G$ and
  consider the two operations that the procedure might perform:

  \textbf{Case} \emph{Operation~\ref{del}}: Suppose the edge-deletion
  operation~\ref{del} is applied to an edge $(x,y)$ in $G$, yielding a
  digraph $G'$.

Now by definition of the condition for applying the edge-deletion
operation, there must be a directed path, $\pi$, between $x$ and $y$ which
is in both $G$ and $G'$. This directed path must start at $x$ and end at
$y$ (if it went from $y$ to $x$, together with $(x,y)$ it would have
formed a directed cycle $(y,\ldots,x,y)$ in $G$, contrary to the fact that
$G$ is a DAG).

\begin{itemize}

\item If the path from $u$ to $v$ does not traverse $(x,y)$, then it
  remains in $G'$, proving that $P(u,v)$ still holds in $G'$.

\item If the path from $u$ to $v$ \emph{does} traverse $(x,y)$, then
  removing $(x,y)$ and replacing it with the other path $\pi$ yields a
  path in $G'$ from $u$ to $v$, proving that $P(u,v)$ still holds in $G'$.
\end{itemize}

This completes the proof that $P$ is preserved by the edge-deletion
operation~\ref{del}.

\textbf{Case} \emph{Operation~\ref{add}}: Adding an $(x,y)$ to a graph
preserves all previously existing paths, so $P(u,v)$ will hold in $G'$.
So the edge adding operation~\ref{add} preserves $P$

We conclude that $P(u,v)$ is indeed a preserved invariant of the
procedure.

From part~\eqref{lineg}, the final graph is a line graph, which implies
that its path relation, $L^*$, is a total order.  Also, if $G$ is a DAG,
then its path relation, $G^*$, is a partial order.  Then $L^*$ is a
topological sort of $G^*$ means that $u\,G^*\,v$ implies $u\,L^*\,v$ for
all vertices $u,v$.

But $u\,G^*\,v$ is equivalent to $P(u,v)$ holding in $G$.  So by
invariance, $u\,G^*\,v$ implies $P(u,v)$ holds in the final line graph,
that is, $u\,L^*\,v$, as required.
\end{proof}
\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: F06.ps8}
\end{pcomments}

\pkeywords{
   %I don't know the format for these keywords, how do I look them up?
	recursion
        linear recurrence
        plug_and_chug
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem} %from Leighton's PS8
Less well-known than the Towers of Hanoi--- but no less fascinating---
are Towers of Sheboygan, WI.  As in Hanoi, the puzzle in Sheboygan
involves 3 posts and $n$ disks of different sizes.  Initially, all the
disks are on post \#1:

\begin{center}
\unitlength=0.6pt
\begin{picture}(600,190)(0,-30)
% \put(0,-30){\dashbox(600,190){}} % bounding box

\put(99,0){\dashbox(2,140){}}
\put(99,140){\framebox(2,20){}}
\put(30,0){\framebox(140,20){}}
\put(40,20){\framebox(120,20){}}
\put(50,40){\framebox(100,20){}}
\put(60,60){\framebox(80,20){}}
\put(70,80){\framebox(60,20){}}
\put(80,100){\framebox(40,20){}}
\put(90,120){\framebox(20,20){}}
\put(299,0){\framebox(2,160){}}
\put(499,0){\framebox(2,160){}}
\put(0,-5){\framebox(600,5){}}
\put(100,-20){\makebox(0,0){Post \#1}}
\put(300,-20){\makebox(0,0){Post \#2}}
\put(500,-20){\makebox(0,0){Post \#3}}
\end{picture}
\end{center}

The objective is to transfer all $n$ disks to post \#2 via a sequence
of moves.  A move consists of removing the top disk from one post and
dropping it onto another post with the restriction that a larger disk
can never lie above a smaller disk.  Furthermore, a local ordinance
requires that \textit{a disk can be moved only from post \#1 to post
\#2, from \#2 to \#3, or from \#3 to \#1.}  Thus, for example, moving
a disk directly from post \#1 to post \#3 is not permitted.
\end{problem}

\bparts
\ppart Briefly describe a solution to the Towers of Sheboygan puzzle.

\begin{solution} 
Use a recursive procedure: to move an initial stack of $n$
blocks to the next post, move the top stack of $n-1$ disks to the furthest
post by moving it to the next post two times, then move the big, $n$th
disk to the next post, and finally move the top stack another two times to
land on top of the big disk.

This procedure leads to a simple linear recurrence, and gets full credit
as an answer.  But it turns out not to be the most efficient procedure for
moving the stack.

Namely, a better (indeed optimal, but we won't prove this) procedure can
be defined in terms of two mutually recursive procedures, procedure
$P_1(n)$ for moving a stack of $n$ disks 1 pole forward, and $P_2(n)$
for moving a stack of $n$ disks 2 poles forward.  It's obvious how to do
this for $n=1$.  For $n>1$, define:

$P_1(n)$: Apply $P_2(n-1)$ to move the top $n-1$ disks two poles forward
to the third pole.  Then move the remaining big disk once to land on
the second pole.  Then apply $P_2(n-1)$ again to move the stack of $n-1$
disks two poles forward from the third pole to land on top of the big
disk.

$P_2(n)$: Apply $P_2(n-1)$ to move the top $n-1$ disks two poles forward
to land on the third pole.  Then move the remaining big disk to the second
pole.  Then apply $P_1(n-1)$ to move the stack of $n-1$ disks one pole
forward to land on the first pole.  Now move the big disk 1 pole forward
again to land on the third pole.  Finally, apply $P_2(n-1)$ again to move
the stack of $n-1$ disks two poles forward to land on the big disk.
\end{solution} 

\ppart Let $S_n$ be the number of moves needed to solve the $n$-disk
problem.  Express $S_n$ with a recurrence equation and sufficient base
cases.

\begin{solution} 
For the first procedure, we have
\begin{align}
S_1 & = 1,\notag\\
S_n & = 2S_{n-1} + 1 + 2S_{n-1} = 4S_{n-1} + 1 & \text{for }n > 1\label{4S}.
\end{align}

For the second procedure, in addition to the number, $S_n$, of steps to
move a stack of $n$ disks one pole forward a stack of $n$, let 
$T_n$ be the number of steps to move a stack of $n$ disks two poles
forward.  From the definitions of procedures $P_1$ and $P_2$ we have
\begin{align}
S_1 & = 1,\notag\\
T_1 & = 2,\notag\\
S_n & = T_{n-1} + 1 + T_{n-1} & \text{for } n > 1,\label{ST}\\
T_n & = T_{n-1} + 1 + S_{n-1} + 1 + T_{n-1} & \text{for } n > 1.\label{TT}
\end{align}
From these equations we first calculate that $T_2=7$.  Then,
using~\eqref{ST} to substitute for $S_{n-1}$ in~\eqref{TT}, we conclude
that for $n > 2$,
\begin{equation}\label{Trec}
T_n = 2T_{n-1} + 2 + (2T_{n-2} +1) = 2T_{n-1} + 2T_{n-2} + 3.
\end{equation}
\end{solution} 

\ppart Find a closed-form expression for $S_n$ by solving the
recurrence.

\begin{solution} 
For recurrence~\eqref{4S}, Plug \& Chug works nicely:
\begin{align*}
S_{n} & = 4S_{n-1} + 1\\
      & = 4(4S_{n-2}+1) + 1\\
      & = 4^2 S_{n-2} + 4 + 1\\
      & = 4^2 (4S_{n-3}+1) + 4 + 1\\
      & = 4^3 S_{n-3}+ 4^2 + 4 + 1 = \dots\\
      & = 4^{n-1} S_1 + 4^{n-2} + \dots + 4^2 + 4 + 1\\
      & = 4^{n-1} + (4^{n-1}-1)/3\\
      & = \frac{4^n - 1}{3}
\end{align*}

For recurrence~\eqref{Trec}, we apply the general approach for
inhomogeneous linear recurrences: the characteristic polynomial is $x^2 -
2x - 2 $ with roots $1 \pm \sqrt{3}$, so the general solution to the
homogenous part of~\eqref{Trec} is
\[
A(1 + \sqrt{3})^n + B(1 - \sqrt{3})^n.
\]

Since the inhomogeneous term of~\eqref{Trec} is constant, we guess that a
particular solution will be some constant, $c$.  This requires that $c =
2c + 2c + 3$, namely, $c=-1$.  So the most general solution
to~\eqref{Trec} is of the form
\begin{equation}\label{AB}
A(1 + \sqrt{3})^n + B(1 - \sqrt{3})^n - 1.
\end{equation}
Now we use the boundary conditions $T_1 =2, T_2 = 7$ and~\eqref{AB} to
obtain linear equations in $A$ and $B$:
\begin{align*}
A(1 + \sqrt{3}) + B(1 - \sqrt{3}) - 1 & = 2\\
A(1 + \sqrt{3})^2 + B(1 - \sqrt{3})^2 - 1 & = 7.
\end{align*}


Solving these equations, we find $A = (3+2\sqrt{3})/6$ and $B =
(3-2\sqrt{3})/6$, so
\[
T_n = \frac{3+2\sqrt{3}}{6} (1 + \sqrt{3})^n + \frac{3-2\sqrt{3}}{6} (1 - \sqrt{
3})^n
      -1.
\]
Now using~\eqref{ST}, we conclude that
\[
S_n = \frac{3+2\sqrt{3}}{3}(1 + \sqrt{3})^{n-1} + \frac{3-2\sqrt{3}}{3}(1 - \sqr
t{3})^{n-1} - 1.
\]
In particular, we conclude that $S_n = \Theta((1+ \sqrt{3})^n) = o(4^n)$,
so the second procedure for moving a stack of $n$ disks is vastly more
efficient thah the first one.
\end{solution}

\eparts


%PStranslate_sentence_into_predicate_formula

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S06.ps1}
\end{pcomments}

\pkeywords{
  predicate
formula
translate
sentence
first-order logic
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Translate the following sentence into a predicate formula:
\begin{quote}
There is a student who has e-mailed at most two other people in the class,
besides possibly himself.
\end{quote}

The domain of discourse should be the set of students in the class; in
addition, the only predicates that you may use are 
\begin{itemize}
\item equality, and
\item $E(x,y)$, meaning that ``$x$ has sent e-mail to $y$.''
\end{itemize}


\begin{solution}
A good way to begin tackling this problem is by trying to translate parts
of the sentence. First of all, our formula must be of the form
\[
\exists x. P(x)
\]
where $P(x)$ should be a formula that says that ``student $x$ has
e-mailed at most two other people in the class, besides possibly
himself''.

One way to write $P(x)$ is to write that ``whenever we meet a student
that has been e-mailed by $x$, this student is either $x$ himself or
$y$ or $z$, where $y$ and $z$ are two students in the class.''

To write the part ``whenever we meet a student that has been e-mailed
by $x$, this student is either $x$ himself or $y$ or $z$'' we write
\[
\forall s.
E(x,s) 
\QIMPLIES
s=x \QOR
s=y \QOR
s=z.
\]
The part ``where $y$ and $z$ are two students in the class'' simply
means that there exist two such students; so by adding the appropriate
existential quantifiers, we get
\[
P(x)::=\quad
\exists y.
\exists z.\;\;
\forall s.
E(x,s) 
\QIMPLIES
s=x \QOR
s=y \QOR
s=z
\]
At this point you may be thinking that $P(x)$ says that ``$x$ has
e-mailed \emph{exactly} two students besides possibly
himself''. However, note that we did not require that $y$ and $z$ be
distinct, or that they be different from $x$.  So, our formula 
describes all possibilities: 
\begin{itemize}
\item $x$ and exactly 2 other students: $x\neq y$, $x\neq z$, $y\neq z$.
\item $x$ and exactly 1 other student: $x\neq y$ $x\neq z$, $y=z$.
\item $x$ and no other student: $x=y=z$.
\end{itemize}
Overall the full formula is:
\[
\exists x.\;\;
\exists y.
\exists z.\;\;
\forall s.
E(x,s) 
\QIMPLIES
s=x \QOR
s=y \QOR
s=z.
\]
\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: F09.ps2}
  \pcomment{from: S03.ps4}
\end{pcomments}

\pkeywords{
  logic
  predicate_calculus
  domain_of_discourse
  translating_english_statements
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Translate the following statements into predicate logic.  For
each, specify the domain of discourse.  In addition to logic symbols,
you may build predicates using arithmetic, relational symbols and
constants.  For example, the statement ``$n$ is an odd number'' could
be translated as $\exists m (2m+1 = n)$ where the domain of discourse
is $\mathbb{Z}$, the set of integers.

\bparts
\ppart 
(Lagrange's Four-Square Theorem) Every natural number is
expressible as the sum of four perfect squares.

\begin{solution}
The domain of discourse is $\mathbb{N}$.

\[
\forall n \exists w \exists x \exists y \exists z (n = w^2 + x^2 + y^2 + z^2)
\]

\end{solution}

\ppart
(Goldbach Conjecture) Every even integer greater than two
is the sum of two primes.

\begin{solution}
The domain of discourse is $\mathbb{N}$.

Denote $prime(p)$ as 
\[
(p > 1)
\wedge
\neg \left( \exists m \exists n (m > 1 \wedge n > 1 \wedge mn = p) \right)
\]

the statement could be translated as 

\[
\forall n 
\left(
((n > 2) \wedge \exists m (n = 2m)) \rightarrow \exists p \exists q (prime(p) \wedge prime(q) \wedge (n = p + q))
\right)
\]
\end{solution}

\ppart
The function $f : \mathbb{R} \mapsto \mathbb{R}$ is
continuous.

\begin{solution}
The domain of discourse is $\mathbb{R}$

\[
\forall a \forall x \exists b \forall y
\left(
(a > 0 \wedge b > 0 \wedge |x-y| < b) \rightarrow |f(x) - f(y)| < a
\right)
\]
\end{solution}

\ppart
(Fermat's Last Theorem) There are no nontrivial solutions
to the equation:

\[
x^n + y^n = z^n
\]

over the natural numbers when $n > 2$.

\begin{solution}
The domain of discourse is $\mathbb{N}$.

\[
\forall x \forall y \forall z \forall n
\left(
(x > 0 \wedge y > 0 \wedge z > 0 \wedge n > 2)
\rightarrow
\neg (x^n + y^n = z^n)
\right)
\]
\end{solution}

\ppart
There is no largest prime number.

\begin{solution}
The domain of discourse is $\mathbb{Z}$.

\[
\neg \left(\exists p (Prime(p) \wedge (\forall q (Prime(q) \implies p \geq q)))
\right)
\]
\end{solution}

\ppart
(Bertrand's Postulate) If $n > 1$, then there is always
at least one prime $p$ such that $n < p < 2n$.

\begin{solution}
The domain of discourse is $\mathbb{Z}$.
\[
\forall n
\left( (n > 1) \implies (\exists p ( Prime(p)  \wedge (n < p) \wedge (p < 2n))) 
\right)
\]
\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{spring02 pset4-2}
\end{pcomments}

\pkeywords{
 graph theory
}


\begin{problem}
We provide an alternative definition for a tree.

{\em Definition:} A {\em tree} is a connected graph such that
$\forall u,v \in V$, there is a unique path connecting $u$ to $v$.

Prove that this definition is equivalent to the one that defines a tree
to be an acyclic graph of $n$ vertices that has $n-1$ edges.

\begin{solution}
Let $G$ be a graph  of $n$ vertices such that
$\forall u,v \in V$, there is a unique path connecting $u$ to $v$.

First we show that $G$ is acyclic.
Suppose, for the purposes of contradiction, that $G$ has a cycle.
Pick two vertices $u$ and $v$ on the cycle.  Then there are at least
two paths connecting $v$ and $u$, contradicting the uniqueness assumption.
So $G$ is acyclic.

Also we note that the existence of paths between every two vertices
 implies that
$G$ is connected.  So $G$ is a connected acyclic graph, and from class
we know that it has $n-1$ edges.

Conversely, let $G$ be an acyclic graph with $n$ vertices and $n-1$ edges.
We know from class that such a graph is connected so there exists at least 
one path between any two vertices.

Suppose, for the purposes of contradiction, that there are two distinct
paths $C$ and $C'$ connecting the vertices $u$ and $v$. 
Starting at $u$ consider the first vertex $u'$ where $C$ differs 
from $C'$ (such a vertex exists because the graphs are distinct).  
Also consider the first vertex $v'$ where $C$ and $C'$ meet again
(such a vertex exists because both paths end at $v$).  Then there is a
simple cycle that starts at $u'$ follows $C$ until it reaches $v'$ and
returns to $u'$ following $C'$.
This contradicts the acyclicity of the graph.


\end{solution}

\end{problem} 
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps6}
\end{pcomments}

\pkeywords{
  planar_graphs
  handshaking
  graph_coloring
  strong_induction
  induction_on_graphs
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem} A simple graph is \emph{triangle-free} if it 
  has no subgraphs isomorphic to $K_3$.

\bparts

\ppart\label{e2v4} While a triangle-free graph is not necessarily bipartite, 
  explain why the result $e \leq 2v - 4$ still holds for any connected 
  triangle-free planar graph with $v>2$ vertices and $e$ edges.

\begin{solution}
The proof that $e \leq 2v - 4$ for any connected triangle-free 
  planar graph $G$ with more than two vertices is identical to the proof 
  of the same inequality for bipartite graph planar graphs which appealed 
  to the fact that any bipartite graph is triangle-free.
\end{solution}

\ppart\label{triangle-free} Show that any connected triangle-free planar 
  graph has at least one vertex of degree three or less.

\begin{solution}
If $v \leq 4$, \emph{all} vertices have degree at most three,
  so the claim is immediate for $v\leq 4$.

  Also, by the Handshaking Lemma, the sum of degrees is $2e$ so the average
  degree is $2e/v$.  By part~\eqref{e2v4}, $2e/v \leq (4v-8)/v < 4$ for
  $v>2$.  But the average degree can be less than 4 only if at least one
  vertex has degree less than 4.

  It follows that for all $v > 0$, there is a vertex of degree three or
  less.
\end{solution}

\ppart Prove by induction on the number of vertices that any connected 
  triangle-free planar graph is 4-colorable.

  \hint use part \eqref{triangle-free}.

\begin{solution}
\mbox{}

  \begin{proof} By strong induction on the number of vertices with the
  induction hypothesis that if a graph is connected, planar and 
  triangle-free then it is 4-colorable.

  {\bf base case:} A planar graph with a single vertex is trivially 
  connected, triangle-free and 1-colorable.

  {\bf inductive step:} Any connected triangle-free planar graph
  $G$ with 2 or more vertices has a vertex of degree 3 or less. 
  Removing this vertex and any incident edges results in a graph 
  $H$ whose connected components are subgraphs of a planar graph 
  and therefore planar. They are also triangle-free since removing 
  vertices/edges from a graph with no triangles cannot create 
  triangles. Since the components have strictly fewer vertices than $G$, 
  the induction hypothesis implies each connected component is 
  4-colorable and thus $H$ is 4-colorable.

  A 4-coloring of $G$ is then given by a 4-coloring of $H$ where the 
  removed vertex is colored with a color not used for the (at most 3) 
  adjacent vertices. \end{proof}
\end{solution}

\eparts

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%PS_unit_interval

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S09.ps2, revised by ARM 9/19/09}
\end{pcomments}

\pkeywords{
  bijection
  surjections
  real plane
  unit interval
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem} In this problem you will prove a fact that may surprise
  you ---or make you even more convinced that set theory is nonsense: the
  half-open unit interval is actually the \emph{same size} as the
  nonnegative quadrant of the real plane!\footnote{The half open unit
    interval, $(0,1]$, is $\set{r \in \reals
      \suchthat 0 < r \leq 1}$.  Similarly, $[0,\infty) \eqdef \set{r \in
      \reals \suchthat r \geq 0}$.}  Namely, there is a bijection
  from $(0,1]$ to $[0,\infty)^2$.

\bparts

\ppart\label{real-quadrant} Describe a bijection from $(0,1]$ to $[0,
\infty)$.

\hint $1/x$ almost works.

\begin{solution}
$f(x) \eqdef 1/x$ defines a bijection from $(0,1]$ to $[1, \infty)$, so
$g(x) \eqdef f(x) -1$ does the job.
\end{solution}

\ppart\label{surjection2a} An infinite sequence of the decimal digits
$\set{\texttt{0},\texttt{1},\dots,\texttt{9}}$ will be called \emph{long}
if it has infinitely many occurrences of some digit other than 0.  Let $L$
be the set of all such long sequences.  Describe a bijection from $L$ to
the half-open real interval $(0,1]$.

\hint Put a decimal point at the beginning of the sequence.

\begin{solution}
Putting a decimal point in front of a long sequence defines a
  bijection from $L$ to $(0,1]$.  This follows because every real number
in $(0,1]$ has a unique long decimal expansion.  Note that if we didn't
  exclude the non-long sequences, namely, those sequences ending with all
  zeroes, this wouldn't be a bijection.  For example, the sequences
  \texttt{1000}\dots and \texttt{099999}\dots would both map to the same
  real number, namely, $1/10$.
\end{solution}

\ppart\label{surjection2b} Describe a surjective function from $L$ to
$L^2$ that involves alternating digits from two long sequences.  a \hint
The surjection need not be total.

\begin{solution}
Given any long sequence $s = x_0, x_1, x_2, \dots$, let
\[
h_0(s) \eqdef x_0,x_2, x_4, \dots
\]
be the sequence of digits in even positions.  Similarly, let
\[
h_1(s) \eqdef x_1, x_3, x_5, \dots
\]
be the sequence of digits in odd positions.  Then $h$ is a surjective
function from $L$ to $L^2$, where
\begin{eqnarray}
h(s) \eqdef \begin{cases}
  (h_1(s),h_2(s)), &  \text{if $h_1(s) \in L$ and $h_2(s) \in L$,}\\
  \text{undefined}, & \text{otherwise.}
 \end{cases}
\end{eqnarray}

\end{solution}

\ppart\label{surjection2c} Prove the following lemma and use it to
conclude that there is a bijection from $L^2$ to $(0,1]^2$.

\begin{lemma}\label{product-map}
  Let $A$ and $B$ be nonempty sets.  If there is a bijection from $A$
  to $B$, then there is also a bijection from $A \times A$ to $B \times
  B$.
\end{lemma}

\begin{solution}
\begin{proof}
  Suppose $f : A \to B$ is a bijection.  Let $g : A^2 \to B^2$ be the
  function defined by the rule $g(x,y) = (f(x),f(y))$.  It is easy to show
  that $g$ is a bijection:

\begin{itemize}
\item \textbf{$g$ is total}: Since $f$ is total, $f(a_1)$ and $f(a_2)$ exist
$\forall a_1, a_2 \in A$ and so $g(a_1,a_2) = (f(a_1), f(a_2))$ also exists.

\item \textbf{$g$ is surjective}: Since $f$ is surjective, for any $b_i
  \in B$ there exists $a_i \in A$ such that $b_i = f(a_i)$.  So for any
  $(b_1,b_2)$ is $B^2$, there are is a pair $(a_1,a_2) \in A^2$ such that
  $g(a_1,a_2) \eqdef (f(a_1),f(a_2)) = (b_1,b_2)$.  This shows that $g$ is
  a surjection.

\item \textbf{$g$ is injective}:
\begin{align*}
  g(a_1,a_2) = g(a_3,a_4) &\qiff (f(a_1),f(a_2)) = (f(a_3),f(a_4))
       & \text{(by def of $g$)}\\
  &\qiff f(a_1) = f(a_3) \QAND f(a_2) = f(a_4)\\
  &\qiff a_1 =a_3 \QAND a_2 = a_4 \text{(since $f$ is injective)}\\
  & (a_1,a_2) = (a_3,a_4),
 \end{align*}
which confirms that $g$ is injective.
\end{itemize}
\end{proof}

Since it was shown in part~\eqref{surjection2a} that there is a bijection
from $L$, to $(0,1]$, an immediate corollary of Lemma \ref{product-map} is
that there is a bijection from $L^2$ to $(0,1]^2$.
\end{solution} 


\ppart\label{01012} Conclude from the previous parts that there is a
surjection from $(0,1]$ and $(0,1]^2$.  Then appeal to the
Schr\"oder-Bernstein Theorem to show that there is actually a bijection
from $(0,1]$ and $(0,1]^2$.

\begin{solution}
  There is a bijection between $(0,1]$ and $L$ by
  part~\eqref{surjection2a}, a surjective function from $L$ to $L^2$ and
  by part~\eqref{surjection2b}, and a bijection from from $L^2$ to
  $(0,1]^2$ by part~\eqref{surjection2c}.  These jections compose to yield
  a surjection from $(0,1]$ to $(0,1]^2$.

  Conversely, there is obviously a surjective function $f: (0,1]^2 \to (0,1]$, namely
  \[
   f(\ang{x,y}) \eqdef x.
  \]

  The Schr\"oder-Bernstein Theorem now implies that there is a bijection
  from $(0,1]$ to $(0,1]^2$.
\end{solution}

\ppart Complete the proof that there is a bijection from $(0,1]$ to
$[0,\infty)^2$.

\begin{solution}
  There is a bijection from $(0,1]$ to $(0,1]^2$ by part~\eqref{01012},
  and there is a bijection from $(0,1]^2$ to $[0,\infty)^2$ by
  parts~\eqref{real-quadrant} and Lemma\ref{product-map}.  These
  bijections compose to yield a bijection from $(0,1]$ to $[0,\infty)^2$.
\end{solution}

\eparts
\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: S06.ps1}
\end{pcomments}

\pkeywords{
  validity
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}  Prove that
\[  %\begin{equation}\label{v}
[\forall x.\; \neg P(x)] \implies \neg \exists z.\; P(z).
\]  %\end{equation}
is valid.  (Use the validity proof from the subsection on Validity in
the Course Notes, namely section 5.1.5, as guides to writing your proof.)

\begin{solution}
\begin{proof}
Assume
\begin{equation}\label{eq:1}
\forall x.\; \neg P(x).
\end{equation}

Now we prove by contradiction that $ \neg \exists z.\; P(z)$ holds.
Namely, we assume $\exists z.\; P(z)$ and reach a contradiction.

So suppose $\exists z.\; P(z)$ holds.  So there is an element, $c$,
such that $P(c)$.  But from~\eqref{eq:1}, we know that $\neg P(c)$
holds, contradicting the fact that $P(c)$ holds.  Hence, the
assumption $\exists z.\; P(z)$ must be false, that is, $\neg \exists
z.\; P(z)$ is true.
\end{proof}
\end{solution}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: F07.ps2}
\end{pcomments}

\pkeywords{
  partial_order
  weak_partial_order
  reflexive
  antisymmetric
  transitive
  subset
  isomorphic
  inverse_image
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\prinv}[1]{\text{L}#1}

\begin{problem}
This problem asks for a proof of Notes Lemma~\ref{rgb}:

Let $\preceq$ be a weak partial order on a set, $A$.  For any element $a
\in A$, let
\[
\prinv(a) \eqdef \set{b \in A \suchthat b \preceq a}.
\]
That is, $\prinv(a)$ is the inverse image of $a$ under the $\preceq$
relation.\footnote{We already have a notation for $\prinv(a)$, namely,
  $(\preceq\set{a})$, but this looks funny.}
Let $\mathcal{L}$ be the set of such inverse images, that is,
\[
\mathcal{L} \eqdef \set{\prinv(a) \suchthat a \in A}.
\]
Then the function $\prinv{}:A \to \mathcal{L}$ is an isomorphism from the
$\preceq$ relation on $A$, to the subset relation on $\mathcal{L}$.

\bparts

\ppart
Prove that the function $\prinv{}:A \to \mathcal{L}$ is a bijection.

\begin{solution}
  By definition, $\prinv{}$ is a surjective function onto $\mathcal{L}$.
  So all we have to do is prove it is an injection.  To prove this,
  suppose $\prinv(a) = \prinv(b)$.  Now since $a \in \prinv(a)$ by
  reflexivity, we also have $a \in \prinv(b)$.  This means $a \preceq b$.
  Likewise, $b \preceq a$.  Hence $a=b$, by antisymmetry.
\end{solution}

\ppart Complete the proof by showing that
\begin{equation}\label{apbiff}
a \preceq b  \qiff  \prinv(a) \subseteq \prinv(b)
\end{equation}
for all $a,b \in A$.

\begin{solution}
  For the left-to-right direction, suppose $a \preceq b$.  To prove that
  $\prinv(a) \subseteq \prinv(b)$, suppose $c \in \prinv(a)$, which means
  that $c \preceq a$.  So by transitivity, $c \preceq b$, which means $c
  \in \prinv(b)$.  Hence every $c \in \prinv(a)$ is also in $\prinv(b)$,
  which proves containment.

  For the right-to-left direction, suppose $\prinv(a) \subseteq
  \prinv(b)$.  But $a \in \prinv(a)$ by reflexivity, so $a \in \prinv(b)$,
  which means that $a \preceq b$.

\iffalse
%elegant, but harder to follow:

\begin{align*}
a \preceq b
  & \qiff \forall c \in A.\, c \preceq a \QIMPLIES c \preceq b 
           & \text{(because $a \preceq a$)}\\
  & \qiff \forall c \in A.\, c \in \prinv(a) \QIMPLIES c \in \prinv(b)
           & \text{(def of $\prinv$)}\\
  & \qiff \prinv(a) \subseteq \prinv(b)
\end{align*}
\fi

\end{solution}

\eparts
\end{problem}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{by ARM 9/24/09 from partial order notesproblem}
\end{pcomments}

\pkeywords{Chain
           anti-chain
           partial_order}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
  What is the size of the longest chain that is guaranteed to exist in any
  partially ordered set of $n$ elements?  What about the largest
  antichain?

\begin{solution}
For $n>0$, chain size is 1 in the ``discrete'' partial order in
which every two different elements are incomparable.  Antichain size is 1
if $n>0$ and the partial order is total.
\end{solution}
\end{problem}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
\documentclass[problem]{mcs}

%TP_inverse_relation_table.tex

\begin{pcomments}
  \pcomment{from: excerpted from CP_relational_properties_table
            do not use with that problem}

%  \pcomment{}
\end{pcomments}

\pkeywords{
  relations
  total
  relational_properties
  functions
  injections
  surjections
  bijections
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
  The \term{inverse}, $\inv{R}$, of a binary relation, $R$, from $A$ to
  $B$, is the relation from $B$ to $A$ defined by:
\[
b \mrel{\inv{R}} a \qiff a \mrel{R} b.
\]
In other words, you get the diagram for $\inv{R}$ from $R$ by ``reversing
the arrows'' in the diagram describing $R$.  Now many of the relational
properties of $R$ correspond to different properties of $\inv{R}$.  For
example, $R$ is an \emph{total} iff $\inv{R}$ is a \emph{surjection}.

Fill in the remaining entries is this table:
\begin{center}
\begin{tabular}{l|cl}
$R$ is  & iff & $\inv{R}$ is \\ \hline
total                    && a surjection\\
a function\\
a surjection\\
an injection\\
a bijection
\end{tabular}
\end{center}

\hint Explain what's going on in terms of ``arrows'' from $A$ to $B$ in
the diagram for $R$.

\begin{solution}\mbox{}

\begin{center}
\begin{tabular}{l|cl}
$R$ is  & iff & $\inv{R}$ is \\ \hline
total                    && a surjection\\
a function               && \insolutions{an injection}\\
a surjection             && \insolutions{total}\\
an injection             && \insolutions{a function}\\
a bijection              && \insolutions{a bijection}
\end{tabular}
\end{center}

\end{solution}

\end{problem}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
%TP_mating_ritual_invariant

\documentclass[problem]{mcs}

\begin{pcomments}

  \pcomment{from F07.miniquiz-oct12 edited by ARM 10/3/09}
\end{pcomments}

\pkeywords{
 stable_matching
 Mating_ritual
 invariant}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem} Circle all of the properties below that are preserved
  invariants of the \emph{Mating Ritual}.  Assume that the numbers of boys
  and girls are the same, and that Harry is one of the boys and Alice is
  one of the girls.

\begin{itemize}

\item[a.] Alice is the only girl on Harry's list.

\item[b.] There is a girl who does not have any boys serenading her.

\item[c.] If Alice is not on Harry's list, then Alice has a suitor that
  she prefers to Harry.

%\item[d.] All the boys have the same number of girls left uncrossed in their list. 

\item[d.] Alice is crossed off Harry's list and Harry prefers Alice to anyone
  he is serenading.

\item[e.] % obscure & probably too tricky

If Alice is on Harry's list, then she prefers to Harry to any suitor
  she has.

\end{itemize}

\begin{solution}

The 1st, 3rd, and 5th are preserved invariants.

\begin{enumerate}

\item[a.] Invariant; no girl will be added to Harry's list. If Alice got
crossed off, there would be no one for Harry to marry.  So she must
remain as the sole girl on his list.

\item[b.] Not invariant; a girl may not have a suitor on the first day, ---if,
for example, she's not at the top of any boy's list ---but every girl is
guaranteed to have one at the end, namely, her husband.

\item[c.] Invariant; this is the basic invariant used to verify
the Ritual.

\item[d.] Invariant; Harry crosses off the girls in his order of
preference, so if Alice is crossed off, Harry likes her better than
anybody that's left.

\item[e.] Not invariant.  Suppose the preference among two couples are

\begin{tabular}{lccc}
Harry:& Alice, & Elvira\\
Billy:& Elvira, & Jenny, & Alice\\
Wilfred: & Elvira, & Jenny, & Alice\\
Alice:& Billy, & Wilfred, & Harry\\
Elvira:& Harry, & Wilfred, & Billy
\end{tabular}

The alleged invariant is true on the first day since Harry is Alice's only
suitor.  But Elvira rejects Billy in favor of Wilfred on the first
afternoon, so on the second day, Billy and Harry are serenading Alice, and
since Alice prefers Billy to Harry, the alleged invariant is no longerr true.
\end{enumerate}

\end{enumerate}

\end{solution}

\end{problem}

\endinput
%TP_subsequence_of_101

\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{by ARM 9/24/09 from partial order notesproblem}
\end{pcomments}

\pkeywords{Chain
           anti-chain
           increasing_subsequence
           decreasing_subsequence}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
Describe a sequence consisting of the integers from 1 to 10,000 in some
order so that there is no increasing or decreasing subsequence of size
101.

\begin{solution}
\TBA{TBA}
\end{solution}
\end{problem}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
number_theory
Eulers_theorem
modular_arithmetic
RSA
quantifiers
predicate_calculus
domain_of_discourse
counter_model
translating_english_statements
root_2
irrational
rational
well-ordering
WOP
contradiction
binary
strings
logic
circuits
boolean
relations
relational_properties
partial_orders
recursive_data
trees
binary_trees
induction
structural_induction
strong_induction
ordinary_induction
mapping_lemma
functions
injections
surjections
bijections
Schroeder_Bernstein
scheduling
chains_and_antichains
minimal_vs_minimum
implies
set_theory
fun_game
Russells_paradox
proof_by_cases
primes
polynomials
faulty_reasoning
false_proof
series
Pulverizer
divides
remainders
congruence
gcd
lcm
linear_combinations
graphs
connectivity
trees
spanning_trees
state_machines
complete_graphs
paths
cycles
increasing_decreasing_variables
termination
environment
valid
satisfiable
postage_stamps
lexicographic
unreachable_states
partial_correctness
isomorphisms
buildup_error
degree
handshaking
chromatic_number
graph_coloring
bipartite_matching
degree-constrained
Halls_Theorem
planar_graphs
planar_embeddings
Eulers_formula
networks
digraphs
DAGs
covering_edges
transitive_closure
Euler_circuit
series
closed_form
harmonic_numbers
integral_method
asymptotics
Stirlings_formula
counting
counting_rules
truth_tables
games
Euler_circuits
bipartite
induction_on_graphs
topological_sort
permutations
prime_factorization
recurrences


                 
%%%%%%%%%%%%%%  Fall 2000  Problem Set 5    %%%%%%%%%%%%%%   %%%%%%%%%%%%%%%
\problem
% 5
% Matching, invariant
Consider an instance of the matching problem with $n$ boys and $n$
girls.  Call a person {\em unlucky} if he or she is matched up with
one of his or her $\floor{\frac{n}{2}}$ last choices.  In this
problem, we will prove the following: 
 
{\bf Theorem}  The matching algorithm from class never produces a
matching in which every person is unlucky.

Fix an execution of the matching algorithm.  Define the variables 
$B_i, G_i, i \in \{ 1, 2, \ldots, n \}$ as follows:
\begin{description}
\item $B_i = j$ if the $i$-th boy is currently courting the $j$-th girl
on his list
\item $G_i$ is the number of boys that the $i$-th girl has rejected.
\end{description}

\ppart
Show that $\sum_{i=1} ^n B_i - \sum_{i=1} ^n G_i$ is preserved at each
step of the matching algorithm.

\begin{solution}
\medskip
\textbf{Solution:}
Let $S = \sum_{i=1} ^n B_i - \sum_{i=1} ^n G_i$.  Suppose that at step
$t$, boy $b_i$ proposes to girl $g_j$.  There are three possible outcomes:

If $g_j$ has not had any previous proposals, she must accept.  In this
case, none of the $B_i$s and none of the $G_j$s change, so $S$ is preserved.

If $g_j$ rejects, then $G_j$ increases by 1, $B_i$ increases by 1, and
the other $B$s and $G$s remain the same.  $S$ is preserved again.

If $g_j$ accepts $b_i$ because she likes him better than her current
mate $b_{i'}$, then $G_j$ increases by 1, $B_{i'}$ increases by 1, and
the other $B$s and $G$s remain the same.  $S$ is preserved in this case
as well.

\end{solution}

\ppart
Formulate an invariant that you can use to prove the theorem, and 
show that your invariant is correct.

\begin{solution}
\medskip
\textbf{Solution:}
Let $P : S = n$.  In the initial state, this is true because everyone is
courting the first girl on their list.  From part (a) it follows that
all transitions preserve the truth value of $P$.  Therefore $P$ is an
invariant.

\end{solution}

\ppart
Use your invariant to prove the theorem.

\begin{solution}
\medskip
\textbf{Solution:}
We prove the statement by contradiction.  Consider a match M in which
every person is unlucky.  Then:
\begin{description}
\item For every $i \in \{ 1, \ldots, n \}$, 
$B_i \geq \ceil{\frac{n}{2}} + 1$, and
\item For every $i \in \{ 1, \ldots, n \}$,
$G_i \leq \floor{\frac{n}{2}} - 1$.
\end{description}

It follows that $\sum_{i=1} ^n B_i - \sum_{i=1} ^n G_i \geq 2n$.  This
violates the invariant $P$.

\end{solution}  
\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{from: Sxx.cpxx}
%  \pcomment{}
%  \pcomment{}
\end{pcomments}

\pkeywords{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endinput
