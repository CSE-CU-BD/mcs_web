\documentclass[problem]{mcs}

\begin{pcomments}
  \pcomment{CP_pairwise_independent_theorem}
  \pcomment{from: S09.cp14t, F07.rec15t}
\end{pcomments}

\pkeywords{
  pairwise_independent
  sampling
  variance
  law_of_large_numbers
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem starts here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}
	
The proof of the \idx{Pairwise Independent Sampling}
Theorem~\bref{th:pairwise-sampling} was given for a sequence $R_1,
R_2, \dots$ of pairwise independent random variables with the same
mean and variance.

The theorem generalizes straighforwardly to sequences of pairwise
independent random variables, possibly with \emph{different}
distributions, as long as all their variances are bounded by some
constant.

\begin{theorem*}[Generalized Pairwise Independent Sampling]
Let $X_1, X_2, \dots$ be a sequence of pairwise independent random
variables such that $\variance{X_i} \leq b$ for some $b\geq 0$ and all
$i\geq 1$.  Let
\begin{align*}
A_n & \eqdef \frac{X_1 + X_2 + \cdots + X_n}{n},\\
\mu_n & \eqdef \expect{A_n}.
\end{align*}
Then for every $\epsilon > 0$,
\begin{equation}\label{gpis}
\pr{\abs{A_n - \mu_n} > \epsilon} \leq \frac{b}{\epsilon^2} \cdot \frac{1}{n}.
\end{equation}
\end{theorem*}

\bparts
\ppart
Prove the Generalized Pairwise Independent Sampling Theorem.

\begin{solution}
Essentially identical to the proof of
Theorem~\bref{th:pairwise-sampling} in the text, except that $G$ gets
replaced by $X$ and $\variance{G_i}$ by $b$, with the equality where
the $b$ is first used becoming $\leq$.
\end{solution}

\ppart
Conclude that the following holds:
\begin{corollary*}[Generalized \idx{Weak Law of Large Numbers}]
For every $\epsilon > 0$,
\[
\lim_{n \rightarrow \infty}
        \pr{\abs{A_n - \mu_n}  \leq \epsilon} = 1.
\]
\end{corollary*}

\begin{solution}
\begin{align*}
\pr{\abs{A_n - \mu_n}  \leq \epsilon} = & 1- \pr{\abs{A_n - \mu_n}  >
 \epsilon}\\
   \geq & 1- b/(n\epsilon^2) & \text{(by~\eqref{gpis})},
\end{align*}
and for any fixed $\epsilon$, this last term approaches 1 as $n$
approaches infinity.
\end{solution}

\eparts

\end{problem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem ends here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\iffalse

\inhandout{\newpage}
\section*{Pairwise Independent Sampling}

Let $R$ be a random variable, and $a$ a constant. Then
\begin{equation}\label{a2R}
\variance{a R} = a^2 \variance{R}.
\end{equation}

\begin{theorem*}[Pairwise Independent Sampling]
Let $G_1, \dots, G_n$ be pairwise independent variables with the same
mean, $\mu$, and deviation, $\sigma$.  Define
\[
S_n \eqdef \sum_{i=1}^n G_i.
\]
Then
\[
\pr{\abs{\frac{S_n}{n} - \mu} \geq x}
    \leq \frac{1}{n} \paren{\frac{\sigma}{x}}^2.
\]
\end{theorem*}

\begin{proof}
\begin{align*}
\Expect{\frac{S_n}{n}} & = \Expect{\frac{\sum_{i=1}^n G_i}{n}}
         & \text{(def of $S_n$)}\\
 & = \frac{\sum_{i=1}^n \expect{G_i}}{n} 
     & \text{(linearity of expectation)}\\
 & = \frac{\sum_{i=1}^n \mu}{n}\\
 & = \frac{n\mu}{n} = \mu.
\end{align*}

\begin{align}
\Variance{\frac{S_n}{n}} & =  \paren{\frac{1}{n}}^2 \variance{S_n}
          & \mbox{(by~\eqref{a2R})}\notag\\
 & =  \frac{1}{n^2} \Variance{\sum_{i=1}^n G_i} 
          & \text{(def of $S_n$)}\notag\\
 & =  \frac{1}{n^2} \sum_{i=1}^n \variance{G_i}
        & \text{(pairwise independent additivity)}\notag\\
 & =  \frac{1}{n^2}\cdot n\sigma^2 =  \frac{\sigma^2}{n}.\label{Snu}
\end{align}

This is enough to apply \idx{Chebyshev's Theorem} and conclude:
\begin{align*}
\Pr{\abs{\frac{S_n}{n} - \mu} \geq x} & \leq \frac{\Variance{S_n/n}}{x^2}.
       & \text{(Chebyshev's bound)}\\
    & = \frac{\sigma^2/n}{x^2} & \text{(by~\eqref{Snu})}\\
    & = \frac{1}{n} \paren{\frac{\sigma}{x}}^2.
\end{align*}

\end{proof}
\fi


\endinput
